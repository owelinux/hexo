{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/matery/source/favicon.png","path":"favicon.png","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/contact.jpg","path":"medias/contact.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/gzh.jpg","path":"medias/gzh.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","path":"libs/codeBlock/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/explosion.min.js","path":"libs/others/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/fireworks.js","path":"libs/others/fireworks.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/text.js","path":"libs/others/text.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/0xbird.png","path":"medias/avatars/0xbird.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","path":"medias/avatars/ajin.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","path":"medias/avatars/antnlp.ico","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/avatar.jpg","path":"medias/avatars/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/babyq.png","path":"medias/avatars/babyq.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/bytedtrans.png","path":"medias/avatars/bytedtrans.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","path":"medias/avatars/cww97.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","path":"medias/avatars/duyupei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","path":"medias/avatars/feibar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.png","path":"medias/avatars/feibar.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/fun4go.png","path":"medias/avatars/fun4go.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","path":"medias/avatars/gsy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hael.jpg","path":"medias/avatars/hael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","path":"medias/avatars/huaji.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","path":"medias/avatars/hzwer.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","path":"medias/avatars/ids2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","path":"medias/avatars/jiejie.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","path":"medias/avatars/jingjing.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","path":"medias/avatars/jitao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","path":"medias/avatars/kewlgrl.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","path":"medias/avatars/ldy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","path":"medias/avatars/lijiaqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","path":"medias/avatars/liyangzone.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","path":"medias/avatars/liyucheng.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","path":"medias/avatars/lyn-draw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lzh.png","path":"medias/avatars/lzh.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","path":"medias/avatars/mashiro.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","path":"medias/avatars/masterx.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/michael.jpg","path":"medias/avatars/michael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","path":"medias/avatars/milyyy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","path":"medias/avatars/mizunashi.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","path":"medias/avatars/mouse.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mpy634.png","path":"medias/avatars/mpy634.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","path":"medias/avatars/myzhihu.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","path":"medias/avatars/qiandongwei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qianqian.png","path":"medias/avatars/qianqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","path":"medias/avatars/qiqiang.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/spacesac.png","path":"medias/avatars/spacesac.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","path":"medias/avatars/sunchangzhi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","path":"medias/avatars/taotao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","path":"medias/avatars/taowei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","path":"medias/avatars/tawn.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","path":"medias/avatars/xiejiadong.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","path":"medias/avatars/xuzhongyou.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/yezijie.png","path":"medias/avatars/yezijie.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","path":"medias/avatars/zhangting.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","path":"medias/avatars/zhangyi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","path":"medias/avatars/zhaokangzhe.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","path":"medias/avatars/zzw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/24.jpg","path":"medias/featureimages/24.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/25.jpg","path":"medias/featureimages/25.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/26.jpg","path":"medias/featureimages/26.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/27.jpg","path":"medias/featureimages/27.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/28.jpg","path":"medias/featureimages/28.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/cv-en.pdf","path":"medias/files/cv-en.pdf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/cv-zh.pdf","path":"medias/files/cv-zh.pdf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/then=silence.mp3","path":"medias/music/then=silence.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/两个世界.mp3","path":"medias/music/两个世界.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","path":"medias/music/avatars/daoshu.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","path":"medias/music/avatars/tiantangdemogui.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","path":"medias/music/avatars/yequ.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","path":"medias/music/avatars/yiluxiangbei.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/_data/musics.json","hash":"24e528c1cccb353daf36d10e1688430411746844","modified":1613631510207},{"_id":"source/about/index.md","hash":"62d3cd4c955fa02cc1a7d9ccb30d08827f73be2a","modified":1615258953990},{"_id":"source/404.md","hash":"d97f69ff63501de89cfd341c68e4d6ed5c8a5b3a","modified":1612836024538},{"_id":"source/_data/friends.json","hash":"27c1adda7a67bb25d01027219703f5aba4d956d5","modified":1613631540602},{"_id":"source/CNAME","hash":"01be6d84dda167c26d8375c14af3b1723459f94b","modified":1612838601026},{"_id":"source/archives/index.md","hash":"30a0e3a59be650ae34d7bb86ac7da53e21e9cf5b","modified":1612836024583},{"_id":"source/contact/index.md","hash":"d92cdc8e5ae91d6be2c7a31b378ef0c6041a9ad5","modified":1612836024584},{"_id":"source/categories/index.md","hash":"67687d3f908737f7c680f096b3e80d9412f23b0e","modified":1612836024583},{"_id":"source/_posts/2018-07-24-article7-linux-nginxlog.md","hash":"b1e9eed5c8d424b107583a2a8e0fd94608d51dfe","modified":1612839743460},{"_id":"source/_posts/2018-07-25-article8-linux-prometheus.md","hash":"83f88ba650e92520c9ab6f7154cf3236fed04b72","modified":1612836024564},{"_id":"source/_posts/2018-07-28-article10-linux-metricbeat-diskio.md","hash":"29f7f7af547c948a9c3f2f148cea26cd80dd6df3","modified":1612836024565},{"_id":"source/_posts/2018-08-07-article12-linux-srcache-nginx-module.md","hash":"f266b2615c159360b8493ada090d49850e7f61d5","modified":1612836024566},{"_id":"source/_posts/2018-07-28-article9-linux-lsof.md","hash":"fab5ac2f636004abd7625dea03a3114d6ecb7270","modified":1612836024565},{"_id":"source/_posts/2018-08-03-article11-linux-luncene.md","hash":"f3770599e72090339be3c714202278fe7bf0f72a","modified":1612836024566},{"_id":"source/_posts/2018-08-08-article13-linux-ssh-rsync-passwd.md","hash":"7502674b7e827c6d9252c91aca5a17099c18cb87","modified":1612836024567},{"_id":"source/_posts/2018-08-09-article14-linux-ansible.md","hash":"d3318941bc476f35d19fa24c444859806d388aa0","modified":1612836024567},{"_id":"source/_posts/2018-08-21-article15-linux-curl.md","hash":"890d82e8abe206f686dc5985fbbc1ba0b9ed335a","modified":1612836024567},{"_id":"source/_posts/2018-08-22-article16-linux-elk.md","hash":"195006bc7728d3fb31fa7e781a55004baa0a7f3c","modified":1612836024568},{"_id":"source/_posts/2018-08-23-article17-linux-update-es.md","hash":"ee0553f5ca5a56fda71068d5f50a7791f79b4e8b","modified":1612836024568},{"_id":"source/_posts/2018-08-23-article18-linux-es-think.md","hash":"e72e278e6e852f151517b51d8abc75de42d3138f","modified":1612836024568},{"_id":"source/_posts/2018-08-24-article19-linux-telegraf-infludb.md","hash":"9bea9ce108d7f4985098d8ea1d6600cbb1943ee2","modified":1612836024569},{"_id":"source/_posts/2018-08-28-article20-linux-git-proxy.md","hash":"4c7deeb1a66542d51a1430d15a52c19577871ce3","modified":1612836024569},{"_id":"source/_posts/2018-08-29-article21-linux-pip.md","hash":"016fe1c91189688bb1157b18b16d29201914f2f3","modified":1612836024569},{"_id":"source/_posts/2018-08-30-article22-linux-convirt.md","hash":"914bc3013cb23e70577088f522056fb1db73ba28","modified":1612836024570},{"_id":"source/_posts/2018-08-31-article23-linux-convirt-create.md","hash":"b807e432c31d8c994fe192fc97b02fab7c4485a8","modified":1612836024570},{"_id":"source/_posts/2018-08-31-article24-life-work.md","hash":"a3780589886524da1d193a1ee416ff4735ab8926","modified":1612836024571},{"_id":"source/_posts/2018-09-03-article26-linux-fastdfs-2.md","hash":"5779ccb89474b44da9fdd7dc968862bf5a89328e","modified":1612836024571},{"_id":"source/_posts/2018-09-03-article25-linux-fastdfs-1.md","hash":"3b45df667babe360cec7dba9bc9332e53172c03f","modified":1612836024571},{"_id":"source/_posts/2018-09-03-article27-linux-fastdfs-3.md","hash":"6185e5a408dcd16a3b0c5ab90ccbc249212f016a","modified":1612836024572},{"_id":"source/_posts/2018-09-03-article28-linux-fastdfs-4.md","hash":"43e3e7f193dd44effa2c779c4f29710902733a25","modified":1612836024572},{"_id":"source/_posts/2018-09-04-article29-linux-yum-mysql.md","hash":"d0ec17a5c456390be8e704c9000faf7d4b12746d","modified":1612836024573},{"_id":"source/_posts/2018-09-06-article31-linux-let-ssl.md","hash":"7ce3006edc3b6eceab30d2721c3241d84715bf6a","modified":1612836024574},{"_id":"source/_posts/2018-09-04-article30-linux-CDH.md","hash":"ca17d4663efa377adb01238d5e244c1fa5ad707d","modified":1612836024573},{"_id":"source/_posts/2018-09-10-article32-linux-1.md","hash":"071eb02efd94545e5a5c60b41345034ec05add89","modified":1612836024574},{"_id":"source/_posts/2018-09-10-article34-linux-3.md","hash":"e0a772f94254b25aa56da188b9b49a7f7c49e7ed","modified":1612836024575},{"_id":"source/_posts/2018-09-10-article33-linux-2.md","hash":"251afcdb042355f70a6811b673c677e934da113b","modified":1612836024575},{"_id":"source/_posts/2018-09-12-article35-linux-docker-01.md","hash":"1ecf89b3d84010be6e89f34938b6205cff66cc85","modified":1612836024576},{"_id":"source/_posts/2018-09-19-article36-linux-docker-02.md","hash":"dfcf401a775fb6744bdec5c2d505632a99ac44d6","modified":1612836024576},{"_id":"source/_posts/2018-09-20-article37-linux-rpmbuild.md","hash":"730dbf5f464c95f54d261d064be0d05c04351b43","modified":1612836024577},{"_id":"source/_posts/2018-11-28-article38-docker-swarm.md","hash":"d6d92baad43077356b6b07294cc29dfe4164f641","modified":1612836024577},{"_id":"source/_posts/2018-12-06-article40-linux-jira-ad.md","hash":"77c7c5588f1aaccf73a685cb8535df23f2472562","modified":1612836024578},{"_id":"source/_posts/2018-12-05-article39-linux-jira.md","hash":"0d2350b294b2c367429655eed2efe95a326705ad","modified":1612836024578},{"_id":"source/_posts/2018-12-11-article41-linux-gitlab-ad.md","hash":"70acfa58abcc02e06c6d08a52cd39f791d15a203","modified":1612836024579},{"_id":"source/_posts/2018-12-27-article43-k8s-Ingress.md","hash":"63dcc151a059c481375cb8040f4afbae3e9db2a3","modified":1612836024579},{"_id":"source/_posts/2018-12-28-article44-k8s-pvc.md","hash":"abca3ebc1688217be821b0dfb0810ba0d49f7c47","modified":1612836024579},{"_id":"source/_posts/jenkins-email.md","hash":"34cc8ee0c396c12677619b5670f4db77cc4c22ee","modified":1612836024581},{"_id":"source/_posts/k8s重启deployment.md","hash":"8683c971425e32ea796a783a69072e02d1bf9c28","modified":1612836024582},{"_id":"source/_posts/blog-jekyll.md","hash":"83487e3e80f3ebe850c07ff4919c618f5fe4960a","modified":1613813744544},{"_id":"source/_posts/k8s-cluster.md","hash":"ad449eecfef812cd5ec6ffd8a34397bc621f3b9c","modified":1612836024581},{"_id":"source/_posts/2019-01-04-article45-docker.md","hash":"d697be1669e968adf07d39507919290c786fce66","modified":1612836024580},{"_id":"source/_posts/linux-Precautions.md","hash":"0285e311f2973a2d9e03ce17be1217759adea744","modified":1613813891399},{"_id":"source/_posts/linux-lnmp.md","hash":"bec78fa7cc60e5a3bf98bb8509881a511c250102","modified":1613813983230},{"_id":"source/_posts/linux-suggest.md","hash":"2eeb402bb881ae39fa37fbd529256905266bcd27","modified":1613813855883},{"_id":"source/_posts/linux-tools.md","hash":"3a8bad12c27955b93211346d20d00f5d2c4911fc","modified":1613813944948},{"_id":"source/_posts/linux-init7.md","hash":"ae4d68868c4eae88ba9bb830d35cd37441b2f6bf","modified":1613814019614},{"_id":"source/friends/index.md","hash":"05b26c31534ee60dada392073e4c840c3b935cd6","modified":1612836024584},{"_id":"source/tags/index.md","hash":"fe3d7ecc91b81b062a6a60c06859dc24b9d704ac","modified":1612836024584},{"_id":"source/_posts/个人收藏工具.md","hash":"9c163b99448c85f121fb7c1d4f78b114d2a1fe05","modified":1613630858413},{"_id":"themes/matery/.gitignore","hash":"eaa3d84cb77d92a21b111fd1e37f53edc1ff9de0","modified":1612836024585},{"_id":"themes/matery/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1612836024585},{"_id":"themes/matery/_config.yml","hash":"e389fceb5c134c85686f60588b183101230f5ffd","modified":1615256692358},{"_id":"themes/matery/languages/default.yml","hash":"527c795b8c41fe62bf35603ffebfa6d4a7929a2c","modified":1612836024587},{"_id":"themes/matery/README_CN.md","hash":"a94324950e0299bcfcbc106cf2ca65c93e1fe843","modified":1612836024586},{"_id":"themes/matery/README.md","hash":"7ef16198a2c5ff580f006582286354caf160c7fe","modified":1612836024586},{"_id":"themes/matery/languages/zh-CN.yml","hash":"d92db4b986bb6f0d228e9a8249383103bf56342d","modified":1612836024588},{"_id":"themes/matery/layout/404.ejs","hash":"f08a0f507b36f3652520a41381f71167488405c7","modified":1612836024588},{"_id":"themes/matery/layout/about.ejs","hash":"e87752e59f021b5139b1155a264da11ab469a9aa","modified":1612836024603},{"_id":"themes/matery/layout/archive.ejs","hash":"1b5023571894404d75caffa28128fc9c49f9095d","modified":1612836024604},{"_id":"themes/matery/layout/contact.ejs","hash":"1513c5a40b7cc0b6e5854cf8c3253958bcb486cb","modified":1612836024605},{"_id":"themes/matery/layout/category.ejs","hash":"2d421e10c3b8fd2c4f725e5eaa967c4a1429c707","modified":1612836024605},{"_id":"themes/matery/layout/categories.ejs","hash":"c431e772d0f7700592228bbd9502793bdc28a893","modified":1612836024604},{"_id":"themes/matery/layout/friends.ejs","hash":"895e40a864796680fbef581e4b09f252fbdd963a","modified":1612836024605},{"_id":"themes/matery/layout/index.ejs","hash":"7fc5a6c4f0229c0be43b7d1315524c468346fbb8","modified":1612836024606},{"_id":"themes/matery/layout/tag.ejs","hash":"5cdf3a1d72f54285ee9cb826fd0e4a0449093215","modified":1612836024607},{"_id":"themes/matery/layout/tags.ejs","hash":"851c0ee599e91e7b1d657673859e8b6ff79cf50b","modified":1612836024607},{"_id":"themes/matery/layout/layout.ejs","hash":"2ba4110dc596424b1220a259c8e594da774e7f59","modified":1612836024606},{"_id":"themes/matery/layout/post.ejs","hash":"f1a35f32e5901e167ae9a750e7cb3635549cea2e","modified":1612836024606},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"cb99dc352397ec5d0765794d7b8884972e61973b","modified":1612836024589},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"ab610754bf6aea844b5ae0802ed37c73b5f1dc9f","modified":1612836024589},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"d5a7b9bb96e04c0a3485dd873748f19c50a6a04f","modified":1612836024589},{"_id":"themes/matery/layout/_partial/FROM python:3.6.7","hash":"1ed60b94863d348dcb7f6fc7b82d3f707fc465a3","modified":1613729655869},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"42dda8e67f7f09d148347887e52f18aea546df26","modified":1612836024589},{"_id":"themes/matery/source/favicon.png","hash":"1960592407fdb598c531cd36865ea197f4965608","modified":1612841957300},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"8563c66e5213d8144d0df8e7274aca174d204075","modified":1613630466502},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"a3a140e6aeeb6f289e4b821a577ef548267f3de1","modified":1612836024591},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"fd4034bca2eb3987dcf113e6477260bee97eb1e7","modified":1612836024592},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"d28b45c847d536a5eb285600d02cd0f59bc4805a","modified":1613786419403},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"890c8f04c1f4905dfceb3ea9fd6efdd040d79c01","modified":1612836024592},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"d8c40dbc8106b5bc53ceb727ad968c1d8f234261","modified":1612836024592},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"821e1af65990521c9e0288178d8e5b18c73a9cab","modified":1612836024593},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"d4042e5521ceb5f3255cd4455ac7ccd227fee6df","modified":1612836024593},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"42728561c09589f79b698eb059ab4def53ed3642","modified":1612836024594},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"3a82fcb6f31d69971cb564985842c14ac02cdca0","modified":1612836024595},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"e761f0104fbf431671bbe6bebc91ca82f737f4d2","modified":1612836024594},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"166c0b9753f3f913bd801e82ad5b268004be198d","modified":1612836024595},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"dfdeea9c59d157acb851d4bf44bf95f81787523c","modified":1612836024595},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"82cb8090cde663fa7ad67418a802997b3057e957","modified":1612836024595},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"3b42900247d5ea4ea5b68e2be44420a0d54785ad","modified":1612836024596},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"f85a222ec3f9bc27eb7978015e63a16514b38791","modified":1612836024597},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"4e73f10eacb5d00a0681cb44fe5c039cd8ab03cd","modified":1612836024597},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"73624d9db81e87ff0c12310bb873fbd0b5221021","modified":1612836024597},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"782b3f9dbdd5ff7797421f8a134eeec63efc54ae","modified":1612838975055},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"e859fe6e0259e0c123cb7ceda6e4cac836318ffc","modified":1612836024598},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"e2865b3003ec07892e9112692e7ec786ee926ae8","modified":1612836024598},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"0f2e1e27d21492cf228e786daead985b1e1dcea4","modified":1612836024598},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"c3039180ddb2eb17e724b8441e5f93e79859aef7","modified":1612836024599},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"fc50cb4bbc1f4d0e4c9f5941f1c3c74bea742db7","modified":1612836024600},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"b2b22d4fc4e46b051f67216c391f629f4ff552b5","modified":1612836024599},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"6ae58a57b83a5999d0b6a737ec868f084d208f89","modified":1612836024600},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"5284712d84bbaa4f0d88026ac3ec5a8c13e00056","modified":1612836024599},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"785cb588a31215876f6737213054ba0e8552fff0","modified":1612836024601},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"9ea672db65f1e5b8fad1ffafb1614f25adc97e63","modified":1612836024600},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"4608af6151f0e32f668c89f09343748340021478","modified":1612836024601},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"c6f713316ce75ad08ac5d1587bd8ce42e894e9ae","modified":1612836024601},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"0aaf0a111b9aa07ff37f6286eeac5506283f47f8","modified":1612836024602},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"6310903eb0e434d6f9a59ca669aab7fae38d4797","modified":1612836024602},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"bf604fe9c435f0fb9a559cac9c35772579b590e8","modified":1612836024603},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"d439d86818de179d64965d4f7f5fa56147fd9221","modified":1612836024602},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"05f5e2acace5730cdf7bed650375ad88f6b5d1b7","modified":1612836024603},{"_id":"themes/matery/source/css/gitment.css","hash":"d5ef623065d1fbc897119f7b70ccf7563e329917","modified":1612836024607},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"4e3e855767ac5a48b13af1d6a42df13d8975e03f","modified":1612836024608},{"_id":"themes/matery/source/css/my.css","hash":"37683a9f11c68903a53e2b8593ca8c095a721896","modified":1612836024609},{"_id":"themes/matery/source/js/search.js","hash":"77ecae23dd3edd8ad962c5b12954652bb2f7a1b6","modified":1612836024612},{"_id":"themes/matery/source/css/matery.css","hash":"0d345a72318fd7aadcb6fcaa6f3abac94b91001c","modified":1612836024608},{"_id":"themes/matery/source/js/matery.js","hash":"208b7806caa943c115aa0825c9c72a0781404775","modified":1612836024612},{"_id":"themes/matery/source/medias/logo.png","hash":"1960592407fdb598c531cd36865ea197f4965608","modified":1612841966038},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"5dfcbcee866e9dc564916416281885f3e320871e","modified":1612836024612},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"ded9739f803d114c9168d3351fded72b3b478b4c","modified":1612836024613},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"5a8e6d07ffa55642418ab3fd4b263aa08284b77a","modified":1612836024614},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1612836024614},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"70c0c4a9bf698747b7c058c21287ad617355e5dd","modified":1612836024615},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1612836024652},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1612836024653},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1612836024653},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1612836024654},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1612836024654},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"5d52d3b34fceb9d7e11f1beaf7ed380b4249dec4","modified":1612836024656},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"33810b2b757fc4327bc1d3b83bb5e0d3dc1fec5b","modified":1612836024655},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"a0625d8b432af8bdc820f8768d36cde439e7257c","modified":1612836024667},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"021898a16279ac2ffe75af4f902fab2a0a39f11a","modified":1612836024665},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"4e6538c8312aeeab845d361c37a8c1a0931241f0","modified":1612836024668},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"26849509f196a2d21bbfd15696e5d5153163b8f1","modified":1612836024668},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"f81cd7bfcf7aa2d043bd3e6077df42656fc44b82","modified":1612836024700},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1612836024703},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1612836024703},{"_id":"themes/matery/source/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1612836024704},{"_id":"themes/matery/source/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1612836024704},{"_id":"themes/matery/source/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1612836024705},{"_id":"themes/matery/source/libs/others/snow.js","hash":"b393f069781eef788a0ae66b2681cece8fea2851","modified":1612836024705},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1612836024706},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1612836024711},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1612836024711},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","hash":"76cb8e872472ff47a1b061c3bcff1c03f30c02b8","modified":1612836024717},{"_id":"themes/matery/source/medias/avatars/babyq.png","hash":"be5432588003e5a52c02e690622eec72b5f7346c","modified":1612836024719},{"_id":"themes/matery/source/medias/avatars/avatar.jpg","hash":"6850c3643f81caf79c8be7c454a501f0d3962e14","modified":1612836024718},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","hash":"6af987cafc55d8d031534dd5e0f722fff19f70ec","modified":1612836024720},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","hash":"343f47cb5c83cd866a1c824cbe2a112d02516d06","modified":1612836024722},{"_id":"themes/matery/source/medias/avatars/fun4go.png","hash":"0f4333973a972a629cfbabf601bc7c192b65376c","modified":1612836024725},{"_id":"themes/matery/source/medias/avatars/hael.jpg","hash":"e66ccedab38bb2e8fc45fac024e234ab8e7b9d54","modified":1612836024727},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","hash":"86be7eed2a491455ccfe3e7da46366ff477765ca","modified":1612836024727},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","hash":"53a66bb5e65d2abd5b7412edf094c1e0b1094492","modified":1612836024728},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","hash":"2c8d3ac6ab5ac6196bac83766fde975daca91c32","modified":1612836024728},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","hash":"3af0fd1029a1511bb3c0e90871e41b35e714b01f","modified":1612836024735},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","hash":"906ef214d1f2fe52a663738340ad5623f826bd82","modified":1612836024735},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","hash":"9d96b3838acfae9a23b6e290fcfafceff0419c63","modified":1612836024736},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","hash":"febab557e4c0d859ab4cc14b57d8106f5e3fccfb","modified":1612836024737},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","hash":"12055a27fa667c87d2319475968056e1a8ad0f08","modified":1612836024738},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","hash":"c9f7e83d895fa241cefd6e742f356106b35f1b89","modified":1612836024743},{"_id":"themes/matery/source/medias/avatars/michael.jpg","hash":"331a2ab20c299196f5a3089b8445fc8f55346cb6","modified":1612836024744},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","hash":"2eae273885b9859150a1f98f74b3df12ca9a207c","modified":1612836024768},{"_id":"themes/matery/source/medias/avatars/mpy634.png","hash":"30f88e09c02b37c2dc684d4ee3237e327bb23f8b","modified":1612836024769},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","hash":"081459866f922d9558a88cd4d7155d91fa730322","modified":1612836024773},{"_id":"themes/matery/source/medias/avatars/spacesac.png","hash":"ff1bdb058f1f0499312da1a082ba97d78590db1a","modified":1612836024774},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","hash":"bbe2a15fd474ab62dbd14fea72deb1113a4fb005","modified":1612836024774},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","hash":"e668254375ddd40a684ff4669c3421851bebd36e","modified":1612836024775},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","hash":"e58b03b70656aa7a27238be38dac3896d9d16f10","modified":1612836024775},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","hash":"68a1cbacbb2370912b000c9d8d2b16196c918a50","modified":1612836024776},{"_id":"themes/matery/source/medias/avatars/yezijie.png","hash":"8a53537eb69f749115e512b6da061e7f23cd04e5","modified":1612836024779},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","hash":"c8242bd13f08a9ddb97e26f216bc729b12ed9058","modified":1612836024782},{"_id":"themes/matery/source/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1612836024804},{"_id":"themes/matery/source/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1612836024968},{"_id":"themes/matery/source/medias/files/cv-en.pdf","hash":"2a62ab3797f8bc8e2e5e04c4950198525c635139","modified":1612836024988},{"_id":"themes/matery/source/medias/reward/wechat.png","hash":"61eb27bc4ec65f4f116d34740903fb5af75bf561","modified":1612836024996},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1612836024616},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1612836024672},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1612836024672},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1612836024673},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1612836024673},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1612836024697},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1612836024698},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1612836024674},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1612836024698},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1612836024698},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"7126de5cec8371e580b7b1f22512da0985cc39e5","modified":1612836024707},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1612836024707},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1612836024708},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1612836024708},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1612836024709},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1612836024710},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1612836024710},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"f8cd48e1fff82ecd54a7ce3e69de8dba7c92d113","modified":1612836024699},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","hash":"f005578ddb4d3d731838db89a708f39f18d50e60","modified":1612836024993},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","hash":"103beb9ab33434b434fa37a30aecdb29db633024","modified":1612836024993},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","hash":"01b12e3aca7385a88412c12539e1a608a78896fa","modified":1612836024995},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"5a13983930b019450e4fe01a407c64b3dd316be4","modified":1612836024668},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"82276be41d2001e820020a219b90ad5b026302d1","modified":1612836024656},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"7a551393b8360731104fdef1af36a6f3638f5855","modified":1612836024669},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"f1558f12d96a352e490166d543a8e821dd3bb2bc","modified":1612836024712},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","hash":"29475f350b989331cebd702a315f020917d06ed8","modified":1612836024717},{"_id":"themes/matery/source/medias/avatars/bytedtrans.png","hash":"ce59d69e5106f20548f4ec9b6429c8fcc787ea08","modified":1612836024720},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","hash":"6a175e2ba56a2280d40a2e654b559be41c3a0a48","modified":1612836024727},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","hash":"a52476e25bec2391674e77a889a89341fbb29791","modified":1612836024729},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","hash":"3c02ed4cf57dc37e4f4b8314bf5094833a854cb0","modified":1612836024722},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","hash":"ac2826d9c28346efeb967df01465a2c74d9041fe","modified":1612836024745},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","hash":"992e0d803160d2ae867be5eb0032d324d1cedffb","modified":1612836024770},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","hash":"5fc300701d3b4250a307ed70e3a3aa0d5395c808","modified":1612836024768},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","hash":"6873551596a4513d01898ad866c4073c68270c57","modified":1612836024771},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","hash":"1db4dfaf23cf250f222a398326562d4170d3aaa1","modified":1612836024778},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","hash":"10ee25ae3531f046a8bd3696c1cc8a16f0f25e1b","modified":1612836024780},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","hash":"f1a31f89426bd4dccdaba2170f4fc701336702e1","modified":1612836024777},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","hash":"5d385b5732644b07b937a4919abc83cb95e14513","modified":1612836024783},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"309f484b6e69e877de6a7fb847d66497d22bbd65","modified":1612836024786},{"_id":"themes/matery/source/medias/files/cv-zh.pdf","hash":"4f58778031b0a0e669e036b16639741e44fc2375","modified":1612836024989},{"_id":"themes/matery/source/medias/reward/alipay.jpg","hash":"9bade255a1918cfb3c3bcefbbbc8f163bf2e19e3","modified":1612836024996},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1612836024652},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1612836024650},{"_id":"themes/matery/source/medias/contact.jpg","hash":"7eb0906c0e2be9d96650e3bc01da0dc66167aa85","modified":1612836024804},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"f63c7c489524ccb5d95e74fcd6618116c58fb305","modified":1612836024666},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c843f0dc497314574c608ca28cc742bb041786d5","modified":1612836024703},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"2c27939768606603bee3b5e6c8a722596a667e60","modified":1612836024701},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"04c6b2782ce4610c429563110f6a20a47432fc4c","modified":1612836024714},{"_id":"themes/matery/source/medias/avatars/0xbird.png","hash":"f9d597dfcb49e1e2be06138b24028291f5638610","modified":1612836024716},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","hash":"837d5d5df4dcb086d2da114d0d85084b4ec18768","modified":1612836024740},{"_id":"themes/matery/source/medias/avatars/lzh.png","hash":"8ffcbf19d6b38b891dbe408d9a4e9513b56f247e","modified":1612836024741},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","hash":"250e911c16eeb6acb1e6214ad3e6a3d762850a8e","modified":1612836024743},{"_id":"themes/matery/source/medias/avatars/qianqian.png","hash":"fed254c4e7eb58ee22d647acb83f1d08f4508f8f","modified":1612836024772},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"d4db93afdff4ce889dd8271bcf9e80eb3c0bf866","modified":1612836024785},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"280fa1c6493d7fdccfc18bd486446bacd9afe623","modified":1612836024788},{"_id":"themes/matery/source/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1612836024822},{"_id":"themes/matery/source/medias/featureimages/22.jpg","hash":"02ec4566225102778c3837f08b24de02faf460a6","modified":1612836024881},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1612836024619},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1612836024620},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1612836024649},{"_id":"themes/matery/source/medias/gzh.jpg","hash":"2ba0d0e95e8a079f6293cc8578c17034b5e6b8cf","modified":1612836024990},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","hash":"5934b9baccebccbc2be2ead5d84ad32dd41f9559","modified":1612836024734},{"_id":"themes/matery/source/medias/avatars/feibar.png","hash":"eceaefcbbca1bf49b582eaa649d311cf4fe69dd6","modified":1612836024725},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"4fcbc9dd8ec0316e9dd5bfd0caf86f1520b10b3f","modified":1612836024802},{"_id":"themes/matery/source/medias/featureimages/14.jpg","hash":"1c1063c29f827cf52eeef7ca8dc2d7e4efa31a76","modified":1612836024824},{"_id":"themes/matery/source/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1612836024819},{"_id":"themes/matery/source/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1612836024870},{"_id":"themes/matery/source/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1612836024894},{"_id":"themes/matery/source/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1612836024926},{"_id":"themes/matery/source/medias/featureimages/23.jpg","hash":"ee598933707f8bb98ecbf36925f24e8a1c4bd2d6","modified":1612836024886},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","hash":"c9130036aac9a7ac8d62e33550a9d64896cdc364","modified":1612836024782},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"a3cfdee2120195ab36b2fdd074d5558852e69297","modified":1612836024796},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"255aaa4375da855bd80b38cfcc253de892a9d4cf","modified":1612836024794},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"6ddd1bcbb62a2d28c5be3b9acb7418849d60b2e7","modified":1612836024800},{"_id":"themes/matery/source/medias/featureimages/17.jpg","hash":"11a6de283124964370dbfaf0e74f2f1e9ac8394d","modified":1612836024858},{"_id":"themes/matery/source/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1612836024918},{"_id":"themes/matery/source/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1612836024928},{"_id":"themes/matery/source/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1612836024923},{"_id":"themes/matery/source/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1612836024975},{"_id":"themes/matery/source/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1612836024972},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","hash":"eee120fdf5ccbe86aa7d51826c4c773e76e6357f","modified":1612836024992},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","hash":"bfcab0139edb2509de984cb0a9b156879c355158","modified":1612836024731},{"_id":"themes/matery/source/medias/featureimages/18.jpg","hash":"c74ce6fa4eee122e147ec55532744f34a87ae2bf","modified":1612836024861},{"_id":"themes/matery/source/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1612836024811},{"_id":"themes/matery/source/medias/featureimages/20.jpg","hash":"84ba9cf61045de789426eeb6333910266ce29b8c","modified":1612836024874},{"_id":"themes/matery/source/medias/featureimages/16.jpg","hash":"0801e96a2f4cbd14b2ad44547e5ffbb23822e751","modified":1612836024855},{"_id":"themes/matery/source/medias/featureimages/19.jpg","hash":"2a47d1123d9c4c6255b7b4817a582d2fa9aea808","modified":1612836024866},{"_id":"themes/matery/source/medias/featureimages/21.jpg","hash":"a77810cc2224446f5d4e1a857a8d480f21e81f83","modified":1612836024879},{"_id":"themes/matery/source/medias/featureimages/24.jpg","hash":"72bc68fb0673b84ab9f863d2979396cdc268a76c","modified":1612836024891},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1612836024647},{"_id":"themes/matery/source/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1612836024817},{"_id":"themes/matery/source/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1612836024980},{"_id":"themes/matery/source/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1612836024807},{"_id":"themes/matery/source/medias/featureimages/15.jpg","hash":"aff885598033614639944c7559b4849f883e2b34","modified":1612836024853},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"8789b5e4daf0029a6c88f238f10e54d01c4fce82","modified":1612836024664},{"_id":"themes/matery/source/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1612836024987},{"_id":"themes/matery/source/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1612836024968},{"_id":"themes/matery/source/medias/music/两个世界.mp3","hash":"037156041aae0f3e99676e7c643fff71adc6b6a0","modified":1612848097807},{"_id":"themes/matery/source/medias/music/then=silence.mp3","hash":"49e35c938c2e7ad0fb4a6f31b97215681df3a3e4","modified":1612853266845},{"_id":"public/baidu_urls.txt","hash":"f8c468161564bbc23ec083a50f09382d275c5cad","modified":1615258979865},{"_id":"public/baidusitemap.xml","hash":"4416ca9f77f36cfd98fb9ed144653626fd6835dc","modified":1615258979865},{"_id":"public/atom.xml","hash":"edce374e56d24649880df258295fb69873cae26f","modified":1615258979865},{"_id":"public/search.xml","hash":"f02f410c31cc49c1748f7e2f7bfbb23bb69a7e07","modified":1615258979865},{"_id":"public/sitemap.xml","hash":"e54b56835a0357e6358720cbbc230dd9f4400402","modified":1615258979865},{"_id":"public/404.html","hash":"b96fa263dc87f22319ce9a7d25f577ba47be1ce7","modified":1615258979865},{"_id":"public/archives/index.html","hash":"52098a383dd987f3fc3b38a27f44b794e84b8dba","modified":1615258979865},{"_id":"public/about/index.html","hash":"898faa163c57b9dc71aa6e95dc338595fd67a462","modified":1615258979865},{"_id":"public/contact/index.html","hash":"2673b2648abe7a4d002cadd1f643c63292f41ca9","modified":1615258979865},{"_id":"public/friends/index.html","hash":"df5a198455a00c456cd439d52bf6092d0e612c9d","modified":1615258979865},{"_id":"public/categories/index.html","hash":"caa2e995be97bfb87d466ac87410c76f3c31487a","modified":1615258979865},{"_id":"public/tags/index.html","hash":"c28229f6128d165857d1c147d6cf00059123f363","modified":1615258979865},{"_id":"public/2021/02/18/ge-ren-shou-cang-gong-ju/index.html","hash":"0f85a29daf3f890fabe2cd5a555018c194728300","modified":1615258979865},{"_id":"public/2021/02/09/jenkins-email/index.html","hash":"8f42dfb98acad4f6eee76397e52e1f66c2543d27","modified":1615258979865},{"_id":"public/2021/02/09/k8s-cluster/index.html","hash":"d842b6b6a4b15c683a36ef3c3dfeb505b1719da2","modified":1615258979865},{"_id":"public/2021/02/09/k8s-chong-qi-deployment/index.html","hash":"e4cbdfcb4f84619a149c98960d0bd365a1a8262e","modified":1615258979865},{"_id":"public/2021/02/09/2019-01-04-article45-docker/index.html","hash":"25a71fe95563f86aaa6a3c083057c17240cdee43","modified":1615258979865},{"_id":"public/2018/12/27/2018-12-27-article43-k8s-ingress/index.html","hash":"0c7decbd98bf23715396a2bd6faacc8f3861c28c","modified":1615258979865},{"_id":"public/2018/12/27/2018-12-28-article44-k8s-pvc/index.html","hash":"9b7575501fb1ecbc77fce24210ceb7c739eee38b","modified":1615258979865},{"_id":"public/2018/12/06/2018-12-06-article40-linux-jira-ad/index.html","hash":"2ae554f6c47139a89caa44d72597518c1b762047","modified":1615258979865},{"_id":"public/2018/12/06/2018-12-11-article41-linux-gitlab-ad/index.html","hash":"7362a179bc20dcbf8dd38c50c3078f5c80ff2687","modified":1615258979865},{"_id":"public/2018/11/28/2018-11-28-article38-docker-swarm/index.html","hash":"34ee2b9d0c6d212ed4ff956046106b1a265f0134","modified":1615258979865},{"_id":"public/2018/12/05/2018-12-05-article39-linux-jira/index.html","hash":"130db5ba369c02c5e33a2dfac1f34ec42229d427","modified":1615258979865},{"_id":"public/2018/09/20/2018-09-20-article37-linux-rpmbuild/index.html","hash":"a283e7d6c00fb7d97a74f0c5dd791ff0db31b318","modified":1615258979865},{"_id":"public/2018/09/19/2018-09-19-article36-linux-docker-02/index.html","hash":"1389a403a82b8fcedaf16c8044e92681644c7d21","modified":1615258979865},{"_id":"public/2018/09/12/2018-09-12-article35-linux-docker-01/index.html","hash":"5ad1bc790dd96b69f62646893d5ac0ab07e94cde","modified":1615258979865},{"_id":"public/2018/09/10/2018-09-10-article32-linux-1/index.html","hash":"b7c9f332950bd58fe99aee825a02134c8124954c","modified":1615258979865},{"_id":"public/2018/09/10/2018-09-10-article33-linux-2/index.html","hash":"ad2af2bf6de0509d15b1ccd3eb65839317008e52","modified":1615258979865},{"_id":"public/2018/09/10/2018-09-10-article34-linux-3/index.html","hash":"ab9e297c909ec21a52c6c1acb31e69d8014fd2b8","modified":1615258979865},{"_id":"public/2018/09/06/2018-09-06-article31-linux-let-ssl/index.html","hash":"b67110a522f2eb1c0632b1ce3af966157b050cdc","modified":1615258979865},{"_id":"public/2018/09/04/2018-09-04-article29-linux-yum-mysql/index.html","hash":"21f6a9b612f9d68b58a3c31f3f574080cd08aba7","modified":1615258979865},{"_id":"public/2018/09/04/2018-09-04-article30-linux-cdh/index.html","hash":"7f9fe3334e4cde3de09df9cac3ed3da2b2531e1c","modified":1615258979865},{"_id":"public/2018/09/03/2018-09-03-article27-linux-fastdfs-3/index.html","hash":"a203bb6926a951dca5f74c2e42dcf725ee525047","modified":1615258979865},{"_id":"public/2018/09/03/2018-09-03-article28-linux-fastdfs-4/index.html","hash":"c3dcc72b91068013512d71970a5d35903893879d","modified":1615258979865},{"_id":"public/2018/09/03/2018-09-03-article26-linux-fastdfs-2/index.html","hash":"99781cbbbcfe21382026ef188d7e2a1860a1149e","modified":1615258979865},{"_id":"public/2018/09/03/2018-09-03-article25-linux-fastdfs-1/index.html","hash":"cdee5b987fb813bcb11d3473113ddb044b34a1d4","modified":1615258979865},{"_id":"public/2018/08/31/2018-08-31-article24-life-work/index.html","hash":"b2b30900bbe84d1e15fc6216b15a3fc64ee92cc4","modified":1615258979865},{"_id":"public/2018/08/31/2018-08-31-article23-linux-convirt-create/index.html","hash":"c8bd0a9e0c157f83a8ceba5c3c9ebf6f2a8eaa13","modified":1615258979865},{"_id":"public/2018/08/30/2018-08-30-article22-linux-convirt/index.html","hash":"bbb931f9c1efaa1ba10aece6289985f84598f29f","modified":1615258979865},{"_id":"public/2018/08/29/2018-08-29-article21-linux-pip/index.html","hash":"1a671a96a7e7efe02ac4177b4f9c6ca1dceae015","modified":1615258979865},{"_id":"public/2018/08/28/2018-08-28-article20-linux-git-proxy/index.html","hash":"ae28e0bef8c8ba1e1814a1bb7b27d8ada8ed7b8a","modified":1615258979865},{"_id":"public/2018/08/24/2018-08-24-article19-linux-telegraf-infludb/index.html","hash":"38b3b82b7a9a129da3d83eabb75e83bfebb961aa","modified":1615258979865},{"_id":"public/2018/08/23/2018-08-23-article18-linux-es-think/index.html","hash":"0a056f11934d542042f6504f64a360ce0650bcbd","modified":1615258979865},{"_id":"public/2018/08/23/2018-08-23-article17-linux-update-es/index.html","hash":"2b69b5f376152c298f99a1d1a1df6e7fd45c116d","modified":1615258979865},{"_id":"public/2018/08/22/2018-08-22-article16-linux-elk/index.html","hash":"558962e4469494abea6071b065f72558c3aa906b","modified":1615258979865},{"_id":"public/2018/08/21/2018-08-21-article15-linux-curl/index.html","hash":"5a4ff86d4ddc9e3915a52ae68d919d183454755b","modified":1615258979865},{"_id":"public/2018/08/08/2018-08-09-article14-linux-ansible/index.html","hash":"ab188b3af1ffc7cb98d2e6e5879738a5a546e6a4","modified":1615258979865},{"_id":"public/2018/08/08/2018-08-08-article13-linux-ssh-rsync-passwd/index.html","hash":"847e319fe92a146268227166c5c822c552a559c0","modified":1615258979865},{"_id":"public/2018/08/07/2018-08-07-article12-linux-srcache-nginx-module/index.html","hash":"36070474b20de060be449d28a7124dd713be5a39","modified":1615258979865},{"_id":"public/2018/08/03/2018-08-03-article11-linux-luncene/index.html","hash":"14cc1c3e5928e24dcbb0a9566056c3903fcbbd3b","modified":1615258979865},{"_id":"public/2018/07/30/2018-07-28-article10-linux-metricbeat-diskio/index.html","hash":"95d99a7fd62529027f3793c6cc99626b6ebdbaf3","modified":1615258979865},{"_id":"public/2018/07/28/2018-07-28-article9-linux-lsof/index.html","hash":"64db01142777717feb5e0abf0dfebb849bae28f2","modified":1615258979865},{"_id":"public/2018/07/25/2018-07-25-article8-linux-prometheus/index.html","hash":"e549cb5fa7982f9077eb2812701886883ab351e8","modified":1615258979865},{"_id":"public/2018/07/24/2018-07-24-article7-linux-nginxlog/index.html","hash":"f5790a30b9b1baa2d38fbc2d6130f9b99b60b498","modified":1615258979865},{"_id":"public/2018/07/19/linux-tools/index.html","hash":"2dc8d9cab85da212bbceabfe581e7adef1a98d1a","modified":1615258979865},{"_id":"public/2018/07/18/linux-init7/index.html","hash":"fe1119654bfff41c64031dbeb7916f6110f35558","modified":1615258979865},{"_id":"public/2018/07/17/linux-precautions/index.html","hash":"fa5736bc7d4dffa0f715dce9010a8cc643d3c953","modified":1615258979865},{"_id":"public/2018/07/16/linux-lnmp/index.html","hash":"638b7a05d58cf1303ce245fec48381b2e89945d4","modified":1615258979865},{"_id":"public/2018/07/16/linux-suggest/index.html","hash":"12c19ab7f09a3fc93b1cabc3d9feb326cb29261d","modified":1615258979865},{"_id":"public/2018/07/14/blog-jekyll/index.html","hash":"6c178f791e85e4e2b210e28269f027dd2be76cd6","modified":1615258979865},{"_id":"public/archives/page/2/index.html","hash":"ab440a60f267a3e7f5d875b2fd3faadc4ef52f41","modified":1615258979865},{"_id":"public/archives/page/3/index.html","hash":"47cdf045d2850bc24b6289caef681f5f0aa1bd93","modified":1615258979865},{"_id":"public/archives/page/4/index.html","hash":"b509f6b2579d86b6dd46c3398236d05a49229451","modified":1615258979865},{"_id":"public/archives/2018/index.html","hash":"3d7d2ffa2a7dd719bec2757fcca6fa6e117dedd9","modified":1615258979865},{"_id":"public/archives/2018/page/2/index.html","hash":"982492899774a13862a96a1484512603b893ae85","modified":1615258979865},{"_id":"public/archives/2018/page/3/index.html","hash":"a8c5ad98075a1cf2ea78114cf2c9380f918cba91","modified":1615258979865},{"_id":"public/archives/2018/page/4/index.html","hash":"33dcb487c389aab156a26e9a7c707ada7d060dc7","modified":1615258979865},{"_id":"public/archives/2018/07/index.html","hash":"e69b852764efd4e4bd2649532cc55d5372fdbf75","modified":1615258979865},{"_id":"public/archives/2018/08/index.html","hash":"fff8cdf657903f4cc21d4abfb8257315ae59fc70","modified":1615258979865},{"_id":"public/archives/2018/08/page/2/index.html","hash":"73058d56a5d0a678fa91af4ccf54931c80fd6dfc","modified":1615258979865},{"_id":"public/archives/2018/09/index.html","hash":"89f55c37a2dce979f7b381aeffcdd61171934157","modified":1615258979865},{"_id":"public/archives/2018/09/page/2/index.html","hash":"2f88b6917153e736d971d95e4e5996bc56ca5678","modified":1615258979865},{"_id":"public/archives/2018/11/index.html","hash":"3f08f6298dd5a6a6d74d4f55c04f3983b2c3b3e0","modified":1615258979865},{"_id":"public/archives/2018/12/index.html","hash":"98630fb012bf290097893fc81ea1584e6d3f3b4f","modified":1615258979865},{"_id":"public/archives/2021/index.html","hash":"524f132ad55c59392ec740cda12a78940954cd2d","modified":1615258979865},{"_id":"public/archives/2021/02/index.html","hash":"55d20028d7d6951ce1be3be3a9b1771d3cad09f6","modified":1615258979865},{"_id":"public/categories/linux运维/index.html","hash":"2e8848dd446c34d343f94dc5a11e0c7f6b36dd0d","modified":1615258979865},{"_id":"public/categories/linux/index.html","hash":"b91d3a66ef60f88cb4f1aef9293edde5818a6882","modified":1615258979865},{"_id":"public/categories/linux/page/2/index.html","hash":"3b07fe1fc3ca544be4816a9c2c1b1b406fcdb146","modified":1615258979865},{"_id":"public/categories/linux/page/3/index.html","hash":"a712f230f12c3a504a5de10f77f3fdfc7f7ce2a8","modified":1615258979865},{"_id":"public/categories/linux/page/4/index.html","hash":"4b123d11d15274ca34941e3f018d89e754755d1e","modified":1615258979865},{"_id":"public/categories/生活/index.html","hash":"c54a9a47d9f77430de996cb706403016acc5e0a7","modified":1615258979865},{"_id":"public/categories/linux-容器与虚拟化/index.html","hash":"20c4ba030ab9bbcc30fdfab6038bfa1d9511e458","modified":1615258979865},{"_id":"public/categories/随笔/index.html","hash":"83d707dfb3df5f6c7d9f2b622fa31f77538ff21d","modified":1615258979865},{"_id":"public/index.html","hash":"fb1bbb65329d23889488ae548511fe2682df136a","modified":1615258979865},{"_id":"public/page/2/index.html","hash":"39c54ef6e1672765547c844769dee105f1e56a06","modified":1615258979865},{"_id":"public/page/3/index.html","hash":"c458632c37864117af0ffe4b16a0b4e6046c5c7f","modified":1615258979865},{"_id":"public/page/4/index.html","hash":"afd44c59a61bc69a5fcd35e71e21810ded91d53a","modified":1615258979865},{"_id":"public/tags/日志分析/index.html","hash":"6113ec0252f45e221578e7dbf5caf1206b769067","modified":1615258979865},{"_id":"public/tags/nginx/index.html","hash":"64f3d1a205416ee321e3b8756f7989057038a062","modified":1615258979865},{"_id":"public/tags/prometheus-snmp-监控/index.html","hash":"b20eabc23adf256b558a3894a1de7e365e4a0168","modified":1615258979865},{"_id":"public/tags/linux-监控-metricbeat/index.html","hash":"3063b93fe25ea77c67b8efff6610da93944b3fb2","modified":1615258979865},{"_id":"public/tags/linux/index.html","hash":"1567d589ddf3f7118ca1b635005e72ed99b429a6","modified":1615258979865},{"_id":"public/tags/linux/page/2/index.html","hash":"f2f7287391bf2997ad621d5bbb93de5e8737ea0b","modified":1615258979865},{"_id":"public/tags/lucene-ELK-kibana/index.html","hash":"cb1300677af9db2c18f555fcecc7c6e5c1539db1","modified":1615258979865},{"_id":"public/tags/linux-ssh/index.html","hash":"81eb6c8258301e07c380a31c8772620cd5a01a41","modified":1615258979865},{"_id":"public/tags/nginx-pika-cache/index.html","hash":"b4a58f9bba61c6f075e49840ec921ae94e95f745","modified":1615258979865},{"_id":"public/tags/linux-ansible-自动化/index.html","hash":"c42a922236eb7494f0371103b2ccccf5c89d811c","modified":1615258979865},{"_id":"public/tags/linux-ELK/index.html","hash":"2c0fade5fa398d2368b2032b037819a815960c68","modified":1615258979865},{"_id":"public/tags/linux-telegraf-infludb-granfan/index.html","hash":"48911ada81d46dd0ec398530a5e06b920384fa1b","modified":1615258979865},{"_id":"public/tags/linux-git/index.html","hash":"14d46a711b7e2905d90b6755d221f34942760c74","modified":1615258979865},{"_id":"public/tags/linux-convirt/index.html","hash":"ce8791c7f129fdc6bc0aab08287f68b3fd7ad6a7","modified":1615258979865},{"_id":"public/tags/生活/index.html","hash":"1b00cc91f9c01b5a06995ada3643b09e343bac1c","modified":1615258979865},{"_id":"public/tags/fastdfs/index.html","hash":"e38db00c320e0ae7d5132c413e3bb25b7710a741","modified":1615258979865},{"_id":"public/tags/mysql/index.html","hash":"8bad2f768579d8f0c29bcee308fb2bbb459facac","modified":1615258979865},{"_id":"public/tags/CDH/index.html","hash":"7ec33b6ff6afbd9e2111f8467bc572bde54da195","modified":1615258979865},{"_id":"public/tags/https/index.html","hash":"519405b1d983fda8d673158f321a6869d904613c","modified":1615258979865},{"_id":"public/tags/linux-docker/index.html","hash":"427483557eb971e37fb0d302eadcd148377e6f33","modified":1615258979865},{"_id":"public/tags/博客/index.html","hash":"1272ae6a30e6876bd21b7487834cb92f9c637e9f","modified":1615258979865},{"_id":"public/tags/系统调优/index.html","hash":"86dd45d91c3186557ad8a667ebb920651e14913c","modified":1615258979865},{"_id":"public/tags/学习方法/index.html","hash":"5474f0f0c83291d5774ffb6a860d5237c70b9ca1","modified":1615258979865},{"_id":"public/tags/lnmp/index.html","hash":"935d342b03f47dabbb8e1a1dba0de907b529e19d","modified":1615258979865},{"_id":"public/tags/运维工具/index.html","hash":"6fc44ea34c3904fb138e9f6e6ba7a106aa8dbb03","modified":1615258979865},{"_id":"public/CNAME","hash":"01be6d84dda167c26d8375c14af3b1723459f94b","modified":1615258979865},{"_id":"public/favicon.png","hash":"1960592407fdb598c531cd36865ea197f4965608","modified":1615258979865},{"_id":"public/medias/logo.png","hash":"1960592407fdb598c531cd36865ea197f4965608","modified":1615258979865},{"_id":"public/medias/avatars/ajin.jpg","hash":"76cb8e872472ff47a1b061c3bcff1c03f30c02b8","modified":1615258979865},{"_id":"public/medias/avatars/avatar.jpg","hash":"6850c3643f81caf79c8be7c454a501f0d3962e14","modified":1615258979865},{"_id":"public/medias/avatars/babyq.png","hash":"be5432588003e5a52c02e690622eec72b5f7346c","modified":1615258979865},{"_id":"public/medias/avatars/cww97.jpg","hash":"6af987cafc55d8d031534dd5e0f722fff19f70ec","modified":1615258979865},{"_id":"public/medias/avatars/feibar.jpg","hash":"343f47cb5c83cd866a1c824cbe2a112d02516d06","modified":1615258979865},{"_id":"public/medias/avatars/fun4go.png","hash":"0f4333973a972a629cfbabf601bc7c192b65376c","modified":1615258979865},{"_id":"public/medias/avatars/hael.jpg","hash":"e66ccedab38bb2e8fc45fac024e234ab8e7b9d54","modified":1615258979865},{"_id":"public/medias/avatars/huaji.jpg","hash":"86be7eed2a491455ccfe3e7da46366ff477765ca","modified":1615258979865},{"_id":"public/medias/avatars/hzwer.jpg","hash":"53a66bb5e65d2abd5b7412edf094c1e0b1094492","modified":1615258979865},{"_id":"public/medias/avatars/ids2.jpg","hash":"2c8d3ac6ab5ac6196bac83766fde975daca91c32","modified":1615258979865},{"_id":"public/medias/avatars/kewlgrl.jpg","hash":"3af0fd1029a1511bb3c0e90871e41b35e714b01f","modified":1615258979865},{"_id":"public/medias/avatars/ldy.jpg","hash":"906ef214d1f2fe52a663738340ad5623f826bd82","modified":1615258979865},{"_id":"public/medias/avatars/lijiaqian.png","hash":"9d96b3838acfae9a23b6e290fcfafceff0419c63","modified":1615258979865},{"_id":"public/medias/avatars/liyangzone.jpg","hash":"febab557e4c0d859ab4cc14b57d8106f5e3fccfb","modified":1615258979865},{"_id":"public/medias/avatars/liyucheng.jpg","hash":"12055a27fa667c87d2319475968056e1a8ad0f08","modified":1615258979865},{"_id":"public/medias/avatars/masterx.jpg","hash":"c9f7e83d895fa241cefd6e742f356106b35f1b89","modified":1615258979865},{"_id":"public/medias/avatars/michael.jpg","hash":"331a2ab20c299196f5a3089b8445fc8f55346cb6","modified":1615258979865},{"_id":"public/medias/avatars/mouse.jpg","hash":"2eae273885b9859150a1f98f74b3df12ca9a207c","modified":1615258979865},{"_id":"public/medias/avatars/mpy634.png","hash":"30f88e09c02b37c2dc684d4ee3237e327bb23f8b","modified":1615258979865},{"_id":"public/medias/avatars/qiqiang.jpg","hash":"081459866f922d9558a88cd4d7155d91fa730322","modified":1615258979865},{"_id":"public/medias/avatars/sunchangzhi.jpg","hash":"bbe2a15fd474ab62dbd14fea72deb1113a4fb005","modified":1615258979865},{"_id":"public/medias/avatars/spacesac.png","hash":"ff1bdb058f1f0499312da1a082ba97d78590db1a","modified":1615258979865},{"_id":"public/medias/avatars/taotao.jpg","hash":"e668254375ddd40a684ff4669c3421851bebd36e","modified":1615258979865},{"_id":"public/medias/avatars/taowei.jpg","hash":"e58b03b70656aa7a27238be38dac3896d9d16f10","modified":1615258979865},{"_id":"public/medias/avatars/tawn.jpg","hash":"68a1cbacbb2370912b000c9d8d2b16196c918a50","modified":1615258979865},{"_id":"public/medias/avatars/yezijie.png","hash":"8a53537eb69f749115e512b6da061e7f23cd04e5","modified":1615258979865},{"_id":"public/medias/avatars/zhaokangzhe.jpg","hash":"c8242bd13f08a9ddb97e26f216bc729b12ed9058","modified":1615258979865},{"_id":"public/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1615258979865},{"_id":"public/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1615258979865},{"_id":"public/medias/files/cv-en.pdf","hash":"2a62ab3797f8bc8e2e5e04c4950198525c635139","modified":1615258979865},{"_id":"public/medias/reward/wechat.png","hash":"61eb27bc4ec65f4f116d34740903fb5af75bf561","modified":1615258979865},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1615258979865},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1615258979865},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1615258979865},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1615258979865},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1615258979865},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1615258979865},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1615258979865},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1615258979865},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1615258979865},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1615258979865},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1615258979865},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1615258979865},{"_id":"public/medias/music/avatars/tiantangdemogui.jpg","hash":"f005578ddb4d3d731838db89a708f39f18d50e60","modified":1615258979865},{"_id":"public/medias/music/avatars/yequ.jpg","hash":"103beb9ab33434b434fa37a30aecdb29db633024","modified":1615258979865},{"_id":"public/medias/music/avatars/yiluxiangbei.jpg","hash":"01b12e3aca7385a88412c12539e1a608a78896fa","modified":1615258979865},{"_id":"public/css/prism-tomorrow.css","hash":"7efd268869bf07673639975ec764c9bdffd0fb04","modified":1615258979865},{"_id":"public/css/prism-line-numbers.css","hash":"e0db113a99e4a09d2161a539b1652d96e4a22fac","modified":1615258979865},{"_id":"public/medias/avatars/antnlp.ico","hash":"29475f350b989331cebd702a315f020917d06ed8","modified":1615258979865},{"_id":"public/medias/avatars/bytedtrans.png","hash":"ce59d69e5106f20548f4ec9b6429c8fcc787ea08","modified":1615258979865},{"_id":"public/medias/avatars/duyupei.jpg","hash":"3c02ed4cf57dc37e4f4b8314bf5094833a854cb0","modified":1615258979865},{"_id":"public/medias/avatars/gsy.jpg","hash":"6a175e2ba56a2280d40a2e654b559be41c3a0a48","modified":1615258979865},{"_id":"public/medias/avatars/jiejie.jpg","hash":"a52476e25bec2391674e77a889a89341fbb29791","modified":1615258979865},{"_id":"public/medias/avatars/milyyy.jpg","hash":"ac2826d9c28346efeb967df01465a2c74d9041fe","modified":1615258979865},{"_id":"public/medias/avatars/mizunashi.png","hash":"5fc300701d3b4250a307ed70e3a3aa0d5395c808","modified":1615258979865},{"_id":"public/medias/avatars/myzhihu.png","hash":"992e0d803160d2ae867be5eb0032d324d1cedffb","modified":1615258979865},{"_id":"public/medias/avatars/qiandongwei.jpg","hash":"6873551596a4513d01898ad866c4073c68270c57","modified":1615258979865},{"_id":"public/medias/avatars/xiejiadong.jpg","hash":"f1a31f89426bd4dccdaba2170f4fc701336702e1","modified":1615258979865},{"_id":"public/medias/avatars/xuzhongyou.jpg","hash":"1db4dfaf23cf250f222a398326562d4170d3aaa1","modified":1615258979865},{"_id":"public/medias/avatars/zhangting.jpg","hash":"10ee25ae3531f046a8bd3696c1cc8a16f0f25e1b","modified":1615258979865},{"_id":"public/medias/avatars/zzw.jpg","hash":"5d385b5732644b07b937a4919abc83cb95e14513","modified":1615258979865},{"_id":"public/medias/banner/1.jpg","hash":"309f484b6e69e877de6a7fb847d66497d22bbd65","modified":1615258979865},{"_id":"public/medias/files/cv-zh.pdf","hash":"4f58778031b0a0e669e036b16639741e44fc2375","modified":1615258979865},{"_id":"public/medias/reward/alipay.jpg","hash":"9bade255a1918cfb3c3bcefbbbc8f163bf2e19e3","modified":1615258979865},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1615258979865},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1615258979865},{"_id":"public/medias/contact.jpg","hash":"7eb0906c0e2be9d96650e3bc01da0dc66167aa85","modified":1615258979865},{"_id":"public/medias/avatars/0xbird.png","hash":"f9d597dfcb49e1e2be06138b24028291f5638610","modified":1615258979865},{"_id":"public/medias/avatars/lyn-draw.jpg","hash":"837d5d5df4dcb086d2da114d0d85084b4ec18768","modified":1615258979865},{"_id":"public/medias/avatars/mashiro.jpg","hash":"250e911c16eeb6acb1e6214ad3e6a3d762850a8e","modified":1615258979865},{"_id":"public/medias/avatars/qianqian.png","hash":"fed254c4e7eb58ee22d647acb83f1d08f4508f8f","modified":1615258979865},{"_id":"public/medias/banner/2.jpg","hash":"280fa1c6493d7fdccfc18bd486446bacd9afe623","modified":1615258979865},{"_id":"public/medias/banner/6.jpg","hash":"4fcbc9dd8ec0316e9dd5bfd0caf86f1520b10b3f","modified":1615258979865},{"_id":"public/medias/featureimages/22.jpg","hash":"02ec4566225102778c3837f08b24de02faf460a6","modified":1615258979865},{"_id":"public/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1615258979865},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1615258979865},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1615258979865},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1615258979865},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1615258979865},{"_id":"public/css/my.css","hash":"497e50351f7838f8546cac76850a42e7e380a110","modified":1615258979865},{"_id":"public/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1615258979865},{"_id":"public/js/matery.js","hash":"92f07106944f5ef7cd72e84bb3534513d00eebe1","modified":1615258979865},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1615258979865},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1615258979865},{"_id":"public/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1615258979865},{"_id":"public/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1615258979865},{"_id":"public/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1615258979865},{"_id":"public/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1615258979865},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1615258979865},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1615258979865},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1615258979865},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1615258979865},{"_id":"public/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1615258979865},{"_id":"public/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1615258979865},{"_id":"public/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1615258979865},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1615258979865},{"_id":"public/libs/others/snow.js","hash":"7f3b1ad2f64d4473210a2c3218893649c73c980e","modified":1615258979865},{"_id":"public/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1615258979865},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1615258979865},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1615258979865},{"_id":"public/medias/gzh.jpg","hash":"2ba0d0e95e8a079f6293cc8578c17034b5e6b8cf","modified":1615258979865},{"_id":"public/medias/avatars/jitao.jpg","hash":"5934b9baccebccbc2be2ead5d84ad32dd41f9559","modified":1615258979865},{"_id":"public/medias/avatars/lzh.png","hash":"8ffcbf19d6b38b891dbe408d9a4e9513b56f247e","modified":1615258979865},{"_id":"public/medias/banner/0.jpg","hash":"d4db93afdff4ce889dd8271bcf9e80eb3c0bf866","modified":1615258979865},{"_id":"public/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1615258979865},{"_id":"public/medias/featureimages/14.jpg","hash":"1c1063c29f827cf52eeef7ca8dc2d7e4efa31a76","modified":1615258979865},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1615258979865},{"_id":"public/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1615258979865},{"_id":"public/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1615258979865},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1615258979865},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1615258979865},{"_id":"public/libs/awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1615258979865},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1615258979865},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1615258979865},{"_id":"public/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1615258979865},{"_id":"public/medias/avatars/feibar.png","hash":"eceaefcbbca1bf49b582eaa649d311cf4fe69dd6","modified":1615258979865},{"_id":"public/medias/avatars/zhangyi.jpg","hash":"c9130036aac9a7ac8d62e33550a9d64896cdc364","modified":1615258979865},{"_id":"public/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1615258979865},{"_id":"public/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1615258979865},{"_id":"public/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1615258979865},{"_id":"public/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1615258979865},{"_id":"public/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1615258979865},{"_id":"public/medias/music/avatars/daoshu.jpg","hash":"eee120fdf5ccbe86aa7d51826c4c773e76e6357f","modified":1615258979865},{"_id":"public/css/matery.css","hash":"caa63c2c7908e45ebbbea0fbdc72d09b7b6d5b76","modified":1615258979865},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1615258979865},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1615258979865},{"_id":"public/medias/avatars/jingjing.jpg","hash":"bfcab0139edb2509de984cb0a9b156879c355158","modified":1615258979865},{"_id":"public/medias/banner/4.jpg","hash":"a3cfdee2120195ab36b2fdd074d5558852e69297","modified":1615258979865},{"_id":"public/medias/featureimages/17.jpg","hash":"11a6de283124964370dbfaf0e74f2f1e9ac8394d","modified":1615258979865},{"_id":"public/medias/featureimages/23.jpg","hash":"ee598933707f8bb98ecbf36925f24e8a1c4bd2d6","modified":1615258979865},{"_id":"public/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1615258979865},{"_id":"public/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1615258979865},{"_id":"public/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1615258979865},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1615258979865},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1615258979865},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1615258979865},{"_id":"public/medias/featureimages/18.jpg","hash":"c74ce6fa4eee122e147ec55532744f34a87ae2bf","modified":1615258979865},{"_id":"public/medias/featureimages/21.jpg","hash":"a77810cc2224446f5d4e1a857a8d480f21e81f83","modified":1615258979865},{"_id":"public/medias/featureimages/24.jpg","hash":"72bc68fb0673b84ab9f863d2979396cdc268a76c","modified":1615258979865},{"_id":"public/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1615258979865},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1615258979865},{"_id":"public/libs/valine/Valine.min.js","hash":"4e34802ccbb59f1daa58a62241ff57f923e50600","modified":1615258979865},{"_id":"public/medias/banner/3.jpg","hash":"255aaa4375da855bd80b38cfcc253de892a9d4cf","modified":1615258979865},{"_id":"public/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1615258979865},{"_id":"public/medias/featureimages/16.jpg","hash":"0801e96a2f4cbd14b2ad44547e5ffbb23822e751","modified":1615258979865},{"_id":"public/medias/featureimages/20.jpg","hash":"84ba9cf61045de789426eeb6333910266ce29b8c","modified":1615258979865},{"_id":"public/medias/featureimages/19.jpg","hash":"2a47d1123d9c4c6255b7b4817a582d2fa9aea808","modified":1615258979865},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1615258979865},{"_id":"public/libs/jquery/jquery-2.2.0.min.js","hash":"5d7e5bbfa540f0e53bd599e4305e1a4e815b5dd1","modified":1615258979865},{"_id":"public/medias/banner/5.jpg","hash":"6ddd1bcbb62a2d28c5be3b9acb7418849d60b2e7","modified":1615258979865},{"_id":"public/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1615258979865},{"_id":"public/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1615258979865},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1615258979865},{"_id":"public/libs/materialize/materialize.min.css","hash":"4d46df5f22cbc24eefa76228c7ee308dc3585594","modified":1615258979865},{"_id":"public/libs/valine/av-min.js","hash":"2577e72b52b736d99649f9e95be8976d58563333","modified":1615258979865},{"_id":"public/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1615258979865},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"28bdb33c9eb609c2f30d431df1a4cf8ca70bf841","modified":1615258979865},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1615258979865},{"_id":"public/medias/featureimages/15.jpg","hash":"aff885598033614639944c7559b4849f883e2b34","modified":1615258979865},{"_id":"public/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1615258979865},{"_id":"public/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1615258979865},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1615258979865},{"_id":"public/medias/music/两个世界.mp3","hash":"037156041aae0f3e99676e7c643fff71adc6b6a0","modified":1615258979865},{"_id":"public/medias/music/then=silence.mp3","hash":"49e35c938c2e7ad0fb4a6f31b97215681df3a3e4","modified":1615258979865}],"Category":[{"name":"linux运维","_id":"ckm1fhpzj0004yc977scudire"},{"name":"linux","_id":"ckm1fhpzq000cyc974xl33cki"},{"name":"生活","_id":"ckm1fhq0f001nyc97094cel4u"},{"name":"linux 容器与虚拟化","_id":"ckm1fhq0t002myc97hxhwbr1s"},{"name":"随笔","_id":"ckm1fhq1v004byc978uke14fl"}],"Data":[{"_id":"friends","data":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]},{"_id":"musics","data":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}],"Page":[{"title":"404","date":"2019-07-19T08:41:10.000Z","type":"404","layout":"404","description":"你来到了没有知识的荒原 :(","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"你来到了没有知识的荒原 :(\"\n---\n","updated":"2021-02-09T02:00:24.538Z","path":"404.html","comments":1,"_id":"ckm1fhpzb0000yc97fsj01pmo","content":"","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"archives","date":"2019-07-19T08:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2021-02-09T02:00:24.583Z","path":"archives/index.html","comments":1,"_id":"ckm1fhpzh0002yc974mwehikz","content":"","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"about","date":"2019-07-19T08:41:10.000Z","type":"about","layout":"about","mathjax":true,"_content":"\n\n## CV\n[中文版](/medias/files/cv-zh.pdf)\n[English Version](/medias/files/cv-en.pdf)\n\n## 教育背景\n* <b>本科 华东科技大学文华学院 通信工程</b>\n2012/09 - 2016/06\n\n* <b>武汉誉天教育 受邀进修学习 国际知名认证和实战技能培训</b>\n2015/09 - 2015/12\n## 研究方向\n主要研究**成分句法分析、依存句法分析、机器翻译**等方向，\n对**序列标注、语言模型、实体关系抽取、迁移学习**等方向也感兴趣。\n\n## 工作经历\n* <b>深圳明源云科技有限公司 容器平台-运维工程师（T3.2）</b>\n2018/11 - 至今\n\n  负责容器平台基础建设（ci/cd、chart业务模版等）\n\n  负责落地大型数据平台组件建设（flink/spark on k8s 、cacal、dremio等）\n\n  负责企业监控系统建设及维护（prometheus-operator、日志监控、thanos等）\n\n  ......\n\n* <b>土巴兔 高级运维工程师）</b>\n2018/03 - 2018/11\n\n  负责千万级pv流量监控系统维护\n\n  负责\"718装修节\"高可用系统的构建及维护（缓存系统pika、nginx、CDN、lua脚本等）\n\n  ......\n\n* <b>深圳蓝贝 运维工程师）</b>\n2016/06 - 2018/03\n\n  负责海外业务架构设计与落地（lnmp、proxy、lvs等）\n\n  负责风控大数据+账单系统维护及优化（hadoop、spark、kafka、ES等方向）\n\n  负责企业大型监控方案落地与实施（zabbix、grafana、telegraf、elk等）\n\n  推动容器平台k8s建设与落地（k8s 1.12）\n\n  ......\n## 联系方式\n* <b>电子邮箱</b>\nowelinux@gmail.com\n* <b>微信</b>\nlovek8s\n\n![](/medias/contact.jpg)","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-07-19 16:41:10\ntype: \"about\"\nlayout: \"about\"\nmathjax: true\n---\n\n\n## CV\n[中文版](/medias/files/cv-zh.pdf)\n[English Version](/medias/files/cv-en.pdf)\n\n## 教育背景\n* <b>本科 华东科技大学文华学院 通信工程</b>\n2012/09 - 2016/06\n\n* <b>武汉誉天教育 受邀进修学习 国际知名认证和实战技能培训</b>\n2015/09 - 2015/12\n## 研究方向\n主要研究**成分句法分析、依存句法分析、机器翻译**等方向，\n对**序列标注、语言模型、实体关系抽取、迁移学习**等方向也感兴趣。\n\n## 工作经历\n* <b>深圳明源云科技有限公司 容器平台-运维工程师（T3.2）</b>\n2018/11 - 至今\n\n  负责容器平台基础建设（ci/cd、chart业务模版等）\n\n  负责落地大型数据平台组件建设（flink/spark on k8s 、cacal、dremio等）\n\n  负责企业监控系统建设及维护（prometheus-operator、日志监控、thanos等）\n\n  ......\n\n* <b>土巴兔 高级运维工程师）</b>\n2018/03 - 2018/11\n\n  负责千万级pv流量监控系统维护\n\n  负责\"718装修节\"高可用系统的构建及维护（缓存系统pika、nginx、CDN、lua脚本等）\n\n  ......\n\n* <b>深圳蓝贝 运维工程师）</b>\n2016/06 - 2018/03\n\n  负责海外业务架构设计与落地（lnmp、proxy、lvs等）\n\n  负责风控大数据+账单系统维护及优化（hadoop、spark、kafka、ES等方向）\n\n  负责企业大型监控方案落地与实施（zabbix、grafana、telegraf、elk等）\n\n  推动容器平台k8s建设与落地（k8s 1.12）\n\n  ......\n## 联系方式\n* <b>电子邮箱</b>\nowelinux@gmail.com\n* <b>微信</b>\nlovek8s\n\n![](/medias/contact.jpg)","updated":"2021-03-09T03:02:33.990Z","path":"about/index.html","comments":1,"_id":"ckm1fhpzl0006yc979dbn4roi","content":"<h2 id=\"CV\"><a href=\"#CV\" class=\"headerlink\" title=\"CV\"></a>CV</h2><p><a href=\"/medias/files/cv-zh.pdf\">中文版</a><br><a href=\"/medias/files/cv-en.pdf\">English Version</a></p>\n<h2 id=\"教育背景\"><a href=\"#教育背景\" class=\"headerlink\" title=\"教育背景\"></a>教育背景</h2><ul>\n<li><p><b>本科 华东科技大学文华学院 通信工程</b><br>2012/09 - 2016/06</p>\n</li>\n<li><p><b>武汉誉天教育 受邀进修学习 国际知名认证和实战技能培训</b><br>2015/09 - 2015/12</p>\n<h2 id=\"研究方向\"><a href=\"#研究方向\" class=\"headerlink\" title=\"研究方向\"></a>研究方向</h2><p>主要研究<strong>成分句法分析、依存句法分析、机器翻译</strong>等方向，<br>对<strong>序列标注、语言模型、实体关系抽取、迁移学习</strong>等方向也感兴趣。</p>\n</li>\n</ul>\n<h2 id=\"工作经历\"><a href=\"#工作经历\" class=\"headerlink\" title=\"工作经历\"></a>工作经历</h2><ul>\n<li><p><b>深圳明源云科技有限公司 容器平台-运维工程师（T3.2）</b><br>2018/11 - 至今</p>\n<p>负责容器平台基础建设（ci/cd、chart业务模版等）</p>\n<p>负责落地大型数据平台组件建设（flink/spark on k8s 、cacal、dremio等）</p>\n<p>负责企业监控系统建设及维护（prometheus-operator、日志监控、thanos等）</p>\n<p>……</p>\n</li>\n<li><p><b>土巴兔 高级运维工程师）</b><br>2018/03 - 2018/11</p>\n<p>负责千万级pv流量监控系统维护</p>\n<p>负责”718装修节”高可用系统的构建及维护（缓存系统pika、nginx、CDN、lua脚本等）</p>\n<p>……</p>\n</li>\n<li><p><b>深圳蓝贝 运维工程师）</b><br>2016/06 - 2018/03</p>\n<p>负责海外业务架构设计与落地（lnmp、proxy、lvs等）</p>\n<p>负责风控大数据+账单系统维护及优化（hadoop、spark、kafka、ES等方向）</p>\n<p>负责企业大型监控方案落地与实施（zabbix、grafana、telegraf、elk等）</p>\n<p>推动容器平台k8s建设与落地（k8s 1.12）</p>\n<p>……</p>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2></li>\n<li><p><b>电子邮箱</b><br><a href=\"mailto:&#x6f;&#x77;&#101;&#108;&#105;&#110;&#117;&#x78;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109;\">&#x6f;&#x77;&#101;&#108;&#105;&#110;&#117;&#x78;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109;</a></p>\n</li>\n<li><p><b>微信</b><br>lovek8s</p>\n</li>\n</ul>\n<p><img src=\"/medias/contact.jpg\"></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"CV\"><a href=\"#CV\" class=\"headerlink\" title=\"CV\"></a>CV</h2><p><a href=\"/medias/files/cv-zh.pdf\">中文版</a><br><a href=\"/medias/files/cv-en.pdf\">English Version</a></p>\n<h2 id=\"教育背景\"><a href=\"#教育背景\" class=\"headerlink\" title=\"教育背景\"></a>教育背景</h2><ul>\n<li><p><b>本科 华东科技大学文华学院 通信工程</b><br>2012/09 - 2016/06</p>\n</li>\n<li><p><b>武汉誉天教育 受邀进修学习 国际知名认证和实战技能培训</b><br>2015/09 - 2015/12</p>\n<h2 id=\"研究方向\"><a href=\"#研究方向\" class=\"headerlink\" title=\"研究方向\"></a>研究方向</h2><p>主要研究<strong>成分句法分析、依存句法分析、机器翻译</strong>等方向，<br>对<strong>序列标注、语言模型、实体关系抽取、迁移学习</strong>等方向也感兴趣。</p>\n</li>\n</ul>\n<h2 id=\"工作经历\"><a href=\"#工作经历\" class=\"headerlink\" title=\"工作经历\"></a>工作经历</h2><ul>\n<li><p><b>深圳明源云科技有限公司 容器平台-运维工程师（T3.2）</b><br>2018/11 - 至今</p>\n<p>负责容器平台基础建设（ci/cd、chart业务模版等）</p>\n<p>负责落地大型数据平台组件建设（flink/spark on k8s 、cacal、dremio等）</p>\n<p>负责企业监控系统建设及维护（prometheus-operator、日志监控、thanos等）</p>\n<p>……</p>\n</li>\n<li><p><b>土巴兔 高级运维工程师）</b><br>2018/03 - 2018/11</p>\n<p>负责千万级pv流量监控系统维护</p>\n<p>负责”718装修节”高可用系统的构建及维护（缓存系统pika、nginx、CDN、lua脚本等）</p>\n<p>……</p>\n</li>\n<li><p><b>深圳蓝贝 运维工程师）</b><br>2016/06 - 2018/03</p>\n<p>负责海外业务架构设计与落地（lnmp、proxy、lvs等）</p>\n<p>负责风控大数据+账单系统维护及优化（hadoop、spark、kafka、ES等方向）</p>\n<p>负责企业大型监控方案落地与实施（zabbix、grafana、telegraf、elk等）</p>\n<p>推动容器平台k8s建设与落地（k8s 1.12）</p>\n<p>……</p>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2></li>\n<li><p><b>电子邮箱</b><br><a href=\"mailto:&#x6f;&#x77;&#101;&#108;&#105;&#110;&#117;&#x78;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109;\">&#x6f;&#x77;&#101;&#108;&#105;&#110;&#117;&#x78;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109;</a></p>\n</li>\n<li><p><b>微信</b><br>lovek8s</p>\n</li>\n</ul>\n<p><img src=\"/medias/contact.jpg\"></p>\n"},{"title":"contact","date":"2019-07-26T09:17:02.000Z","type":"contact","layout":"contact","_content":"\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言，或者加 QQ 技术交流群【群号：864832264】。\n\n我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n例如我的博客友链，大家可以加到自己博客里哦：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2019-07-26 17:17:02\ntype: \"contact\"\nlayout: \"contact\"\n---\n\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言，或者加 QQ 技术交流群【群号：864832264】。\n\n我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n例如我的博客友链，大家可以加到自己博客里哦：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","updated":"2021-02-09T02:00:24.584Z","path":"contact/index.html","comments":1,"_id":"ckm1fhpzn0008yc97ckeiady6","content":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言，或者加 QQ 技术交流群【群号：864832264】。</p>\n<p>我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n<p>例如我的博客友链，大家可以加到自己博客里哦：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com/\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言，或者加 QQ 技术交流群【群号：864832264】。</p>\n<p>我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n<p>例如我的博客友链，大家可以加到自己博客里哦：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com/\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n"},{"title":"friends","date":"2019-07-19T08:42:10.000Z","type":"friends","layout":"friends","_content":"\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n例如我的博客友链，大家可以加到自己博客里哦：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2019-07-19 16:42:10\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n例如我的博客友链，大家可以加到自己博客里哦：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","updated":"2021-02-09T02:00:24.584Z","path":"friends/index.html","comments":1,"_id":"ckm1fhpzp000ayc97f3rkgsy8","content":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n<p>例如我的博客友链，大家可以加到自己博客里哦：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com/\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n<p>例如我的博客友链，大家可以加到自己博客里哦：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com/\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n"},{"title":"categories","date":"2019-07-19T08:39:20.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-07-19 16:39:20\ntype: \"categories\"\nlayout: \"categories\"\n---","updated":"2021-02-09T02:00:24.583Z","path":"categories/index.html","comments":1,"_id":"ckm1fhpzr000eyc97dez068qu","content":"","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-07-19 16:40:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2021-02-09T02:00:24.584Z","path":"tags/index.html","comments":1,"_id":"ckm1fhpzt000gyc97b4gddljk","content":"","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""}],"Post":[{"title":"Nginx Access Log日志统计分析常用命令","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-24T14:20:54.000Z","password":null,"summary":null,"_content":"\n## Nginx 日志格式\n```\nlog_format  main  '$host $remote_addr - $remote_user [$time_local] \"$request\" '\n        '$status $body_bytes_sent $upstream_response_time \"$http_referer\" '\n        '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$uid_got\" \"$uid_set\" \"$http_x_tencent_ua\" \"$upstream_addr\" \"$upstream_http_x_cached_from\" \"$upstream_http_cache_control\"';\n```\n\n## IP 相关统计\n\n### 统计IP访问量\n```\nawk '{print $2}' access.log | sort -n | uniq | wc -l\n```\n### 查看某一时间段的IP访问量(4-5点)\n```\ngrep \"07/Apr/2017:0[4-5]\" access.log | awk '{print $1}' | sort | uniq -c| sort -nr | wc -l\n```\n### 查看访问最频繁的前100个IP\n```\nawk '{print $2}' access.log | sort -n |uniq -c | sort -rn | head -n 100\n```\n### 查看访问100次以上的IP\n```\nawk '{print $2}' access.log | sort -n |uniq -c |awk '{if($1 >100) print $0}'|sort -rn\n```\n### 查询某个IP的详细访问情况,按访问频率排序\n```\ngrep '104.217.108.66' access.log |awk '{print $7}'|sort |uniq -c |sort -rn |head -n 100\n```\n## 页面访问统计\n### 查看访问最频的页面(TOP100)\n```\nawk '{print $7}' access.log | sort |uniq -c | sort -rn | head -n 100\n```\n### 查看访问最频的页面([排除php页面】(TOP100)\n```\ngrep -v \".php\"  access.log | awk '{print $7}' | sort |uniq -c | sort -rn | head -n 100\n```\n### 查看页面访问次数超过100次的页面\n```\ncat access.log | cut -d ' ' -f 7 | sort |uniq -c | awk '{if ($1 > 100) print $0}' | less\n```\n### 查看最近1000条记录，访问量最高的页面\n```\ntail -1000 access.log |awk '{print $7}'|sort|uniq -c|sort -nr|less\n```\n## 每秒请求量统计\n### 统计每秒的请求数,top100的时间点(精确到秒)\n```\nawk '{print $5}' access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100\n```\n## 每分钟请求量统计\n### 统计每分钟的请求数,top100的时间点(精确到分钟)\n```\nawk '{print $5}' access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100\n```\n## 每小时请求量统计\n### 统计每小时的请求数,top100的时间点(精确到小时)\n```\nawk '{print $5}' access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100\n```\n## 性能分析\n在nginx log中最后一个字段加入$request_time\n\n### 列出传输时间超过 3 秒的页面，显示前20条\n```\ncat access.log|awk '($NF > 3){print $7}'|sort -n|uniq -c|sort -nr|head -20\n```\n### 列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\n```\ncat access.log|awk '($NF > 1 &&  $7~/\\.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n```\n## 蜘蛛抓取统计\n### 统计蜘蛛抓取次数\n```\ngrep 'Baiduspider' access.log |wc -l\n```\n### 统计蜘蛛抓取404的次数\n```\ngrep 'Baiduspider' access.log |grep '404' | wc -l\n```\n## TCP连接统计\n### 查看当前TCP连接数\n```\nnetstat -tan | grep \"ESTABLISHED\" | grep \":80\" | wc -l\n```\n### 用tcpdump嗅探80端口的访问看看谁最高\n```\ntcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr\n```\n\n## 脚本分析\n","source":"_posts/2018-07-24-article7-linux-nginxlog.md","raw":"---\ntitle: Nginx Access Log日志统计分析常用命令\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate:   2018-07-24 22:20:54\npassword:\nsummary:\ntags:\n- 日志分析\n- nginx\ncategories:\n- linux运维\n---\n\n## Nginx 日志格式\n```\nlog_format  main  '$host $remote_addr - $remote_user [$time_local] \"$request\" '\n        '$status $body_bytes_sent $upstream_response_time \"$http_referer\" '\n        '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$uid_got\" \"$uid_set\" \"$http_x_tencent_ua\" \"$upstream_addr\" \"$upstream_http_x_cached_from\" \"$upstream_http_cache_control\"';\n```\n\n## IP 相关统计\n\n### 统计IP访问量\n```\nawk '{print $2}' access.log | sort -n | uniq | wc -l\n```\n### 查看某一时间段的IP访问量(4-5点)\n```\ngrep \"07/Apr/2017:0[4-5]\" access.log | awk '{print $1}' | sort | uniq -c| sort -nr | wc -l\n```\n### 查看访问最频繁的前100个IP\n```\nawk '{print $2}' access.log | sort -n |uniq -c | sort -rn | head -n 100\n```\n### 查看访问100次以上的IP\n```\nawk '{print $2}' access.log | sort -n |uniq -c |awk '{if($1 >100) print $0}'|sort -rn\n```\n### 查询某个IP的详细访问情况,按访问频率排序\n```\ngrep '104.217.108.66' access.log |awk '{print $7}'|sort |uniq -c |sort -rn |head -n 100\n```\n## 页面访问统计\n### 查看访问最频的页面(TOP100)\n```\nawk '{print $7}' access.log | sort |uniq -c | sort -rn | head -n 100\n```\n### 查看访问最频的页面([排除php页面】(TOP100)\n```\ngrep -v \".php\"  access.log | awk '{print $7}' | sort |uniq -c | sort -rn | head -n 100\n```\n### 查看页面访问次数超过100次的页面\n```\ncat access.log | cut -d ' ' -f 7 | sort |uniq -c | awk '{if ($1 > 100) print $0}' | less\n```\n### 查看最近1000条记录，访问量最高的页面\n```\ntail -1000 access.log |awk '{print $7}'|sort|uniq -c|sort -nr|less\n```\n## 每秒请求量统计\n### 统计每秒的请求数,top100的时间点(精确到秒)\n```\nawk '{print $5}' access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100\n```\n## 每分钟请求量统计\n### 统计每分钟的请求数,top100的时间点(精确到分钟)\n```\nawk '{print $5}' access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100\n```\n## 每小时请求量统计\n### 统计每小时的请求数,top100的时间点(精确到小时)\n```\nawk '{print $5}' access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100\n```\n## 性能分析\n在nginx log中最后一个字段加入$request_time\n\n### 列出传输时间超过 3 秒的页面，显示前20条\n```\ncat access.log|awk '($NF > 3){print $7}'|sort -n|uniq -c|sort -nr|head -20\n```\n### 列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\n```\ncat access.log|awk '($NF > 1 &&  $7~/\\.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n```\n## 蜘蛛抓取统计\n### 统计蜘蛛抓取次数\n```\ngrep 'Baiduspider' access.log |wc -l\n```\n### 统计蜘蛛抓取404的次数\n```\ngrep 'Baiduspider' access.log |grep '404' | wc -l\n```\n## TCP连接统计\n### 查看当前TCP连接数\n```\nnetstat -tan | grep \"ESTABLISHED\" | grep \":80\" | wc -l\n```\n### 用tcpdump嗅探80端口的访问看看谁最高\n```\ntcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr\n```\n\n## 脚本分析\n","slug":"2018-07-24-article7-linux-nginxlog","published":1,"updated":"2021-02-09T03:02:23.460Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhpzd0001yc976z9ae6qc","content":"<h2 id=\"Nginx-日志格式\"><a href=\"#Nginx-日志格式\" class=\"headerlink\" title=\"Nginx 日志格式\"></a>Nginx 日志格式</h2><pre><code>log_format  main  &#39;$host $remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;\n        &#39;$status $body_bytes_sent $upstream_response_time &quot;$http_referer&quot; &#39;\n        &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$uid_got&quot; &quot;$uid_set&quot; &quot;$http_x_tencent_ua&quot; &quot;$upstream_addr&quot; &quot;$upstream_http_x_cached_from&quot; &quot;$upstream_http_cache_control&quot;&#39;;\n</code></pre>\n<h2 id=\"IP-相关统计\"><a href=\"#IP-相关统计\" class=\"headerlink\" title=\"IP 相关统计\"></a>IP 相关统计</h2><h3 id=\"统计IP访问量\"><a href=\"#统计IP访问量\" class=\"headerlink\" title=\"统计IP访问量\"></a>统计IP访问量</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n | uniq | wc -l\n</code></pre>\n<h3 id=\"查看某一时间段的IP访问量-4-5点\"><a href=\"#查看某一时间段的IP访问量-4-5点\" class=\"headerlink\" title=\"查看某一时间段的IP访问量(4-5点)\"></a>查看某一时间段的IP访问量(4-5点)</h3><pre><code>grep &quot;07/Apr/2017:0[4-5]&quot; access.log | awk &#39;&#123;print $1&#125;&#39; | sort | uniq -c| sort -nr | wc -l\n</code></pre>\n<h3 id=\"查看访问最频繁的前100个IP\"><a href=\"#查看访问最频繁的前100个IP\" class=\"headerlink\" title=\"查看访问最频繁的前100个IP\"></a>查看访问最频繁的前100个IP</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看访问100次以上的IP\"><a href=\"#查看访问100次以上的IP\" class=\"headerlink\" title=\"查看访问100次以上的IP\"></a>查看访问100次以上的IP</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n |uniq -c |awk &#39;&#123;if($1 &gt;100) print $0&#125;&#39;|sort -rn\n</code></pre>\n<h3 id=\"查询某个IP的详细访问情况-按访问频率排序\"><a href=\"#查询某个IP的详细访问情况-按访问频率排序\" class=\"headerlink\" title=\"查询某个IP的详细访问情况,按访问频率排序\"></a>查询某个IP的详细访问情况,按访问频率排序</h3><pre><code>grep &#39;104.217.108.66&#39; access.log |awk &#39;&#123;print $7&#125;&#39;|sort |uniq -c |sort -rn |head -n 100\n</code></pre>\n<h2 id=\"页面访问统计\"><a href=\"#页面访问统计\" class=\"headerlink\" title=\"页面访问统计\"></a>页面访问统计</h2><h3 id=\"查看访问最频的页面-TOP100\"><a href=\"#查看访问最频的页面-TOP100\" class=\"headerlink\" title=\"查看访问最频的页面(TOP100)\"></a>查看访问最频的页面(TOP100)</h3><pre><code>awk &#39;&#123;print $7&#125;&#39; access.log | sort |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看访问最频的页面-排除php页面】-TOP100\"><a href=\"#查看访问最频的页面-排除php页面】-TOP100\" class=\"headerlink\" title=\"查看访问最频的页面([排除php页面】(TOP100)\"></a>查看访问最频的页面([排除php页面】(TOP100)</h3><pre><code>grep -v &quot;.php&quot;  access.log | awk &#39;&#123;print $7&#125;&#39; | sort |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看页面访问次数超过100次的页面\"><a href=\"#查看页面访问次数超过100次的页面\" class=\"headerlink\" title=\"查看页面访问次数超过100次的页面\"></a>查看页面访问次数超过100次的页面</h3><pre><code>cat access.log | cut -d &#39; &#39; -f 7 | sort |uniq -c | awk &#39;&#123;if ($1 &gt; 100) print $0&#125;&#39; | less\n</code></pre>\n<h3 id=\"查看最近1000条记录，访问量最高的页面\"><a href=\"#查看最近1000条记录，访问量最高的页面\" class=\"headerlink\" title=\"查看最近1000条记录，访问量最高的页面\"></a>查看最近1000条记录，访问量最高的页面</h3><pre><code>tail -1000 access.log |awk &#39;&#123;print $7&#125;&#39;|sort|uniq -c|sort -nr|less\n</code></pre>\n<h2 id=\"每秒请求量统计\"><a href=\"#每秒请求量统计\" class=\"headerlink\" title=\"每秒请求量统计\"></a>每秒请求量统计</h2><h3 id=\"统计每秒的请求数-top100的时间点-精确到秒\"><a href=\"#统计每秒的请求数-top100的时间点-精确到秒\" class=\"headerlink\" title=\"统计每秒的请求数,top100的时间点(精确到秒)\"></a>统计每秒的请求数,top100的时间点(精确到秒)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"每分钟请求量统计\"><a href=\"#每分钟请求量统计\" class=\"headerlink\" title=\"每分钟请求量统计\"></a>每分钟请求量统计</h2><h3 id=\"统计每分钟的请求数-top100的时间点-精确到分钟\"><a href=\"#统计每分钟的请求数-top100的时间点-精确到分钟\" class=\"headerlink\" title=\"统计每分钟的请求数,top100的时间点(精确到分钟)\"></a>统计每分钟的请求数,top100的时间点(精确到分钟)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"每小时请求量统计\"><a href=\"#每小时请求量统计\" class=\"headerlink\" title=\"每小时请求量统计\"></a>每小时请求量统计</h2><h3 id=\"统计每小时的请求数-top100的时间点-精确到小时\"><a href=\"#统计每小时的请求数-top100的时间点-精确到小时\" class=\"headerlink\" title=\"统计每小时的请求数,top100的时间点(精确到小时)\"></a>统计每小时的请求数,top100的时间点(精确到小时)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>在nginx log中最后一个字段加入$request_time</p>\n<h3 id=\"列出传输时间超过-3-秒的页面，显示前20条\"><a href=\"#列出传输时间超过-3-秒的页面，显示前20条\" class=\"headerlink\" title=\"列出传输时间超过 3 秒的页面，显示前20条\"></a>列出传输时间超过 3 秒的页面，显示前20条</h3><pre><code>cat access.log|awk &#39;($NF &gt; 3)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -20\n</code></pre>\n<h3 id=\"列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\"><a href=\"#列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\" class=\"headerlink\" title=\"列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\"></a>列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条</h3><pre><code>cat access.log|awk &#39;($NF &gt; 1 &amp;&amp;  $7~/\\.php/)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -100\n</code></pre>\n<h2 id=\"蜘蛛抓取统计\"><a href=\"#蜘蛛抓取统计\" class=\"headerlink\" title=\"蜘蛛抓取统计\"></a>蜘蛛抓取统计</h2><h3 id=\"统计蜘蛛抓取次数\"><a href=\"#统计蜘蛛抓取次数\" class=\"headerlink\" title=\"统计蜘蛛抓取次数\"></a>统计蜘蛛抓取次数</h3><pre><code>grep &#39;Baiduspider&#39; access.log |wc -l\n</code></pre>\n<h3 id=\"统计蜘蛛抓取404的次数\"><a href=\"#统计蜘蛛抓取404的次数\" class=\"headerlink\" title=\"统计蜘蛛抓取404的次数\"></a>统计蜘蛛抓取404的次数</h3><pre><code>grep &#39;Baiduspider&#39; access.log |grep &#39;404&#39; | wc -l\n</code></pre>\n<h2 id=\"TCP连接统计\"><a href=\"#TCP连接统计\" class=\"headerlink\" title=\"TCP连接统计\"></a>TCP连接统计</h2><h3 id=\"查看当前TCP连接数\"><a href=\"#查看当前TCP连接数\" class=\"headerlink\" title=\"查看当前TCP连接数\"></a>查看当前TCP连接数</h3><pre><code>netstat -tan | grep &quot;ESTABLISHED&quot; | grep &quot;:80&quot; | wc -l\n</code></pre>\n<h3 id=\"用tcpdump嗅探80端口的访问看看谁最高\"><a href=\"#用tcpdump嗅探80端口的访问看看谁最高\" class=\"headerlink\" title=\"用tcpdump嗅探80端口的访问看看谁最高\"></a>用tcpdump嗅探80端口的访问看看谁最高</h3><pre><code>tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;&#123;print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4&#125;&#39; | sort | uniq -c | sort -nr\n</code></pre>\n<h2 id=\"脚本分析\"><a href=\"#脚本分析\" class=\"headerlink\" title=\"脚本分析\"></a>脚本分析</h2>","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"Nginx-日志格式\"><a href=\"#Nginx-日志格式\" class=\"headerlink\" title=\"Nginx 日志格式\"></a>Nginx 日志格式</h2><pre><code>log_format  main  &#39;$host $remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;\n        &#39;$status $body_bytes_sent $upstream_response_time &quot;$http_referer&quot; &#39;\n        &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$uid_got&quot; &quot;$uid_set&quot; &quot;$http_x_tencent_ua&quot; &quot;$upstream_addr&quot; &quot;$upstream_http_x_cached_from&quot; &quot;$upstream_http_cache_control&quot;&#39;;\n</code></pre>\n<h2 id=\"IP-相关统计\"><a href=\"#IP-相关统计\" class=\"headerlink\" title=\"IP 相关统计\"></a>IP 相关统计</h2><h3 id=\"统计IP访问量\"><a href=\"#统计IP访问量\" class=\"headerlink\" title=\"统计IP访问量\"></a>统计IP访问量</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n | uniq | wc -l\n</code></pre>\n<h3 id=\"查看某一时间段的IP访问量-4-5点\"><a href=\"#查看某一时间段的IP访问量-4-5点\" class=\"headerlink\" title=\"查看某一时间段的IP访问量(4-5点)\"></a>查看某一时间段的IP访问量(4-5点)</h3><pre><code>grep &quot;07/Apr/2017:0[4-5]&quot; access.log | awk &#39;&#123;print $1&#125;&#39; | sort | uniq -c| sort -nr | wc -l\n</code></pre>\n<h3 id=\"查看访问最频繁的前100个IP\"><a href=\"#查看访问最频繁的前100个IP\" class=\"headerlink\" title=\"查看访问最频繁的前100个IP\"></a>查看访问最频繁的前100个IP</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看访问100次以上的IP\"><a href=\"#查看访问100次以上的IP\" class=\"headerlink\" title=\"查看访问100次以上的IP\"></a>查看访问100次以上的IP</h3><pre><code>awk &#39;&#123;print $2&#125;&#39; access.log | sort -n |uniq -c |awk &#39;&#123;if($1 &gt;100) print $0&#125;&#39;|sort -rn\n</code></pre>\n<h3 id=\"查询某个IP的详细访问情况-按访问频率排序\"><a href=\"#查询某个IP的详细访问情况-按访问频率排序\" class=\"headerlink\" title=\"查询某个IP的详细访问情况,按访问频率排序\"></a>查询某个IP的详细访问情况,按访问频率排序</h3><pre><code>grep &#39;104.217.108.66&#39; access.log |awk &#39;&#123;print $7&#125;&#39;|sort |uniq -c |sort -rn |head -n 100\n</code></pre>\n<h2 id=\"页面访问统计\"><a href=\"#页面访问统计\" class=\"headerlink\" title=\"页面访问统计\"></a>页面访问统计</h2><h3 id=\"查看访问最频的页面-TOP100\"><a href=\"#查看访问最频的页面-TOP100\" class=\"headerlink\" title=\"查看访问最频的页面(TOP100)\"></a>查看访问最频的页面(TOP100)</h3><pre><code>awk &#39;&#123;print $7&#125;&#39; access.log | sort |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看访问最频的页面-排除php页面】-TOP100\"><a href=\"#查看访问最频的页面-排除php页面】-TOP100\" class=\"headerlink\" title=\"查看访问最频的页面([排除php页面】(TOP100)\"></a>查看访问最频的页面([排除php页面】(TOP100)</h3><pre><code>grep -v &quot;.php&quot;  access.log | awk &#39;&#123;print $7&#125;&#39; | sort |uniq -c | sort -rn | head -n 100\n</code></pre>\n<h3 id=\"查看页面访问次数超过100次的页面\"><a href=\"#查看页面访问次数超过100次的页面\" class=\"headerlink\" title=\"查看页面访问次数超过100次的页面\"></a>查看页面访问次数超过100次的页面</h3><pre><code>cat access.log | cut -d &#39; &#39; -f 7 | sort |uniq -c | awk &#39;&#123;if ($1 &gt; 100) print $0&#125;&#39; | less\n</code></pre>\n<h3 id=\"查看最近1000条记录，访问量最高的页面\"><a href=\"#查看最近1000条记录，访问量最高的页面\" class=\"headerlink\" title=\"查看最近1000条记录，访问量最高的页面\"></a>查看最近1000条记录，访问量最高的页面</h3><pre><code>tail -1000 access.log |awk &#39;&#123;print $7&#125;&#39;|sort|uniq -c|sort -nr|less\n</code></pre>\n<h2 id=\"每秒请求量统计\"><a href=\"#每秒请求量统计\" class=\"headerlink\" title=\"每秒请求量统计\"></a>每秒请求量统计</h2><h3 id=\"统计每秒的请求数-top100的时间点-精确到秒\"><a href=\"#统计每秒的请求数-top100的时间点-精确到秒\" class=\"headerlink\" title=\"统计每秒的请求数,top100的时间点(精确到秒)\"></a>统计每秒的请求数,top100的时间点(精确到秒)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"每分钟请求量统计\"><a href=\"#每分钟请求量统计\" class=\"headerlink\" title=\"每分钟请求量统计\"></a>每分钟请求量统计</h2><h3 id=\"统计每分钟的请求数-top100的时间点-精确到分钟\"><a href=\"#统计每分钟的请求数-top100的时间点-精确到分钟\" class=\"headerlink\" title=\"统计每分钟的请求数,top100的时间点(精确到分钟)\"></a>统计每分钟的请求数,top100的时间点(精确到分钟)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"每小时请求量统计\"><a href=\"#每小时请求量统计\" class=\"headerlink\" title=\"每小时请求量统计\"></a>每小时请求量统计</h2><h3 id=\"统计每小时的请求数-top100的时间点-精确到小时\"><a href=\"#统计每小时的请求数-top100的时间点-精确到小时\" class=\"headerlink\" title=\"统计每小时的请求数,top100的时间点(精确到小时)\"></a>统计每小时的请求数,top100的时间点(精确到小时)</h3><pre><code>awk &#39;&#123;print $5&#125;&#39; access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100\n</code></pre>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>在nginx log中最后一个字段加入$request_time</p>\n<h3 id=\"列出传输时间超过-3-秒的页面，显示前20条\"><a href=\"#列出传输时间超过-3-秒的页面，显示前20条\" class=\"headerlink\" title=\"列出传输时间超过 3 秒的页面，显示前20条\"></a>列出传输时间超过 3 秒的页面，显示前20条</h3><pre><code>cat access.log|awk &#39;($NF &gt; 3)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -20\n</code></pre>\n<h3 id=\"列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\"><a href=\"#列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\" class=\"headerlink\" title=\"列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条\"></a>列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条</h3><pre><code>cat access.log|awk &#39;($NF &gt; 1 &amp;&amp;  $7~/\\.php/)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -100\n</code></pre>\n<h2 id=\"蜘蛛抓取统计\"><a href=\"#蜘蛛抓取统计\" class=\"headerlink\" title=\"蜘蛛抓取统计\"></a>蜘蛛抓取统计</h2><h3 id=\"统计蜘蛛抓取次数\"><a href=\"#统计蜘蛛抓取次数\" class=\"headerlink\" title=\"统计蜘蛛抓取次数\"></a>统计蜘蛛抓取次数</h3><pre><code>grep &#39;Baiduspider&#39; access.log |wc -l\n</code></pre>\n<h3 id=\"统计蜘蛛抓取404的次数\"><a href=\"#统计蜘蛛抓取404的次数\" class=\"headerlink\" title=\"统计蜘蛛抓取404的次数\"></a>统计蜘蛛抓取404的次数</h3><pre><code>grep &#39;Baiduspider&#39; access.log |grep &#39;404&#39; | wc -l\n</code></pre>\n<h2 id=\"TCP连接统计\"><a href=\"#TCP连接统计\" class=\"headerlink\" title=\"TCP连接统计\"></a>TCP连接统计</h2><h3 id=\"查看当前TCP连接数\"><a href=\"#查看当前TCP连接数\" class=\"headerlink\" title=\"查看当前TCP连接数\"></a>查看当前TCP连接数</h3><pre><code>netstat -tan | grep &quot;ESTABLISHED&quot; | grep &quot;:80&quot; | wc -l\n</code></pre>\n<h3 id=\"用tcpdump嗅探80端口的访问看看谁最高\"><a href=\"#用tcpdump嗅探80端口的访问看看谁最高\" class=\"headerlink\" title=\"用tcpdump嗅探80端口的访问看看谁最高\"></a>用tcpdump嗅探80端口的访问看看谁最高</h3><pre><code>tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;&#123;print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4&#125;&#39; | sort | uniq -c | sort -nr\n</code></pre>\n<h2 id=\"脚本分析\"><a href=\"#脚本分析\" class=\"headerlink\" title=\"脚本分析\"></a>脚本分析</h2>"},{"layout":"post","title":"prometheus监控之snmp流量采集","date":"2018-07-25T11:20:54.000Z","author":"owelinux","excerpt":"prometheus监控之snmp流量采集.","mathjax":true,"_content":"\n* content\n{:toc}\n\n\n## 下载并运行prometheus\n```\nwget https://github.com/prometheus/prometheus/releases/download/v2.3.2/prometheus-2.3.2.linux-amd64.tar.gz\ntar -zxvf prometheus-2.3.2.linux-amd64.tar.gz\nmv prometheus-2.3.2.linux-amd64 prometheus\n```\n\n## 配置prometheus监控本身\n```\nglobal:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n\n  # Attach these labels to any time series or alerts when communicating with\n  # external systems (federation, remote storage, Alertmanager).\n  external_labels:\n    monitor: 'codelab-monitor'\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it's Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n  - job_name: 'prometheus'\n\n    # Override the global default and scrape targets from this job every 5 seconds.\n    scrape_interval: 5s\n\n    static_configs:\n      - targets: ['localhost:9090']\n```\n\n### 启动prometheus\n```\n./prometheus --config.file=prometheus.yml\n```\n### 打开浏览器验证\n http://localhost:9090/graph\n\n## 配置写数据到es\n### 下载prometheusbeat\n```\nmkdir -p ${GOPATH}/github.com/infonova/prometheusbeat\ncd ${GOPATH}/github.com/infonova/prometheusbeat\ngit clone https://github.com/infonova/prometheusbeat\nmake package\n./prometheusbeat -c prometheusbeat.yml -e -d \"*\"\n\n# 查看服务是否启动\nss -lntp | grep 8088\nLISTEN     0      65535                     *:8088                     *:*      users:((\"prometheusbeat\",29237,6))\n```\n### 配置prometheus输入es\n```\n#remote_write:\n#  - url: \"http://localhost:9201/write\"\nremote_write:\n  - url: \"http://localhost:8088/prometheus\"\n```\n## 监控snmp\n\n### 安装snmp服务\n```\nyum -y install net-snmp*\n防火墙\n#prometheus\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9116 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p udp -m state --state NEW -m udp --dport 161 -j ACCEPT\n```\n\n### 安装snmp插件\n```\nwget https://github.com/prometheus/snmp_exporter/releases/download/v0.11.0/snmp_exporter-0.11.0.linux-amd64.tar.gz\ntar -zxvf snmp_exporter-0.11.0.linux-amd64.tar.gz\n./snmp_exporter \n```\n### 配置prometheus的snmp\n```\n  - job_name: 'snmp'\n    static_configs:\n      - targets:\n        - 192.168.1.1\n        labels:\n          tag: aliyun-hb2-10\n    metrics_path: /snmp\n    params:\n      module: [if_mib]\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: 191.168.1.1:9116\n```\n### 验证snmp监控数据\n```\ncurl 'http://localhost:9116/snmp?target=192.168.1.1' \n```\n### snmp指标\n针对普通网络设备的端口，MIB的相关定义是Interface组，主要管理如下信息:\nifIndex                 端口索引号\nifDescr                 端口描述\nifType                  端口类型\nifMtu                   最大传输包字节数\nifSpeed                 端口速度\nifPhysAddress           物理地址\nifOperStatus            操作状态\nifLastChange            上次状态更新时间\n*ifInOctets             输入字节数\n*ifInUcastPkts          输入非广播包数\n*ifInNUcastPkts         输入广播包数\n*ifInDiscards           输入包丢弃数\n*ifInErrors             输入包错误数\n*ifInUnknownProtos      输入未知协议包数\n*ifOutOctets            输出字节数\n*ifOutUcastPkts         输出非广播包数\n*ifOutNUcastPkts        输出广播包数\n*ifOutDiscards          输出包丢弃数\n*ifOutErrors            输出包错误数\nifOutQLen               输出队长\n其中，*号标识的是与网络流量有关的信息。\n1、获取CISCO2900端口1的上行总流量\n          snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1\n    返回结果\n         IF-MIB::ifInOctets.1 = Counter32: 4861881\n2、五秒后再获取一次\n         snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1\n    返回结果\n     IF-MIB::ifInOctets.1 = Counter32: 4870486\n3、计算结果\n （后值48704863-前值4861881）/ 5＝1721b/s  （应该是BYTE）\n\n### 配置snmp告警指标\n```\ncat rules/traffic.yml \ngroups:\n  - name: traffic\n    rules:\n    - record: traffic_out_bps \n      expr: (ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60\n      #expr: sum by (tag, job, instance, ifIndex) ((ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60)\n      #labels:\n      #  instance: \"{{ $labels.instance }}\"\n      #  ifIndex: \"{{ $labels.ifIndex }}\"\n    - record: traffic_in_bps\n      expr: (ifHCInOctets - (ifHCInOctets offset 1m)) *8/60\n\n    ### alert\n    - alert: BeijingProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=~\"7|9\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: BeijingProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=~\"7|9\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 500\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n    - alert: BeijingProxyWanTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=~\"6|8\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out bond0 has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: BeijingProxyWanTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=~\"6|8\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in bond0 has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n    - alert: AliyunProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=\"2\", tag=~\"aliyun.+\"}[5m]) /1024/1024)) > 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: AliyunProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=\"2\", tag=~\"aliyun.+\"}[5m]) /1024/1024)) > 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n```\n### snmp 传输到granfan\n\n### 参考\nhttps://github.com/infonova/prometheusbeat\nhttps://prometheus.io\nhttps://github.com/prometheus/snmp_exporter\nhttps://blog.csdn.net/huithe/article/details/7588673","source":"_posts/2018-07-25-article8-linux-prometheus.md","raw":"---\nlayout: post\ntitle:  \"prometheus监控之snmp流量采集\"\ndate:   2018-07-25 19:20:54\nauthor: owelinux\ncategories: linux\ntags: prometheus snmp 监控\nexcerpt: prometheus监控之snmp流量采集.\nmathjax: true\n---\n\n* content\n{:toc}\n\n\n## 下载并运行prometheus\n```\nwget https://github.com/prometheus/prometheus/releases/download/v2.3.2/prometheus-2.3.2.linux-amd64.tar.gz\ntar -zxvf prometheus-2.3.2.linux-amd64.tar.gz\nmv prometheus-2.3.2.linux-amd64 prometheus\n```\n\n## 配置prometheus监控本身\n```\nglobal:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n\n  # Attach these labels to any time series or alerts when communicating with\n  # external systems (federation, remote storage, Alertmanager).\n  external_labels:\n    monitor: 'codelab-monitor'\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it's Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n  - job_name: 'prometheus'\n\n    # Override the global default and scrape targets from this job every 5 seconds.\n    scrape_interval: 5s\n\n    static_configs:\n      - targets: ['localhost:9090']\n```\n\n### 启动prometheus\n```\n./prometheus --config.file=prometheus.yml\n```\n### 打开浏览器验证\n http://localhost:9090/graph\n\n## 配置写数据到es\n### 下载prometheusbeat\n```\nmkdir -p ${GOPATH}/github.com/infonova/prometheusbeat\ncd ${GOPATH}/github.com/infonova/prometheusbeat\ngit clone https://github.com/infonova/prometheusbeat\nmake package\n./prometheusbeat -c prometheusbeat.yml -e -d \"*\"\n\n# 查看服务是否启动\nss -lntp | grep 8088\nLISTEN     0      65535                     *:8088                     *:*      users:((\"prometheusbeat\",29237,6))\n```\n### 配置prometheus输入es\n```\n#remote_write:\n#  - url: \"http://localhost:9201/write\"\nremote_write:\n  - url: \"http://localhost:8088/prometheus\"\n```\n## 监控snmp\n\n### 安装snmp服务\n```\nyum -y install net-snmp*\n防火墙\n#prometheus\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9116 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p udp -m state --state NEW -m udp --dport 161 -j ACCEPT\n```\n\n### 安装snmp插件\n```\nwget https://github.com/prometheus/snmp_exporter/releases/download/v0.11.0/snmp_exporter-0.11.0.linux-amd64.tar.gz\ntar -zxvf snmp_exporter-0.11.0.linux-amd64.tar.gz\n./snmp_exporter \n```\n### 配置prometheus的snmp\n```\n  - job_name: 'snmp'\n    static_configs:\n      - targets:\n        - 192.168.1.1\n        labels:\n          tag: aliyun-hb2-10\n    metrics_path: /snmp\n    params:\n      module: [if_mib]\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: 191.168.1.1:9116\n```\n### 验证snmp监控数据\n```\ncurl 'http://localhost:9116/snmp?target=192.168.1.1' \n```\n### snmp指标\n针对普通网络设备的端口，MIB的相关定义是Interface组，主要管理如下信息:\nifIndex                 端口索引号\nifDescr                 端口描述\nifType                  端口类型\nifMtu                   最大传输包字节数\nifSpeed                 端口速度\nifPhysAddress           物理地址\nifOperStatus            操作状态\nifLastChange            上次状态更新时间\n*ifInOctets             输入字节数\n*ifInUcastPkts          输入非广播包数\n*ifInNUcastPkts         输入广播包数\n*ifInDiscards           输入包丢弃数\n*ifInErrors             输入包错误数\n*ifInUnknownProtos      输入未知协议包数\n*ifOutOctets            输出字节数\n*ifOutUcastPkts         输出非广播包数\n*ifOutNUcastPkts        输出广播包数\n*ifOutDiscards          输出包丢弃数\n*ifOutErrors            输出包错误数\nifOutQLen               输出队长\n其中，*号标识的是与网络流量有关的信息。\n1、获取CISCO2900端口1的上行总流量\n          snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1\n    返回结果\n         IF-MIB::ifInOctets.1 = Counter32: 4861881\n2、五秒后再获取一次\n         snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1\n    返回结果\n     IF-MIB::ifInOctets.1 = Counter32: 4870486\n3、计算结果\n （后值48704863-前值4861881）/ 5＝1721b/s  （应该是BYTE）\n\n### 配置snmp告警指标\n```\ncat rules/traffic.yml \ngroups:\n  - name: traffic\n    rules:\n    - record: traffic_out_bps \n      expr: (ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60\n      #expr: sum by (tag, job, instance, ifIndex) ((ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60)\n      #labels:\n      #  instance: \"{{ $labels.instance }}\"\n      #  ifIndex: \"{{ $labels.ifIndex }}\"\n    - record: traffic_in_bps\n      expr: (ifHCInOctets - (ifHCInOctets offset 1m)) *8/60\n\n    ### alert\n    - alert: BeijingProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=~\"7|9\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: BeijingProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=~\"7|9\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 500\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n    - alert: BeijingProxyWanTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=~\"6|8\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out bond0 has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: BeijingProxyWanTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=~\"6|8\", tag=~\"beijing.+\"}[5m]) /1024/1024)) >= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in bond0 has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n    - alert: AliyunProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps{ifIndex=\"2\", tag=~\"aliyun.+\"}[5m]) /1024/1024)) > 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic out has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n    - alert: AliyunProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps{ifIndex=\"2\", tag=~\"aliyun.+\"}[5m]) /1024/1024)) > 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: \"traffic in has problem (network: {{ $labels.tag }}, current: {{ $value }}Mbps)\"\n\n```\n### snmp 传输到granfan\n\n### 参考\nhttps://github.com/infonova/prometheusbeat\nhttps://prometheus.io\nhttps://github.com/prometheus/snmp_exporter\nhttps://blog.csdn.net/huithe/article/details/7588673","slug":"2018-07-25-article8-linux-prometheus","published":1,"updated":"2021-02-09T02:00:24.564Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzh0003yc97gqbq150z","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h2 id=\"下载并运行prometheus\"><a href=\"#下载并运行prometheus\" class=\"headerlink\" title=\"下载并运行prometheus\"></a>下载并运行prometheus</h2><pre><code>wget https://github.com/prometheus/prometheus/releases/download/v2.3.2/prometheus-2.3.2.linux-amd64.tar.gz\ntar -zxvf prometheus-2.3.2.linux-amd64.tar.gz\nmv prometheus-2.3.2.linux-amd64 prometheus\n</code></pre>\n<h2 id=\"配置prometheus监控本身\"><a href=\"#配置prometheus监控本身\" class=\"headerlink\" title=\"配置prometheus监控本身\"></a>配置prometheus监控本身</h2><pre><code>global:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n\n  # Attach these labels to any time series or alerts when communicating with\n  # external systems (federation, remote storage, Alertmanager).\n  external_labels:\n    monitor: &#39;codelab-monitor&#39;\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it&#39;s Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.\n  - job_name: &#39;prometheus&#39;\n\n    # Override the global default and scrape targets from this job every 5 seconds.\n    scrape_interval: 5s\n\n    static_configs:\n      - targets: [&#39;localhost:9090&#39;]\n</code></pre>\n<h3 id=\"启动prometheus\"><a href=\"#启动prometheus\" class=\"headerlink\" title=\"启动prometheus\"></a>启动prometheus</h3><pre><code>./prometheus --config.file=prometheus.yml\n</code></pre>\n<h3 id=\"打开浏览器验证\"><a href=\"#打开浏览器验证\" class=\"headerlink\" title=\"打开浏览器验证\"></a>打开浏览器验证</h3><p> <a href=\"http://localhost:9090/graph\">http://localhost:9090/graph</a></p>\n<h2 id=\"配置写数据到es\"><a href=\"#配置写数据到es\" class=\"headerlink\" title=\"配置写数据到es\"></a>配置写数据到es</h2><h3 id=\"下载prometheusbeat\"><a href=\"#下载prometheusbeat\" class=\"headerlink\" title=\"下载prometheusbeat\"></a>下载prometheusbeat</h3><pre><code>mkdir -p $&#123;GOPATH&#125;/github.com/infonova/prometheusbeat\ncd $&#123;GOPATH&#125;/github.com/infonova/prometheusbeat\ngit clone https://github.com/infonova/prometheusbeat\nmake package\n./prometheusbeat -c prometheusbeat.yml -e -d &quot;*&quot;\n\n# 查看服务是否启动\nss -lntp | grep 8088\nLISTEN     0      65535                     *:8088                     *:*      users:((&quot;prometheusbeat&quot;,29237,6))\n</code></pre>\n<h3 id=\"配置prometheus输入es\"><a href=\"#配置prometheus输入es\" class=\"headerlink\" title=\"配置prometheus输入es\"></a>配置prometheus输入es</h3><pre><code>#remote_write:\n#  - url: &quot;http://localhost:9201/write&quot;\nremote_write:\n  - url: &quot;http://localhost:8088/prometheus&quot;\n</code></pre>\n<h2 id=\"监控snmp\"><a href=\"#监控snmp\" class=\"headerlink\" title=\"监控snmp\"></a>监控snmp</h2><h3 id=\"安装snmp服务\"><a href=\"#安装snmp服务\" class=\"headerlink\" title=\"安装snmp服务\"></a>安装snmp服务</h3><pre><code>yum -y install net-snmp*\n防火墙\n#prometheus\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9116 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p udp -m state --state NEW -m udp --dport 161 -j ACCEPT\n</code></pre>\n<h3 id=\"安装snmp插件\"><a href=\"#安装snmp插件\" class=\"headerlink\" title=\"安装snmp插件\"></a>安装snmp插件</h3><pre><code>wget https://github.com/prometheus/snmp_exporter/releases/download/v0.11.0/snmp_exporter-0.11.0.linux-amd64.tar.gz\ntar -zxvf snmp_exporter-0.11.0.linux-amd64.tar.gz\n./snmp_exporter \n</code></pre>\n<h3 id=\"配置prometheus的snmp\"><a href=\"#配置prometheus的snmp\" class=\"headerlink\" title=\"配置prometheus的snmp\"></a>配置prometheus的snmp</h3><pre><code>  - job_name: &#39;snmp&#39;\n    static_configs:\n      - targets:\n        - 192.168.1.1\n        labels:\n          tag: aliyun-hb2-10\n    metrics_path: /snmp\n    params:\n      module: [if_mib]\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: 191.168.1.1:9116\n</code></pre>\n<h3 id=\"验证snmp监控数据\"><a href=\"#验证snmp监控数据\" class=\"headerlink\" title=\"验证snmp监控数据\"></a>验证snmp监控数据</h3><pre><code>curl &#39;http://localhost:9116/snmp?target=192.168.1.1&#39; \n</code></pre>\n<h3 id=\"snmp指标\"><a href=\"#snmp指标\" class=\"headerlink\" title=\"snmp指标\"></a>snmp指标</h3><p>针对普通网络设备的端口，MIB的相关定义是Interface组，主要管理如下信息:<br>ifIndex                 端口索引号<br>ifDescr                 端口描述<br>ifType                  端口类型<br>ifMtu                   最大传输包字节数<br>ifSpeed                 端口速度<br>ifPhysAddress           物理地址<br>ifOperStatus            操作状态<br>ifLastChange            上次状态更新时间<br><em>ifInOctets             输入字节数<br>*ifInUcastPkts          输入非广播包数<br>*ifInNUcastPkts         输入广播包数<br>*ifInDiscards           输入包丢弃数<br>*ifInErrors             输入包错误数<br>*ifInUnknownProtos      输入未知协议包数<br>*ifOutOctets            输出字节数<br>*ifOutUcastPkts         输出非广播包数<br>*ifOutNUcastPkts        输出广播包数<br>*ifOutDiscards          输出包丢弃数<br>*ifOutErrors            输出包错误数<br>ifOutQLen               输出队长<br>其中，</em>号标识的是与网络流量有关的信息。<br>1、获取CISCO2900端口1的上行总流量<br>          snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1<br>    返回结果<br>         IF-MIB::ifInOctets.1 = Counter32: 4861881<br>2、五秒后再获取一次<br>         snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1<br>    返回结果<br>     IF-MIB::ifInOctets.1 = Counter32: 4870486<br>3、计算结果<br> （后值48704863-前值4861881）/ 5＝1721b/s  （应该是BYTE）</p>\n<h3 id=\"配置snmp告警指标\"><a href=\"#配置snmp告警指标\" class=\"headerlink\" title=\"配置snmp告警指标\"></a>配置snmp告警指标</h3><pre><code>cat rules/traffic.yml \ngroups:\n  - name: traffic\n    rules:\n    - record: traffic_out_bps \n      expr: (ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60\n      #expr: sum by (tag, job, instance, ifIndex) ((ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60)\n      #labels:\n      #  instance: &quot;&#123;&#123; $labels.instance &#125;&#125;&quot;\n      #  ifIndex: &quot;&#123;&#123; $labels.ifIndex &#125;&#125;&quot;\n    - record: traffic_in_bps\n      expr: (ifHCInOctets - (ifHCInOctets offset 1m)) *8/60\n\n    ### alert\n    - alert: BeijingProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=~&quot;7|9&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: BeijingProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=~&quot;7|9&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 500\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n\n    - alert: BeijingProxyWanTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=~&quot;6|8&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out bond0 has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: BeijingProxyWanTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=~&quot;6|8&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in bond0 has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n\n    - alert: AliyunProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=&quot;2&quot;, tag=~&quot;aliyun.+&quot;&#125;[5m]) /1024/1024)) &gt; 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: AliyunProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=&quot;2&quot;, tag=~&quot;aliyun.+&quot;&#125;[5m]) /1024/1024)) &gt; 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n</code></pre>\n<h3 id=\"snmp-传输到granfan\"><a href=\"#snmp-传输到granfan\" class=\"headerlink\" title=\"snmp 传输到granfan\"></a>snmp 传输到granfan</h3><h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p><a href=\"https://github.com/infonova/prometheusbeat\">https://github.com/infonova/prometheusbeat</a><br><a href=\"https://prometheus.io/\">https://prometheus.io</a><br><a href=\"https://github.com/prometheus/snmp_exporter\">https://github.com/prometheus/snmp_exporter</a><br><a href=\"https://blog.csdn.net/huithe/article/details/7588673\">https://blog.csdn.net/huithe/article/details/7588673</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h2 id=\"下载并运行prometheus\"><a href=\"#下载并运行prometheus\" class=\"headerlink\" title=\"下载并运行prometheus\"></a>下载并运行prometheus</h2><pre><code>wget https://github.com/prometheus/prometheus/releases/download/v2.3.2/prometheus-2.3.2.linux-amd64.tar.gz\ntar -zxvf prometheus-2.3.2.linux-amd64.tar.gz\nmv prometheus-2.3.2.linux-amd64 prometheus\n</code></pre>\n<h2 id=\"配置prometheus监控本身\"><a href=\"#配置prometheus监控本身\" class=\"headerlink\" title=\"配置prometheus监控本身\"></a>配置prometheus监控本身</h2><pre><code>global:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n\n  # Attach these labels to any time series or alerts when communicating with\n  # external systems (federation, remote storage, Alertmanager).\n  external_labels:\n    monitor: &#39;codelab-monitor&#39;\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it&#39;s Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.\n  - job_name: &#39;prometheus&#39;\n\n    # Override the global default and scrape targets from this job every 5 seconds.\n    scrape_interval: 5s\n\n    static_configs:\n      - targets: [&#39;localhost:9090&#39;]\n</code></pre>\n<h3 id=\"启动prometheus\"><a href=\"#启动prometheus\" class=\"headerlink\" title=\"启动prometheus\"></a>启动prometheus</h3><pre><code>./prometheus --config.file=prometheus.yml\n</code></pre>\n<h3 id=\"打开浏览器验证\"><a href=\"#打开浏览器验证\" class=\"headerlink\" title=\"打开浏览器验证\"></a>打开浏览器验证</h3><p> <a href=\"http://localhost:9090/graph\">http://localhost:9090/graph</a></p>\n<h2 id=\"配置写数据到es\"><a href=\"#配置写数据到es\" class=\"headerlink\" title=\"配置写数据到es\"></a>配置写数据到es</h2><h3 id=\"下载prometheusbeat\"><a href=\"#下载prometheusbeat\" class=\"headerlink\" title=\"下载prometheusbeat\"></a>下载prometheusbeat</h3><pre><code>mkdir -p $&#123;GOPATH&#125;/github.com/infonova/prometheusbeat\ncd $&#123;GOPATH&#125;/github.com/infonova/prometheusbeat\ngit clone https://github.com/infonova/prometheusbeat\nmake package\n./prometheusbeat -c prometheusbeat.yml -e -d &quot;*&quot;\n\n# 查看服务是否启动\nss -lntp | grep 8088\nLISTEN     0      65535                     *:8088                     *:*      users:((&quot;prometheusbeat&quot;,29237,6))\n</code></pre>\n<h3 id=\"配置prometheus输入es\"><a href=\"#配置prometheus输入es\" class=\"headerlink\" title=\"配置prometheus输入es\"></a>配置prometheus输入es</h3><pre><code>#remote_write:\n#  - url: &quot;http://localhost:9201/write&quot;\nremote_write:\n  - url: &quot;http://localhost:8088/prometheus&quot;\n</code></pre>\n<h2 id=\"监控snmp\"><a href=\"#监控snmp\" class=\"headerlink\" title=\"监控snmp\"></a>监控snmp</h2><h3 id=\"安装snmp服务\"><a href=\"#安装snmp服务\" class=\"headerlink\" title=\"安装snmp服务\"></a>安装snmp服务</h3><pre><code>yum -y install net-snmp*\n防火墙\n#prometheus\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p tcp -m state --state NEW -m tcp --dport 9116 -j ACCEPT\n-A INPUT -s 192.168.1.0/23 -p udp -m state --state NEW -m udp --dport 161 -j ACCEPT\n</code></pre>\n<h3 id=\"安装snmp插件\"><a href=\"#安装snmp插件\" class=\"headerlink\" title=\"安装snmp插件\"></a>安装snmp插件</h3><pre><code>wget https://github.com/prometheus/snmp_exporter/releases/download/v0.11.0/snmp_exporter-0.11.0.linux-amd64.tar.gz\ntar -zxvf snmp_exporter-0.11.0.linux-amd64.tar.gz\n./snmp_exporter \n</code></pre>\n<h3 id=\"配置prometheus的snmp\"><a href=\"#配置prometheus的snmp\" class=\"headerlink\" title=\"配置prometheus的snmp\"></a>配置prometheus的snmp</h3><pre><code>  - job_name: &#39;snmp&#39;\n    static_configs:\n      - targets:\n        - 192.168.1.1\n        labels:\n          tag: aliyun-hb2-10\n    metrics_path: /snmp\n    params:\n      module: [if_mib]\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: 191.168.1.1:9116\n</code></pre>\n<h3 id=\"验证snmp监控数据\"><a href=\"#验证snmp监控数据\" class=\"headerlink\" title=\"验证snmp监控数据\"></a>验证snmp监控数据</h3><pre><code>curl &#39;http://localhost:9116/snmp?target=192.168.1.1&#39; \n</code></pre>\n<h3 id=\"snmp指标\"><a href=\"#snmp指标\" class=\"headerlink\" title=\"snmp指标\"></a>snmp指标</h3><p>针对普通网络设备的端口，MIB的相关定义是Interface组，主要管理如下信息:<br>ifIndex                 端口索引号<br>ifDescr                 端口描述<br>ifType                  端口类型<br>ifMtu                   最大传输包字节数<br>ifSpeed                 端口速度<br>ifPhysAddress           物理地址<br>ifOperStatus            操作状态<br>ifLastChange            上次状态更新时间<br><em>ifInOctets             输入字节数<br>*ifInUcastPkts          输入非广播包数<br>*ifInNUcastPkts         输入广播包数<br>*ifInDiscards           输入包丢弃数<br>*ifInErrors             输入包错误数<br>*ifInUnknownProtos      输入未知协议包数<br>*ifOutOctets            输出字节数<br>*ifOutUcastPkts         输出非广播包数<br>*ifOutNUcastPkts        输出广播包数<br>*ifOutDiscards          输出包丢弃数<br>*ifOutErrors            输出包错误数<br>ifOutQLen               输出队长<br>其中，</em>号标识的是与网络流量有关的信息。<br>1、获取CISCO2900端口1的上行总流量<br>          snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1<br>    返回结果<br>         IF-MIB::ifInOctets.1 = Counter32: 4861881<br>2、五秒后再获取一次<br>         snmpwalk -v 1 -c public 192.168.1.254 IF-MIB::ifInOctets.1<br>    返回结果<br>     IF-MIB::ifInOctets.1 = Counter32: 4870486<br>3、计算结果<br> （后值48704863-前值4861881）/ 5＝1721b/s  （应该是BYTE）</p>\n<h3 id=\"配置snmp告警指标\"><a href=\"#配置snmp告警指标\" class=\"headerlink\" title=\"配置snmp告警指标\"></a>配置snmp告警指标</h3><pre><code>cat rules/traffic.yml \ngroups:\n  - name: traffic\n    rules:\n    - record: traffic_out_bps \n      expr: (ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60\n      #expr: sum by (tag, job, instance, ifIndex) ((ifHCOutOctets - (ifHCOutOctets offset 1m)) *8/60)\n      #labels:\n      #  instance: &quot;&#123;&#123; $labels.instance &#125;&#125;&quot;\n      #  ifIndex: &quot;&#123;&#123; $labels.ifIndex &#125;&#125;&quot;\n    - record: traffic_in_bps\n      expr: (ifHCInOctets - (ifHCInOctets offset 1m)) *8/60\n\n    ### alert\n    - alert: BeijingProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=~&quot;7|9&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: BeijingProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=~&quot;7|9&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 500\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n\n    - alert: BeijingProxyWanTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=~&quot;6|8&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out bond0 has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: BeijingProxyWanTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=~&quot;6|8&quot;, tag=~&quot;beijing.+&quot;&#125;[5m]) /1024/1024)) &gt;= 30\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in bond0 has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n\n    - alert: AliyunProxyTrafficOutProblem\n      expr: (sum by(tag) (avg_over_time(traffic_out_bps&#123;ifIndex=&quot;2&quot;, tag=~&quot;aliyun.+&quot;&#125;[5m]) /1024/1024)) &gt; 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic out has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n    - alert: AliyunProxyTrafficInProblem\n      expr: (sum by(tag) (avg_over_time(traffic_in_bps&#123;ifIndex=&quot;2&quot;, tag=~&quot;aliyun.+&quot;&#125;[5m]) /1024/1024)) &gt; 200\n      for: 2m\n      labels:\n        level: CRITICAL\n      annotations:\n        message: &quot;traffic in has problem (network: &#123;&#123; $labels.tag &#125;&#125;, current: &#123;&#123; $value &#125;&#125;Mbps)&quot;\n</code></pre>\n<h3 id=\"snmp-传输到granfan\"><a href=\"#snmp-传输到granfan\" class=\"headerlink\" title=\"snmp 传输到granfan\"></a>snmp 传输到granfan</h3><h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p><a href=\"https://github.com/infonova/prometheusbeat\">https://github.com/infonova/prometheusbeat</a><br><a href=\"https://prometheus.io/\">https://prometheus.io</a><br><a href=\"https://github.com/prometheus/snmp_exporter\">https://github.com/prometheus/snmp_exporter</a><br><a href=\"https://blog.csdn.net/huithe/article/details/7588673\">https://blog.csdn.net/huithe/article/details/7588673</a></p>\n"},{"layout":"post","title":"metricbeat部署及监控linux系统指标汇总","date":"2018-07-30T03:09:54.000Z","author":"owelinux","excerpt":"metricbeat部署及监控linux系统指标汇总.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Metricbeat\n## 轻量型指标采集器\n用于从系统和服务收集指标。从 CPU 到内存，从 Redis 到 Nginx，Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据。\n\n## 系统级监控，更简洁\n将 Metricbeat 部署到您所有的 Linux、Windows 和 Mac 主机，并将它连接到 Elasticsearch 就大功告成啦：您可以获取系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据，以及获得如同系统上 top 命令类似的各个进程的统计数据。探索[在线演示](https://demo.elastic.co/app/kibana#/dashboard/Metricbeat-system-overview?_g=()&_a=(description:'',filters:!(),fullScreenMode:!f,options:(darkTheme:!f,useMargins:!f),panels:!((gridData:(h:5,i:'9',w:48,x:0,y:0),id:System-Navigation,panelIndex:'9',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'11',w:8,x:0,y:5),id:c6f2ffd0-4d17-11e7-a196-69b9a7a020a9,panelIndex:'11',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:25,i:'12',w:24,x:24,y:15),id:fe064790-1b1f-11e7-bec4-a5e9ec5cab8b,panelIndex:'12',type:visualization,version:'6.3.1'),(gridData:(h:25,i:'13',w:24,x:0,y:15),id:'855899e0-1b1c-11e7-b09e-037021c4f8df',panelIndex:'13',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%25%20-%2015%25':'rgb(247,252,245)','15%25%20-%2030%25':'rgb(199,233,192)','30%25%20-%2045%25':'rgb(116,196,118)','45%25%20-%2060%25':'rgb(35,139,69)'))),gridData:(h:30,i:'14',w:48,x:0,y:40),id:'7cdb1330-4d1a-11e7-a196-69b9a7a020a9',panelIndex:'14',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'16',w:8,x:32,y:5),id:'522ee670-1b92-11e7-bec4-a5e9ec5cab8b',panelIndex:'16',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'17',w:8,x:40,y:5),id:'1aae9140-1b93-11e7-8ada-3df93aab833e',panelIndex:'17',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'18',w:8,x:24,y:5),id:'825fdb80-4d1d-11e7-b5f2-2b7c1895bf32',panelIndex:'18',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'19',w:8,x:16,y:5),id:d3166e80-1b91-11e7-bec4-a5e9ec5cab8b,panelIndex:'19',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'20',w:8,x:8,y:5),id:'83e12df0-1b91-11e7-bec4-a5e9ec5cab8b',panelIndex:'20',type:visualization,version:'6.3.1')),query:(language:lucene,query:(query_string:(analyze_wildcard:!t,default_field:'*',query:'*'))),timeRestore:!f,title:'%5BMetricbeat%20System%5D%20Overview',viewMode:view))。\n\n## 安装 Metricbeat\n```\nwget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.3.2-linux-x86_64.tar.gz\ntar -zxvf metricbeat-6.3.2-linux-x86_64.tar.gz\nmv metricbeat-6.3.2-linux-x86_64 metricbeat\n```\n\n## 配置 Metricbeat\n```\nmetricbeat.config.modules:\n  path: ${path.config}/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nsetup.kibana:\n  host: \"localhost:5602\"\noutput.elasticsearch:\n  hosts: [\"192.168.1.1:29200\"]\n## 开启sytem监控\n$ cat modules.d/system.yml \n- module: system\n  period: 10s\n  metricsets:\n    - cpu\n    - load\n    - memory\n    - network\n    - process\n    - process_summary\n    #- core\n    - diskio\n    - socket\n  processes: ['.*']\n  process.include_top_n:\n    by_cpu: 5      # include top 5 processes by CPU\n    by_memory: 5   # include top 5 processes by memory\n\n- module: system\n  period: 1m\n  metricsets:\n    - filesystem\n    #- fsstat\n  processors:\n  - drop_event.when.regexp:\n      system.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'\n\n- module: system\n  period: 1m\n  metricsets:\n    - uptime\n```\n\n## 启动kibana、es、metricbeat\n```\n/usr/local/metricbeat/metricbeat -e -c /usr/local/metricbeat/metricbeat.yml\n```\n## 使用Granfan可视化 \n### 系统指标采集汇总\n\n| 指标类型 | 指标    |  指标含义  |\n| -------- | ---------------------:| :-------------------------: |\n| cpu      | system.cpu.total.pct | cpu使用总的百分比 |\n| cpu      | system.cpu.cores | cpu核数 |\n| cpu      | system.cpu.iowait.pct | 等待输入输出的CPU时间百分比 |\n| cpu      | system.cpu.user.pct | 用户空间占用CPU百分比 |\n| cpu      | system.cpu.system.pct | 内核空间占用CPU百分比 |\n| cpu      | system.cpu.nice.pct | 进程改变占用CPU百分比|\n| cpu      | system.cpu.idle.pct | 空闲CPU百分比 |\n| memory   | system.memory.used.bytes | 内存使用大小 |\n| memory   | system.memory.used.pct | 内存使用百分比 |\n| memory   | system.memory.free | 内存剩余大小 |\n| memory   | system.memory.total | 内存总大小 |\n| memory   | system.memory.swap.used.pct | swap内存使用百分比 |\n| memory   | system.memory.swap.used.bytes | swap内存使用大小 |\n| memory   | system.memory.swap.free | swap剩余内存 |\n| memory   | system.memory.swap.total | swap内存总大小 |\n| network  | system.network.name | 网卡名 |\n| network  | system.network.in.packets | 网卡入口包数量 |\n| network  | system.network.in.errors | 网卡入口错误包数量 |\n| network  | system.network.in.dropped | 网卡入口拒收包数量 |\n| network  | system.network.in.bytes | 网卡入口包大小 |\n| network  | system.network.out.packets\t| 网卡出口网卡包数量 |\n| network  | system.network.out.bytes | 网卡出口包大小 |\n| network  | system.network.out.errors | 网卡出口错误包数量 |\n| network  | system.network.out.dropped | 网卡出口拒收包数量 |\t\n| load  | system.load.1 | 1分钟的系统平均负载 |\n| load  | system.load.5 | 5分钟的系统平均负载 |\n| load  | system.load.15 | 15分钟的系统平均负载 |\n| process_summary | system.process.summary.stopped | 停止进程 | \n| process_summary | system.process.summary.zombie | 僵尸进程 |\n| process_summary | system.process.summary.unknown | 无状态进程 |\n| process_summary | system.process.summary.total | 进程总数 |\n| process_summary | system.process.summary.sleeping | 休眠进程 |\n| process_summary | system.process.summary.running | 运行进程 |\n| uptime | system.uptime.duration.ms | 系统运行时间 |\n| socket | system.socket.local.ip | 本机ip |\n| diskio | system.diskio.iostat.read.per_sec.bytes | 每秒从设备（drive expressed）读取的数据量(kB_read/s) |\n| diskio | system.diskio.iostat.write.per_sec.bytes | 每秒向设备（drive expressed）写入的数据量(kB_wrtn/s) | \n| diskio | system.diskio.iostat.read.request.per_sec | 每秒读取的扇区数(rsec/s) |\n| diskio | system.diskio.iostat.write.request.per_sec | 每秒写入的扇区数(wsec/s)\t |\n| diskio | system.diskio.iostat.read.request.merges_per_sec | 每秒这个设备相关的读取请求有多少被Merge(rrqm/s) |\n| diskio | system.diskio.iostat.write.request.merges_per_sec | 每秒这个设备相关的写入请求有多少被Merge(wrqm/s) |\n| diskio | system.diskio.iostat.await | 每一个IO请求的处理的平均时间（单位是微秒) |\n| diskio | system.diskio.read.bytes  | 读取的总数据量(kB_read) |\n| diskio | system.diskio.write.bytes | 写入的总数量数据量(kB_wrtn) | \n| filesystem | system.filesystem.device_name | 文件系统设备名 | \n| filesystem | system.filesystem.free | 磁盘剩余空间 |\n| filesystem | system.filesystem.mount_point | 磁盘挂载分区 |\n| filesystem | system.filesystem.total | 磁盘总大小 |\n| filesystem | system.filesystem.used.pct | 磁盘使用率 |\n| filesystem | system.filesystem.used.bytes | 磁盘使用大小 |\n| filesystem | system.filesystem.used.bytes | 磁盘使用大小 |\n\n### 增加主机分组，并在grafana引用\n```\n[root@bj-ops3 metricbeat]# grep -Ev '#|^$' metricbeat.yml \nmetricbeat.config.modules:\n  path: ${path.config}/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nname: 192.168.1.1\nfields:\n  group: OPS\nsetup.kibana:\n  host: \"localhost:5602\"\noutput.elasticsearch:\n  hosts: [\"192.168.1.1:29200\"]\n```\n## grafana配置\n![](https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/mericbeat_group.png)\n\n### 绘图模板\n[system-metrics](https://grafana.com/dashboards/7225)\n### 效果如下图\n![](https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/system_merticbeat.png)\n\n## 参考：\n> * [https://www.elastic.co/cn/products/beats/metricbeat](https://www.elastic.co/cn/products/beats/metricbeat)\n> * [https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html](https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html)\n","source":"_posts/2018-07-28-article10-linux-metricbeat-diskio.md","raw":"---\nlayout: post\ntitle:  \"metricbeat部署及监控linux系统指标汇总\"\ndate:   2018-07-30 11:09:54\nauthor: owelinux\ncategories: linux \ntags:  linux 监控 metricbeat\nexcerpt: metricbeat部署及监控linux系统指标汇总.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Metricbeat\n## 轻量型指标采集器\n用于从系统和服务收集指标。从 CPU 到内存，从 Redis 到 Nginx，Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据。\n\n## 系统级监控，更简洁\n将 Metricbeat 部署到您所有的 Linux、Windows 和 Mac 主机，并将它连接到 Elasticsearch 就大功告成啦：您可以获取系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据，以及获得如同系统上 top 命令类似的各个进程的统计数据。探索[在线演示](https://demo.elastic.co/app/kibana#/dashboard/Metricbeat-system-overview?_g=()&_a=(description:'',filters:!(),fullScreenMode:!f,options:(darkTheme:!f,useMargins:!f),panels:!((gridData:(h:5,i:'9',w:48,x:0,y:0),id:System-Navigation,panelIndex:'9',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'11',w:8,x:0,y:5),id:c6f2ffd0-4d17-11e7-a196-69b9a7a020a9,panelIndex:'11',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:25,i:'12',w:24,x:24,y:15),id:fe064790-1b1f-11e7-bec4-a5e9ec5cab8b,panelIndex:'12',type:visualization,version:'6.3.1'),(gridData:(h:25,i:'13',w:24,x:0,y:15),id:'855899e0-1b1c-11e7-b09e-037021c4f8df',panelIndex:'13',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%25%20-%2015%25':'rgb(247,252,245)','15%25%20-%2030%25':'rgb(199,233,192)','30%25%20-%2045%25':'rgb(116,196,118)','45%25%20-%2060%25':'rgb(35,139,69)'))),gridData:(h:30,i:'14',w:48,x:0,y:40),id:'7cdb1330-4d1a-11e7-a196-69b9a7a020a9',panelIndex:'14',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'16',w:8,x:32,y:5),id:'522ee670-1b92-11e7-bec4-a5e9ec5cab8b',panelIndex:'16',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'17',w:8,x:40,y:5),id:'1aae9140-1b93-11e7-8ada-3df93aab833e',panelIndex:'17',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'18',w:8,x:24,y:5),id:'825fdb80-4d1d-11e7-b5f2-2b7c1895bf32',panelIndex:'18',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'19',w:8,x:16,y:5),id:d3166e80-1b91-11e7-bec4-a5e9ec5cab8b,panelIndex:'19',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'20',w:8,x:8,y:5),id:'83e12df0-1b91-11e7-bec4-a5e9ec5cab8b',panelIndex:'20',type:visualization,version:'6.3.1')),query:(language:lucene,query:(query_string:(analyze_wildcard:!t,default_field:'*',query:'*'))),timeRestore:!f,title:'%5BMetricbeat%20System%5D%20Overview',viewMode:view))。\n\n## 安装 Metricbeat\n```\nwget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.3.2-linux-x86_64.tar.gz\ntar -zxvf metricbeat-6.3.2-linux-x86_64.tar.gz\nmv metricbeat-6.3.2-linux-x86_64 metricbeat\n```\n\n## 配置 Metricbeat\n```\nmetricbeat.config.modules:\n  path: ${path.config}/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nsetup.kibana:\n  host: \"localhost:5602\"\noutput.elasticsearch:\n  hosts: [\"192.168.1.1:29200\"]\n## 开启sytem监控\n$ cat modules.d/system.yml \n- module: system\n  period: 10s\n  metricsets:\n    - cpu\n    - load\n    - memory\n    - network\n    - process\n    - process_summary\n    #- core\n    - diskio\n    - socket\n  processes: ['.*']\n  process.include_top_n:\n    by_cpu: 5      # include top 5 processes by CPU\n    by_memory: 5   # include top 5 processes by memory\n\n- module: system\n  period: 1m\n  metricsets:\n    - filesystem\n    #- fsstat\n  processors:\n  - drop_event.when.regexp:\n      system.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'\n\n- module: system\n  period: 1m\n  metricsets:\n    - uptime\n```\n\n## 启动kibana、es、metricbeat\n```\n/usr/local/metricbeat/metricbeat -e -c /usr/local/metricbeat/metricbeat.yml\n```\n## 使用Granfan可视化 \n### 系统指标采集汇总\n\n| 指标类型 | 指标    |  指标含义  |\n| -------- | ---------------------:| :-------------------------: |\n| cpu      | system.cpu.total.pct | cpu使用总的百分比 |\n| cpu      | system.cpu.cores | cpu核数 |\n| cpu      | system.cpu.iowait.pct | 等待输入输出的CPU时间百分比 |\n| cpu      | system.cpu.user.pct | 用户空间占用CPU百分比 |\n| cpu      | system.cpu.system.pct | 内核空间占用CPU百分比 |\n| cpu      | system.cpu.nice.pct | 进程改变占用CPU百分比|\n| cpu      | system.cpu.idle.pct | 空闲CPU百分比 |\n| memory   | system.memory.used.bytes | 内存使用大小 |\n| memory   | system.memory.used.pct | 内存使用百分比 |\n| memory   | system.memory.free | 内存剩余大小 |\n| memory   | system.memory.total | 内存总大小 |\n| memory   | system.memory.swap.used.pct | swap内存使用百分比 |\n| memory   | system.memory.swap.used.bytes | swap内存使用大小 |\n| memory   | system.memory.swap.free | swap剩余内存 |\n| memory   | system.memory.swap.total | swap内存总大小 |\n| network  | system.network.name | 网卡名 |\n| network  | system.network.in.packets | 网卡入口包数量 |\n| network  | system.network.in.errors | 网卡入口错误包数量 |\n| network  | system.network.in.dropped | 网卡入口拒收包数量 |\n| network  | system.network.in.bytes | 网卡入口包大小 |\n| network  | system.network.out.packets\t| 网卡出口网卡包数量 |\n| network  | system.network.out.bytes | 网卡出口包大小 |\n| network  | system.network.out.errors | 网卡出口错误包数量 |\n| network  | system.network.out.dropped | 网卡出口拒收包数量 |\t\n| load  | system.load.1 | 1分钟的系统平均负载 |\n| load  | system.load.5 | 5分钟的系统平均负载 |\n| load  | system.load.15 | 15分钟的系统平均负载 |\n| process_summary | system.process.summary.stopped | 停止进程 | \n| process_summary | system.process.summary.zombie | 僵尸进程 |\n| process_summary | system.process.summary.unknown | 无状态进程 |\n| process_summary | system.process.summary.total | 进程总数 |\n| process_summary | system.process.summary.sleeping | 休眠进程 |\n| process_summary | system.process.summary.running | 运行进程 |\n| uptime | system.uptime.duration.ms | 系统运行时间 |\n| socket | system.socket.local.ip | 本机ip |\n| diskio | system.diskio.iostat.read.per_sec.bytes | 每秒从设备（drive expressed）读取的数据量(kB_read/s) |\n| diskio | system.diskio.iostat.write.per_sec.bytes | 每秒向设备（drive expressed）写入的数据量(kB_wrtn/s) | \n| diskio | system.diskio.iostat.read.request.per_sec | 每秒读取的扇区数(rsec/s) |\n| diskio | system.diskio.iostat.write.request.per_sec | 每秒写入的扇区数(wsec/s)\t |\n| diskio | system.diskio.iostat.read.request.merges_per_sec | 每秒这个设备相关的读取请求有多少被Merge(rrqm/s) |\n| diskio | system.diskio.iostat.write.request.merges_per_sec | 每秒这个设备相关的写入请求有多少被Merge(wrqm/s) |\n| diskio | system.diskio.iostat.await | 每一个IO请求的处理的平均时间（单位是微秒) |\n| diskio | system.diskio.read.bytes  | 读取的总数据量(kB_read) |\n| diskio | system.diskio.write.bytes | 写入的总数量数据量(kB_wrtn) | \n| filesystem | system.filesystem.device_name | 文件系统设备名 | \n| filesystem | system.filesystem.free | 磁盘剩余空间 |\n| filesystem | system.filesystem.mount_point | 磁盘挂载分区 |\n| filesystem | system.filesystem.total | 磁盘总大小 |\n| filesystem | system.filesystem.used.pct | 磁盘使用率 |\n| filesystem | system.filesystem.used.bytes | 磁盘使用大小 |\n| filesystem | system.filesystem.used.bytes | 磁盘使用大小 |\n\n### 增加主机分组，并在grafana引用\n```\n[root@bj-ops3 metricbeat]# grep -Ev '#|^$' metricbeat.yml \nmetricbeat.config.modules:\n  path: ${path.config}/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nname: 192.168.1.1\nfields:\n  group: OPS\nsetup.kibana:\n  host: \"localhost:5602\"\noutput.elasticsearch:\n  hosts: [\"192.168.1.1:29200\"]\n```\n## grafana配置\n![](https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/mericbeat_group.png)\n\n### 绘图模板\n[system-metrics](https://grafana.com/dashboards/7225)\n### 效果如下图\n![](https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/system_merticbeat.png)\n\n## 参考：\n> * [https://www.elastic.co/cn/products/beats/metricbeat](https://www.elastic.co/cn/products/beats/metricbeat)\n> * [https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html](https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html)\n","slug":"2018-07-28-article10-linux-metricbeat-diskio","published":1,"updated":"2021-02-09T02:00:24.565Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzm0007yc977l5mgsrc","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Metricbeat\"><a href=\"#Metricbeat\" class=\"headerlink\" title=\"Metricbeat\"></a>Metricbeat</h1><h2 id=\"轻量型指标采集器\"><a href=\"#轻量型指标采集器\" class=\"headerlink\" title=\"轻量型指标采集器\"></a>轻量型指标采集器</h2><p>用于从系统和服务收集指标。从 CPU 到内存，从 Redis 到 Nginx，Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据。</p>\n<h2 id=\"系统级监控，更简洁\"><a href=\"#系统级监控，更简洁\" class=\"headerlink\" title=\"系统级监控，更简洁\"></a>系统级监控，更简洁</h2><p>将 Metricbeat 部署到您所有的 Linux、Windows 和 Mac 主机，并将它连接到 Elasticsearch 就大功告成啦：您可以获取系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据，以及获得如同系统上 top 命令类似的各个进程的统计数据。探索<a href=\"https://demo.elastic.co/app/kibana#/dashboard/Metricbeat-system-overview?_g=()&_a=(description:'',filters:!(),fullScreenMode:!f,options:(darkTheme:!f,useMargins:!f),panels:!((gridData:(h:5,i:'9',w:48,x:0,y:0),id:System-Navigation,panelIndex:'9',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'11',w:8,x:0,y:5),id:c6f2ffd0-4d17-11e7-a196-69b9a7a020a9,panelIndex:'11',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:25,i:'12',w:24,x:24,y:15),id:fe064790-1b1f-11e7-bec4-a5e9ec5cab8b,panelIndex:'12',type:visualization,version:'6.3.1'),(gridData:(h:25,i:'13',w:24,x:0,y:15),id:'855899e0-1b1c-11e7-b09e-037021c4f8df',panelIndex:'13',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%25%20-%2015%25':'rgb(247,252,245)','15%25%20-%2030%25':'rgb(199,233,192)','30%25%20-%2045%25':'rgb(116,196,118)','45%25%20-%2060%25':'rgb(35,139,69)'))),gridData:(h:30,i:'14',w:48,x:0,y:40),id:'7cdb1330-4d1a-11e7-a196-69b9a7a020a9',panelIndex:'14',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'16',w:8,x:32,y:5),id:'522ee670-1b92-11e7-bec4-a5e9ec5cab8b',panelIndex:'16',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'17',w:8,x:40,y:5),id:'1aae9140-1b93-11e7-8ada-3df93aab833e',panelIndex:'17',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'18',w:8,x:24,y:5),id:'825fdb80-4d1d-11e7-b5f2-2b7c1895bf32',panelIndex:'18',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'19',w:8,x:16,y:5),id:d3166e80-1b91-11e7-bec4-a5e9ec5cab8b,panelIndex:'19',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'20',w:8,x:8,y:5),id:'83e12df0-1b91-11e7-bec4-a5e9ec5cab8b',panelIndex:'20',type:visualization,version:'6.3.1')),query:(language:lucene,query:(query_string:(analyze_wildcard:!t,default_field:'*',query:'*'))),timeRestore:!f,title:'%5BMetricbeat%20System%5D%20Overview',viewMode:view)\">在线演示</a>。</p>\n<h2 id=\"安装-Metricbeat\"><a href=\"#安装-Metricbeat\" class=\"headerlink\" title=\"安装 Metricbeat\"></a>安装 Metricbeat</h2><pre><code>wget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.3.2-linux-x86_64.tar.gz\ntar -zxvf metricbeat-6.3.2-linux-x86_64.tar.gz\nmv metricbeat-6.3.2-linux-x86_64 metricbeat\n</code></pre>\n<h2 id=\"配置-Metricbeat\"><a href=\"#配置-Metricbeat\" class=\"headerlink\" title=\"配置 Metricbeat\"></a>配置 Metricbeat</h2><pre><code>metricbeat.config.modules:\n  path: $&#123;path.config&#125;/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nsetup.kibana:\n  host: &quot;localhost:5602&quot;\noutput.elasticsearch:\n  hosts: [&quot;192.168.1.1:29200&quot;]\n## 开启sytem监控\n$ cat modules.d/system.yml \n- module: system\n  period: 10s\n  metricsets:\n    - cpu\n    - load\n    - memory\n    - network\n    - process\n    - process_summary\n    #- core\n    - diskio\n    - socket\n  processes: [&#39;.*&#39;]\n  process.include_top_n:\n    by_cpu: 5      # include top 5 processes by CPU\n    by_memory: 5   # include top 5 processes by memory\n\n- module: system\n  period: 1m\n  metricsets:\n    - filesystem\n    #- fsstat\n  processors:\n  - drop_event.when.regexp:\n      system.filesystem.mount_point: &#39;^/(sys|cgroup|proc|dev|etc|host|lib)($|/)&#39;\n\n- module: system\n  period: 1m\n  metricsets:\n    - uptime\n</code></pre>\n<h2 id=\"启动kibana、es、metricbeat\"><a href=\"#启动kibana、es、metricbeat\" class=\"headerlink\" title=\"启动kibana、es、metricbeat\"></a>启动kibana、es、metricbeat</h2><pre><code>/usr/local/metricbeat/metricbeat -e -c /usr/local/metricbeat/metricbeat.yml\n</code></pre>\n<h2 id=\"使用Granfan可视化\"><a href=\"#使用Granfan可视化\" class=\"headerlink\" title=\"使用Granfan可视化\"></a>使用Granfan可视化</h2><h3 id=\"系统指标采集汇总\"><a href=\"#系统指标采集汇总\" class=\"headerlink\" title=\"系统指标采集汇总\"></a>系统指标采集汇总</h3><table>\n<thead>\n<tr>\n<th>指标类型</th>\n<th align=\"right\">指标</th>\n<th align=\"center\">指标含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.total.pct</td>\n<td align=\"center\">cpu使用总的百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.cores</td>\n<td align=\"center\">cpu核数</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.iowait.pct</td>\n<td align=\"center\">等待输入输出的CPU时间百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.user.pct</td>\n<td align=\"center\">用户空间占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.system.pct</td>\n<td align=\"center\">内核空间占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.nice.pct</td>\n<td align=\"center\">进程改变占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.idle.pct</td>\n<td align=\"center\">空闲CPU百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.used.bytes</td>\n<td align=\"center\">内存使用大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.used.pct</td>\n<td align=\"center\">内存使用百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.free</td>\n<td align=\"center\">内存剩余大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.total</td>\n<td align=\"center\">内存总大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.used.pct</td>\n<td align=\"center\">swap内存使用百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.used.bytes</td>\n<td align=\"center\">swap内存使用大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.free</td>\n<td align=\"center\">swap剩余内存</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.total</td>\n<td align=\"center\">swap内存总大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.name</td>\n<td align=\"center\">网卡名</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.packets</td>\n<td align=\"center\">网卡入口包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.errors</td>\n<td align=\"center\">网卡入口错误包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.dropped</td>\n<td align=\"center\">网卡入口拒收包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.bytes</td>\n<td align=\"center\">网卡入口包大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.packets</td>\n<td align=\"center\">网卡出口网卡包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.bytes</td>\n<td align=\"center\">网卡出口包大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.errors</td>\n<td align=\"center\">网卡出口错误包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.dropped</td>\n<td align=\"center\">网卡出口拒收包数量</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.1</td>\n<td align=\"center\">1分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.5</td>\n<td align=\"center\">5分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.15</td>\n<td align=\"center\">15分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.stopped</td>\n<td align=\"center\">停止进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.zombie</td>\n<td align=\"center\">僵尸进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.unknown</td>\n<td align=\"center\">无状态进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.total</td>\n<td align=\"center\">进程总数</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.sleeping</td>\n<td align=\"center\">休眠进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.running</td>\n<td align=\"center\">运行进程</td>\n</tr>\n<tr>\n<td>uptime</td>\n<td align=\"right\">system.uptime.duration.ms</td>\n<td align=\"center\">系统运行时间</td>\n</tr>\n<tr>\n<td>socket</td>\n<td align=\"right\">system.socket.local.ip</td>\n<td align=\"center\">本机ip</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.per_sec.bytes</td>\n<td align=\"center\">每秒从设备（drive expressed）读取的数据量(kB_read/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.per_sec.bytes</td>\n<td align=\"center\">每秒向设备（drive expressed）写入的数据量(kB_wrtn/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.request.per_sec</td>\n<td align=\"center\">每秒读取的扇区数(rsec/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.request.per_sec</td>\n<td align=\"center\">每秒写入的扇区数(wsec/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.request.merges_per_sec</td>\n<td align=\"center\">每秒这个设备相关的读取请求有多少被Merge(rrqm/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.request.merges_per_sec</td>\n<td align=\"center\">每秒这个设备相关的写入请求有多少被Merge(wrqm/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.await</td>\n<td align=\"center\">每一个IO请求的处理的平均时间（单位是微秒)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.read.bytes</td>\n<td align=\"center\">读取的总数据量(kB_read)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.write.bytes</td>\n<td align=\"center\">写入的总数量数据量(kB_wrtn)</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.device_name</td>\n<td align=\"center\">文件系统设备名</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.free</td>\n<td align=\"center\">磁盘剩余空间</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.mount_point</td>\n<td align=\"center\">磁盘挂载分区</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.total</td>\n<td align=\"center\">磁盘总大小</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.pct</td>\n<td align=\"center\">磁盘使用率</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.bytes</td>\n<td align=\"center\">磁盘使用大小</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.bytes</td>\n<td align=\"center\">磁盘使用大小</td>\n</tr>\n</tbody></table>\n<h3 id=\"增加主机分组，并在grafana引用\"><a href=\"#增加主机分组，并在grafana引用\" class=\"headerlink\" title=\"增加主机分组，并在grafana引用\"></a>增加主机分组，并在grafana引用</h3><pre><code>[root@bj-ops3 metricbeat]# grep -Ev &#39;#|^$&#39; metricbeat.yml \nmetricbeat.config.modules:\n  path: $&#123;path.config&#125;/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nname: 192.168.1.1\nfields:\n  group: OPS\nsetup.kibana:\n  host: &quot;localhost:5602&quot;\noutput.elasticsearch:\n  hosts: [&quot;192.168.1.1:29200&quot;]\n</code></pre>\n<h2 id=\"grafana配置\"><a href=\"#grafana配置\" class=\"headerlink\" title=\"grafana配置\"></a>grafana配置</h2><p><img src=\"https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/mericbeat_group.png\"></p>\n<h3 id=\"绘图模板\"><a href=\"#绘图模板\" class=\"headerlink\" title=\"绘图模板\"></a>绘图模板</h3><p><a href=\"https://grafana.com/dashboards/7225\">system-metrics</a></p>\n<h3 id=\"效果如下图\"><a href=\"#效果如下图\" class=\"headerlink\" title=\"效果如下图\"></a>效果如下图</h3><p><img src=\"https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/system_merticbeat.png\"></p>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/cn/products/beats/metricbeat\">https://www.elastic.co/cn/products/beats/metricbeat</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html\">https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Metricbeat\"><a href=\"#Metricbeat\" class=\"headerlink\" title=\"Metricbeat\"></a>Metricbeat</h1><h2 id=\"轻量型指标采集器\"><a href=\"#轻量型指标采集器\" class=\"headerlink\" title=\"轻量型指标采集器\"></a>轻量型指标采集器</h2><p>用于从系统和服务收集指标。从 CPU 到内存，从 Redis 到 Nginx，Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据。</p>\n<h2 id=\"系统级监控，更简洁\"><a href=\"#系统级监控，更简洁\" class=\"headerlink\" title=\"系统级监控，更简洁\"></a>系统级监控，更简洁</h2><p>将 Metricbeat 部署到您所有的 Linux、Windows 和 Mac 主机，并将它连接到 Elasticsearch 就大功告成啦：您可以获取系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据，以及获得如同系统上 top 命令类似的各个进程的统计数据。探索<a href=\"https://demo.elastic.co/app/kibana#/dashboard/Metricbeat-system-overview?_g=()&_a=(description:'',filters:!(),fullScreenMode:!f,options:(darkTheme:!f,useMargins:!f),panels:!((gridData:(h:5,i:'9',w:48,x:0,y:0),id:System-Navigation,panelIndex:'9',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'11',w:8,x:0,y:5),id:c6f2ffd0-4d17-11e7-a196-69b9a7a020a9,panelIndex:'11',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:25,i:'12',w:24,x:24,y:15),id:fe064790-1b1f-11e7-bec4-a5e9ec5cab8b,panelIndex:'12',type:visualization,version:'6.3.1'),(gridData:(h:25,i:'13',w:24,x:0,y:15),id:'855899e0-1b1c-11e7-b09e-037021c4f8df',panelIndex:'13',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%25%20-%2015%25':'rgb(247,252,245)','15%25%20-%2030%25':'rgb(199,233,192)','30%25%20-%2045%25':'rgb(116,196,118)','45%25%20-%2060%25':'rgb(35,139,69)'))),gridData:(h:30,i:'14',w:48,x:0,y:40),id:'7cdb1330-4d1a-11e7-a196-69b9a7a020a9',panelIndex:'14',type:visualization,version:'6.3.1'),(embeddableConfig:(vis:(defaultColors:('0%20-%20100':'rgb(0,104,55)'))),gridData:(h:10,i:'16',w:8,x:32,y:5),id:'522ee670-1b92-11e7-bec4-a5e9ec5cab8b',panelIndex:'16',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'17',w:8,x:40,y:5),id:'1aae9140-1b93-11e7-8ada-3df93aab833e',panelIndex:'17',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'18',w:8,x:24,y:5),id:'825fdb80-4d1d-11e7-b5f2-2b7c1895bf32',panelIndex:'18',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'19',w:8,x:16,y:5),id:d3166e80-1b91-11e7-bec4-a5e9ec5cab8b,panelIndex:'19',type:visualization,version:'6.3.1'),(gridData:(h:10,i:'20',w:8,x:8,y:5),id:'83e12df0-1b91-11e7-bec4-a5e9ec5cab8b',panelIndex:'20',type:visualization,version:'6.3.1')),query:(language:lucene,query:(query_string:(analyze_wildcard:!t,default_field:'*',query:'*'))),timeRestore:!f,title:'%5BMetricbeat%20System%5D%20Overview',viewMode:view)\">在线演示</a>。</p>\n<h2 id=\"安装-Metricbeat\"><a href=\"#安装-Metricbeat\" class=\"headerlink\" title=\"安装 Metricbeat\"></a>安装 Metricbeat</h2><pre><code>wget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.3.2-linux-x86_64.tar.gz\ntar -zxvf metricbeat-6.3.2-linux-x86_64.tar.gz\nmv metricbeat-6.3.2-linux-x86_64 metricbeat\n</code></pre>\n<h2 id=\"配置-Metricbeat\"><a href=\"#配置-Metricbeat\" class=\"headerlink\" title=\"配置 Metricbeat\"></a>配置 Metricbeat</h2><pre><code>metricbeat.config.modules:\n  path: $&#123;path.config&#125;/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nsetup.kibana:\n  host: &quot;localhost:5602&quot;\noutput.elasticsearch:\n  hosts: [&quot;192.168.1.1:29200&quot;]\n## 开启sytem监控\n$ cat modules.d/system.yml \n- module: system\n  period: 10s\n  metricsets:\n    - cpu\n    - load\n    - memory\n    - network\n    - process\n    - process_summary\n    #- core\n    - diskio\n    - socket\n  processes: [&#39;.*&#39;]\n  process.include_top_n:\n    by_cpu: 5      # include top 5 processes by CPU\n    by_memory: 5   # include top 5 processes by memory\n\n- module: system\n  period: 1m\n  metricsets:\n    - filesystem\n    #- fsstat\n  processors:\n  - drop_event.when.regexp:\n      system.filesystem.mount_point: &#39;^/(sys|cgroup|proc|dev|etc|host|lib)($|/)&#39;\n\n- module: system\n  period: 1m\n  metricsets:\n    - uptime\n</code></pre>\n<h2 id=\"启动kibana、es、metricbeat\"><a href=\"#启动kibana、es、metricbeat\" class=\"headerlink\" title=\"启动kibana、es、metricbeat\"></a>启动kibana、es、metricbeat</h2><pre><code>/usr/local/metricbeat/metricbeat -e -c /usr/local/metricbeat/metricbeat.yml\n</code></pre>\n<h2 id=\"使用Granfan可视化\"><a href=\"#使用Granfan可视化\" class=\"headerlink\" title=\"使用Granfan可视化\"></a>使用Granfan可视化</h2><h3 id=\"系统指标采集汇总\"><a href=\"#系统指标采集汇总\" class=\"headerlink\" title=\"系统指标采集汇总\"></a>系统指标采集汇总</h3><table>\n<thead>\n<tr>\n<th>指标类型</th>\n<th align=\"right\">指标</th>\n<th align=\"center\">指标含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.total.pct</td>\n<td align=\"center\">cpu使用总的百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.cores</td>\n<td align=\"center\">cpu核数</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.iowait.pct</td>\n<td align=\"center\">等待输入输出的CPU时间百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.user.pct</td>\n<td align=\"center\">用户空间占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.system.pct</td>\n<td align=\"center\">内核空间占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.nice.pct</td>\n<td align=\"center\">进程改变占用CPU百分比</td>\n</tr>\n<tr>\n<td>cpu</td>\n<td align=\"right\">system.cpu.idle.pct</td>\n<td align=\"center\">空闲CPU百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.used.bytes</td>\n<td align=\"center\">内存使用大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.used.pct</td>\n<td align=\"center\">内存使用百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.free</td>\n<td align=\"center\">内存剩余大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.total</td>\n<td align=\"center\">内存总大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.used.pct</td>\n<td align=\"center\">swap内存使用百分比</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.used.bytes</td>\n<td align=\"center\">swap内存使用大小</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.free</td>\n<td align=\"center\">swap剩余内存</td>\n</tr>\n<tr>\n<td>memory</td>\n<td align=\"right\">system.memory.swap.total</td>\n<td align=\"center\">swap内存总大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.name</td>\n<td align=\"center\">网卡名</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.packets</td>\n<td align=\"center\">网卡入口包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.errors</td>\n<td align=\"center\">网卡入口错误包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.dropped</td>\n<td align=\"center\">网卡入口拒收包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.in.bytes</td>\n<td align=\"center\">网卡入口包大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.packets</td>\n<td align=\"center\">网卡出口网卡包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.bytes</td>\n<td align=\"center\">网卡出口包大小</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.errors</td>\n<td align=\"center\">网卡出口错误包数量</td>\n</tr>\n<tr>\n<td>network</td>\n<td align=\"right\">system.network.out.dropped</td>\n<td align=\"center\">网卡出口拒收包数量</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.1</td>\n<td align=\"center\">1分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.5</td>\n<td align=\"center\">5分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>load</td>\n<td align=\"right\">system.load.15</td>\n<td align=\"center\">15分钟的系统平均负载</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.stopped</td>\n<td align=\"center\">停止进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.zombie</td>\n<td align=\"center\">僵尸进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.unknown</td>\n<td align=\"center\">无状态进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.total</td>\n<td align=\"center\">进程总数</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.sleeping</td>\n<td align=\"center\">休眠进程</td>\n</tr>\n<tr>\n<td>process_summary</td>\n<td align=\"right\">system.process.summary.running</td>\n<td align=\"center\">运行进程</td>\n</tr>\n<tr>\n<td>uptime</td>\n<td align=\"right\">system.uptime.duration.ms</td>\n<td align=\"center\">系统运行时间</td>\n</tr>\n<tr>\n<td>socket</td>\n<td align=\"right\">system.socket.local.ip</td>\n<td align=\"center\">本机ip</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.per_sec.bytes</td>\n<td align=\"center\">每秒从设备（drive expressed）读取的数据量(kB_read/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.per_sec.bytes</td>\n<td align=\"center\">每秒向设备（drive expressed）写入的数据量(kB_wrtn/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.request.per_sec</td>\n<td align=\"center\">每秒读取的扇区数(rsec/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.request.per_sec</td>\n<td align=\"center\">每秒写入的扇区数(wsec/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.read.request.merges_per_sec</td>\n<td align=\"center\">每秒这个设备相关的读取请求有多少被Merge(rrqm/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.write.request.merges_per_sec</td>\n<td align=\"center\">每秒这个设备相关的写入请求有多少被Merge(wrqm/s)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.iostat.await</td>\n<td align=\"center\">每一个IO请求的处理的平均时间（单位是微秒)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.read.bytes</td>\n<td align=\"center\">读取的总数据量(kB_read)</td>\n</tr>\n<tr>\n<td>diskio</td>\n<td align=\"right\">system.diskio.write.bytes</td>\n<td align=\"center\">写入的总数量数据量(kB_wrtn)</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.device_name</td>\n<td align=\"center\">文件系统设备名</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.free</td>\n<td align=\"center\">磁盘剩余空间</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.mount_point</td>\n<td align=\"center\">磁盘挂载分区</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.total</td>\n<td align=\"center\">磁盘总大小</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.pct</td>\n<td align=\"center\">磁盘使用率</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.bytes</td>\n<td align=\"center\">磁盘使用大小</td>\n</tr>\n<tr>\n<td>filesystem</td>\n<td align=\"right\">system.filesystem.used.bytes</td>\n<td align=\"center\">磁盘使用大小</td>\n</tr>\n</tbody></table>\n<h3 id=\"增加主机分组，并在grafana引用\"><a href=\"#增加主机分组，并在grafana引用\" class=\"headerlink\" title=\"增加主机分组，并在grafana引用\"></a>增加主机分组，并在grafana引用</h3><pre><code>[root@bj-ops3 metricbeat]# grep -Ev &#39;#|^$&#39; metricbeat.yml \nmetricbeat.config.modules:\n  path: $&#123;path.config&#125;/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 1\n  index.codec: best_compression\nname: 192.168.1.1\nfields:\n  group: OPS\nsetup.kibana:\n  host: &quot;localhost:5602&quot;\noutput.elasticsearch:\n  hosts: [&quot;192.168.1.1:29200&quot;]\n</code></pre>\n<h2 id=\"grafana配置\"><a href=\"#grafana配置\" class=\"headerlink\" title=\"grafana配置\"></a>grafana配置</h2><p><img src=\"https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/mericbeat_group.png\"></p>\n<h3 id=\"绘图模板\"><a href=\"#绘图模板\" class=\"headerlink\" title=\"绘图模板\"></a>绘图模板</h3><p><a href=\"https://grafana.com/dashboards/7225\">system-metrics</a></p>\n<h3 id=\"效果如下图\"><a href=\"#效果如下图\" class=\"headerlink\" title=\"效果如下图\"></a>效果如下图</h3><p><img src=\"https://owelinux.github.io/images/2018-07-28-article10-linux-metricbeat-diskio/system_merticbeat.png\"></p>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/cn/products/beats/metricbeat\">https://www.elastic.co/cn/products/beats/metricbeat</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html\">https://www.elastic.co/guide/en/beats/metricbeat/current/exported-fields-system.html</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"linux常用命令lsof详解","date":"2018-07-28T01:35:54.000Z","author":"owelinux","excerpt":"linux常用命令lsof详解.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# linux常用命令lsof详解\n\n## lsof 简介  \nlsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接 和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 \n\n可以列出被进程所打开的文件的信息。被打开的文件可以是：\n> * 1.普通的文件\n> * 2.目录  \n> * 3.网络文件系统的文件\n> * 4.字符设备文件  \n> * 5.(函数)共享库  \n> * 6.管道，命名管道 \n> * 7.符号链接\n> * 8.底层的socket字流，网络socket，unix域名socket\n> * 9.在linux里面，大部分的东西都是被当做文件的…..还有其他很多\n## lsof 常用参数\n> * lsof  filename 显示打开指定文件的所有进程 \n> * lsof -a 表示两个参数都必须满足时才显示结果 \n> * lsof -c string   显示COMMAND列中包含指定字符的进程所有打开的文件 \n> * lsof -u username  显示所属user进程打开的文件 \n> * lsof -g gid 显示归属gid的进程情况 \n> * lsof +d /DIR/ 显示目录下被进程打开的文件 \n> * lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 \n> * lsof -d FD 显示指定文件描述符的进程 \n> * lsof -n 不将IP转换为hostname，缺省是不加上-n参数 \n> * lsof -i 用以显示符合条件的进程情况 \n> * lsof -i[46] [protocol][@hostname|hostaddr][:service|port]  \n> * lsof +L/-L 打开或关闭文件的连结数计算，当+L没有指定时，所有的连结数都会显示(默认)；若+L后指定数字，则只要连结数小于该数字的信息会显示；连结数会显示在NLINK列。\n例如：+L1将显示没有unlinked的文件信息；+aL1，则显示指定文件系统所有unlinked的文件信息。-L 默认参数，其后不能跟数字，将不显示连结数信息lsof +L1\n\n## lsof 使用实例\n### 1.列出所有打开的文件:\n```\nlsof\n备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位\n```\n### 2. 查看谁正在使用某个文件\n```\nlsof   /filepath/file\n```\n### 3.递归查看某个目录的文件信息\n```\nlsof +D /filepath/filepath2/\n备注: 使用了+D，对应目录下的所有子目录和文件都会被列出\n```\n### 4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法\n```\nlsof | grep ‘/filepath/filepath2/’\n```\n### 5. 列出某个用户打开的文件信息\n```\nlsof  -u username\n```\n### 6. 列出某个程序所打开的文件信息\n```\nlsof -c mysql\n备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了\n```\n### 7. 列出多个程序多打开的文件信息\n```\nlsof -c mysql -c apache\n```\n### 8. 列出某个用户以及某个程序所打开的文件信息\n```\nlsof -u test -c mysql\n```\n### 9. 列出除了某个用户外的被打开的文件信息\n```\nlsof   -u ^root\n备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示\n```\n### 10. 通过某个进程号显示该进行打开的文件\n```\nlsof -p 1\n```\n### 11. 列出多个进程号对应的文件信息\n```\nlsof -p 123,456,789\n```\n### 12. 列出除了某个进程号，其他进程号所打开的文件信息\n```\nlsof -p ^1\n```\n### 13 . 列出所有的网络连接\n```\nlsof -i\n```\n### 14. 列出所有tcp 网络连接信息\n```\nlsof  -i tcp\n```\n### 15. 列出所有udp网络连接信息\n```\nlsof  -i udp\n```\n### 16. 列出谁在使用某个端口\n```\nlsof -i:3306\n```\n### 17. 列出谁在使用某个特定的udp端口\n```\nlsof -i udp:55\nlsof -i tcp:80\n```\n### 18. 列出某个用户的所有活跃的网络端口\n```\nlsof  -a -u test -i\n```\n### 19. 列出所有网络文件系统\n```\nlsof -N\n```\n### 20.域名socket文件\n```\nlsof -u\n```\n### 21.某个用户组所打开的文件信息\n```\nlsof -g 5555\n```\n### 22. 根据文件描述列出对应的文件信息\n```\nlsof -d description(like 2)\n```\n### 23. 根据文件描述范围列出文件信息\n```\nlsof -d 2-3\n```\n### 24.搜索打开的网络连接\n```\nlsof –i@10.65.64.23\n```\n### 25.寻找本地断开的打开文件 \n```\nlsof –a +L1 /data \n```\n### 26.恢复删除的文件\n```\na.使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：  \n# lsof |grep /var/log/messages \nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)  \n\nPID 1283（syslogd）打开文件的文件描述符为 2\n\nb.我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：  \n# head -n 10 /proc/1283/fd/2 \nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart. \nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started. \nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org ) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 \nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map: \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)  \n\n/proc/1283/fd/2 文件内容就是删除数据中的信息\n\nc.使用 I/O 重定向将其复制到文件中，如:  \n# cat /proc/1283/fd/2 > /var/log/messages   \n\n对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n在 Solaris 中查找删除的文件 \n# lsof -a -p 8663 -d ^txt\nCOMMAND  PID   USER   FD   TYPE        DEVICE SIZE/OFF    NODE NAME\nhttpd   8663 nobody  cwd   VDIR         136,8     1024       2 /\nhttpd   8663 nobody    0r  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    1w  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    2w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody    4r  DOOR                    0t0      58 /var/run/name_service_door\n                        (door to nscd[81]) (FA:->0x30002b156c0)\nhttpd   8663 nobody   15w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody   16u  IPv4 0x300046d27c0      0t0     TCP *:80 (LISTEN)\nhttpd   8663 nobody   17w  VREG         136,8        0  145466                                                          /var/apache/logs/access_log\nhttpd   8663 nobody   18w  VREG         281,3        0 9518013 /var/run (swap) \n使用 -a 和 -d 参数对输出进行筛选，以排除代码程序段，\"^\"是取反的意思。Name 列显示出，其中的两个文件（FD 2 和 15）使用磁盘名代替了文件名，并且它们的类型为 VREG（常规文件）。在 Solaris 中，删除的文件将显示文件所在的磁盘的名称。通过这个线索，就可以知道该 FD 指向一个删除的文件。实际上，查看 /proc/8663/fd/15 就可以得到所要查找的数据。\n```\n### 27.lsof 修改句柄限制\n```\n# lsof -n|awk '{print $2}'|sort|uniq -c |sort -nr|more   \n        131 24204  \n         57 24244  \n         57 24231  \n         56 24264  \n其中第一列是打开的文件句柄数量，第二行是进程号。得到进程号后，我们可以通过ps命令得到进程的详细内容。\n#ps -aef|grep 24204  \n mysql    24204 24162 99 16:15 ?        00:24:25 /usr/sbin/mysqld  \n查看得知是mysql进程打开最多文件句柄数量。但是他目前只打开了131个文件句柄数量，远远底于系统默认值1024。\n但是如果系统并发特别大，尤其是squid服务器，很有可能会超过1024。这时候就必须要调整系统参数，以适应应用变化。Linux关于打开文件句柄数量，有硬性限制和软性限制。可以通过ulimit来设定这两个参数。方法如下，以root用户运行以下命令：\n#ulimit -HSn 4096  \n```\n## 参考：\n> * http://czmmiao.iteye.com/blog/1734384\n> * https://blog.csdn.net/kozazyh/article/details/5495532\n","source":"_posts/2018-07-28-article9-linux-lsof.md","raw":"---\nlayout: post\ntitle:  \"linux常用命令lsof详解\"\ndate:   2018-07-28 09:35:54\nauthor: owelinux\ncategories: linux\ntags:  linux\nexcerpt: linux常用命令lsof详解.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# linux常用命令lsof详解\n\n## lsof 简介  \nlsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接 和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 \n\n可以列出被进程所打开的文件的信息。被打开的文件可以是：\n> * 1.普通的文件\n> * 2.目录  \n> * 3.网络文件系统的文件\n> * 4.字符设备文件  \n> * 5.(函数)共享库  \n> * 6.管道，命名管道 \n> * 7.符号链接\n> * 8.底层的socket字流，网络socket，unix域名socket\n> * 9.在linux里面，大部分的东西都是被当做文件的…..还有其他很多\n## lsof 常用参数\n> * lsof  filename 显示打开指定文件的所有进程 \n> * lsof -a 表示两个参数都必须满足时才显示结果 \n> * lsof -c string   显示COMMAND列中包含指定字符的进程所有打开的文件 \n> * lsof -u username  显示所属user进程打开的文件 \n> * lsof -g gid 显示归属gid的进程情况 \n> * lsof +d /DIR/ 显示目录下被进程打开的文件 \n> * lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 \n> * lsof -d FD 显示指定文件描述符的进程 \n> * lsof -n 不将IP转换为hostname，缺省是不加上-n参数 \n> * lsof -i 用以显示符合条件的进程情况 \n> * lsof -i[46] [protocol][@hostname|hostaddr][:service|port]  \n> * lsof +L/-L 打开或关闭文件的连结数计算，当+L没有指定时，所有的连结数都会显示(默认)；若+L后指定数字，则只要连结数小于该数字的信息会显示；连结数会显示在NLINK列。\n例如：+L1将显示没有unlinked的文件信息；+aL1，则显示指定文件系统所有unlinked的文件信息。-L 默认参数，其后不能跟数字，将不显示连结数信息lsof +L1\n\n## lsof 使用实例\n### 1.列出所有打开的文件:\n```\nlsof\n备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位\n```\n### 2. 查看谁正在使用某个文件\n```\nlsof   /filepath/file\n```\n### 3.递归查看某个目录的文件信息\n```\nlsof +D /filepath/filepath2/\n备注: 使用了+D，对应目录下的所有子目录和文件都会被列出\n```\n### 4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法\n```\nlsof | grep ‘/filepath/filepath2/’\n```\n### 5. 列出某个用户打开的文件信息\n```\nlsof  -u username\n```\n### 6. 列出某个程序所打开的文件信息\n```\nlsof -c mysql\n备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了\n```\n### 7. 列出多个程序多打开的文件信息\n```\nlsof -c mysql -c apache\n```\n### 8. 列出某个用户以及某个程序所打开的文件信息\n```\nlsof -u test -c mysql\n```\n### 9. 列出除了某个用户外的被打开的文件信息\n```\nlsof   -u ^root\n备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示\n```\n### 10. 通过某个进程号显示该进行打开的文件\n```\nlsof -p 1\n```\n### 11. 列出多个进程号对应的文件信息\n```\nlsof -p 123,456,789\n```\n### 12. 列出除了某个进程号，其他进程号所打开的文件信息\n```\nlsof -p ^1\n```\n### 13 . 列出所有的网络连接\n```\nlsof -i\n```\n### 14. 列出所有tcp 网络连接信息\n```\nlsof  -i tcp\n```\n### 15. 列出所有udp网络连接信息\n```\nlsof  -i udp\n```\n### 16. 列出谁在使用某个端口\n```\nlsof -i:3306\n```\n### 17. 列出谁在使用某个特定的udp端口\n```\nlsof -i udp:55\nlsof -i tcp:80\n```\n### 18. 列出某个用户的所有活跃的网络端口\n```\nlsof  -a -u test -i\n```\n### 19. 列出所有网络文件系统\n```\nlsof -N\n```\n### 20.域名socket文件\n```\nlsof -u\n```\n### 21.某个用户组所打开的文件信息\n```\nlsof -g 5555\n```\n### 22. 根据文件描述列出对应的文件信息\n```\nlsof -d description(like 2)\n```\n### 23. 根据文件描述范围列出文件信息\n```\nlsof -d 2-3\n```\n### 24.搜索打开的网络连接\n```\nlsof –i@10.65.64.23\n```\n### 25.寻找本地断开的打开文件 \n```\nlsof –a +L1 /data \n```\n### 26.恢复删除的文件\n```\na.使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：  \n# lsof |grep /var/log/messages \nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)  \n\nPID 1283（syslogd）打开文件的文件描述符为 2\n\nb.我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：  \n# head -n 10 /proc/1283/fd/2 \nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart. \nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started. \nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org ) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 \nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map: \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)  \n\n/proc/1283/fd/2 文件内容就是删除数据中的信息\n\nc.使用 I/O 重定向将其复制到文件中，如:  \n# cat /proc/1283/fd/2 > /var/log/messages   \n\n对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n在 Solaris 中查找删除的文件 \n# lsof -a -p 8663 -d ^txt\nCOMMAND  PID   USER   FD   TYPE        DEVICE SIZE/OFF    NODE NAME\nhttpd   8663 nobody  cwd   VDIR         136,8     1024       2 /\nhttpd   8663 nobody    0r  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    1w  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    2w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody    4r  DOOR                    0t0      58 /var/run/name_service_door\n                        (door to nscd[81]) (FA:->0x30002b156c0)\nhttpd   8663 nobody   15w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody   16u  IPv4 0x300046d27c0      0t0     TCP *:80 (LISTEN)\nhttpd   8663 nobody   17w  VREG         136,8        0  145466                                                          /var/apache/logs/access_log\nhttpd   8663 nobody   18w  VREG         281,3        0 9518013 /var/run (swap) \n使用 -a 和 -d 参数对输出进行筛选，以排除代码程序段，\"^\"是取反的意思。Name 列显示出，其中的两个文件（FD 2 和 15）使用磁盘名代替了文件名，并且它们的类型为 VREG（常规文件）。在 Solaris 中，删除的文件将显示文件所在的磁盘的名称。通过这个线索，就可以知道该 FD 指向一个删除的文件。实际上，查看 /proc/8663/fd/15 就可以得到所要查找的数据。\n```\n### 27.lsof 修改句柄限制\n```\n# lsof -n|awk '{print $2}'|sort|uniq -c |sort -nr|more   \n        131 24204  \n         57 24244  \n         57 24231  \n         56 24264  \n其中第一列是打开的文件句柄数量，第二行是进程号。得到进程号后，我们可以通过ps命令得到进程的详细内容。\n#ps -aef|grep 24204  \n mysql    24204 24162 99 16:15 ?        00:24:25 /usr/sbin/mysqld  \n查看得知是mysql进程打开最多文件句柄数量。但是他目前只打开了131个文件句柄数量，远远底于系统默认值1024。\n但是如果系统并发特别大，尤其是squid服务器，很有可能会超过1024。这时候就必须要调整系统参数，以适应应用变化。Linux关于打开文件句柄数量，有硬性限制和软性限制。可以通过ulimit来设定这两个参数。方法如下，以root用户运行以下命令：\n#ulimit -HSn 4096  \n```\n## 参考：\n> * http://czmmiao.iteye.com/blog/1734384\n> * https://blog.csdn.net/kozazyh/article/details/5495532\n","slug":"2018-07-28-article9-linux-lsof","published":1,"updated":"2021-02-09T02:00:24.565Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzo0009yc9753udhc05","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux常用命令lsof详解\"><a href=\"#linux常用命令lsof详解\" class=\"headerlink\" title=\"linux常用命令lsof详解\"></a>linux常用命令lsof详解</h1><h2 id=\"lsof-简介\"><a href=\"#lsof-简介\" class=\"headerlink\" title=\"lsof 简介\"></a>lsof 简介</h2><p>lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接 和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 </p>\n<p>可以列出被进程所打开的文件的信息。被打开的文件可以是：</p>\n<blockquote>\n<ul>\n<li>1.普通的文件</li>\n<li>2.目录  </li>\n<li>3.网络文件系统的文件</li>\n<li>4.字符设备文件  </li>\n<li>5.(函数)共享库  </li>\n<li>6.管道，命名管道 </li>\n<li>7.符号链接</li>\n<li>8.底层的socket字流，网络socket，unix域名socket</li>\n<li>9.在linux里面，大部分的东西都是被当做文件的…..还有其他很多</li>\n</ul>\n</blockquote>\n<h2 id=\"lsof-常用参数\"><a href=\"#lsof-常用参数\" class=\"headerlink\" title=\"lsof 常用参数\"></a>lsof 常用参数</h2><blockquote>\n<ul>\n<li>lsof  filename 显示打开指定文件的所有进程 </li>\n<li>lsof -a 表示两个参数都必须满足时才显示结果 </li>\n<li>lsof -c string   显示COMMAND列中包含指定字符的进程所有打开的文件 </li>\n<li>lsof -u username  显示所属user进程打开的文件 </li>\n<li>lsof -g gid 显示归属gid的进程情况 </li>\n<li>lsof +d /DIR/ 显示目录下被进程打开的文件 </li>\n<li>lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 </li>\n<li>lsof -d FD 显示指定文件描述符的进程 </li>\n<li>lsof -n 不将IP转换为hostname，缺省是不加上-n参数 </li>\n<li>lsof -i 用以显示符合条件的进程情况 </li>\n<li>lsof -i[46] [protocol][@hostname|hostaddr][:service|port]  </li>\n<li>lsof +L/-L 打开或关闭文件的连结数计算，当+L没有指定时，所有的连结数都会显示(默认)；若+L后指定数字，则只要连结数小于该数字的信息会显示；连结数会显示在NLINK列。<br>例如：+L1将显示没有unlinked的文件信息；+aL1，则显示指定文件系统所有unlinked的文件信息。-L 默认参数，其后不能跟数字，将不显示连结数信息lsof +L1</li>\n</ul>\n</blockquote>\n<h2 id=\"lsof-使用实例\"><a href=\"#lsof-使用实例\" class=\"headerlink\" title=\"lsof 使用实例\"></a>lsof 使用实例</h2><h3 id=\"1-列出所有打开的文件\"><a href=\"#1-列出所有打开的文件\" class=\"headerlink\" title=\"1.列出所有打开的文件:\"></a>1.列出所有打开的文件:</h3><pre><code>lsof\n备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位\n</code></pre>\n<h3 id=\"2-查看谁正在使用某个文件\"><a href=\"#2-查看谁正在使用某个文件\" class=\"headerlink\" title=\"2. 查看谁正在使用某个文件\"></a>2. 查看谁正在使用某个文件</h3><pre><code>lsof   /filepath/file\n</code></pre>\n<h3 id=\"3-递归查看某个目录的文件信息\"><a href=\"#3-递归查看某个目录的文件信息\" class=\"headerlink\" title=\"3.递归查看某个目录的文件信息\"></a>3.递归查看某个目录的文件信息</h3><pre><code>lsof +D /filepath/filepath2/\n备注: 使用了+D，对应目录下的所有子目录和文件都会被列出\n</code></pre>\n<h3 id=\"4-比使用-D选项，遍历查看某个目录的所有文件信息-的方法\"><a href=\"#4-比使用-D选项，遍历查看某个目录的所有文件信息-的方法\" class=\"headerlink\" title=\"4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法\"></a>4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法</h3><pre><code>lsof | grep ‘/filepath/filepath2/’\n</code></pre>\n<h3 id=\"5-列出某个用户打开的文件信息\"><a href=\"#5-列出某个用户打开的文件信息\" class=\"headerlink\" title=\"5. 列出某个用户打开的文件信息\"></a>5. 列出某个用户打开的文件信息</h3><pre><code>lsof  -u username\n</code></pre>\n<h3 id=\"6-列出某个程序所打开的文件信息\"><a href=\"#6-列出某个程序所打开的文件信息\" class=\"headerlink\" title=\"6. 列出某个程序所打开的文件信息\"></a>6. 列出某个程序所打开的文件信息</h3><pre><code>lsof -c mysql\n备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了\n</code></pre>\n<h3 id=\"7-列出多个程序多打开的文件信息\"><a href=\"#7-列出多个程序多打开的文件信息\" class=\"headerlink\" title=\"7. 列出多个程序多打开的文件信息\"></a>7. 列出多个程序多打开的文件信息</h3><pre><code>lsof -c mysql -c apache\n</code></pre>\n<h3 id=\"8-列出某个用户以及某个程序所打开的文件信息\"><a href=\"#8-列出某个用户以及某个程序所打开的文件信息\" class=\"headerlink\" title=\"8. 列出某个用户以及某个程序所打开的文件信息\"></a>8. 列出某个用户以及某个程序所打开的文件信息</h3><pre><code>lsof -u test -c mysql\n</code></pre>\n<h3 id=\"9-列出除了某个用户外的被打开的文件信息\"><a href=\"#9-列出除了某个用户外的被打开的文件信息\" class=\"headerlink\" title=\"9. 列出除了某个用户外的被打开的文件信息\"></a>9. 列出除了某个用户外的被打开的文件信息</h3><pre><code>lsof   -u ^root\n备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示\n</code></pre>\n<h3 id=\"10-通过某个进程号显示该进行打开的文件\"><a href=\"#10-通过某个进程号显示该进行打开的文件\" class=\"headerlink\" title=\"10. 通过某个进程号显示该进行打开的文件\"></a>10. 通过某个进程号显示该进行打开的文件</h3><pre><code>lsof -p 1\n</code></pre>\n<h3 id=\"11-列出多个进程号对应的文件信息\"><a href=\"#11-列出多个进程号对应的文件信息\" class=\"headerlink\" title=\"11. 列出多个进程号对应的文件信息\"></a>11. 列出多个进程号对应的文件信息</h3><pre><code>lsof -p 123,456,789\n</code></pre>\n<h3 id=\"12-列出除了某个进程号，其他进程号所打开的文件信息\"><a href=\"#12-列出除了某个进程号，其他进程号所打开的文件信息\" class=\"headerlink\" title=\"12. 列出除了某个进程号，其他进程号所打开的文件信息\"></a>12. 列出除了某个进程号，其他进程号所打开的文件信息</h3><pre><code>lsof -p ^1\n</code></pre>\n<h3 id=\"13-列出所有的网络连接\"><a href=\"#13-列出所有的网络连接\" class=\"headerlink\" title=\"13 . 列出所有的网络连接\"></a>13 . 列出所有的网络连接</h3><pre><code>lsof -i\n</code></pre>\n<h3 id=\"14-列出所有tcp-网络连接信息\"><a href=\"#14-列出所有tcp-网络连接信息\" class=\"headerlink\" title=\"14. 列出所有tcp 网络连接信息\"></a>14. 列出所有tcp 网络连接信息</h3><pre><code>lsof  -i tcp\n</code></pre>\n<h3 id=\"15-列出所有udp网络连接信息\"><a href=\"#15-列出所有udp网络连接信息\" class=\"headerlink\" title=\"15. 列出所有udp网络连接信息\"></a>15. 列出所有udp网络连接信息</h3><pre><code>lsof  -i udp\n</code></pre>\n<h3 id=\"16-列出谁在使用某个端口\"><a href=\"#16-列出谁在使用某个端口\" class=\"headerlink\" title=\"16. 列出谁在使用某个端口\"></a>16. 列出谁在使用某个端口</h3><pre><code>lsof -i:3306\n</code></pre>\n<h3 id=\"17-列出谁在使用某个特定的udp端口\"><a href=\"#17-列出谁在使用某个特定的udp端口\" class=\"headerlink\" title=\"17. 列出谁在使用某个特定的udp端口\"></a>17. 列出谁在使用某个特定的udp端口</h3><pre><code>lsof -i udp:55\nlsof -i tcp:80\n</code></pre>\n<h3 id=\"18-列出某个用户的所有活跃的网络端口\"><a href=\"#18-列出某个用户的所有活跃的网络端口\" class=\"headerlink\" title=\"18. 列出某个用户的所有活跃的网络端口\"></a>18. 列出某个用户的所有活跃的网络端口</h3><pre><code>lsof  -a -u test -i\n</code></pre>\n<h3 id=\"19-列出所有网络文件系统\"><a href=\"#19-列出所有网络文件系统\" class=\"headerlink\" title=\"19. 列出所有网络文件系统\"></a>19. 列出所有网络文件系统</h3><pre><code>lsof -N\n</code></pre>\n<h3 id=\"20-域名socket文件\"><a href=\"#20-域名socket文件\" class=\"headerlink\" title=\"20.域名socket文件\"></a>20.域名socket文件</h3><pre><code>lsof -u\n</code></pre>\n<h3 id=\"21-某个用户组所打开的文件信息\"><a href=\"#21-某个用户组所打开的文件信息\" class=\"headerlink\" title=\"21.某个用户组所打开的文件信息\"></a>21.某个用户组所打开的文件信息</h3><pre><code>lsof -g 5555\n</code></pre>\n<h3 id=\"22-根据文件描述列出对应的文件信息\"><a href=\"#22-根据文件描述列出对应的文件信息\" class=\"headerlink\" title=\"22. 根据文件描述列出对应的文件信息\"></a>22. 根据文件描述列出对应的文件信息</h3><pre><code>lsof -d description(like 2)\n</code></pre>\n<h3 id=\"23-根据文件描述范围列出文件信息\"><a href=\"#23-根据文件描述范围列出文件信息\" class=\"headerlink\" title=\"23. 根据文件描述范围列出文件信息\"></a>23. 根据文件描述范围列出文件信息</h3><pre><code>lsof -d 2-3\n</code></pre>\n<h3 id=\"24-搜索打开的网络连接\"><a href=\"#24-搜索打开的网络连接\" class=\"headerlink\" title=\"24.搜索打开的网络连接\"></a>24.搜索打开的网络连接</h3><pre><code>lsof –i@10.65.64.23\n</code></pre>\n<h3 id=\"25-寻找本地断开的打开文件\"><a href=\"#25-寻找本地断开的打开文件\" class=\"headerlink\" title=\"25.寻找本地断开的打开文件\"></a>25.寻找本地断开的打开文件</h3><pre><code>lsof –a +L1 /data \n</code></pre>\n<h3 id=\"26-恢复删除的文件\"><a href=\"#26-恢复删除的文件\" class=\"headerlink\" title=\"26.恢复删除的文件\"></a>26.恢复删除的文件</h3><pre><code>a.使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：  \n# lsof |grep /var/log/messages \nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)  \n\nPID 1283（syslogd）打开文件的文件描述符为 2\n\nb.我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：  \n# head -n 10 /proc/1283/fd/2 \nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart. \nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started. \nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org ) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 \nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map: \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)  \n\n/proc/1283/fd/2 文件内容就是删除数据中的信息\n\nc.使用 I/O 重定向将其复制到文件中，如:  \n# cat /proc/1283/fd/2 &gt; /var/log/messages   \n\n对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n在 Solaris 中查找删除的文件 \n# lsof -a -p 8663 -d ^txt\nCOMMAND  PID   USER   FD   TYPE        DEVICE SIZE/OFF    NODE NAME\nhttpd   8663 nobody  cwd   VDIR         136,8     1024       2 /\nhttpd   8663 nobody    0r  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    1w  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    2w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody    4r  DOOR                    0t0      58 /var/run/name_service_door\n                        (door to nscd[81]) (FA:-&gt;0x30002b156c0)\nhttpd   8663 nobody   15w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody   16u  IPv4 0x300046d27c0      0t0     TCP *:80 (LISTEN)\nhttpd   8663 nobody   17w  VREG         136,8        0  145466                                                          /var/apache/logs/access_log\nhttpd   8663 nobody   18w  VREG         281,3        0 9518013 /var/run (swap) \n使用 -a 和 -d 参数对输出进行筛选，以排除代码程序段，&quot;^&quot;是取反的意思。Name 列显示出，其中的两个文件（FD 2 和 15）使用磁盘名代替了文件名，并且它们的类型为 VREG（常规文件）。在 Solaris 中，删除的文件将显示文件所在的磁盘的名称。通过这个线索，就可以知道该 FD 指向一个删除的文件。实际上，查看 /proc/8663/fd/15 就可以得到所要查找的数据。\n</code></pre>\n<h3 id=\"27-lsof-修改句柄限制\"><a href=\"#27-lsof-修改句柄限制\" class=\"headerlink\" title=\"27.lsof 修改句柄限制\"></a>27.lsof 修改句柄限制</h3><pre><code># lsof -n|awk &#39;&#123;print $2&#125;&#39;|sort|uniq -c |sort -nr|more   \n        131 24204  \n         57 24244  \n         57 24231  \n         56 24264  \n其中第一列是打开的文件句柄数量，第二行是进程号。得到进程号后，我们可以通过ps命令得到进程的详细内容。\n#ps -aef|grep 24204  \n mysql    24204 24162 99 16:15 ?        00:24:25 /usr/sbin/mysqld  \n查看得知是mysql进程打开最多文件句柄数量。但是他目前只打开了131个文件句柄数量，远远底于系统默认值1024。\n但是如果系统并发特别大，尤其是squid服务器，很有可能会超过1024。这时候就必须要调整系统参数，以适应应用变化。Linux关于打开文件句柄数量，有硬性限制和软性限制。可以通过ulimit来设定这两个参数。方法如下，以root用户运行以下命令：\n#ulimit -HSn 4096  \n</code></pre>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><blockquote>\n<ul>\n<li><a href=\"http://czmmiao.iteye.com/blog/1734384\">http://czmmiao.iteye.com/blog/1734384</a></li>\n<li><a href=\"https://blog.csdn.net/kozazyh/article/details/5495532\">https://blog.csdn.net/kozazyh/article/details/5495532</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux常用命令lsof详解\"><a href=\"#linux常用命令lsof详解\" class=\"headerlink\" title=\"linux常用命令lsof详解\"></a>linux常用命令lsof详解</h1><h2 id=\"lsof-简介\"><a href=\"#lsof-简介\" class=\"headerlink\" title=\"lsof 简介\"></a>lsof 简介</h2><p>lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接 和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 </p>\n<p>可以列出被进程所打开的文件的信息。被打开的文件可以是：</p>\n<blockquote>\n<ul>\n<li>1.普通的文件</li>\n<li>2.目录  </li>\n<li>3.网络文件系统的文件</li>\n<li>4.字符设备文件  </li>\n<li>5.(函数)共享库  </li>\n<li>6.管道，命名管道 </li>\n<li>7.符号链接</li>\n<li>8.底层的socket字流，网络socket，unix域名socket</li>\n<li>9.在linux里面，大部分的东西都是被当做文件的…..还有其他很多</li>\n</ul>\n</blockquote>\n<h2 id=\"lsof-常用参数\"><a href=\"#lsof-常用参数\" class=\"headerlink\" title=\"lsof 常用参数\"></a>lsof 常用参数</h2><blockquote>\n<ul>\n<li>lsof  filename 显示打开指定文件的所有进程 </li>\n<li>lsof -a 表示两个参数都必须满足时才显示结果 </li>\n<li>lsof -c string   显示COMMAND列中包含指定字符的进程所有打开的文件 </li>\n<li>lsof -u username  显示所属user进程打开的文件 </li>\n<li>lsof -g gid 显示归属gid的进程情况 </li>\n<li>lsof +d /DIR/ 显示目录下被进程打开的文件 </li>\n<li>lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 </li>\n<li>lsof -d FD 显示指定文件描述符的进程 </li>\n<li>lsof -n 不将IP转换为hostname，缺省是不加上-n参数 </li>\n<li>lsof -i 用以显示符合条件的进程情况 </li>\n<li>lsof -i[46] [protocol][@hostname|hostaddr][:service|port]  </li>\n<li>lsof +L/-L 打开或关闭文件的连结数计算，当+L没有指定时，所有的连结数都会显示(默认)；若+L后指定数字，则只要连结数小于该数字的信息会显示；连结数会显示在NLINK列。<br>例如：+L1将显示没有unlinked的文件信息；+aL1，则显示指定文件系统所有unlinked的文件信息。-L 默认参数，其后不能跟数字，将不显示连结数信息lsof +L1</li>\n</ul>\n</blockquote>\n<h2 id=\"lsof-使用实例\"><a href=\"#lsof-使用实例\" class=\"headerlink\" title=\"lsof 使用实例\"></a>lsof 使用实例</h2><h3 id=\"1-列出所有打开的文件\"><a href=\"#1-列出所有打开的文件\" class=\"headerlink\" title=\"1.列出所有打开的文件:\"></a>1.列出所有打开的文件:</h3><pre><code>lsof\n备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位\n</code></pre>\n<h3 id=\"2-查看谁正在使用某个文件\"><a href=\"#2-查看谁正在使用某个文件\" class=\"headerlink\" title=\"2. 查看谁正在使用某个文件\"></a>2. 查看谁正在使用某个文件</h3><pre><code>lsof   /filepath/file\n</code></pre>\n<h3 id=\"3-递归查看某个目录的文件信息\"><a href=\"#3-递归查看某个目录的文件信息\" class=\"headerlink\" title=\"3.递归查看某个目录的文件信息\"></a>3.递归查看某个目录的文件信息</h3><pre><code>lsof +D /filepath/filepath2/\n备注: 使用了+D，对应目录下的所有子目录和文件都会被列出\n</code></pre>\n<h3 id=\"4-比使用-D选项，遍历查看某个目录的所有文件信息-的方法\"><a href=\"#4-比使用-D选项，遍历查看某个目录的所有文件信息-的方法\" class=\"headerlink\" title=\"4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法\"></a>4. 比使用+D选项，遍历查看某个目录的所有文件信息 的方法</h3><pre><code>lsof | grep ‘/filepath/filepath2/’\n</code></pre>\n<h3 id=\"5-列出某个用户打开的文件信息\"><a href=\"#5-列出某个用户打开的文件信息\" class=\"headerlink\" title=\"5. 列出某个用户打开的文件信息\"></a>5. 列出某个用户打开的文件信息</h3><pre><code>lsof  -u username\n</code></pre>\n<h3 id=\"6-列出某个程序所打开的文件信息\"><a href=\"#6-列出某个程序所打开的文件信息\" class=\"headerlink\" title=\"6. 列出某个程序所打开的文件信息\"></a>6. 列出某个程序所打开的文件信息</h3><pre><code>lsof -c mysql\n备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了\n</code></pre>\n<h3 id=\"7-列出多个程序多打开的文件信息\"><a href=\"#7-列出多个程序多打开的文件信息\" class=\"headerlink\" title=\"7. 列出多个程序多打开的文件信息\"></a>7. 列出多个程序多打开的文件信息</h3><pre><code>lsof -c mysql -c apache\n</code></pre>\n<h3 id=\"8-列出某个用户以及某个程序所打开的文件信息\"><a href=\"#8-列出某个用户以及某个程序所打开的文件信息\" class=\"headerlink\" title=\"8. 列出某个用户以及某个程序所打开的文件信息\"></a>8. 列出某个用户以及某个程序所打开的文件信息</h3><pre><code>lsof -u test -c mysql\n</code></pre>\n<h3 id=\"9-列出除了某个用户外的被打开的文件信息\"><a href=\"#9-列出除了某个用户外的被打开的文件信息\" class=\"headerlink\" title=\"9. 列出除了某个用户外的被打开的文件信息\"></a>9. 列出除了某个用户外的被打开的文件信息</h3><pre><code>lsof   -u ^root\n备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示\n</code></pre>\n<h3 id=\"10-通过某个进程号显示该进行打开的文件\"><a href=\"#10-通过某个进程号显示该进行打开的文件\" class=\"headerlink\" title=\"10. 通过某个进程号显示该进行打开的文件\"></a>10. 通过某个进程号显示该进行打开的文件</h3><pre><code>lsof -p 1\n</code></pre>\n<h3 id=\"11-列出多个进程号对应的文件信息\"><a href=\"#11-列出多个进程号对应的文件信息\" class=\"headerlink\" title=\"11. 列出多个进程号对应的文件信息\"></a>11. 列出多个进程号对应的文件信息</h3><pre><code>lsof -p 123,456,789\n</code></pre>\n<h3 id=\"12-列出除了某个进程号，其他进程号所打开的文件信息\"><a href=\"#12-列出除了某个进程号，其他进程号所打开的文件信息\" class=\"headerlink\" title=\"12. 列出除了某个进程号，其他进程号所打开的文件信息\"></a>12. 列出除了某个进程号，其他进程号所打开的文件信息</h3><pre><code>lsof -p ^1\n</code></pre>\n<h3 id=\"13-列出所有的网络连接\"><a href=\"#13-列出所有的网络连接\" class=\"headerlink\" title=\"13 . 列出所有的网络连接\"></a>13 . 列出所有的网络连接</h3><pre><code>lsof -i\n</code></pre>\n<h3 id=\"14-列出所有tcp-网络连接信息\"><a href=\"#14-列出所有tcp-网络连接信息\" class=\"headerlink\" title=\"14. 列出所有tcp 网络连接信息\"></a>14. 列出所有tcp 网络连接信息</h3><pre><code>lsof  -i tcp\n</code></pre>\n<h3 id=\"15-列出所有udp网络连接信息\"><a href=\"#15-列出所有udp网络连接信息\" class=\"headerlink\" title=\"15. 列出所有udp网络连接信息\"></a>15. 列出所有udp网络连接信息</h3><pre><code>lsof  -i udp\n</code></pre>\n<h3 id=\"16-列出谁在使用某个端口\"><a href=\"#16-列出谁在使用某个端口\" class=\"headerlink\" title=\"16. 列出谁在使用某个端口\"></a>16. 列出谁在使用某个端口</h3><pre><code>lsof -i:3306\n</code></pre>\n<h3 id=\"17-列出谁在使用某个特定的udp端口\"><a href=\"#17-列出谁在使用某个特定的udp端口\" class=\"headerlink\" title=\"17. 列出谁在使用某个特定的udp端口\"></a>17. 列出谁在使用某个特定的udp端口</h3><pre><code>lsof -i udp:55\nlsof -i tcp:80\n</code></pre>\n<h3 id=\"18-列出某个用户的所有活跃的网络端口\"><a href=\"#18-列出某个用户的所有活跃的网络端口\" class=\"headerlink\" title=\"18. 列出某个用户的所有活跃的网络端口\"></a>18. 列出某个用户的所有活跃的网络端口</h3><pre><code>lsof  -a -u test -i\n</code></pre>\n<h3 id=\"19-列出所有网络文件系统\"><a href=\"#19-列出所有网络文件系统\" class=\"headerlink\" title=\"19. 列出所有网络文件系统\"></a>19. 列出所有网络文件系统</h3><pre><code>lsof -N\n</code></pre>\n<h3 id=\"20-域名socket文件\"><a href=\"#20-域名socket文件\" class=\"headerlink\" title=\"20.域名socket文件\"></a>20.域名socket文件</h3><pre><code>lsof -u\n</code></pre>\n<h3 id=\"21-某个用户组所打开的文件信息\"><a href=\"#21-某个用户组所打开的文件信息\" class=\"headerlink\" title=\"21.某个用户组所打开的文件信息\"></a>21.某个用户组所打开的文件信息</h3><pre><code>lsof -g 5555\n</code></pre>\n<h3 id=\"22-根据文件描述列出对应的文件信息\"><a href=\"#22-根据文件描述列出对应的文件信息\" class=\"headerlink\" title=\"22. 根据文件描述列出对应的文件信息\"></a>22. 根据文件描述列出对应的文件信息</h3><pre><code>lsof -d description(like 2)\n</code></pre>\n<h3 id=\"23-根据文件描述范围列出文件信息\"><a href=\"#23-根据文件描述范围列出文件信息\" class=\"headerlink\" title=\"23. 根据文件描述范围列出文件信息\"></a>23. 根据文件描述范围列出文件信息</h3><pre><code>lsof -d 2-3\n</code></pre>\n<h3 id=\"24-搜索打开的网络连接\"><a href=\"#24-搜索打开的网络连接\" class=\"headerlink\" title=\"24.搜索打开的网络连接\"></a>24.搜索打开的网络连接</h3><pre><code>lsof –i@10.65.64.23\n</code></pre>\n<h3 id=\"25-寻找本地断开的打开文件\"><a href=\"#25-寻找本地断开的打开文件\" class=\"headerlink\" title=\"25.寻找本地断开的打开文件\"></a>25.寻找本地断开的打开文件</h3><pre><code>lsof –a +L1 /data \n</code></pre>\n<h3 id=\"26-恢复删除的文件\"><a href=\"#26-恢复删除的文件\" class=\"headerlink\" title=\"26.恢复删除的文件\"></a>26.恢复删除的文件</h3><pre><code>a.使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：  \n# lsof |grep /var/log/messages \nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)  \n\nPID 1283（syslogd）打开文件的文件描述符为 2\n\nb.我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：  \n# head -n 10 /proc/1283/fd/2 \nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart. \nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started. \nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org ) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 \nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map: \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) \nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)  \n\n/proc/1283/fd/2 文件内容就是删除数据中的信息\n\nc.使用 I/O 重定向将其复制到文件中，如:  \n# cat /proc/1283/fd/2 &gt; /var/log/messages   \n\n对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n在 Solaris 中查找删除的文件 \n# lsof -a -p 8663 -d ^txt\nCOMMAND  PID   USER   FD   TYPE        DEVICE SIZE/OFF    NODE NAME\nhttpd   8663 nobody  cwd   VDIR         136,8     1024       2 /\nhttpd   8663 nobody    0r  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    1w  VCHR          13,2          6815752 /devices/pseudo/mm@0:null\nhttpd   8663 nobody    2w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody    4r  DOOR                    0t0      58 /var/run/name_service_door\n                        (door to nscd[81]) (FA:-&gt;0x30002b156c0)\nhttpd   8663 nobody   15w  VREG         136,8      185  145465 / (/dev/dsk/c0t0d0s0)\nhttpd   8663 nobody   16u  IPv4 0x300046d27c0      0t0     TCP *:80 (LISTEN)\nhttpd   8663 nobody   17w  VREG         136,8        0  145466                                                          /var/apache/logs/access_log\nhttpd   8663 nobody   18w  VREG         281,3        0 9518013 /var/run (swap) \n使用 -a 和 -d 参数对输出进行筛选，以排除代码程序段，&quot;^&quot;是取反的意思。Name 列显示出，其中的两个文件（FD 2 和 15）使用磁盘名代替了文件名，并且它们的类型为 VREG（常规文件）。在 Solaris 中，删除的文件将显示文件所在的磁盘的名称。通过这个线索，就可以知道该 FD 指向一个删除的文件。实际上，查看 /proc/8663/fd/15 就可以得到所要查找的数据。\n</code></pre>\n<h3 id=\"27-lsof-修改句柄限制\"><a href=\"#27-lsof-修改句柄限制\" class=\"headerlink\" title=\"27.lsof 修改句柄限制\"></a>27.lsof 修改句柄限制</h3><pre><code># lsof -n|awk &#39;&#123;print $2&#125;&#39;|sort|uniq -c |sort -nr|more   \n        131 24204  \n         57 24244  \n         57 24231  \n         56 24264  \n其中第一列是打开的文件句柄数量，第二行是进程号。得到进程号后，我们可以通过ps命令得到进程的详细内容。\n#ps -aef|grep 24204  \n mysql    24204 24162 99 16:15 ?        00:24:25 /usr/sbin/mysqld  \n查看得知是mysql进程打开最多文件句柄数量。但是他目前只打开了131个文件句柄数量，远远底于系统默认值1024。\n但是如果系统并发特别大，尤其是squid服务器，很有可能会超过1024。这时候就必须要调整系统参数，以适应应用变化。Linux关于打开文件句柄数量，有硬性限制和软性限制。可以通过ulimit来设定这两个参数。方法如下，以root用户运行以下命令：\n#ulimit -HSn 4096  \n</code></pre>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><blockquote>\n<ul>\n<li><a href=\"http://czmmiao.iteye.com/blog/1734384\">http://czmmiao.iteye.com/blog/1734384</a></li>\n<li><a href=\"https://blog.csdn.net/kozazyh/article/details/5495532\">https://blog.csdn.net/kozazyh/article/details/5495532</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"lucene查询语法，适用于ELk：kibana查询","date":"2018-08-03T03:49:54.000Z","author":"owelinux","excerpt":"lucene查询语法，适用于ELk：kibana查询.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# lucene查询语法，适用于ELk：kibana查询\nKibana在ELK中扮演着数据可视化角色，用来查询及展示数据；\nElasticsearch查询采用的是luncene搜索引擎，其4过滤查询语法和lucene一致。\n\n![](http://owelinux.github.io/images/2018-08-03-article11-linux-luncene/elk-lucene.png)\n\n[Kibana官方在线演示](http://demo.elastic.co/app/kibana#/discover)\n\n## 字段搜索\nLucene支持实时数据。执行搜索时，您可以指定字段，也可以使用默认字段。字段名称和默认字段是特定于实现的。\n\n```\n限定字段全文搜索：field:value\n精确搜索：关键字加上双引号 filed:\"value\"\nhttp.code:404 搜索http状态码为404的文档\n```\n字段本身是否存在\n```\n_exists_:http：返回结果中需要有http字段\n_missing_:http：不能含有http字段\n```\n\n## 通配符搜索\nLucene支持单个术语内的单个和多个字符通配符搜索（不在短语查询中）。\n\n```\n? 匹配单个字符\n* 匹配0到多个字符\nte?t,test*,te*t\n```\n注意：您不能使用*或？符号作为搜索的第一个字符。\n\n## 正则表达式搜索\nLucene支持正向表达式搜索.\n```\nname:/joh?n(ath[oa]n)/\n```\n## 模糊搜索\n```\nquikc~ brwn~ foks~\n~:在一个单词后面加上~启用模糊搜索，可以搜到一些拼写错误的单词\nfirst~ 这种也能匹配到 frist\n```\n还可以设置编辑距离（整数），指定需要多少相似度\n```\ncromm~1 会匹配到 from 和 chrome\n默认2，越大越接近搜索的原始值，设置为1基本能搜到80%拼写错误的单词\n```\n## 近似搜索\n在短语后面加上~，可以搜到被隔开或顺序不同的单词\n```\n\"where select\"~5 表示 select 和 where 中间可以隔着5个单词，可以搜到 select password from users where id=1\n```\n\n## 范围搜索\n\n数值/时间/IP/字符串 类型的字段可以对某一范围进行查询\n```\nlength:[100 TO 200]\nsip:[\"172.24.20.110\" TO \"172.24.20.140\"]\ndate:{\"now-6h\" TO \"now\"}\ntag:{b TO e} 搜索b到e中间的字符\ncount:[10 TO *] * 表示一端不限制范围\ncount:[1 TO 5} [ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5\n可以简化成以下写法：\nage:>10\nage:<=10\nage:(>=10 AND <20)\n```\n## 优先级\n使用^使一个词语比另一个搜索优先级更高，默认为1，可以为0~1之间的浮点数，来降低优先级\n```\nquick^2 fox\n```\n## 布尔运算符搜索\n布尔运算符允许通过逻辑运算符组合术语。Lucene支持AND，“+”，OR，NOT和“ - ”作为布尔运算符（注意：布尔运算符必须是ALL CAPS）。\n\nOR\n```\n\"jakarta apache\" jakarta\nor\n\"jakarta apache\" OR jakarta\n```\nAND\n```\n\"jakarta apache\" AND \"Apache Lucene\"\n```\n+:搜索结果中必须包含此项\n```\n+jakarta lucene\n```\nNOT\n```\n\"jakarta apache\" NOT \"Apache Lucene\"\nNOT \"jakarta apache\"\n```\n-：不能含有此项\n```\n\"jakarta apache\" -\"Apache Lucene\"\n```\n## 分组搜索\nLucene支持使用括号将子句分组以形成子查询。如果要控制查询的布尔逻辑，这可能非常有用。\n```\n(jakarta OR apache) AND jakarta\n```\n## 字段分组搜索\nLucene支持使用括号将多个子句分组到单个字段。\n```\ntitle:(+return +\"pink panther\")\nhost:(baidu OR qq OR google) AND host:(com OR cn)\n```\n## 转义特殊字符搜索\nLucene支持转义属于查询语法的特殊字符。\n```\n+ - = && || > < ! ( ) { } [ ] ^ \" ~ * ? : \\ /\n以上字符当作值搜索的时候需要用\\转义\n\\(1\\+1\\)\\=2用来查询(1+1)=2\n```\n# 参考：\n> * [https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html](https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html)\n> * [https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax)\n> * [https://segmentfault.com/a/1190000002972420#articleHeader10](https://segmentfault.com/a/1190000002972420#articleHeader10)\n","source":"_posts/2018-08-03-article11-linux-luncene.md","raw":"---\nlayout: post\ntitle:  \"lucene查询语法，适用于ELk：kibana查询\"\ndate:   2018-08-03 11:49:54\nauthor: owelinux\ncategories: linux\ntags:  lucene ELK kibana\nexcerpt: lucene查询语法，适用于ELk：kibana查询.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# lucene查询语法，适用于ELk：kibana查询\nKibana在ELK中扮演着数据可视化角色，用来查询及展示数据；\nElasticsearch查询采用的是luncene搜索引擎，其4过滤查询语法和lucene一致。\n\n![](http://owelinux.github.io/images/2018-08-03-article11-linux-luncene/elk-lucene.png)\n\n[Kibana官方在线演示](http://demo.elastic.co/app/kibana#/discover)\n\n## 字段搜索\nLucene支持实时数据。执行搜索时，您可以指定字段，也可以使用默认字段。字段名称和默认字段是特定于实现的。\n\n```\n限定字段全文搜索：field:value\n精确搜索：关键字加上双引号 filed:\"value\"\nhttp.code:404 搜索http状态码为404的文档\n```\n字段本身是否存在\n```\n_exists_:http：返回结果中需要有http字段\n_missing_:http：不能含有http字段\n```\n\n## 通配符搜索\nLucene支持单个术语内的单个和多个字符通配符搜索（不在短语查询中）。\n\n```\n? 匹配单个字符\n* 匹配0到多个字符\nte?t,test*,te*t\n```\n注意：您不能使用*或？符号作为搜索的第一个字符。\n\n## 正则表达式搜索\nLucene支持正向表达式搜索.\n```\nname:/joh?n(ath[oa]n)/\n```\n## 模糊搜索\n```\nquikc~ brwn~ foks~\n~:在一个单词后面加上~启用模糊搜索，可以搜到一些拼写错误的单词\nfirst~ 这种也能匹配到 frist\n```\n还可以设置编辑距离（整数），指定需要多少相似度\n```\ncromm~1 会匹配到 from 和 chrome\n默认2，越大越接近搜索的原始值，设置为1基本能搜到80%拼写错误的单词\n```\n## 近似搜索\n在短语后面加上~，可以搜到被隔开或顺序不同的单词\n```\n\"where select\"~5 表示 select 和 where 中间可以隔着5个单词，可以搜到 select password from users where id=1\n```\n\n## 范围搜索\n\n数值/时间/IP/字符串 类型的字段可以对某一范围进行查询\n```\nlength:[100 TO 200]\nsip:[\"172.24.20.110\" TO \"172.24.20.140\"]\ndate:{\"now-6h\" TO \"now\"}\ntag:{b TO e} 搜索b到e中间的字符\ncount:[10 TO *] * 表示一端不限制范围\ncount:[1 TO 5} [ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5\n可以简化成以下写法：\nage:>10\nage:<=10\nage:(>=10 AND <20)\n```\n## 优先级\n使用^使一个词语比另一个搜索优先级更高，默认为1，可以为0~1之间的浮点数，来降低优先级\n```\nquick^2 fox\n```\n## 布尔运算符搜索\n布尔运算符允许通过逻辑运算符组合术语。Lucene支持AND，“+”，OR，NOT和“ - ”作为布尔运算符（注意：布尔运算符必须是ALL CAPS）。\n\nOR\n```\n\"jakarta apache\" jakarta\nor\n\"jakarta apache\" OR jakarta\n```\nAND\n```\n\"jakarta apache\" AND \"Apache Lucene\"\n```\n+:搜索结果中必须包含此项\n```\n+jakarta lucene\n```\nNOT\n```\n\"jakarta apache\" NOT \"Apache Lucene\"\nNOT \"jakarta apache\"\n```\n-：不能含有此项\n```\n\"jakarta apache\" -\"Apache Lucene\"\n```\n## 分组搜索\nLucene支持使用括号将子句分组以形成子查询。如果要控制查询的布尔逻辑，这可能非常有用。\n```\n(jakarta OR apache) AND jakarta\n```\n## 字段分组搜索\nLucene支持使用括号将多个子句分组到单个字段。\n```\ntitle:(+return +\"pink panther\")\nhost:(baidu OR qq OR google) AND host:(com OR cn)\n```\n## 转义特殊字符搜索\nLucene支持转义属于查询语法的特殊字符。\n```\n+ - = && || > < ! ( ) { } [ ] ^ \" ~ * ? : \\ /\n以上字符当作值搜索的时候需要用\\转义\n\\(1\\+1\\)\\=2用来查询(1+1)=2\n```\n# 参考：\n> * [https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html](https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html)\n> * [https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax)\n> * [https://segmentfault.com/a/1190000002972420#articleHeader10](https://segmentfault.com/a/1190000002972420#articleHeader10)\n","slug":"2018-08-03-article11-linux-luncene","published":1,"updated":"2021-02-09T02:00:24.566Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzp000byc975elc2a8b","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"lucene查询语法，适用于ELk：kibana查询\"><a href=\"#lucene查询语法，适用于ELk：kibana查询\" class=\"headerlink\" title=\"lucene查询语法，适用于ELk：kibana查询\"></a>lucene查询语法，适用于ELk：kibana查询</h1><p>Kibana在ELK中扮演着数据可视化角色，用来查询及展示数据；<br>Elasticsearch查询采用的是luncene搜索引擎，其4过滤查询语法和lucene一致。</p>\n<p><img src=\"http://owelinux.github.io/images/2018-08-03-article11-linux-luncene/elk-lucene.png\"></p>\n<p><a href=\"http://demo.elastic.co/app/kibana#/discover\">Kibana官方在线演示</a></p>\n<h2 id=\"字段搜索\"><a href=\"#字段搜索\" class=\"headerlink\" title=\"字段搜索\"></a>字段搜索</h2><p>Lucene支持实时数据。执行搜索时，您可以指定字段，也可以使用默认字段。字段名称和默认字段是特定于实现的。</p>\n<pre><code>限定字段全文搜索：field:value\n精确搜索：关键字加上双引号 filed:&quot;value&quot;\nhttp.code:404 搜索http状态码为404的文档\n</code></pre>\n<p>字段本身是否存在</p>\n<pre><code>_exists_:http：返回结果中需要有http字段\n_missing_:http：不能含有http字段\n</code></pre>\n<h2 id=\"通配符搜索\"><a href=\"#通配符搜索\" class=\"headerlink\" title=\"通配符搜索\"></a>通配符搜索</h2><p>Lucene支持单个术语内的单个和多个字符通配符搜索（不在短语查询中）。</p>\n<pre><code>? 匹配单个字符\n* 匹配0到多个字符\nte?t,test*,te*t\n</code></pre>\n<p>注意：您不能使用*或？符号作为搜索的第一个字符。</p>\n<h2 id=\"正则表达式搜索\"><a href=\"#正则表达式搜索\" class=\"headerlink\" title=\"正则表达式搜索\"></a>正则表达式搜索</h2><p>Lucene支持正向表达式搜索.</p>\n<pre><code>name:/joh?n(ath[oa]n)/\n</code></pre>\n<h2 id=\"模糊搜索\"><a href=\"#模糊搜索\" class=\"headerlink\" title=\"模糊搜索\"></a>模糊搜索</h2><pre><code>quikc~ brwn~ foks~\n~:在一个单词后面加上~启用模糊搜索，可以搜到一些拼写错误的单词\nfirst~ 这种也能匹配到 frist\n</code></pre>\n<p>还可以设置编辑距离（整数），指定需要多少相似度</p>\n<pre><code>cromm~1 会匹配到 from 和 chrome\n默认2，越大越接近搜索的原始值，设置为1基本能搜到80%拼写错误的单词\n</code></pre>\n<h2 id=\"近似搜索\"><a href=\"#近似搜索\" class=\"headerlink\" title=\"近似搜索\"></a>近似搜索</h2><p>在短语后面加上~，可以搜到被隔开或顺序不同的单词</p>\n<pre><code>&quot;where select&quot;~5 表示 select 和 where 中间可以隔着5个单词，可以搜到 select password from users where id=1\n</code></pre>\n<h2 id=\"范围搜索\"><a href=\"#范围搜索\" class=\"headerlink\" title=\"范围搜索\"></a>范围搜索</h2><p>数值/时间/IP/字符串 类型的字段可以对某一范围进行查询</p>\n<pre><code>length:[100 TO 200]\nsip:[&quot;172.24.20.110&quot; TO &quot;172.24.20.140&quot;]\ndate:&#123;&quot;now-6h&quot; TO &quot;now&quot;&#125;\ntag:&#123;b TO e&#125; 搜索b到e中间的字符\ncount:[10 TO *] * 表示一端不限制范围\ncount:[1 TO 5&#125; [ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5\n可以简化成以下写法：\nage:&gt;10\nage:&lt;=10\nage:(&gt;=10 AND &lt;20)\n</code></pre>\n<h2 id=\"优先级\"><a href=\"#优先级\" class=\"headerlink\" title=\"优先级\"></a>优先级</h2><p>使用^使一个词语比另一个搜索优先级更高，默认为1，可以为0~1之间的浮点数，来降低优先级</p>\n<pre><code>quick^2 fox\n</code></pre>\n<h2 id=\"布尔运算符搜索\"><a href=\"#布尔运算符搜索\" class=\"headerlink\" title=\"布尔运算符搜索\"></a>布尔运算符搜索</h2><p>布尔运算符允许通过逻辑运算符组合术语。Lucene支持AND，“+”，OR，NOT和“ - ”作为布尔运算符（注意：布尔运算符必须是ALL CAPS）。</p>\n<p>OR</p>\n<pre><code>&quot;jakarta apache&quot; jakarta\nor\n&quot;jakarta apache&quot; OR jakarta\n</code></pre>\n<p>AND</p>\n<pre><code>&quot;jakarta apache&quot; AND &quot;Apache Lucene&quot;\n</code></pre>\n<p>+:搜索结果中必须包含此项</p>\n<pre><code>+jakarta lucene\n</code></pre>\n<p>NOT</p>\n<pre><code>&quot;jakarta apache&quot; NOT &quot;Apache Lucene&quot;\nNOT &quot;jakarta apache&quot;\n</code></pre>\n<p>-：不能含有此项</p>\n<pre><code>&quot;jakarta apache&quot; -&quot;Apache Lucene&quot;\n</code></pre>\n<h2 id=\"分组搜索\"><a href=\"#分组搜索\" class=\"headerlink\" title=\"分组搜索\"></a>分组搜索</h2><p>Lucene支持使用括号将子句分组以形成子查询。如果要控制查询的布尔逻辑，这可能非常有用。</p>\n<pre><code>(jakarta OR apache) AND jakarta\n</code></pre>\n<h2 id=\"字段分组搜索\"><a href=\"#字段分组搜索\" class=\"headerlink\" title=\"字段分组搜索\"></a>字段分组搜索</h2><p>Lucene支持使用括号将多个子句分组到单个字段。</p>\n<pre><code>title:(+return +&quot;pink panther&quot;)\nhost:(baidu OR qq OR google) AND host:(com OR cn)\n</code></pre>\n<h2 id=\"转义特殊字符搜索\"><a href=\"#转义特殊字符搜索\" class=\"headerlink\" title=\"转义特殊字符搜索\"></a>转义特殊字符搜索</h2><p>Lucene支持转义属于查询语法的特殊字符。</p>\n<pre><code>+ - = &amp;&amp; || &gt; &lt; ! ( ) &#123; &#125; [ ] ^ &quot; ~ * ? : \\ /\n以上字符当作值搜索的时候需要用\\转义\n\\(1\\+1\\)\\=2用来查询(1+1)=2\n</code></pre>\n<h1 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h1><blockquote>\n<ul>\n<li><a href=\"https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html\">https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax\">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000002972420#articleHeader10\">https://segmentfault.com/a/1190000002972420#articleHeader10</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"lucene查询语法，适用于ELk：kibana查询\"><a href=\"#lucene查询语法，适用于ELk：kibana查询\" class=\"headerlink\" title=\"lucene查询语法，适用于ELk：kibana查询\"></a>lucene查询语法，适用于ELk：kibana查询</h1><p>Kibana在ELK中扮演着数据可视化角色，用来查询及展示数据；<br>Elasticsearch查询采用的是luncene搜索引擎，其4过滤查询语法和lucene一致。</p>\n<p><img src=\"http://owelinux.github.io/images/2018-08-03-article11-linux-luncene/elk-lucene.png\"></p>\n<p><a href=\"http://demo.elastic.co/app/kibana#/discover\">Kibana官方在线演示</a></p>\n<h2 id=\"字段搜索\"><a href=\"#字段搜索\" class=\"headerlink\" title=\"字段搜索\"></a>字段搜索</h2><p>Lucene支持实时数据。执行搜索时，您可以指定字段，也可以使用默认字段。字段名称和默认字段是特定于实现的。</p>\n<pre><code>限定字段全文搜索：field:value\n精确搜索：关键字加上双引号 filed:&quot;value&quot;\nhttp.code:404 搜索http状态码为404的文档\n</code></pre>\n<p>字段本身是否存在</p>\n<pre><code>_exists_:http：返回结果中需要有http字段\n_missing_:http：不能含有http字段\n</code></pre>\n<h2 id=\"通配符搜索\"><a href=\"#通配符搜索\" class=\"headerlink\" title=\"通配符搜索\"></a>通配符搜索</h2><p>Lucene支持单个术语内的单个和多个字符通配符搜索（不在短语查询中）。</p>\n<pre><code>? 匹配单个字符\n* 匹配0到多个字符\nte?t,test*,te*t\n</code></pre>\n<p>注意：您不能使用*或？符号作为搜索的第一个字符。</p>\n<h2 id=\"正则表达式搜索\"><a href=\"#正则表达式搜索\" class=\"headerlink\" title=\"正则表达式搜索\"></a>正则表达式搜索</h2><p>Lucene支持正向表达式搜索.</p>\n<pre><code>name:/joh?n(ath[oa]n)/\n</code></pre>\n<h2 id=\"模糊搜索\"><a href=\"#模糊搜索\" class=\"headerlink\" title=\"模糊搜索\"></a>模糊搜索</h2><pre><code>quikc~ brwn~ foks~\n~:在一个单词后面加上~启用模糊搜索，可以搜到一些拼写错误的单词\nfirst~ 这种也能匹配到 frist\n</code></pre>\n<p>还可以设置编辑距离（整数），指定需要多少相似度</p>\n<pre><code>cromm~1 会匹配到 from 和 chrome\n默认2，越大越接近搜索的原始值，设置为1基本能搜到80%拼写错误的单词\n</code></pre>\n<h2 id=\"近似搜索\"><a href=\"#近似搜索\" class=\"headerlink\" title=\"近似搜索\"></a>近似搜索</h2><p>在短语后面加上~，可以搜到被隔开或顺序不同的单词</p>\n<pre><code>&quot;where select&quot;~5 表示 select 和 where 中间可以隔着5个单词，可以搜到 select password from users where id=1\n</code></pre>\n<h2 id=\"范围搜索\"><a href=\"#范围搜索\" class=\"headerlink\" title=\"范围搜索\"></a>范围搜索</h2><p>数值/时间/IP/字符串 类型的字段可以对某一范围进行查询</p>\n<pre><code>length:[100 TO 200]\nsip:[&quot;172.24.20.110&quot; TO &quot;172.24.20.140&quot;]\ndate:&#123;&quot;now-6h&quot; TO &quot;now&quot;&#125;\ntag:&#123;b TO e&#125; 搜索b到e中间的字符\ncount:[10 TO *] * 表示一端不限制范围\ncount:[1 TO 5&#125; [ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5\n可以简化成以下写法：\nage:&gt;10\nage:&lt;=10\nage:(&gt;=10 AND &lt;20)\n</code></pre>\n<h2 id=\"优先级\"><a href=\"#优先级\" class=\"headerlink\" title=\"优先级\"></a>优先级</h2><p>使用^使一个词语比另一个搜索优先级更高，默认为1，可以为0~1之间的浮点数，来降低优先级</p>\n<pre><code>quick^2 fox\n</code></pre>\n<h2 id=\"布尔运算符搜索\"><a href=\"#布尔运算符搜索\" class=\"headerlink\" title=\"布尔运算符搜索\"></a>布尔运算符搜索</h2><p>布尔运算符允许通过逻辑运算符组合术语。Lucene支持AND，“+”，OR，NOT和“ - ”作为布尔运算符（注意：布尔运算符必须是ALL CAPS）。</p>\n<p>OR</p>\n<pre><code>&quot;jakarta apache&quot; jakarta\nor\n&quot;jakarta apache&quot; OR jakarta\n</code></pre>\n<p>AND</p>\n<pre><code>&quot;jakarta apache&quot; AND &quot;Apache Lucene&quot;\n</code></pre>\n<p>+:搜索结果中必须包含此项</p>\n<pre><code>+jakarta lucene\n</code></pre>\n<p>NOT</p>\n<pre><code>&quot;jakarta apache&quot; NOT &quot;Apache Lucene&quot;\nNOT &quot;jakarta apache&quot;\n</code></pre>\n<p>-：不能含有此项</p>\n<pre><code>&quot;jakarta apache&quot; -&quot;Apache Lucene&quot;\n</code></pre>\n<h2 id=\"分组搜索\"><a href=\"#分组搜索\" class=\"headerlink\" title=\"分组搜索\"></a>分组搜索</h2><p>Lucene支持使用括号将子句分组以形成子查询。如果要控制查询的布尔逻辑，这可能非常有用。</p>\n<pre><code>(jakarta OR apache) AND jakarta\n</code></pre>\n<h2 id=\"字段分组搜索\"><a href=\"#字段分组搜索\" class=\"headerlink\" title=\"字段分组搜索\"></a>字段分组搜索</h2><p>Lucene支持使用括号将多个子句分组到单个字段。</p>\n<pre><code>title:(+return +&quot;pink panther&quot;)\nhost:(baidu OR qq OR google) AND host:(com OR cn)\n</code></pre>\n<h2 id=\"转义特殊字符搜索\"><a href=\"#转义特殊字符搜索\" class=\"headerlink\" title=\"转义特殊字符搜索\"></a>转义特殊字符搜索</h2><p>Lucene支持转义属于查询语法的特殊字符。</p>\n<pre><code>+ - = &amp;&amp; || &gt; &lt; ! ( ) &#123; &#125; [ ] ^ &quot; ~ * ? : \\ /\n以上字符当作值搜索的时候需要用\\转义\n\\(1\\+1\\)\\=2用来查询(1+1)=2\n</code></pre>\n<h1 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h1><blockquote>\n<ul>\n<li><a href=\"https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html\">https://lucene.apache.org/core/5_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax\">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000002972420#articleHeader10\">https://segmentfault.com/a/1190000002972420#articleHeader10</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"srcache-nginx-module+pika实现nginx页面缓存","date":"2018-08-07T07:41:54.000Z","author":"owelinux","excerpt":"srcache-nginx-module+pika实现nginx页面缓存.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# srcache-nginx-module+pika实现nginx页面缓存\n\n缓存应用场景：客户端（浏览器缓存）、数据库缓存、代理层缓存、应用层缓存等；\n\n针对代理层缓存，我们可以将静态资源放入cdn或者本地页面缓存加快用户访问速度，缓解服务器压力。\n\n下面我们针对页面缓存采用pika+srcache方案：\n\n## openresty编译模块 \n以下必要模块支持：\n> * srcache-nginx-module\n> * ngx_lua \n> * memc-nginx-module\n> * redis2-nginx-module\n> * redis-nginx-module\n\n生产应用的编译参数：\n```\n[root@WEB3 ~]# /usr/local/openresty/nginx/sbin/nginx -V\nnginx version: openresty/1.11.2.4\nbuilt by gcc 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) \nbuilt with OpenSSL 1.0.1e-fips 11 Feb 2013\nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/local/openresty/nginx --with-cc-opt=-O2 --add-module=../ngx_devel_kit-0.3.0 --add-module=../echo-nginx-module-0.60 --add-module=../xss-nginx-module-0.05 --add-module=../ngx_coolkit-0.2rc3 --add-module=../set-misc-nginx-module-0.31 --add-module=../form-input-nginx-module-0.12 --add-module=../encrypted-session-nginx-module-0.06 --add-module=../srcache-nginx-module-0.31 --add-module=../ngx_lua-0.10.8 --add-module=../ngx_lua_upstream-0.06 --add-module=../headers-more-nginx-module-0.32 --add-module=../array-var-nginx-module-0.05 --add-module=../memc-nginx-module-0.18 --add-module=../redis2-nginx-module-0.14 --add-module=../redis-nginx-module-0.3.7 --add-module=../rds-json-nginx-module-0.14 --add-module=../rds-csv-nginx-module-0.07 --with-ld-opt=-Wl,-rpath,/usr/local/openresty/luajit/lib --with-pcre=/usr/local/pcre-8.38 --with-stream --with-http_ssl_module\n```\n\n## pika介绍\n### Pika是什么\nPika是DBA和基础架构组联合开发的类Redis 存储系统，所以完全支持Redis协议，用户不需要修改任何代码，就可以将服务迁移至Pika。Pika是一个可持久化的大容量Redis存储服务，兼容string、hash、list、zset、set的绝大接口兼容详情，解决Redis由于存储数据量巨大而导致内存不够用的容量瓶颈，并且可以像Redis一样，通过slaveof命令进行主从备份，支持全同步和部分同步。同时DBA团队还提供了迁移工具， 所以用户不会感知这个迁移的过程，迁移是平滑的。\n\n### 与Redis的比较\nPika相对于Redis，最大的不同就是Pika是持久化存储，数据存在磁盘上，而Redis是内存存储，由此不同也给Pika带来了相对于Redis的优势和劣势\n\n优势：\n\n1.容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小\n\n2.加载db速度快：Pika在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rdb或者oplog，Pika重启不用加载所有数据到内存就能恢复之前的数据, 不需要进行回放数据操作。\n\n3.备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题\n\n劣势：\n由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。\n\n### 适用场景\n从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。 而在实际使用中，Pika的性能大约是Redis的50%。\n\n### Pika的特点\n1.容量大，支持百G数据量的存储\n2.兼容Redis，不用修改代码即可平滑从Redis迁移到Pika\n3.支持主从(slaveof)\n4.完善的运维命令\n\n### 当前适用情况\n目前Pika在线上部署并运行了20多个巨型（承载数据与Redis相比）集群 粗略的统计如下：当前每天承载的总请求量超过100亿，当前承载的数据总量约3TB\n\n### 二进制包安装部署\n```\ncd /usr/local/\nwget https://github.com/Qihoo360/pika/releases/download/v3.0.0/pika-linux-x86_64-v3.0.0.tar.bz2\ntar -jxvf pika-linux-x86_64-v3.0.0.tar.bz2 \nmv pika-linux-x86_64-v3.0.0  pika\n# 增加开机自启动\necho \"/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\" >> /etc/rc.local\n# 启动\n/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\n# 验证\n[root@WEB3 output]# ss -lntp | grep 9221\nLISTEN     0      128               127.0.0.1:9221                     *:*      users:((\"pika\",23138,50))\nLISTEN     0      128             10.30.10.11:9221                     *:*      users:((\"pika\",23138,49))\n```\n\n## 配置nginx\ncat nginx.conf\n```\n   lua_package_path \"/usr/local/openresty/nginx/lua/?.lua;;\";\n   lua_shared_dict config 320m;\n   lua_shared_dict srcache_locks 10m;\n   lua_shared_dict mn_whiteurl 1m;\n\n   init_by_lua_file /usr/local/openresty/nginx/lua/init.lua;\n   access_by_lua_file /usr/local/openresty/nginx/lua/waf.lua;\n   body_filter_by_lua_file /usr/local/openresty/nginx/lua/body_cache.lua;\n\n   include /usr/local/openresty/nginx/conf.d/*.conf;\n\n    server {\n        listen       80;\n        server_name  www.test.com;\n        root /var/www/test;\n        index  index.html index.htm index.php;\n\n        access_log  /var/log/nginx/access.log main;\n        error_log /var/log/nginx/error.log;\n\n        userid on;\n        userid_domain test.com;\n        userid_expires 1095d;\n\t\t\n\t    upstream redis_m {\n           server 127.0.0.1:9221;\n           server 192.168.1.1:9221 backup;\n           keepalive 4096;\n        }\n\t\t\n\t\tupstream memcache_m {\n           server 127.0.0.1:11214;\n           server 192.168.1.1:11214 backup;\n           keepalive 4096;\n        }\n\n        location /memc {\n                internal;\n                set $memc_cmd $arg_cmd;\n                memc_cmds_allowed get set add delete flush_all;\n                memc_connect_timeout 300ms;\n                memc_send_timeout 300ms;\n                memc_read_timeout 300ms;\n                set_unescape_uri $memc_key $arg_key;\n                set $memc_exptime $arg_expiretime;\n                memc_pass memcache_m;\n        }\n\n        location = /redisttl {\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query ttl $key;\n            redis2_pass redis_m;\n        }\n        location = /redispersist {\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query persist $key;\n            redis2_pass redis_m;\n        }\n\n        location = /redis2clearcache {\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        }\n\n\n        location = /redis {\n                internal;\n                set $redis_key $arg_key;\n                redis_pass redis_m;\n        }\n\n        location = /redis2 {\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n\n                redis2_query set $key $echo_request_body;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        }\n\n        location = /lua_memc_del {\n                set $cache_stale 0;  # 1 day\n                content_by_lua '\n                ngx.header.content_type = \"text/plain\";\n                if ngx.var.arg_pwd ~= \"to8to\" then\n                        ngx.say(\"error\");\n                else\n                        local res = ngx.location.capture(\"/redis2clearcache\", {\n                                        args = { expiretime = ngx.var.cache_stale,key = ngx.var.arg_key}\n                                        })\n                        if res.status == 200 then\n                                ngx.say(res.body);\n                        else\n                                ngx.say(\"not exist\");\n                        end\n                end\n                ';\n        }\n\n        location / {\n        \n                if (!-e $request_filename)\n                {\n                rewrite ^(.*)$ /index.php last;\n                }\n        }\n\n\n        location ~* ^.+\\.(ico|gif|jpg|jpeg|png|css|js|txt|swf|wav|bmp|webp|apk|zip|rar)$ {\n                access_log off;\n                expires 30d;\n        }\n\n        location ~* \"\\.htaccess$\" {\n            deny  all;\n        }\n        \n        location ~* \"/(\\.svn|\\.git|runtime|protected|framework)/\" {\n            deny all;\n        }\n        \n        location ~* \"^/(assets|html|css|js|images|img|static)/(.*)\\.(php|php5)$\"\n        {\n            deny all;\n        }\n\n        location ~ \\.php$ {\n                if (!-e $request_filename)\n                {\n                    rewrite ^(.*)$ /index.php last;\n                }\n                try_files /index.php =404;\n                set $prefix_wap \"wap\";\n                set_md5 $key $prefix_wap$host$request_uri;\n                set $mtime 3600;\n                set $skip 0;\n\n                if ($request_uri ~* ^\\/(\\?(.*))?$)\n                {\n                        set $skip 1;\n                        set $mtime 0;\n                }\n\n\n                if ($request_uri ~* /index/Citycookie )\n                {\n                        set $skip 1;\n                        set $mtime 0;\n                }\n\n\n\n                if ($request_uri ~* ^/test(.*)$)\n                {\n                        set $skip 0;\n                        set $mtime 604800;\n                }\n\n                #此if判断一定要放在最后,否则会出现POST请求被缓存的情况\n                if ($request_method = POST)\n                {\n                         set $skip 1;\n                         set $mtime 0;\n                }\n\n                srcache_fetch_skip $skip;\n                srcache_store_skip $skip;\n                set $cache_status 0;\n                add_header  Cache-status $cache_status;\n\n                set $cache_lock srcache_locks;\n                set $cache_ttl /redisttl;\n                set $cache_persist /redispersist;\n                set $cache_key $prefix_wap$host$request_uri;\n                set $cache_stale 86400;  # 1 day\n \n                set_by_lua $expireTime 'return ngx.var.mtime + ngx.var.cache_stale';\n                rewrite_by_lua_file /usr/local/openresty/lualib/resty/cache.lua;\n \n                if ($http_x_skip_fetch != TRUE){\n                        srcache_fetch GET /redis key=$key;\n                }\n                srcache_store PUT /redis2 key=$key&expiretime=$expireTime;\n\n                srcache_methods GET PUT POST;\n                add_header X-Cached-From $srcache_fetch_status;\n                add_header Cache-Control max-age=$mtime;\n                if ( $mtime = 0)\n                {\n                    add_header Cache-Control no-cache;\n                }\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;\n                include        fastcgi_params;\n                fastcgi_intercept_errors on;\n        }\n\n    }\n```\n\n## 验证缓存情况\n```\n[root@WEB3 ~]# curl -I  -H 'host:www.test.com' http://127.0.0.1/test/\nHTTP/1.1 200 OK\nServer: openresty\nDate: Tue, 07 Aug 2018 08:49:36 GMT\nContent-Type: text/html;charset=utf-8\nContent-Length: 90799\nConnection: keep-alive\nVary: Accept-Encoding\nCache-status: 0\nX-Cached-From: HIT\nCache-Control: max-age=604800\nSet-Cookie: uid=fwAAAVtpXSC+sTyIAwMHAg==; expires=Fri, 06-Aug-21 08:49:36 GMT; domain=test.com; path=/\n```\n## 缓存命中率分析\n```\n awk '{if($(NF-1) ~ \"HIT\") hit++} END {printf \"file:'$a' time:'$LAST_DAY': %d %d %.2f%n\" ,hit,NR,hit/NR}' /var/log/nginx/access.log\n```\n## 本文涉及的lua脚本\n[cache.lua](https://raw.githubusercontent.com/owelinux/owelinux.github.io/master/images/2018-08-07-article12-linux-srcache-nginx-module/cache.lua)\n\n# 参考：\n> * [https://github.com/Qihoo360/pika/wiki](https://github.com/Qihoo360/pika/wiki)\n> * [https://github.com/openresty/srcache-nginx-module](https://github.com/openresty/srcache-nginx-module)\n","source":"_posts/2018-08-07-article12-linux-srcache-nginx-module.md","raw":"---\nlayout: post\ntitle:  \"srcache-nginx-module+pika实现nginx页面缓存\"\ndate:   2018-08-07 15:41:54\nauthor: owelinux\ncategories: linux\ntags:  nginx pika cache\nexcerpt: srcache-nginx-module+pika实现nginx页面缓存.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# srcache-nginx-module+pika实现nginx页面缓存\n\n缓存应用场景：客户端（浏览器缓存）、数据库缓存、代理层缓存、应用层缓存等；\n\n针对代理层缓存，我们可以将静态资源放入cdn或者本地页面缓存加快用户访问速度，缓解服务器压力。\n\n下面我们针对页面缓存采用pika+srcache方案：\n\n## openresty编译模块 \n以下必要模块支持：\n> * srcache-nginx-module\n> * ngx_lua \n> * memc-nginx-module\n> * redis2-nginx-module\n> * redis-nginx-module\n\n生产应用的编译参数：\n```\n[root@WEB3 ~]# /usr/local/openresty/nginx/sbin/nginx -V\nnginx version: openresty/1.11.2.4\nbuilt by gcc 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) \nbuilt with OpenSSL 1.0.1e-fips 11 Feb 2013\nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/local/openresty/nginx --with-cc-opt=-O2 --add-module=../ngx_devel_kit-0.3.0 --add-module=../echo-nginx-module-0.60 --add-module=../xss-nginx-module-0.05 --add-module=../ngx_coolkit-0.2rc3 --add-module=../set-misc-nginx-module-0.31 --add-module=../form-input-nginx-module-0.12 --add-module=../encrypted-session-nginx-module-0.06 --add-module=../srcache-nginx-module-0.31 --add-module=../ngx_lua-0.10.8 --add-module=../ngx_lua_upstream-0.06 --add-module=../headers-more-nginx-module-0.32 --add-module=../array-var-nginx-module-0.05 --add-module=../memc-nginx-module-0.18 --add-module=../redis2-nginx-module-0.14 --add-module=../redis-nginx-module-0.3.7 --add-module=../rds-json-nginx-module-0.14 --add-module=../rds-csv-nginx-module-0.07 --with-ld-opt=-Wl,-rpath,/usr/local/openresty/luajit/lib --with-pcre=/usr/local/pcre-8.38 --with-stream --with-http_ssl_module\n```\n\n## pika介绍\n### Pika是什么\nPika是DBA和基础架构组联合开发的类Redis 存储系统，所以完全支持Redis协议，用户不需要修改任何代码，就可以将服务迁移至Pika。Pika是一个可持久化的大容量Redis存储服务，兼容string、hash、list、zset、set的绝大接口兼容详情，解决Redis由于存储数据量巨大而导致内存不够用的容量瓶颈，并且可以像Redis一样，通过slaveof命令进行主从备份，支持全同步和部分同步。同时DBA团队还提供了迁移工具， 所以用户不会感知这个迁移的过程，迁移是平滑的。\n\n### 与Redis的比较\nPika相对于Redis，最大的不同就是Pika是持久化存储，数据存在磁盘上，而Redis是内存存储，由此不同也给Pika带来了相对于Redis的优势和劣势\n\n优势：\n\n1.容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小\n\n2.加载db速度快：Pika在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rdb或者oplog，Pika重启不用加载所有数据到内存就能恢复之前的数据, 不需要进行回放数据操作。\n\n3.备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题\n\n劣势：\n由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。\n\n### 适用场景\n从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。 而在实际使用中，Pika的性能大约是Redis的50%。\n\n### Pika的特点\n1.容量大，支持百G数据量的存储\n2.兼容Redis，不用修改代码即可平滑从Redis迁移到Pika\n3.支持主从(slaveof)\n4.完善的运维命令\n\n### 当前适用情况\n目前Pika在线上部署并运行了20多个巨型（承载数据与Redis相比）集群 粗略的统计如下：当前每天承载的总请求量超过100亿，当前承载的数据总量约3TB\n\n### 二进制包安装部署\n```\ncd /usr/local/\nwget https://github.com/Qihoo360/pika/releases/download/v3.0.0/pika-linux-x86_64-v3.0.0.tar.bz2\ntar -jxvf pika-linux-x86_64-v3.0.0.tar.bz2 \nmv pika-linux-x86_64-v3.0.0  pika\n# 增加开机自启动\necho \"/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\" >> /etc/rc.local\n# 启动\n/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\n# 验证\n[root@WEB3 output]# ss -lntp | grep 9221\nLISTEN     0      128               127.0.0.1:9221                     *:*      users:((\"pika\",23138,50))\nLISTEN     0      128             10.30.10.11:9221                     *:*      users:((\"pika\",23138,49))\n```\n\n## 配置nginx\ncat nginx.conf\n```\n   lua_package_path \"/usr/local/openresty/nginx/lua/?.lua;;\";\n   lua_shared_dict config 320m;\n   lua_shared_dict srcache_locks 10m;\n   lua_shared_dict mn_whiteurl 1m;\n\n   init_by_lua_file /usr/local/openresty/nginx/lua/init.lua;\n   access_by_lua_file /usr/local/openresty/nginx/lua/waf.lua;\n   body_filter_by_lua_file /usr/local/openresty/nginx/lua/body_cache.lua;\n\n   include /usr/local/openresty/nginx/conf.d/*.conf;\n\n    server {\n        listen       80;\n        server_name  www.test.com;\n        root /var/www/test;\n        index  index.html index.htm index.php;\n\n        access_log  /var/log/nginx/access.log main;\n        error_log /var/log/nginx/error.log;\n\n        userid on;\n        userid_domain test.com;\n        userid_expires 1095d;\n\t\t\n\t    upstream redis_m {\n           server 127.0.0.1:9221;\n           server 192.168.1.1:9221 backup;\n           keepalive 4096;\n        }\n\t\t\n\t\tupstream memcache_m {\n           server 127.0.0.1:11214;\n           server 192.168.1.1:11214 backup;\n           keepalive 4096;\n        }\n\n        location /memc {\n                internal;\n                set $memc_cmd $arg_cmd;\n                memc_cmds_allowed get set add delete flush_all;\n                memc_connect_timeout 300ms;\n                memc_send_timeout 300ms;\n                memc_read_timeout 300ms;\n                set_unescape_uri $memc_key $arg_key;\n                set $memc_exptime $arg_expiretime;\n                memc_pass memcache_m;\n        }\n\n        location = /redisttl {\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query ttl $key;\n            redis2_pass redis_m;\n        }\n        location = /redispersist {\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query persist $key;\n            redis2_pass redis_m;\n        }\n\n        location = /redis2clearcache {\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        }\n\n\n        location = /redis {\n                internal;\n                set $redis_key $arg_key;\n                redis_pass redis_m;\n        }\n\n        location = /redis2 {\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n\n                redis2_query set $key $echo_request_body;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        }\n\n        location = /lua_memc_del {\n                set $cache_stale 0;  # 1 day\n                content_by_lua '\n                ngx.header.content_type = \"text/plain\";\n                if ngx.var.arg_pwd ~= \"to8to\" then\n                        ngx.say(\"error\");\n                else\n                        local res = ngx.location.capture(\"/redis2clearcache\", {\n                                        args = { expiretime = ngx.var.cache_stale,key = ngx.var.arg_key}\n                                        })\n                        if res.status == 200 then\n                                ngx.say(res.body);\n                        else\n                                ngx.say(\"not exist\");\n                        end\n                end\n                ';\n        }\n\n        location / {\n        \n                if (!-e $request_filename)\n                {\n                rewrite ^(.*)$ /index.php last;\n                }\n        }\n\n\n        location ~* ^.+\\.(ico|gif|jpg|jpeg|png|css|js|txt|swf|wav|bmp|webp|apk|zip|rar)$ {\n                access_log off;\n                expires 30d;\n        }\n\n        location ~* \"\\.htaccess$\" {\n            deny  all;\n        }\n        \n        location ~* \"/(\\.svn|\\.git|runtime|protected|framework)/\" {\n            deny all;\n        }\n        \n        location ~* \"^/(assets|html|css|js|images|img|static)/(.*)\\.(php|php5)$\"\n        {\n            deny all;\n        }\n\n        location ~ \\.php$ {\n                if (!-e $request_filename)\n                {\n                    rewrite ^(.*)$ /index.php last;\n                }\n                try_files /index.php =404;\n                set $prefix_wap \"wap\";\n                set_md5 $key $prefix_wap$host$request_uri;\n                set $mtime 3600;\n                set $skip 0;\n\n                if ($request_uri ~* ^\\/(\\?(.*))?$)\n                {\n                        set $skip 1;\n                        set $mtime 0;\n                }\n\n\n                if ($request_uri ~* /index/Citycookie )\n                {\n                        set $skip 1;\n                        set $mtime 0;\n                }\n\n\n\n                if ($request_uri ~* ^/test(.*)$)\n                {\n                        set $skip 0;\n                        set $mtime 604800;\n                }\n\n                #此if判断一定要放在最后,否则会出现POST请求被缓存的情况\n                if ($request_method = POST)\n                {\n                         set $skip 1;\n                         set $mtime 0;\n                }\n\n                srcache_fetch_skip $skip;\n                srcache_store_skip $skip;\n                set $cache_status 0;\n                add_header  Cache-status $cache_status;\n\n                set $cache_lock srcache_locks;\n                set $cache_ttl /redisttl;\n                set $cache_persist /redispersist;\n                set $cache_key $prefix_wap$host$request_uri;\n                set $cache_stale 86400;  # 1 day\n \n                set_by_lua $expireTime 'return ngx.var.mtime + ngx.var.cache_stale';\n                rewrite_by_lua_file /usr/local/openresty/lualib/resty/cache.lua;\n \n                if ($http_x_skip_fetch != TRUE){\n                        srcache_fetch GET /redis key=$key;\n                }\n                srcache_store PUT /redis2 key=$key&expiretime=$expireTime;\n\n                srcache_methods GET PUT POST;\n                add_header X-Cached-From $srcache_fetch_status;\n                add_header Cache-Control max-age=$mtime;\n                if ( $mtime = 0)\n                {\n                    add_header Cache-Control no-cache;\n                }\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;\n                include        fastcgi_params;\n                fastcgi_intercept_errors on;\n        }\n\n    }\n```\n\n## 验证缓存情况\n```\n[root@WEB3 ~]# curl -I  -H 'host:www.test.com' http://127.0.0.1/test/\nHTTP/1.1 200 OK\nServer: openresty\nDate: Tue, 07 Aug 2018 08:49:36 GMT\nContent-Type: text/html;charset=utf-8\nContent-Length: 90799\nConnection: keep-alive\nVary: Accept-Encoding\nCache-status: 0\nX-Cached-From: HIT\nCache-Control: max-age=604800\nSet-Cookie: uid=fwAAAVtpXSC+sTyIAwMHAg==; expires=Fri, 06-Aug-21 08:49:36 GMT; domain=test.com; path=/\n```\n## 缓存命中率分析\n```\n awk '{if($(NF-1) ~ \"HIT\") hit++} END {printf \"file:'$a' time:'$LAST_DAY': %d %d %.2f%n\" ,hit,NR,hit/NR}' /var/log/nginx/access.log\n```\n## 本文涉及的lua脚本\n[cache.lua](https://raw.githubusercontent.com/owelinux/owelinux.github.io/master/images/2018-08-07-article12-linux-srcache-nginx-module/cache.lua)\n\n# 参考：\n> * [https://github.com/Qihoo360/pika/wiki](https://github.com/Qihoo360/pika/wiki)\n> * [https://github.com/openresty/srcache-nginx-module](https://github.com/openresty/srcache-nginx-module)\n","slug":"2018-08-07-article12-linux-srcache-nginx-module","published":1,"updated":"2021-02-09T02:00:24.566Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzs000fyc9783uyb66w","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"srcache-nginx-module-pika实现nginx页面缓存\"><a href=\"#srcache-nginx-module-pika实现nginx页面缓存\" class=\"headerlink\" title=\"srcache-nginx-module+pika实现nginx页面缓存\"></a>srcache-nginx-module+pika实现nginx页面缓存</h1><p>缓存应用场景：客户端（浏览器缓存）、数据库缓存、代理层缓存、应用层缓存等；</p>\n<p>针对代理层缓存，我们可以将静态资源放入cdn或者本地页面缓存加快用户访问速度，缓解服务器压力。</p>\n<p>下面我们针对页面缓存采用pika+srcache方案：</p>\n<h2 id=\"openresty编译模块\"><a href=\"#openresty编译模块\" class=\"headerlink\" title=\"openresty编译模块\"></a>openresty编译模块</h2><p>以下必要模块支持：</p>\n<blockquote>\n<ul>\n<li>srcache-nginx-module</li>\n<li>ngx_lua </li>\n<li>memc-nginx-module</li>\n<li>redis2-nginx-module</li>\n<li>redis-nginx-module</li>\n</ul>\n</blockquote>\n<p>生产应用的编译参数：</p>\n<pre><code>[root@WEB3 ~]# /usr/local/openresty/nginx/sbin/nginx -V\nnginx version: openresty/1.11.2.4\nbuilt by gcc 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) \nbuilt with OpenSSL 1.0.1e-fips 11 Feb 2013\nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/local/openresty/nginx --with-cc-opt=-O2 --add-module=../ngx_devel_kit-0.3.0 --add-module=../echo-nginx-module-0.60 --add-module=../xss-nginx-module-0.05 --add-module=../ngx_coolkit-0.2rc3 --add-module=../set-misc-nginx-module-0.31 --add-module=../form-input-nginx-module-0.12 --add-module=../encrypted-session-nginx-module-0.06 --add-module=../srcache-nginx-module-0.31 --add-module=../ngx_lua-0.10.8 --add-module=../ngx_lua_upstream-0.06 --add-module=../headers-more-nginx-module-0.32 --add-module=../array-var-nginx-module-0.05 --add-module=../memc-nginx-module-0.18 --add-module=../redis2-nginx-module-0.14 --add-module=../redis-nginx-module-0.3.7 --add-module=../rds-json-nginx-module-0.14 --add-module=../rds-csv-nginx-module-0.07 --with-ld-opt=-Wl,-rpath,/usr/local/openresty/luajit/lib --with-pcre=/usr/local/pcre-8.38 --with-stream --with-http_ssl_module\n</code></pre>\n<h2 id=\"pika介绍\"><a href=\"#pika介绍\" class=\"headerlink\" title=\"pika介绍\"></a>pika介绍</h2><h3 id=\"Pika是什么\"><a href=\"#Pika是什么\" class=\"headerlink\" title=\"Pika是什么\"></a>Pika是什么</h3><p>Pika是DBA和基础架构组联合开发的类Redis 存储系统，所以完全支持Redis协议，用户不需要修改任何代码，就可以将服务迁移至Pika。Pika是一个可持久化的大容量Redis存储服务，兼容string、hash、list、zset、set的绝大接口兼容详情，解决Redis由于存储数据量巨大而导致内存不够用的容量瓶颈，并且可以像Redis一样，通过slaveof命令进行主从备份，支持全同步和部分同步。同时DBA团队还提供了迁移工具， 所以用户不会感知这个迁移的过程，迁移是平滑的。</p>\n<h3 id=\"与Redis的比较\"><a href=\"#与Redis的比较\" class=\"headerlink\" title=\"与Redis的比较\"></a>与Redis的比较</h3><p>Pika相对于Redis，最大的不同就是Pika是持久化存储，数据存在磁盘上，而Redis是内存存储，由此不同也给Pika带来了相对于Redis的优势和劣势</p>\n<p>优势：</p>\n<p>1.容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小</p>\n<p>2.加载db速度快：Pika在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rdb或者oplog，Pika重启不用加载所有数据到内存就能恢复之前的数据, 不需要进行回放数据操作。</p>\n<p>3.备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题</p>\n<p>劣势：<br>由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。</p>\n<h3 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a>适用场景</h3><p>从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。 而在实际使用中，Pika的性能大约是Redis的50%。</p>\n<h3 id=\"Pika的特点\"><a href=\"#Pika的特点\" class=\"headerlink\" title=\"Pika的特点\"></a>Pika的特点</h3><p>1.容量大，支持百G数据量的存储<br>2.兼容Redis，不用修改代码即可平滑从Redis迁移到Pika<br>3.支持主从(slaveof)<br>4.完善的运维命令</p>\n<h3 id=\"当前适用情况\"><a href=\"#当前适用情况\" class=\"headerlink\" title=\"当前适用情况\"></a>当前适用情况</h3><p>目前Pika在线上部署并运行了20多个巨型（承载数据与Redis相比）集群 粗略的统计如下：当前每天承载的总请求量超过100亿，当前承载的数据总量约3TB</p>\n<h3 id=\"二进制包安装部署\"><a href=\"#二进制包安装部署\" class=\"headerlink\" title=\"二进制包安装部署\"></a>二进制包安装部署</h3><pre><code>cd /usr/local/\nwget https://github.com/Qihoo360/pika/releases/download/v3.0.0/pika-linux-x86_64-v3.0.0.tar.bz2\ntar -jxvf pika-linux-x86_64-v3.0.0.tar.bz2 \nmv pika-linux-x86_64-v3.0.0  pika\n# 增加开机自启动\necho &quot;/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf&quot; &gt;&gt; /etc/rc.local\n# 启动\n/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\n# 验证\n[root@WEB3 output]# ss -lntp | grep 9221\nLISTEN     0      128               127.0.0.1:9221                     *:*      users:((&quot;pika&quot;,23138,50))\nLISTEN     0      128             10.30.10.11:9221                     *:*      users:((&quot;pika&quot;,23138,49))\n</code></pre>\n<h2 id=\"配置nginx\"><a href=\"#配置nginx\" class=\"headerlink\" title=\"配置nginx\"></a>配置nginx</h2><p>cat nginx.conf</p>\n<pre><code>   lua_package_path &quot;/usr/local/openresty/nginx/lua/?.lua;;&quot;;\n   lua_shared_dict config 320m;\n   lua_shared_dict srcache_locks 10m;\n   lua_shared_dict mn_whiteurl 1m;\n\n   init_by_lua_file /usr/local/openresty/nginx/lua/init.lua;\n   access_by_lua_file /usr/local/openresty/nginx/lua/waf.lua;\n   body_filter_by_lua_file /usr/local/openresty/nginx/lua/body_cache.lua;\n\n   include /usr/local/openresty/nginx/conf.d/*.conf;\n\n    server &#123;\n        listen       80;\n        server_name  www.test.com;\n        root /var/www/test;\n        index  index.html index.htm index.php;\n\n        access_log  /var/log/nginx/access.log main;\n        error_log /var/log/nginx/error.log;\n\n        userid on;\n        userid_domain test.com;\n        userid_expires 1095d;\n        \n        upstream redis_m &#123;\n           server 127.0.0.1:9221;\n           server 192.168.1.1:9221 backup;\n           keepalive 4096;\n        &#125;\n        \n        upstream memcache_m &#123;\n           server 127.0.0.1:11214;\n           server 192.168.1.1:11214 backup;\n           keepalive 4096;\n        &#125;\n\n        location /memc &#123;\n                internal;\n                set $memc_cmd $arg_cmd;\n                memc_cmds_allowed get set add delete flush_all;\n                memc_connect_timeout 300ms;\n                memc_send_timeout 300ms;\n                memc_read_timeout 300ms;\n                set_unescape_uri $memc_key $arg_key;\n                set $memc_exptime $arg_expiretime;\n                memc_pass memcache_m;\n        &#125;\n\n        location = /redisttl &#123;\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query ttl $key;\n            redis2_pass redis_m;\n        &#125;\n        location = /redispersist &#123;\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query persist $key;\n            redis2_pass redis_m;\n        &#125;\n\n        location = /redis2clearcache &#123;\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        &#125;\n\n\n        location = /redis &#123;\n                internal;\n                set $redis_key $arg_key;\n                redis_pass redis_m;\n        &#125;\n\n        location = /redis2 &#123;\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n\n                redis2_query set $key $echo_request_body;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        &#125;\n\n        location = /lua_memc_del &#123;\n                set $cache_stale 0;  # 1 day\n                content_by_lua &#39;\n                ngx.header.content_type = &quot;text/plain&quot;;\n                if ngx.var.arg_pwd ~= &quot;to8to&quot; then\n                        ngx.say(&quot;error&quot;);\n                else\n                        local res = ngx.location.capture(&quot;/redis2clearcache&quot;, &#123;\n                                        args = &#123; expiretime = ngx.var.cache_stale,key = ngx.var.arg_key&#125;\n                                        &#125;)\n                        if res.status == 200 then\n                                ngx.say(res.body);\n                        else\n                                ngx.say(&quot;not exist&quot;);\n                        end\n                end\n                &#39;;\n        &#125;\n\n        location / &#123;\n        \n                if (!-e $request_filename)\n                &#123;\n                rewrite ^(.*)$ /index.php last;\n                &#125;\n        &#125;\n\n\n        location ~* ^.+\\.(ico|gif|jpg|jpeg|png|css|js|txt|swf|wav|bmp|webp|apk|zip|rar)$ &#123;\n                access_log off;\n                expires 30d;\n        &#125;\n\n        location ~* &quot;\\.htaccess$&quot; &#123;\n            deny  all;\n        &#125;\n        \n        location ~* &quot;/(\\.svn|\\.git|runtime|protected|framework)/&quot; &#123;\n            deny all;\n        &#125;\n        \n        location ~* &quot;^/(assets|html|css|js|images|img|static)/(.*)\\.(php|php5)$&quot;\n        &#123;\n            deny all;\n        &#125;\n\n        location ~ \\.php$ &#123;\n                if (!-e $request_filename)\n                &#123;\n                    rewrite ^(.*)$ /index.php last;\n                &#125;\n                try_files /index.php =404;\n                set $prefix_wap &quot;wap&quot;;\n                set_md5 $key $prefix_wap$host$request_uri;\n                set $mtime 3600;\n                set $skip 0;\n\n                if ($request_uri ~* ^\\/(\\?(.*))?$)\n                &#123;\n                        set $skip 1;\n                        set $mtime 0;\n                &#125;\n\n\n                if ($request_uri ~* /index/Citycookie )\n                &#123;\n                        set $skip 1;\n                        set $mtime 0;\n                &#125;\n\n\n\n                if ($request_uri ~* ^/test(.*)$)\n                &#123;\n                        set $skip 0;\n                        set $mtime 604800;\n                &#125;\n\n                #此if判断一定要放在最后,否则会出现POST请求被缓存的情况\n                if ($request_method = POST)\n                &#123;\n                         set $skip 1;\n                         set $mtime 0;\n                &#125;\n\n                srcache_fetch_skip $skip;\n                srcache_store_skip $skip;\n                set $cache_status 0;\n                add_header  Cache-status $cache_status;\n\n                set $cache_lock srcache_locks;\n                set $cache_ttl /redisttl;\n                set $cache_persist /redispersist;\n                set $cache_key $prefix_wap$host$request_uri;\n                set $cache_stale 86400;  # 1 day\n \n                set_by_lua $expireTime &#39;return ngx.var.mtime + ngx.var.cache_stale&#39;;\n                rewrite_by_lua_file /usr/local/openresty/lualib/resty/cache.lua;\n \n                if ($http_x_skip_fetch != TRUE)&#123;\n                        srcache_fetch GET /redis key=$key;\n                &#125;\n                srcache_store PUT /redis2 key=$key&amp;expiretime=$expireTime;\n\n                srcache_methods GET PUT POST;\n                add_header X-Cached-From $srcache_fetch_status;\n                add_header Cache-Control max-age=$mtime;\n                if ( $mtime = 0)\n                &#123;\n                    add_header Cache-Control no-cache;\n                &#125;\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;\n                include        fastcgi_params;\n                fastcgi_intercept_errors on;\n        &#125;\n\n    &#125;\n</code></pre>\n<h2 id=\"验证缓存情况\"><a href=\"#验证缓存情况\" class=\"headerlink\" title=\"验证缓存情况\"></a>验证缓存情况</h2><pre><code>[root@WEB3 ~]# curl -I  -H &#39;host:www.test.com&#39; http://127.0.0.1/test/\nHTTP/1.1 200 OK\nServer: openresty\nDate: Tue, 07 Aug 2018 08:49:36 GMT\nContent-Type: text/html;charset=utf-8\nContent-Length: 90799\nConnection: keep-alive\nVary: Accept-Encoding\nCache-status: 0\nX-Cached-From: HIT\nCache-Control: max-age=604800\nSet-Cookie: uid=fwAAAVtpXSC+sTyIAwMHAg==; expires=Fri, 06-Aug-21 08:49:36 GMT; domain=test.com; path=/\n</code></pre>\n<h2 id=\"缓存命中率分析\"><a href=\"#缓存命中率分析\" class=\"headerlink\" title=\"缓存命中率分析\"></a>缓存命中率分析</h2><pre><code> awk &#39;&#123;if($(NF-1) ~ &quot;HIT&quot;) hit++&#125; END &#123;printf &quot;file:&#39;$a&#39; time:&#39;$LAST_DAY&#39;: %d %d %.2f%n&quot; ,hit,NR,hit/NR&#125;&#39; /var/log/nginx/access.log\n</code></pre>\n<h2 id=\"本文涉及的lua脚本\"><a href=\"#本文涉及的lua脚本\" class=\"headerlink\" title=\"本文涉及的lua脚本\"></a>本文涉及的lua脚本</h2><p><a href=\"https://raw.githubusercontent.com/owelinux/owelinux.github.io/master/images/2018-08-07-article12-linux-srcache-nginx-module/cache.lua\">cache.lua</a></p>\n<h1 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h1><blockquote>\n<ul>\n<li><a href=\"https://github.com/Qihoo360/pika/wiki\">https://github.com/Qihoo360/pika/wiki</a></li>\n<li><a href=\"https://github.com/openresty/srcache-nginx-module\">https://github.com/openresty/srcache-nginx-module</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"srcache-nginx-module-pika实现nginx页面缓存\"><a href=\"#srcache-nginx-module-pika实现nginx页面缓存\" class=\"headerlink\" title=\"srcache-nginx-module+pika实现nginx页面缓存\"></a>srcache-nginx-module+pika实现nginx页面缓存</h1><p>缓存应用场景：客户端（浏览器缓存）、数据库缓存、代理层缓存、应用层缓存等；</p>\n<p>针对代理层缓存，我们可以将静态资源放入cdn或者本地页面缓存加快用户访问速度，缓解服务器压力。</p>\n<p>下面我们针对页面缓存采用pika+srcache方案：</p>\n<h2 id=\"openresty编译模块\"><a href=\"#openresty编译模块\" class=\"headerlink\" title=\"openresty编译模块\"></a>openresty编译模块</h2><p>以下必要模块支持：</p>\n<blockquote>\n<ul>\n<li>srcache-nginx-module</li>\n<li>ngx_lua </li>\n<li>memc-nginx-module</li>\n<li>redis2-nginx-module</li>\n<li>redis-nginx-module</li>\n</ul>\n</blockquote>\n<p>生产应用的编译参数：</p>\n<pre><code>[root@WEB3 ~]# /usr/local/openresty/nginx/sbin/nginx -V\nnginx version: openresty/1.11.2.4\nbuilt by gcc 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) \nbuilt with OpenSSL 1.0.1e-fips 11 Feb 2013\nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/local/openresty/nginx --with-cc-opt=-O2 --add-module=../ngx_devel_kit-0.3.0 --add-module=../echo-nginx-module-0.60 --add-module=../xss-nginx-module-0.05 --add-module=../ngx_coolkit-0.2rc3 --add-module=../set-misc-nginx-module-0.31 --add-module=../form-input-nginx-module-0.12 --add-module=../encrypted-session-nginx-module-0.06 --add-module=../srcache-nginx-module-0.31 --add-module=../ngx_lua-0.10.8 --add-module=../ngx_lua_upstream-0.06 --add-module=../headers-more-nginx-module-0.32 --add-module=../array-var-nginx-module-0.05 --add-module=../memc-nginx-module-0.18 --add-module=../redis2-nginx-module-0.14 --add-module=../redis-nginx-module-0.3.7 --add-module=../rds-json-nginx-module-0.14 --add-module=../rds-csv-nginx-module-0.07 --with-ld-opt=-Wl,-rpath,/usr/local/openresty/luajit/lib --with-pcre=/usr/local/pcre-8.38 --with-stream --with-http_ssl_module\n</code></pre>\n<h2 id=\"pika介绍\"><a href=\"#pika介绍\" class=\"headerlink\" title=\"pika介绍\"></a>pika介绍</h2><h3 id=\"Pika是什么\"><a href=\"#Pika是什么\" class=\"headerlink\" title=\"Pika是什么\"></a>Pika是什么</h3><p>Pika是DBA和基础架构组联合开发的类Redis 存储系统，所以完全支持Redis协议，用户不需要修改任何代码，就可以将服务迁移至Pika。Pika是一个可持久化的大容量Redis存储服务，兼容string、hash、list、zset、set的绝大接口兼容详情，解决Redis由于存储数据量巨大而导致内存不够用的容量瓶颈，并且可以像Redis一样，通过slaveof命令进行主从备份，支持全同步和部分同步。同时DBA团队还提供了迁移工具， 所以用户不会感知这个迁移的过程，迁移是平滑的。</p>\n<h3 id=\"与Redis的比较\"><a href=\"#与Redis的比较\" class=\"headerlink\" title=\"与Redis的比较\"></a>与Redis的比较</h3><p>Pika相对于Redis，最大的不同就是Pika是持久化存储，数据存在磁盘上，而Redis是内存存储，由此不同也给Pika带来了相对于Redis的优势和劣势</p>\n<p>优势：</p>\n<p>1.容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小</p>\n<p>2.加载db速度快：Pika在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rdb或者oplog，Pika重启不用加载所有数据到内存就能恢复之前的数据, 不需要进行回放数据操作。</p>\n<p>3.备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题</p>\n<p>劣势：<br>由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。</p>\n<h3 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a>适用场景</h3><p>从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。 而在实际使用中，Pika的性能大约是Redis的50%。</p>\n<h3 id=\"Pika的特点\"><a href=\"#Pika的特点\" class=\"headerlink\" title=\"Pika的特点\"></a>Pika的特点</h3><p>1.容量大，支持百G数据量的存储<br>2.兼容Redis，不用修改代码即可平滑从Redis迁移到Pika<br>3.支持主从(slaveof)<br>4.完善的运维命令</p>\n<h3 id=\"当前适用情况\"><a href=\"#当前适用情况\" class=\"headerlink\" title=\"当前适用情况\"></a>当前适用情况</h3><p>目前Pika在线上部署并运行了20多个巨型（承载数据与Redis相比）集群 粗略的统计如下：当前每天承载的总请求量超过100亿，当前承载的数据总量约3TB</p>\n<h3 id=\"二进制包安装部署\"><a href=\"#二进制包安装部署\" class=\"headerlink\" title=\"二进制包安装部署\"></a>二进制包安装部署</h3><pre><code>cd /usr/local/\nwget https://github.com/Qihoo360/pika/releases/download/v3.0.0/pika-linux-x86_64-v3.0.0.tar.bz2\ntar -jxvf pika-linux-x86_64-v3.0.0.tar.bz2 \nmv pika-linux-x86_64-v3.0.0  pika\n# 增加开机自启动\necho &quot;/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf&quot; &gt;&gt; /etc/rc.local\n# 启动\n/usr/local/pika/output/bin/pika -c /usr/local/pika/output/conf/pika.conf\n# 验证\n[root@WEB3 output]# ss -lntp | grep 9221\nLISTEN     0      128               127.0.0.1:9221                     *:*      users:((&quot;pika&quot;,23138,50))\nLISTEN     0      128             10.30.10.11:9221                     *:*      users:((&quot;pika&quot;,23138,49))\n</code></pre>\n<h2 id=\"配置nginx\"><a href=\"#配置nginx\" class=\"headerlink\" title=\"配置nginx\"></a>配置nginx</h2><p>cat nginx.conf</p>\n<pre><code>   lua_package_path &quot;/usr/local/openresty/nginx/lua/?.lua;;&quot;;\n   lua_shared_dict config 320m;\n   lua_shared_dict srcache_locks 10m;\n   lua_shared_dict mn_whiteurl 1m;\n\n   init_by_lua_file /usr/local/openresty/nginx/lua/init.lua;\n   access_by_lua_file /usr/local/openresty/nginx/lua/waf.lua;\n   body_filter_by_lua_file /usr/local/openresty/nginx/lua/body_cache.lua;\n\n   include /usr/local/openresty/nginx/conf.d/*.conf;\n\n    server &#123;\n        listen       80;\n        server_name  www.test.com;\n        root /var/www/test;\n        index  index.html index.htm index.php;\n\n        access_log  /var/log/nginx/access.log main;\n        error_log /var/log/nginx/error.log;\n\n        userid on;\n        userid_domain test.com;\n        userid_expires 1095d;\n        \n        upstream redis_m &#123;\n           server 127.0.0.1:9221;\n           server 192.168.1.1:9221 backup;\n           keepalive 4096;\n        &#125;\n        \n        upstream memcache_m &#123;\n           server 127.0.0.1:11214;\n           server 192.168.1.1:11214 backup;\n           keepalive 4096;\n        &#125;\n\n        location /memc &#123;\n                internal;\n                set $memc_cmd $arg_cmd;\n                memc_cmds_allowed get set add delete flush_all;\n                memc_connect_timeout 300ms;\n                memc_send_timeout 300ms;\n                memc_read_timeout 300ms;\n                set_unescape_uri $memc_key $arg_key;\n                set $memc_exptime $arg_expiretime;\n                memc_pass memcache_m;\n        &#125;\n\n        location = /redisttl &#123;\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query ttl $key;\n            redis2_pass redis_m;\n        &#125;\n        location = /redispersist &#123;\n            internal;\n            set_unescape_uri $key $arg_key;\n            set_md5 $key;\n            redis2_query persist $key;\n            redis2_pass redis_m;\n        &#125;\n\n        location = /redis2clearcache &#123;\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        &#125;\n\n\n        location = /redis &#123;\n                internal;\n                set $redis_key $arg_key;\n                redis_pass redis_m;\n        &#125;\n\n        location = /redis2 &#123;\n                internal;\n                set_unescape_uri $exptime $arg_expiretime;\n                set_unescape_uri $key $arg_key;\n\n                redis2_query set $key $echo_request_body;\n                redis2_query expire $key $exptime;\n                redis2_pass redis_m;\n        &#125;\n\n        location = /lua_memc_del &#123;\n                set $cache_stale 0;  # 1 day\n                content_by_lua &#39;\n                ngx.header.content_type = &quot;text/plain&quot;;\n                if ngx.var.arg_pwd ~= &quot;to8to&quot; then\n                        ngx.say(&quot;error&quot;);\n                else\n                        local res = ngx.location.capture(&quot;/redis2clearcache&quot;, &#123;\n                                        args = &#123; expiretime = ngx.var.cache_stale,key = ngx.var.arg_key&#125;\n                                        &#125;)\n                        if res.status == 200 then\n                                ngx.say(res.body);\n                        else\n                                ngx.say(&quot;not exist&quot;);\n                        end\n                end\n                &#39;;\n        &#125;\n\n        location / &#123;\n        \n                if (!-e $request_filename)\n                &#123;\n                rewrite ^(.*)$ /index.php last;\n                &#125;\n        &#125;\n\n\n        location ~* ^.+\\.(ico|gif|jpg|jpeg|png|css|js|txt|swf|wav|bmp|webp|apk|zip|rar)$ &#123;\n                access_log off;\n                expires 30d;\n        &#125;\n\n        location ~* &quot;\\.htaccess$&quot; &#123;\n            deny  all;\n        &#125;\n        \n        location ~* &quot;/(\\.svn|\\.git|runtime|protected|framework)/&quot; &#123;\n            deny all;\n        &#125;\n        \n        location ~* &quot;^/(assets|html|css|js|images|img|static)/(.*)\\.(php|php5)$&quot;\n        &#123;\n            deny all;\n        &#125;\n\n        location ~ \\.php$ &#123;\n                if (!-e $request_filename)\n                &#123;\n                    rewrite ^(.*)$ /index.php last;\n                &#125;\n                try_files /index.php =404;\n                set $prefix_wap &quot;wap&quot;;\n                set_md5 $key $prefix_wap$host$request_uri;\n                set $mtime 3600;\n                set $skip 0;\n\n                if ($request_uri ~* ^\\/(\\?(.*))?$)\n                &#123;\n                        set $skip 1;\n                        set $mtime 0;\n                &#125;\n\n\n                if ($request_uri ~* /index/Citycookie )\n                &#123;\n                        set $skip 1;\n                        set $mtime 0;\n                &#125;\n\n\n\n                if ($request_uri ~* ^/test(.*)$)\n                &#123;\n                        set $skip 0;\n                        set $mtime 604800;\n                &#125;\n\n                #此if判断一定要放在最后,否则会出现POST请求被缓存的情况\n                if ($request_method = POST)\n                &#123;\n                         set $skip 1;\n                         set $mtime 0;\n                &#125;\n\n                srcache_fetch_skip $skip;\n                srcache_store_skip $skip;\n                set $cache_status 0;\n                add_header  Cache-status $cache_status;\n\n                set $cache_lock srcache_locks;\n                set $cache_ttl /redisttl;\n                set $cache_persist /redispersist;\n                set $cache_key $prefix_wap$host$request_uri;\n                set $cache_stale 86400;  # 1 day\n \n                set_by_lua $expireTime &#39;return ngx.var.mtime + ngx.var.cache_stale&#39;;\n                rewrite_by_lua_file /usr/local/openresty/lualib/resty/cache.lua;\n \n                if ($http_x_skip_fetch != TRUE)&#123;\n                        srcache_fetch GET /redis key=$key;\n                &#125;\n                srcache_store PUT /redis2 key=$key&amp;expiretime=$expireTime;\n\n                srcache_methods GET PUT POST;\n                add_header X-Cached-From $srcache_fetch_status;\n                add_header Cache-Control max-age=$mtime;\n                if ( $mtime = 0)\n                &#123;\n                    add_header Cache-Control no-cache;\n                &#125;\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;\n                include        fastcgi_params;\n                fastcgi_intercept_errors on;\n        &#125;\n\n    &#125;\n</code></pre>\n<h2 id=\"验证缓存情况\"><a href=\"#验证缓存情况\" class=\"headerlink\" title=\"验证缓存情况\"></a>验证缓存情况</h2><pre><code>[root@WEB3 ~]# curl -I  -H &#39;host:www.test.com&#39; http://127.0.0.1/test/\nHTTP/1.1 200 OK\nServer: openresty\nDate: Tue, 07 Aug 2018 08:49:36 GMT\nContent-Type: text/html;charset=utf-8\nContent-Length: 90799\nConnection: keep-alive\nVary: Accept-Encoding\nCache-status: 0\nX-Cached-From: HIT\nCache-Control: max-age=604800\nSet-Cookie: uid=fwAAAVtpXSC+sTyIAwMHAg==; expires=Fri, 06-Aug-21 08:49:36 GMT; domain=test.com; path=/\n</code></pre>\n<h2 id=\"缓存命中率分析\"><a href=\"#缓存命中率分析\" class=\"headerlink\" title=\"缓存命中率分析\"></a>缓存命中率分析</h2><pre><code> awk &#39;&#123;if($(NF-1) ~ &quot;HIT&quot;) hit++&#125; END &#123;printf &quot;file:&#39;$a&#39; time:&#39;$LAST_DAY&#39;: %d %d %.2f%n&quot; ,hit,NR,hit/NR&#125;&#39; /var/log/nginx/access.log\n</code></pre>\n<h2 id=\"本文涉及的lua脚本\"><a href=\"#本文涉及的lua脚本\" class=\"headerlink\" title=\"本文涉及的lua脚本\"></a>本文涉及的lua脚本</h2><p><a href=\"https://raw.githubusercontent.com/owelinux/owelinux.github.io/master/images/2018-08-07-article12-linux-srcache-nginx-module/cache.lua\">cache.lua</a></p>\n<h1 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h1><blockquote>\n<ul>\n<li><a href=\"https://github.com/Qihoo360/pika/wiki\">https://github.com/Qihoo360/pika/wiki</a></li>\n<li><a href=\"https://github.com/openresty/srcache-nginx-module\">https://github.com/openresty/srcache-nginx-module</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"Linux适用于ssh协议免密登录","date":"2018-08-08T07:41:54.000Z","author":"owelinux","excerpt":"Linux适用于ssh协议免密登录.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Linux适用于ssh协议免密登录\n\n免密应用场景：自动化运维、定时同步、跳板机等\n\n## ssh密钥方式\n\n### 生成和导入key\nA服务器执行：\n```\n$ssh-keygen \n$ll /root/.ssh/\n总用量 12\n-rw-------. 1 root root 1675 8月   8 16:39 id_rsa\n-rw-r--r--. 1 root root  393 8月   8 16:39 id_rsa.pub\n-rw-r--r--. 1 root root  184 7月  17 16:06 known_hosts\n```\n> * id_rsa:私钥\n> * id_rsa.pub：公钥\n\n### 拷贝密钥并授权：\n```\n方法一：\n$cat /root/.ssh/id_rsa.pub | ssh root@远程服务器B 'cat - >> ~/.ssh/authorized_keys'\n方法二：\n$ssh-copy-id  -i /root/.ssh/id_rsa root@远程服务器B\n```\n### ssh_config配置\n> * PubkeyAuthentication yes  //将该项改为yes\n> * UsePAM yes ;如果想禁用密码登录改为：UserPAM no\n\n### 测试\n```\n$ssh root@远程服务器B\n```\n\n### 问题排查\n\n注：对于普通用户authorized_keys的权限必须限定为600（go-rwx），否则普通用户无法实现无密钥访问，而ROOT用户按照默认即可实现无密钥访问\nchmod go-rwx ~/.ssh/authorized_keys\n\n不能免密登录多半是权限问题：\n> * .ssh的权限700， \n> * authorized_keys的权限600\n> * 排错日志：/var/log/secure\n\n## rsync/scp+ssh+密码登录\n```\n$yum -y install rsync sshpass\n```\nsshpass常用命令选项：\n> * -f 密码文件\n> * -p 密码\n> * -e 密码不显示屏幕   \n\n```\nssh：\n$sshpass -f password_filename ssh remote_user@remote_host 'df -h'\n\nscp:\n$scp -r /local/dir --rsh=\"sshpass -p 'my_pass_here' ssh -l remote_user\" remote_host:/remote/dir\n\nrsync:\n$rsync --rsh=\"sshpass -p 'my_pass_here' ssh -l remote_user\" remote_host:/remote/dir /local/dir\nor\n$sshpass -p remote_password rsync -avz --delete -e ssh remote_user@remote_host:/remote/dir /local/dir\n```\n上面的命令中:\n> * remote_use/remote_password是远程的密码\n> * -avz是打包传送、显示明细、压缩\n> * -e ssh是关键，即over ssh\n> * 我们要从远程同步到本地\n> * /remote/dir是远程服务器路径\n> * /local/dir是本地服务器路径\n","source":"_posts/2018-08-08-article13-linux-ssh-rsync-passwd.md","raw":"---\nlayout: post\ntitle:  \"Linux适用于ssh协议免密登录\"\ndate:   2018-08-08 15:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux ssh\nexcerpt: Linux适用于ssh协议免密登录.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Linux适用于ssh协议免密登录\n\n免密应用场景：自动化运维、定时同步、跳板机等\n\n## ssh密钥方式\n\n### 生成和导入key\nA服务器执行：\n```\n$ssh-keygen \n$ll /root/.ssh/\n总用量 12\n-rw-------. 1 root root 1675 8月   8 16:39 id_rsa\n-rw-r--r--. 1 root root  393 8月   8 16:39 id_rsa.pub\n-rw-r--r--. 1 root root  184 7月  17 16:06 known_hosts\n```\n> * id_rsa:私钥\n> * id_rsa.pub：公钥\n\n### 拷贝密钥并授权：\n```\n方法一：\n$cat /root/.ssh/id_rsa.pub | ssh root@远程服务器B 'cat - >> ~/.ssh/authorized_keys'\n方法二：\n$ssh-copy-id  -i /root/.ssh/id_rsa root@远程服务器B\n```\n### ssh_config配置\n> * PubkeyAuthentication yes  //将该项改为yes\n> * UsePAM yes ;如果想禁用密码登录改为：UserPAM no\n\n### 测试\n```\n$ssh root@远程服务器B\n```\n\n### 问题排查\n\n注：对于普通用户authorized_keys的权限必须限定为600（go-rwx），否则普通用户无法实现无密钥访问，而ROOT用户按照默认即可实现无密钥访问\nchmod go-rwx ~/.ssh/authorized_keys\n\n不能免密登录多半是权限问题：\n> * .ssh的权限700， \n> * authorized_keys的权限600\n> * 排错日志：/var/log/secure\n\n## rsync/scp+ssh+密码登录\n```\n$yum -y install rsync sshpass\n```\nsshpass常用命令选项：\n> * -f 密码文件\n> * -p 密码\n> * -e 密码不显示屏幕   \n\n```\nssh：\n$sshpass -f password_filename ssh remote_user@remote_host 'df -h'\n\nscp:\n$scp -r /local/dir --rsh=\"sshpass -p 'my_pass_here' ssh -l remote_user\" remote_host:/remote/dir\n\nrsync:\n$rsync --rsh=\"sshpass -p 'my_pass_here' ssh -l remote_user\" remote_host:/remote/dir /local/dir\nor\n$sshpass -p remote_password rsync -avz --delete -e ssh remote_user@remote_host:/remote/dir /local/dir\n```\n上面的命令中:\n> * remote_use/remote_password是远程的密码\n> * -avz是打包传送、显示明细、压缩\n> * -e ssh是关键，即over ssh\n> * 我们要从远程同步到本地\n> * /remote/dir是远程服务器路径\n> * /local/dir是本地服务器路径\n","slug":"2018-08-08-article13-linux-ssh-rsync-passwd","published":1,"updated":"2021-02-09T02:00:24.567Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzt000hyc97bldc6inl","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Linux适用于ssh协议免密登录\"><a href=\"#Linux适用于ssh协议免密登录\" class=\"headerlink\" title=\"Linux适用于ssh协议免密登录\"></a>Linux适用于ssh协议免密登录</h1><p>免密应用场景：自动化运维、定时同步、跳板机等</p>\n<h2 id=\"ssh密钥方式\"><a href=\"#ssh密钥方式\" class=\"headerlink\" title=\"ssh密钥方式\"></a>ssh密钥方式</h2><h3 id=\"生成和导入key\"><a href=\"#生成和导入key\" class=\"headerlink\" title=\"生成和导入key\"></a>生成和导入key</h3><p>A服务器执行：</p>\n<pre><code>$ssh-keygen \n$ll /root/.ssh/\n总用量 12\n-rw-------. 1 root root 1675 8月   8 16:39 id_rsa\n-rw-r--r--. 1 root root  393 8月   8 16:39 id_rsa.pub\n-rw-r--r--. 1 root root  184 7月  17 16:06 known_hosts\n</code></pre>\n<blockquote>\n<ul>\n<li>id_rsa:私钥</li>\n<li>id_rsa.pub：公钥</li>\n</ul>\n</blockquote>\n<h3 id=\"拷贝密钥并授权：\"><a href=\"#拷贝密钥并授权：\" class=\"headerlink\" title=\"拷贝密钥并授权：\"></a>拷贝密钥并授权：</h3><pre><code>方法一：\n$cat /root/.ssh/id_rsa.pub | ssh root@远程服务器B &#39;cat - &gt;&gt; ~/.ssh/authorized_keys&#39;\n方法二：\n$ssh-copy-id  -i /root/.ssh/id_rsa root@远程服务器B\n</code></pre>\n<h3 id=\"ssh-config配置\"><a href=\"#ssh-config配置\" class=\"headerlink\" title=\"ssh_config配置\"></a>ssh_config配置</h3><blockquote>\n<ul>\n<li>PubkeyAuthentication yes  //将该项改为yes</li>\n<li>UsePAM yes ;如果想禁用密码登录改为：UserPAM no</li>\n</ul>\n</blockquote>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><pre><code>$ssh root@远程服务器B\n</code></pre>\n<h3 id=\"问题排查\"><a href=\"#问题排查\" class=\"headerlink\" title=\"问题排查\"></a>问题排查</h3><p>注：对于普通用户authorized_keys的权限必须限定为600（go-rwx），否则普通用户无法实现无密钥访问，而ROOT用户按照默认即可实现无密钥访问<br>chmod go-rwx ~/.ssh/authorized_keys</p>\n<p>不能免密登录多半是权限问题：</p>\n<blockquote>\n<ul>\n<li>.ssh的权限700， </li>\n<li>authorized_keys的权限600</li>\n<li>排错日志：/var/log/secure</li>\n</ul>\n</blockquote>\n<h2 id=\"rsync-scp-ssh-密码登录\"><a href=\"#rsync-scp-ssh-密码登录\" class=\"headerlink\" title=\"rsync/scp+ssh+密码登录\"></a>rsync/scp+ssh+密码登录</h2><pre><code>$yum -y install rsync sshpass\n</code></pre>\n<p>sshpass常用命令选项：</p>\n<blockquote>\n<ul>\n<li>-f 密码文件</li>\n<li>-p 密码</li>\n<li>-e 密码不显示屏幕   </li>\n</ul>\n</blockquote>\n<pre><code>ssh：\n$sshpass -f password_filename ssh remote_user@remote_host &#39;df -h&#39;\n\nscp:\n$scp -r /local/dir --rsh=&quot;sshpass -p &#39;my_pass_here&#39; ssh -l remote_user&quot; remote_host:/remote/dir\n\nrsync:\n$rsync --rsh=&quot;sshpass -p &#39;my_pass_here&#39; ssh -l remote_user&quot; remote_host:/remote/dir /local/dir\nor\n$sshpass -p remote_password rsync -avz --delete -e ssh remote_user@remote_host:/remote/dir /local/dir\n</code></pre>\n<p>上面的命令中:</p>\n<blockquote>\n<ul>\n<li>remote_use/remote_password是远程的密码</li>\n<li>-avz是打包传送、显示明细、压缩</li>\n<li>-e ssh是关键，即over ssh</li>\n<li>我们要从远程同步到本地</li>\n<li>/remote/dir是远程服务器路径</li>\n<li>/local/dir是本地服务器路径</li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Linux适用于ssh协议免密登录\"><a href=\"#Linux适用于ssh协议免密登录\" class=\"headerlink\" title=\"Linux适用于ssh协议免密登录\"></a>Linux适用于ssh协议免密登录</h1><p>免密应用场景：自动化运维、定时同步、跳板机等</p>\n<h2 id=\"ssh密钥方式\"><a href=\"#ssh密钥方式\" class=\"headerlink\" title=\"ssh密钥方式\"></a>ssh密钥方式</h2><h3 id=\"生成和导入key\"><a href=\"#生成和导入key\" class=\"headerlink\" title=\"生成和导入key\"></a>生成和导入key</h3><p>A服务器执行：</p>\n<pre><code>$ssh-keygen \n$ll /root/.ssh/\n总用量 12\n-rw-------. 1 root root 1675 8月   8 16:39 id_rsa\n-rw-r--r--. 1 root root  393 8月   8 16:39 id_rsa.pub\n-rw-r--r--. 1 root root  184 7月  17 16:06 known_hosts\n</code></pre>\n<blockquote>\n<ul>\n<li>id_rsa:私钥</li>\n<li>id_rsa.pub：公钥</li>\n</ul>\n</blockquote>\n<h3 id=\"拷贝密钥并授权：\"><a href=\"#拷贝密钥并授权：\" class=\"headerlink\" title=\"拷贝密钥并授权：\"></a>拷贝密钥并授权：</h3><pre><code>方法一：\n$cat /root/.ssh/id_rsa.pub | ssh root@远程服务器B &#39;cat - &gt;&gt; ~/.ssh/authorized_keys&#39;\n方法二：\n$ssh-copy-id  -i /root/.ssh/id_rsa root@远程服务器B\n</code></pre>\n<h3 id=\"ssh-config配置\"><a href=\"#ssh-config配置\" class=\"headerlink\" title=\"ssh_config配置\"></a>ssh_config配置</h3><blockquote>\n<ul>\n<li>PubkeyAuthentication yes  //将该项改为yes</li>\n<li>UsePAM yes ;如果想禁用密码登录改为：UserPAM no</li>\n</ul>\n</blockquote>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><pre><code>$ssh root@远程服务器B\n</code></pre>\n<h3 id=\"问题排查\"><a href=\"#问题排查\" class=\"headerlink\" title=\"问题排查\"></a>问题排查</h3><p>注：对于普通用户authorized_keys的权限必须限定为600（go-rwx），否则普通用户无法实现无密钥访问，而ROOT用户按照默认即可实现无密钥访问<br>chmod go-rwx ~/.ssh/authorized_keys</p>\n<p>不能免密登录多半是权限问题：</p>\n<blockquote>\n<ul>\n<li>.ssh的权限700， </li>\n<li>authorized_keys的权限600</li>\n<li>排错日志：/var/log/secure</li>\n</ul>\n</blockquote>\n<h2 id=\"rsync-scp-ssh-密码登录\"><a href=\"#rsync-scp-ssh-密码登录\" class=\"headerlink\" title=\"rsync/scp+ssh+密码登录\"></a>rsync/scp+ssh+密码登录</h2><pre><code>$yum -y install rsync sshpass\n</code></pre>\n<p>sshpass常用命令选项：</p>\n<blockquote>\n<ul>\n<li>-f 密码文件</li>\n<li>-p 密码</li>\n<li>-e 密码不显示屏幕   </li>\n</ul>\n</blockquote>\n<pre><code>ssh：\n$sshpass -f password_filename ssh remote_user@remote_host &#39;df -h&#39;\n\nscp:\n$scp -r /local/dir --rsh=&quot;sshpass -p &#39;my_pass_here&#39; ssh -l remote_user&quot; remote_host:/remote/dir\n\nrsync:\n$rsync --rsh=&quot;sshpass -p &#39;my_pass_here&#39; ssh -l remote_user&quot; remote_host:/remote/dir /local/dir\nor\n$sshpass -p remote_password rsync -avz --delete -e ssh remote_user@remote_host:/remote/dir /local/dir\n</code></pre>\n<p>上面的命令中:</p>\n<blockquote>\n<ul>\n<li>remote_use/remote_password是远程的密码</li>\n<li>-avz是打包传送、显示明细、压缩</li>\n<li>-e ssh是关键，即over ssh</li>\n<li>我们要从远程同步到本地</li>\n<li>/remote/dir是远程服务器路径</li>\n<li>/local/dir是本地服务器路径</li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"自动化运维之Ansible使用指南","date":"2018-08-08T07:41:54.000Z","author":"owelinux","excerpt":"自动化运维之Ansible使用指南.","mathjax":true,"_content":"\n* content\n{:toc}\n\n# 自动化运维之Ansible使用指南\n\n\n## 运维自动化工具介绍\n在日常服务器维护中，从系统安装到程序部署再到发布应用，在大规模的生产环境中，如果需要手动的每台服务器进行安装配置将会给运维人员带来许多繁琐而又重复的工作。这就促使了在每个运维层次中出现了不同的自动化运维工具。\n常见的自动化运维工具分类有以下几类：\n\n### 系统安装运维工具（OS Provisioning）：\n常见的有：PXE,Cobbler，Red Hat Satelite(redhat)系统专用等\n\n### 操作系统的配置运维工具(OS Config)：\n常见的有：cfengine，puppet,saltsack,chef等\n\n### 应用程序部署工具(Application Service Orchestration):\n常见的有:Func,Fabric,ControITier,Capistrano等\n\n### 根据工作模式不同上面的运维工具有分为以下两类：\nagent：基于ssl协议实现，agent工作在被监控端，例如：puppet\nagentless: 基于ssh key实现，例如：ansible\n\n## ansible介绍\nansible是一款轻量级自动化运维工具，由Python语言开发，结合了多种自动化运维工具的特性，实现了批量系统配置、批量程序部署、批量命令执行等功能；ansible是基于模块化实现批量操作的。\n![](https://upload-images.jianshu.io/upload_images/1542757-c4b2d6eede79a975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n\n## ansible组成\nAnsible： 核心\nModules： 包括 Ansible 自带的核心模块及自定义模块\nPlugins： 完成模块功能的补充，包括连接插件、邮件插件等\nPlaybooks： 网上很多翻译为剧本，个人觉得理解为编排更为合理；定义 Ansible 多任务配置文件，有 Ansible 自动执行\nInventory： 定义 Ansible 管理主机的清单\nansible特点\n模块化、部署简单、工作于agentless模式、默认使用ssh协议、支持自定义模块、支持Palybook等\n\n## ansible 基本安装介绍\n```\n### 系统环境\n$ uname -a\nLinux note1 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n$ cat /etc/redhat-release \nCentOS release 6.6 (Final)\n\n### epel源\n$ wget -O /etc/yum.repos.d/epel.repo  http://mirrors.aliyun.com/repo/epel-6.repo\n\n### 安装ansible\n$ yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto ansible\n\n### 配置ansible主机文件\n$ > /etc/ansible/hosts         \n$ cat /etc/ansible/hosts      \n[web]\n192.168.70.51\n[db]\n192.168.70.50\n\n### 配置主机免密钥登陆\n$ ssh-keygen -t rsa -P ''\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.51\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.50\n\n### 测试ping\n$ ansible all -m ping \n\n解决办法:Are you sure you want to continue connecting (yes/no)?\n方法一：\n$ vim /etc/ansible/ansible.cfg 或者 ~/.ansible.cfg\n[defaults]\nhost_key_checking = False\n\n方法一：\n$ export ANSIBLE_HOST_KEY_CHECKING=False\n$ ansible all -m ping                                \n192.168.70.50 | success >> {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n192.168.70.51 | success >> {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n```\n## Ansible命令参数介绍\n> * -v,–verbose   详细模式，如果命令执行成功，输出详细的结果(-vv –vvv -vvvv)\n> * -i PATH,–inventory=PATH   指定host文件的路径，默认是在/etc/ansible/hosts \n> * -f NUM,–forks=NU  NUM是指定一个整数，默认是5，指定fork开启同步进程的个数。 \n> * -m NAME,–module-name=NAME   指定使用的module名称，默认是command\n> * -m DIRECTORY,–module-path=DIRECTORY   指定module的目录来加载module，默认是/usr/share/ansible, \n> * -a,MODULE_ARGS   指定module模块的参数 \n> * -k,-ask-pass     提示输入ssh的密码，而不是使用基于ssh的密钥认证\n> * -sudo                   指定使用sudo获得root权限\n> * -K,-ask-sudo-pass       提示输入sudo密码，与–sudo一起使用 \n> * -u USERNAME,-user=USERNAME  指定移动端的执行用户 \n> * -C,-check               测试此命令执行会改变什么内容，不会真正的去执行\n\n## 主机清单介绍hosts\nAnsible 通过读取默认的主机清单配置/etc/ansible/hosts，可以同时连接到多个远程主机上执行任务，默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。\n```\n[dbserver]  []表示主机的分组名,可以按照功能,系统进行分类,便于进行操作\n192.168.10.2 \none.example.com \nwww.bds.com:5309         #支持指定ssh端口5309 \njumper ansible_ssh_port=5309 ansible_ssh_host=192.168.10.2   #设置主机别名为jumper\nwww[01:50].bds.com       #支持通配符匹配www01.bds.com www02.bds.com\n[web]                   #提醒下这里面字母是随便定义的\nweb-[a:f].bds.com        #支持字母匹配 web-a.bds.com ..web-f.bds.com\n为主机指定类型和连接用户\n[bds]\nLocalhost  ansible_connection=local\nother1.example.com ansible_connection=ssh ansible_ssh_user=deploy\nother2.example.com ansible_connection=ssh ansible_ssh_user=deploy\nansible hosts配置文件中支持指令\n注意: 前面如果不配置主机免密钥登录,可以在/etc/ansible/hosts中定义用户和密码,主机ip地址,和ssh端口,这样也可以进行免密码访问,但是这个/hosts文件要保护好,因为所有的密码都写在里面\n```\n## hosts文件配置参数介绍\n> * ansible_ssh_host : 指定主机别名对应的真实 IP，如：100 ansible_ssh_host=192.168.1.100，随后连接该主机无须指定完整 IP，只需指定 251 就行\n\n> * ansible_ssh_port : 指定连接到这个主机的 ssh 端口，默认 22\n\n> * ansible_ssh_user : 连接到该主机的 ssh 用户\n\n> * ansible_ssh_pass : 连接到该主机的 ssh 密码（连-k 选项都省了），安全考虑还是建议使用私钥或在命令行指定-k 选项输入\n\n> * ansible_sudo_pass : sudo 密码\n\n> * ansible_sudo_exe : sudo 命令路径\n\n> * ansible_connection : 连接类型，可以是 local、ssh 或 paramiko，ansible1.2 之前默认为 paramiko\n\n> * ansible_ssh_private_key_file : 私钥文件路径\n\n> * ansible_shell_type : 目标系统的 shell 类型，默认为 sh,如果设置 csh/fish，那么命令需要遵循它们语法\n\n> * ansible_python_interpreter : python 解释器路径，默认是/usr/bin/python，但是如要要连BSD系统的话，就需要该指令修改 python 路径\n\n> * ansible__interpreter : 这里的\"*\"可以是 ruby 或 perl 或其他语言的解释器，作用和 ansible_python_interpreter 类似\n\n## ansible 常用模块介绍\n\n### ansible使用帮助\n```\n$ ansible-doc  -l                 #查询ansible的所有模块\n$ ansible-doc -s module_name      #查看模块的属性信息\n```\n\n### ansible语法\n```\nansible <pattern_goes_here> -m <module_name> -a <arguments>\n```\n\n### raw模块\ncommand模块功能相同，但比command的模块功能强大(支持管道和变量)\nAnsible raw：[https://docs.ansible.com/ansible/raw_module.html](https://docs.ansible.com/ansible/raw_module.html)\n```\n$ ansible all -m raw -a \"hostname\"\n```\n\n### command模块\n默认模块 ,用于在各个被管理节点运行指定的命令(不支持管道和变量)\nAnsible command模块：[https://docs.ansible.com/ansible/list_of_commands_modules.html](https://docs.ansible.com/ansible/list_of_commands_modules.html)\n```\n$ ansible all -m command -a \"hostname \"\n```\n\n### shell模块\ncommand模块功能相同，但比command的模块功能强大(支持管道和变量)\nAnsible shell模块：[https://docs.ansible.com/ansible/shell_module.html](https://docs.ansible.com/ansible/shell_module.html)\n```\n$ ansible all -m shell -a \"cat /etc/passwd| grep root \"                         \n```\n\n### user模块\n用户模块,用于在各管理节点管理用户所使用\nAnsible User模块：[https://docs.ansible.com/ansible/user_module.html](https://docs.ansible.com/ansible/user_module.html)\n```\n### 创建一个用户\n$ ansible db -m user -a 'name=DBA uid=505 home=/Data/dba shell=/sbin/nologin'    \n        \n### 删除一个用户\n$ ansible db -m user  -a 'name=budongshu uid=506  state=absent'\n```\n### group模块\nAnsible group模块：[https://docs.ansible.com/ansible/group_module.html](https://docs.ansible.com/ansible/group_module.html)\n```\nansible db -m group  -a 'name=test  gid=1000' \n```\n\n### cron模块\n计划定时任务,用于在各管理节点管理计划任务\nAnsible cron模块：[https://docs.ansible.com/ansible/cron_module.html](https://docs.ansible.com/ansible/cron_module.html)\n```\n$ ansible all -m cron -a \"name=time minute='*/2' job='/usr/sbin/ntpdate \n```\n\n### copy模块\n复制模块,复制文件到各个节点\nAnsible copy模块：[https://docs.ansible.com/ansible/copy_module.html](https://docs.ansible.com/ansible/copy_module.html)\n```\n$ ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ mode=600\"\n```\n\n### file模块\n文件模块 , 修改各个节点指定的文件属性\nAnsible File模块：[https://docs.ansible.com/ansible/list_of_files_modules.html](https://docs.ansible.com/ansible/list_of_files_modules.html)\n```\n$ ansible all -m file -a 'path=/tmp/hosts mode=644 owner=DBA'  \n\n$ ansible all -m file -a \"dest=/tmp/ansible.txt mode=755 owner=root \ngroup=root state=directory\"\n\n### file删除文件或者目录\n$ ansible all -m file -a \"dest=/tmp/ansible.txt state=absent\"   \n注：state的其他选项：link(链接)、hard(硬链接)\n```\n### stat 模块\n获取远程文件状态信息，包含atime、ctime、mtime、md5、uid、gid等\nAnsible Setup模块：[https://docs.ansible.com/ansible/setup_module.html](https://docs.ansible.com/ansible/setup_module.html)\n```\n$ ansible all -m stat -a \"path=/etc/passwd \"\n```\n\n### ping 模块\n测试模块 ,测试各个节点是否正常在线\n```\n$ansible all -m stat -a 'path=/etc/passwd'\n```\n \n### template模块\n根据官方的翻译是：template使用了Jinjia2格式作为文件模板，进行文档内变量的替换的模块。他的每次使用都会被ansible标记为changed状态。\nAnsible Template模块：[https://docs.ansible.com/ansible/template_module.html](https://docs.ansible.com/ansible/template_module.html)\n\n### yum模块\n用于管理节点安装软件所使用\nAnsible yum模块：[https://docs.ansible.com/ansible/yum_module.html](https://docs.ansible.com/ansible/yum_module.html)\n```\n$ ansible all -m yum -a 'name=ntp state=present'\n```\n> * 卸载的软件只需要将 name=ntp state=absent \n> * 安装特定版本 name=nginx-1.6.2 state=present\n> * 指定某个源仓库安装软件包name=htop enablerepo=epel state=present\n> * 更新软件到最新版 name=nginx state=latest\n\n### service模块\n管理各个节点的服务\nAnsible service模块：[https://docs.ansible.com/ansible/service_module.html](https://docs.ansible.com/ansible/service_module.html)\n```\n$ ansible all -m service -a \"name=ntpd enabled=true state=started\"     state 支持其它选项 started stopped restarted\n``` \n### script模块\n自动复制脚本到远程节点,并运行\nAnsible script模块：[http://docs.ansible.com/ansible/script_module.html](http://docs.ansible.com/ansible/script_module.html)\n```\n$ ansible all -m script -a 'ansible_test.sh'\n```\n\n### setup模块\n收集ansible的facts信息\nAnsible script模块：[http://docs.ansible.com/ansible/script_module.html](http://docs.ansible.com/ansible/script_module.html)\n```\n$ ansible all -m setup  #收集主机的facts信息,可以通过变量引用这些信息\n```\n## ansible 主机清单通配模式介绍\n可以看到上面执行命令的时候有个ansible -m all ,以上我用的all或指定主机,这里也可以进行通配 ,在/etc/ansible/hosts 进行设置如下\n```\n[web]\n10.10.10.2\n10.10.10.3\n[db]\n10.10.10.4 \n[allhost:children]     #可以把一个组当做另一个组的子成员\nweb\ndb\n例子:\nansible web -m shell -a ‘uptime’     #代表web组中的所有主机\nansible allhost -m shell -a ‘uptime’ #代表allhost组中的所有子成员组\n其它匹配方式\n```\n\n```\n1.1 通配所有主机\nall , *\n\n1.2 通配具有规则特征的主机或者主机名\none.bds.com\n.bds.com\n192.168.10.2\n192.168.10.\n\n1.3 通配俩组的所有主机,组名之间通过冒号分开,表示or的意思\nweb:db\n\n1.4 非模式匹配: 表示在 web组不在db组的主机\nweb:!db\n\n1.5 交集匹配: 表示同时都在 web 和db组的主机\nweb:&db\n\n1.6 匹配一个组的特定编号的主机 从零开始计算\nweb[0]\n\n1.7 匹配 web组的第 1 个到第 25 个主机\nweb [0-25]\n\n1.8 组合匹配\n在web组或者在db组中,必须还存在test1组中,但不在test2组中\nweb:db:&test1:!test2\n\n1.9 大部分人都在patterns应用正则表达式,但你可以.只需要以 ‘~’ 开头即可:\n~(web|db).*.example.com\n\n2.0 同时让我们提前了解一些技能,除了如上,你也可以通过 --limit 标记来添加排除条件,/usr/bin/ansible or /usr/bin/ansible-playbook都支持:\nansible-playbook site.yml --limit datacenter2\n\n2.1 如果你想从文件读取hosts,文件名以@为前缀即可.从Ansible 1.2开始支持该功能:\nansible-playbook site.yml --limit @retry_hosts.txt\n```\n## 参考\n> * [https://www.jianshu.com/p/b9956ea83a78](https://www.jianshu.com/p/b9956ea83a78)\n> * [http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/](http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/)\n> * [http://ansible-tran.readthedocs.io/en/latest/index.html](http://ansible-tran.readthedocs.io/en/latest/index.html)\n> * [https://docs.ansible.com/ansible/2.3/index.html](https://docs.ansible.com/ansible/2.3/index.html)\n","source":"_posts/2018-08-09-article14-linux-ansible.md","raw":"---\nlayout: post\ntitle:  \"自动化运维之Ansible使用指南\"\ndate:   2018-08-08 15:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux ansible 自动化\nexcerpt: 自动化运维之Ansible使用指南.\nmathjax: true\n---\n\n* content\n{:toc}\n\n# 自动化运维之Ansible使用指南\n\n\n## 运维自动化工具介绍\n在日常服务器维护中，从系统安装到程序部署再到发布应用，在大规模的生产环境中，如果需要手动的每台服务器进行安装配置将会给运维人员带来许多繁琐而又重复的工作。这就促使了在每个运维层次中出现了不同的自动化运维工具。\n常见的自动化运维工具分类有以下几类：\n\n### 系统安装运维工具（OS Provisioning）：\n常见的有：PXE,Cobbler，Red Hat Satelite(redhat)系统专用等\n\n### 操作系统的配置运维工具(OS Config)：\n常见的有：cfengine，puppet,saltsack,chef等\n\n### 应用程序部署工具(Application Service Orchestration):\n常见的有:Func,Fabric,ControITier,Capistrano等\n\n### 根据工作模式不同上面的运维工具有分为以下两类：\nagent：基于ssl协议实现，agent工作在被监控端，例如：puppet\nagentless: 基于ssh key实现，例如：ansible\n\n## ansible介绍\nansible是一款轻量级自动化运维工具，由Python语言开发，结合了多种自动化运维工具的特性，实现了批量系统配置、批量程序部署、批量命令执行等功能；ansible是基于模块化实现批量操作的。\n![](https://upload-images.jianshu.io/upload_images/1542757-c4b2d6eede79a975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n\n## ansible组成\nAnsible： 核心\nModules： 包括 Ansible 自带的核心模块及自定义模块\nPlugins： 完成模块功能的补充，包括连接插件、邮件插件等\nPlaybooks： 网上很多翻译为剧本，个人觉得理解为编排更为合理；定义 Ansible 多任务配置文件，有 Ansible 自动执行\nInventory： 定义 Ansible 管理主机的清单\nansible特点\n模块化、部署简单、工作于agentless模式、默认使用ssh协议、支持自定义模块、支持Palybook等\n\n## ansible 基本安装介绍\n```\n### 系统环境\n$ uname -a\nLinux note1 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n$ cat /etc/redhat-release \nCentOS release 6.6 (Final)\n\n### epel源\n$ wget -O /etc/yum.repos.d/epel.repo  http://mirrors.aliyun.com/repo/epel-6.repo\n\n### 安装ansible\n$ yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto ansible\n\n### 配置ansible主机文件\n$ > /etc/ansible/hosts         \n$ cat /etc/ansible/hosts      \n[web]\n192.168.70.51\n[db]\n192.168.70.50\n\n### 配置主机免密钥登陆\n$ ssh-keygen -t rsa -P ''\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.51\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.50\n\n### 测试ping\n$ ansible all -m ping \n\n解决办法:Are you sure you want to continue connecting (yes/no)?\n方法一：\n$ vim /etc/ansible/ansible.cfg 或者 ~/.ansible.cfg\n[defaults]\nhost_key_checking = False\n\n方法一：\n$ export ANSIBLE_HOST_KEY_CHECKING=False\n$ ansible all -m ping                                \n192.168.70.50 | success >> {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n192.168.70.51 | success >> {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n```\n## Ansible命令参数介绍\n> * -v,–verbose   详细模式，如果命令执行成功，输出详细的结果(-vv –vvv -vvvv)\n> * -i PATH,–inventory=PATH   指定host文件的路径，默认是在/etc/ansible/hosts \n> * -f NUM,–forks=NU  NUM是指定一个整数，默认是5，指定fork开启同步进程的个数。 \n> * -m NAME,–module-name=NAME   指定使用的module名称，默认是command\n> * -m DIRECTORY,–module-path=DIRECTORY   指定module的目录来加载module，默认是/usr/share/ansible, \n> * -a,MODULE_ARGS   指定module模块的参数 \n> * -k,-ask-pass     提示输入ssh的密码，而不是使用基于ssh的密钥认证\n> * -sudo                   指定使用sudo获得root权限\n> * -K,-ask-sudo-pass       提示输入sudo密码，与–sudo一起使用 \n> * -u USERNAME,-user=USERNAME  指定移动端的执行用户 \n> * -C,-check               测试此命令执行会改变什么内容，不会真正的去执行\n\n## 主机清单介绍hosts\nAnsible 通过读取默认的主机清单配置/etc/ansible/hosts，可以同时连接到多个远程主机上执行任务，默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。\n```\n[dbserver]  []表示主机的分组名,可以按照功能,系统进行分类,便于进行操作\n192.168.10.2 \none.example.com \nwww.bds.com:5309         #支持指定ssh端口5309 \njumper ansible_ssh_port=5309 ansible_ssh_host=192.168.10.2   #设置主机别名为jumper\nwww[01:50].bds.com       #支持通配符匹配www01.bds.com www02.bds.com\n[web]                   #提醒下这里面字母是随便定义的\nweb-[a:f].bds.com        #支持字母匹配 web-a.bds.com ..web-f.bds.com\n为主机指定类型和连接用户\n[bds]\nLocalhost  ansible_connection=local\nother1.example.com ansible_connection=ssh ansible_ssh_user=deploy\nother2.example.com ansible_connection=ssh ansible_ssh_user=deploy\nansible hosts配置文件中支持指令\n注意: 前面如果不配置主机免密钥登录,可以在/etc/ansible/hosts中定义用户和密码,主机ip地址,和ssh端口,这样也可以进行免密码访问,但是这个/hosts文件要保护好,因为所有的密码都写在里面\n```\n## hosts文件配置参数介绍\n> * ansible_ssh_host : 指定主机别名对应的真实 IP，如：100 ansible_ssh_host=192.168.1.100，随后连接该主机无须指定完整 IP，只需指定 251 就行\n\n> * ansible_ssh_port : 指定连接到这个主机的 ssh 端口，默认 22\n\n> * ansible_ssh_user : 连接到该主机的 ssh 用户\n\n> * ansible_ssh_pass : 连接到该主机的 ssh 密码（连-k 选项都省了），安全考虑还是建议使用私钥或在命令行指定-k 选项输入\n\n> * ansible_sudo_pass : sudo 密码\n\n> * ansible_sudo_exe : sudo 命令路径\n\n> * ansible_connection : 连接类型，可以是 local、ssh 或 paramiko，ansible1.2 之前默认为 paramiko\n\n> * ansible_ssh_private_key_file : 私钥文件路径\n\n> * ansible_shell_type : 目标系统的 shell 类型，默认为 sh,如果设置 csh/fish，那么命令需要遵循它们语法\n\n> * ansible_python_interpreter : python 解释器路径，默认是/usr/bin/python，但是如要要连BSD系统的话，就需要该指令修改 python 路径\n\n> * ansible__interpreter : 这里的\"*\"可以是 ruby 或 perl 或其他语言的解释器，作用和 ansible_python_interpreter 类似\n\n## ansible 常用模块介绍\n\n### ansible使用帮助\n```\n$ ansible-doc  -l                 #查询ansible的所有模块\n$ ansible-doc -s module_name      #查看模块的属性信息\n```\n\n### ansible语法\n```\nansible <pattern_goes_here> -m <module_name> -a <arguments>\n```\n\n### raw模块\ncommand模块功能相同，但比command的模块功能强大(支持管道和变量)\nAnsible raw：[https://docs.ansible.com/ansible/raw_module.html](https://docs.ansible.com/ansible/raw_module.html)\n```\n$ ansible all -m raw -a \"hostname\"\n```\n\n### command模块\n默认模块 ,用于在各个被管理节点运行指定的命令(不支持管道和变量)\nAnsible command模块：[https://docs.ansible.com/ansible/list_of_commands_modules.html](https://docs.ansible.com/ansible/list_of_commands_modules.html)\n```\n$ ansible all -m command -a \"hostname \"\n```\n\n### shell模块\ncommand模块功能相同，但比command的模块功能强大(支持管道和变量)\nAnsible shell模块：[https://docs.ansible.com/ansible/shell_module.html](https://docs.ansible.com/ansible/shell_module.html)\n```\n$ ansible all -m shell -a \"cat /etc/passwd| grep root \"                         \n```\n\n### user模块\n用户模块,用于在各管理节点管理用户所使用\nAnsible User模块：[https://docs.ansible.com/ansible/user_module.html](https://docs.ansible.com/ansible/user_module.html)\n```\n### 创建一个用户\n$ ansible db -m user -a 'name=DBA uid=505 home=/Data/dba shell=/sbin/nologin'    \n        \n### 删除一个用户\n$ ansible db -m user  -a 'name=budongshu uid=506  state=absent'\n```\n### group模块\nAnsible group模块：[https://docs.ansible.com/ansible/group_module.html](https://docs.ansible.com/ansible/group_module.html)\n```\nansible db -m group  -a 'name=test  gid=1000' \n```\n\n### cron模块\n计划定时任务,用于在各管理节点管理计划任务\nAnsible cron模块：[https://docs.ansible.com/ansible/cron_module.html](https://docs.ansible.com/ansible/cron_module.html)\n```\n$ ansible all -m cron -a \"name=time minute='*/2' job='/usr/sbin/ntpdate \n```\n\n### copy模块\n复制模块,复制文件到各个节点\nAnsible copy模块：[https://docs.ansible.com/ansible/copy_module.html](https://docs.ansible.com/ansible/copy_module.html)\n```\n$ ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ mode=600\"\n```\n\n### file模块\n文件模块 , 修改各个节点指定的文件属性\nAnsible File模块：[https://docs.ansible.com/ansible/list_of_files_modules.html](https://docs.ansible.com/ansible/list_of_files_modules.html)\n```\n$ ansible all -m file -a 'path=/tmp/hosts mode=644 owner=DBA'  \n\n$ ansible all -m file -a \"dest=/tmp/ansible.txt mode=755 owner=root \ngroup=root state=directory\"\n\n### file删除文件或者目录\n$ ansible all -m file -a \"dest=/tmp/ansible.txt state=absent\"   \n注：state的其他选项：link(链接)、hard(硬链接)\n```\n### stat 模块\n获取远程文件状态信息，包含atime、ctime、mtime、md5、uid、gid等\nAnsible Setup模块：[https://docs.ansible.com/ansible/setup_module.html](https://docs.ansible.com/ansible/setup_module.html)\n```\n$ ansible all -m stat -a \"path=/etc/passwd \"\n```\n\n### ping 模块\n测试模块 ,测试各个节点是否正常在线\n```\n$ansible all -m stat -a 'path=/etc/passwd'\n```\n \n### template模块\n根据官方的翻译是：template使用了Jinjia2格式作为文件模板，进行文档内变量的替换的模块。他的每次使用都会被ansible标记为changed状态。\nAnsible Template模块：[https://docs.ansible.com/ansible/template_module.html](https://docs.ansible.com/ansible/template_module.html)\n\n### yum模块\n用于管理节点安装软件所使用\nAnsible yum模块：[https://docs.ansible.com/ansible/yum_module.html](https://docs.ansible.com/ansible/yum_module.html)\n```\n$ ansible all -m yum -a 'name=ntp state=present'\n```\n> * 卸载的软件只需要将 name=ntp state=absent \n> * 安装特定版本 name=nginx-1.6.2 state=present\n> * 指定某个源仓库安装软件包name=htop enablerepo=epel state=present\n> * 更新软件到最新版 name=nginx state=latest\n\n### service模块\n管理各个节点的服务\nAnsible service模块：[https://docs.ansible.com/ansible/service_module.html](https://docs.ansible.com/ansible/service_module.html)\n```\n$ ansible all -m service -a \"name=ntpd enabled=true state=started\"     state 支持其它选项 started stopped restarted\n``` \n### script模块\n自动复制脚本到远程节点,并运行\nAnsible script模块：[http://docs.ansible.com/ansible/script_module.html](http://docs.ansible.com/ansible/script_module.html)\n```\n$ ansible all -m script -a 'ansible_test.sh'\n```\n\n### setup模块\n收集ansible的facts信息\nAnsible script模块：[http://docs.ansible.com/ansible/script_module.html](http://docs.ansible.com/ansible/script_module.html)\n```\n$ ansible all -m setup  #收集主机的facts信息,可以通过变量引用这些信息\n```\n## ansible 主机清单通配模式介绍\n可以看到上面执行命令的时候有个ansible -m all ,以上我用的all或指定主机,这里也可以进行通配 ,在/etc/ansible/hosts 进行设置如下\n```\n[web]\n10.10.10.2\n10.10.10.3\n[db]\n10.10.10.4 \n[allhost:children]     #可以把一个组当做另一个组的子成员\nweb\ndb\n例子:\nansible web -m shell -a ‘uptime’     #代表web组中的所有主机\nansible allhost -m shell -a ‘uptime’ #代表allhost组中的所有子成员组\n其它匹配方式\n```\n\n```\n1.1 通配所有主机\nall , *\n\n1.2 通配具有规则特征的主机或者主机名\none.bds.com\n.bds.com\n192.168.10.2\n192.168.10.\n\n1.3 通配俩组的所有主机,组名之间通过冒号分开,表示or的意思\nweb:db\n\n1.4 非模式匹配: 表示在 web组不在db组的主机\nweb:!db\n\n1.5 交集匹配: 表示同时都在 web 和db组的主机\nweb:&db\n\n1.6 匹配一个组的特定编号的主机 从零开始计算\nweb[0]\n\n1.7 匹配 web组的第 1 个到第 25 个主机\nweb [0-25]\n\n1.8 组合匹配\n在web组或者在db组中,必须还存在test1组中,但不在test2组中\nweb:db:&test1:!test2\n\n1.9 大部分人都在patterns应用正则表达式,但你可以.只需要以 ‘~’ 开头即可:\n~(web|db).*.example.com\n\n2.0 同时让我们提前了解一些技能,除了如上,你也可以通过 --limit 标记来添加排除条件,/usr/bin/ansible or /usr/bin/ansible-playbook都支持:\nansible-playbook site.yml --limit datacenter2\n\n2.1 如果你想从文件读取hosts,文件名以@为前缀即可.从Ansible 1.2开始支持该功能:\nansible-playbook site.yml --limit @retry_hosts.txt\n```\n## 参考\n> * [https://www.jianshu.com/p/b9956ea83a78](https://www.jianshu.com/p/b9956ea83a78)\n> * [http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/](http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/)\n> * [http://ansible-tran.readthedocs.io/en/latest/index.html](http://ansible-tran.readthedocs.io/en/latest/index.html)\n> * [https://docs.ansible.com/ansible/2.3/index.html](https://docs.ansible.com/ansible/2.3/index.html)\n","slug":"2018-08-09-article14-linux-ansible","published":1,"updated":"2021-02-09T02:00:24.567Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzx000lyc97hq6y0bj7","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"自动化运维之Ansible使用指南\"><a href=\"#自动化运维之Ansible使用指南\" class=\"headerlink\" title=\"自动化运维之Ansible使用指南\"></a>自动化运维之Ansible使用指南</h1><h2 id=\"运维自动化工具介绍\"><a href=\"#运维自动化工具介绍\" class=\"headerlink\" title=\"运维自动化工具介绍\"></a>运维自动化工具介绍</h2><p>在日常服务器维护中，从系统安装到程序部署再到发布应用，在大规模的生产环境中，如果需要手动的每台服务器进行安装配置将会给运维人员带来许多繁琐而又重复的工作。这就促使了在每个运维层次中出现了不同的自动化运维工具。<br>常见的自动化运维工具分类有以下几类：</p>\n<h3 id=\"系统安装运维工具（OS-Provisioning）：\"><a href=\"#系统安装运维工具（OS-Provisioning）：\" class=\"headerlink\" title=\"系统安装运维工具（OS Provisioning）：\"></a>系统安装运维工具（OS Provisioning）：</h3><p>常见的有：PXE,Cobbler，Red Hat Satelite(redhat)系统专用等</p>\n<h3 id=\"操作系统的配置运维工具-OS-Config-：\"><a href=\"#操作系统的配置运维工具-OS-Config-：\" class=\"headerlink\" title=\"操作系统的配置运维工具(OS Config)：\"></a>操作系统的配置运维工具(OS Config)：</h3><p>常见的有：cfengine，puppet,saltsack,chef等</p>\n<h3 id=\"应用程序部署工具-Application-Service-Orchestration\"><a href=\"#应用程序部署工具-Application-Service-Orchestration\" class=\"headerlink\" title=\"应用程序部署工具(Application Service Orchestration):\"></a>应用程序部署工具(Application Service Orchestration):</h3><p>常见的有:Func,Fabric,ControITier,Capistrano等</p>\n<h3 id=\"根据工作模式不同上面的运维工具有分为以下两类：\"><a href=\"#根据工作模式不同上面的运维工具有分为以下两类：\" class=\"headerlink\" title=\"根据工作模式不同上面的运维工具有分为以下两类：\"></a>根据工作模式不同上面的运维工具有分为以下两类：</h3><p>agent：基于ssl协议实现，agent工作在被监控端，例如：puppet<br>agentless: 基于ssh key实现，例如：ansible</p>\n<h2 id=\"ansible介绍\"><a href=\"#ansible介绍\" class=\"headerlink\" title=\"ansible介绍\"></a>ansible介绍</h2><p>ansible是一款轻量级自动化运维工具，由Python语言开发，结合了多种自动化运维工具的特性，实现了批量系统配置、批量程序部署、批量命令执行等功能；ansible是基于模块化实现批量操作的。<br><img src=\"https://upload-images.jianshu.io/upload_images/1542757-c4b2d6eede79a975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700\"></p>\n<h2 id=\"ansible组成\"><a href=\"#ansible组成\" class=\"headerlink\" title=\"ansible组成\"></a>ansible组成</h2><p>Ansible： 核心<br>Modules： 包括 Ansible 自带的核心模块及自定义模块<br>Plugins： 完成模块功能的补充，包括连接插件、邮件插件等<br>Playbooks： 网上很多翻译为剧本，个人觉得理解为编排更为合理；定义 Ansible 多任务配置文件，有 Ansible 自动执行<br>Inventory： 定义 Ansible 管理主机的清单<br>ansible特点<br>模块化、部署简单、工作于agentless模式、默认使用ssh协议、支持自定义模块、支持Palybook等</p>\n<h2 id=\"ansible-基本安装介绍\"><a href=\"#ansible-基本安装介绍\" class=\"headerlink\" title=\"ansible 基本安装介绍\"></a>ansible 基本安装介绍</h2><pre><code>### 系统环境\n$ uname -a\nLinux note1 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n$ cat /etc/redhat-release \nCentOS release 6.6 (Final)\n\n### epel源\n$ wget -O /etc/yum.repos.d/epel.repo  http://mirrors.aliyun.com/repo/epel-6.repo\n\n### 安装ansible\n$ yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto ansible\n\n### 配置ansible主机文件\n$ &gt; /etc/ansible/hosts         \n$ cat /etc/ansible/hosts      \n[web]\n192.168.70.51\n[db]\n192.168.70.50\n\n### 配置主机免密钥登陆\n$ ssh-keygen -t rsa -P &#39;&#39;\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.51\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.50\n\n### 测试ping\n$ ansible all -m ping \n\n解决办法:Are you sure you want to continue connecting (yes/no)?\n方法一：\n$ vim /etc/ansible/ansible.cfg 或者 ~/.ansible.cfg\n[defaults]\nhost_key_checking = False\n\n方法一：\n$ export ANSIBLE_HOST_KEY_CHECKING=False\n$ ansible all -m ping                                \n192.168.70.50 | success &gt;&gt; &#123;\n    &quot;changed&quot;: false, \n    &quot;ping&quot;: &quot;pong&quot;\n&#125;\n192.168.70.51 | success &gt;&gt; &#123;\n    &quot;changed&quot;: false, \n    &quot;ping&quot;: &quot;pong&quot;\n&#125;\n</code></pre>\n<h2 id=\"Ansible命令参数介绍\"><a href=\"#Ansible命令参数介绍\" class=\"headerlink\" title=\"Ansible命令参数介绍\"></a>Ansible命令参数介绍</h2><blockquote>\n<ul>\n<li>-v,–verbose   详细模式，如果命令执行成功，输出详细的结果(-vv –vvv -vvvv)</li>\n<li>-i PATH,–inventory=PATH   指定host文件的路径，默认是在/etc/ansible/hosts </li>\n<li>-f NUM,–forks=NU  NUM是指定一个整数，默认是5，指定fork开启同步进程的个数。 </li>\n<li>-m NAME,–module-name=NAME   指定使用的module名称，默认是command</li>\n<li>-m DIRECTORY,–module-path=DIRECTORY   指定module的目录来加载module，默认是/usr/share/ansible, </li>\n<li>-a,MODULE_ARGS   指定module模块的参数 </li>\n<li>-k,-ask-pass     提示输入ssh的密码，而不是使用基于ssh的密钥认证</li>\n<li>-sudo                   指定使用sudo获得root权限</li>\n<li>-K,-ask-sudo-pass       提示输入sudo密码，与–sudo一起使用 </li>\n<li>-u USERNAME,-user=USERNAME  指定移动端的执行用户 </li>\n<li>-C,-check               测试此命令执行会改变什么内容，不会真正的去执行</li>\n</ul>\n</blockquote>\n<h2 id=\"主机清单介绍hosts\"><a href=\"#主机清单介绍hosts\" class=\"headerlink\" title=\"主机清单介绍hosts\"></a>主机清单介绍hosts</h2><p>Ansible 通过读取默认的主机清单配置/etc/ansible/hosts，可以同时连接到多个远程主机上执行任务，默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。</p>\n<pre><code>[dbserver]  []表示主机的分组名,可以按照功能,系统进行分类,便于进行操作\n192.168.10.2 \none.example.com \nwww.bds.com:5309         #支持指定ssh端口5309 \njumper ansible_ssh_port=5309 ansible_ssh_host=192.168.10.2   #设置主机别名为jumper\nwww[01:50].bds.com       #支持通配符匹配www01.bds.com www02.bds.com\n[web]                   #提醒下这里面字母是随便定义的\nweb-[a:f].bds.com        #支持字母匹配 web-a.bds.com ..web-f.bds.com\n为主机指定类型和连接用户\n[bds]\nLocalhost  ansible_connection=local\nother1.example.com ansible_connection=ssh ansible_ssh_user=deploy\nother2.example.com ansible_connection=ssh ansible_ssh_user=deploy\nansible hosts配置文件中支持指令\n注意: 前面如果不配置主机免密钥登录,可以在/etc/ansible/hosts中定义用户和密码,主机ip地址,和ssh端口,这样也可以进行免密码访问,但是这个/hosts文件要保护好,因为所有的密码都写在里面\n</code></pre>\n<h2 id=\"hosts文件配置参数介绍\"><a href=\"#hosts文件配置参数介绍\" class=\"headerlink\" title=\"hosts文件配置参数介绍\"></a>hosts文件配置参数介绍</h2><blockquote>\n<ul>\n<li>ansible_ssh_host : 指定主机别名对应的真实 IP，如：100 ansible_ssh_host=192.168.1.100，随后连接该主机无须指定完整 IP，只需指定 251 就行</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_port : 指定连接到这个主机的 ssh 端口，默认 22</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_user : 连接到该主机的 ssh 用户</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_pass : 连接到该主机的 ssh 密码（连-k 选项都省了），安全考虑还是建议使用私钥或在命令行指定-k 选项输入</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_sudo_pass : sudo 密码</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_sudo_exe : sudo 命令路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_connection : 连接类型，可以是 local、ssh 或 paramiko，ansible1.2 之前默认为 paramiko</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_private_key_file : 私钥文件路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_shell_type : 目标系统的 shell 类型，默认为 sh,如果设置 csh/fish，那么命令需要遵循它们语法</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_python_interpreter : python 解释器路径，默认是/usr/bin/python，但是如要要连BSD系统的话，就需要该指令修改 python 路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible__interpreter : 这里的”*”可以是 ruby 或 perl 或其他语言的解释器，作用和 ansible_python_interpreter 类似</li>\n</ul>\n</blockquote>\n<h2 id=\"ansible-常用模块介绍\"><a href=\"#ansible-常用模块介绍\" class=\"headerlink\" title=\"ansible 常用模块介绍\"></a>ansible 常用模块介绍</h2><h3 id=\"ansible使用帮助\"><a href=\"#ansible使用帮助\" class=\"headerlink\" title=\"ansible使用帮助\"></a>ansible使用帮助</h3><pre><code>$ ansible-doc  -l                 #查询ansible的所有模块\n$ ansible-doc -s module_name      #查看模块的属性信息\n</code></pre>\n<h3 id=\"ansible语法\"><a href=\"#ansible语法\" class=\"headerlink\" title=\"ansible语法\"></a>ansible语法</h3><pre><code>ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt;\n</code></pre>\n<h3 id=\"raw模块\"><a href=\"#raw模块\" class=\"headerlink\" title=\"raw模块\"></a>raw模块</h3><p>command模块功能相同，但比command的模块功能强大(支持管道和变量)<br>Ansible raw：<a href=\"https://docs.ansible.com/ansible/raw_module.html\">https://docs.ansible.com/ansible/raw_module.html</a></p>\n<pre><code>$ ansible all -m raw -a &quot;hostname&quot;\n</code></pre>\n<h3 id=\"command模块\"><a href=\"#command模块\" class=\"headerlink\" title=\"command模块\"></a>command模块</h3><p>默认模块 ,用于在各个被管理节点运行指定的命令(不支持管道和变量)<br>Ansible command模块：<a href=\"https://docs.ansible.com/ansible/list_of_commands_modules.html\">https://docs.ansible.com/ansible/list_of_commands_modules.html</a></p>\n<pre><code>$ ansible all -m command -a &quot;hostname &quot;\n</code></pre>\n<h3 id=\"shell模块\"><a href=\"#shell模块\" class=\"headerlink\" title=\"shell模块\"></a>shell模块</h3><p>command模块功能相同，但比command的模块功能强大(支持管道和变量)<br>Ansible shell模块：<a href=\"https://docs.ansible.com/ansible/shell_module.html\">https://docs.ansible.com/ansible/shell_module.html</a></p>\n<pre><code>$ ansible all -m shell -a &quot;cat /etc/passwd| grep root &quot;                         \n</code></pre>\n<h3 id=\"user模块\"><a href=\"#user模块\" class=\"headerlink\" title=\"user模块\"></a>user模块</h3><p>用户模块,用于在各管理节点管理用户所使用<br>Ansible User模块：<a href=\"https://docs.ansible.com/ansible/user_module.html\">https://docs.ansible.com/ansible/user_module.html</a></p>\n<pre><code>### 创建一个用户\n$ ansible db -m user -a &#39;name=DBA uid=505 home=/Data/dba shell=/sbin/nologin&#39;    \n        \n### 删除一个用户\n$ ansible db -m user  -a &#39;name=budongshu uid=506  state=absent&#39;\n</code></pre>\n<h3 id=\"group模块\"><a href=\"#group模块\" class=\"headerlink\" title=\"group模块\"></a>group模块</h3><p>Ansible group模块：<a href=\"https://docs.ansible.com/ansible/group_module.html\">https://docs.ansible.com/ansible/group_module.html</a></p>\n<pre><code>ansible db -m group  -a &#39;name=test  gid=1000&#39; \n</code></pre>\n<h3 id=\"cron模块\"><a href=\"#cron模块\" class=\"headerlink\" title=\"cron模块\"></a>cron模块</h3><p>计划定时任务,用于在各管理节点管理计划任务<br>Ansible cron模块：<a href=\"https://docs.ansible.com/ansible/cron_module.html\">https://docs.ansible.com/ansible/cron_module.html</a></p>\n<pre><code>$ ansible all -m cron -a &quot;name=time minute=&#39;*/2&#39; job=&#39;/usr/sbin/ntpdate \n</code></pre>\n<h3 id=\"copy模块\"><a href=\"#copy模块\" class=\"headerlink\" title=\"copy模块\"></a>copy模块</h3><p>复制模块,复制文件到各个节点<br>Ansible copy模块：<a href=\"https://docs.ansible.com/ansible/copy_module.html\">https://docs.ansible.com/ansible/copy_module.html</a></p>\n<pre><code>$ ansible all -m copy -a &quot;src=/etc/hosts dest=/tmp/ mode=600&quot;\n</code></pre>\n<h3 id=\"file模块\"><a href=\"#file模块\" class=\"headerlink\" title=\"file模块\"></a>file模块</h3><p>文件模块 , 修改各个节点指定的文件属性<br>Ansible File模块：<a href=\"https://docs.ansible.com/ansible/list_of_files_modules.html\">https://docs.ansible.com/ansible/list_of_files_modules.html</a></p>\n<pre><code>$ ansible all -m file -a &#39;path=/tmp/hosts mode=644 owner=DBA&#39;  \n\n$ ansible all -m file -a &quot;dest=/tmp/ansible.txt mode=755 owner=root \ngroup=root state=directory&quot;\n\n### file删除文件或者目录\n$ ansible all -m file -a &quot;dest=/tmp/ansible.txt state=absent&quot;   \n注：state的其他选项：link(链接)、hard(硬链接)\n</code></pre>\n<h3 id=\"stat-模块\"><a href=\"#stat-模块\" class=\"headerlink\" title=\"stat 模块\"></a>stat 模块</h3><p>获取远程文件状态信息，包含atime、ctime、mtime、md5、uid、gid等<br>Ansible Setup模块：<a href=\"https://docs.ansible.com/ansible/setup_module.html\">https://docs.ansible.com/ansible/setup_module.html</a></p>\n<pre><code>$ ansible all -m stat -a &quot;path=/etc/passwd &quot;\n</code></pre>\n<h3 id=\"ping-模块\"><a href=\"#ping-模块\" class=\"headerlink\" title=\"ping 模块\"></a>ping 模块</h3><p>测试模块 ,测试各个节点是否正常在线</p>\n<pre><code>$ansible all -m stat -a &#39;path=/etc/passwd&#39;\n</code></pre>\n<h3 id=\"template模块\"><a href=\"#template模块\" class=\"headerlink\" title=\"template模块\"></a>template模块</h3><p>根据官方的翻译是：template使用了Jinjia2格式作为文件模板，进行文档内变量的替换的模块。他的每次使用都会被ansible标记为changed状态。<br>Ansible Template模块：<a href=\"https://docs.ansible.com/ansible/template_module.html\">https://docs.ansible.com/ansible/template_module.html</a></p>\n<h3 id=\"yum模块\"><a href=\"#yum模块\" class=\"headerlink\" title=\"yum模块\"></a>yum模块</h3><p>用于管理节点安装软件所使用<br>Ansible yum模块：<a href=\"https://docs.ansible.com/ansible/yum_module.html\">https://docs.ansible.com/ansible/yum_module.html</a></p>\n<pre><code>$ ansible all -m yum -a &#39;name=ntp state=present&#39;\n</code></pre>\n<blockquote>\n<ul>\n<li>卸载的软件只需要将 name=ntp state=absent </li>\n<li>安装特定版本 name=nginx-1.6.2 state=present</li>\n<li>指定某个源仓库安装软件包name=htop enablerepo=epel state=present</li>\n<li>更新软件到最新版 name=nginx state=latest</li>\n</ul>\n</blockquote>\n<h3 id=\"service模块\"><a href=\"#service模块\" class=\"headerlink\" title=\"service模块\"></a>service模块</h3><p>管理各个节点的服务<br>Ansible service模块：<a href=\"https://docs.ansible.com/ansible/service_module.html\">https://docs.ansible.com/ansible/service_module.html</a></p>\n<pre><code>$ ansible all -m service -a &quot;name=ntpd enabled=true state=started&quot;     state 支持其它选项 started stopped restarted\n</code></pre>\n<h3 id=\"script模块\"><a href=\"#script模块\" class=\"headerlink\" title=\"script模块\"></a>script模块</h3><p>自动复制脚本到远程节点,并运行<br>Ansible script模块：<a href=\"http://docs.ansible.com/ansible/script_module.html\">http://docs.ansible.com/ansible/script_module.html</a></p>\n<pre><code>$ ansible all -m script -a &#39;ansible_test.sh&#39;\n</code></pre>\n<h3 id=\"setup模块\"><a href=\"#setup模块\" class=\"headerlink\" title=\"setup模块\"></a>setup模块</h3><p>收集ansible的facts信息<br>Ansible script模块：<a href=\"http://docs.ansible.com/ansible/script_module.html\">http://docs.ansible.com/ansible/script_module.html</a></p>\n<pre><code>$ ansible all -m setup  #收集主机的facts信息,可以通过变量引用这些信息\n</code></pre>\n<h2 id=\"ansible-主机清单通配模式介绍\"><a href=\"#ansible-主机清单通配模式介绍\" class=\"headerlink\" title=\"ansible 主机清单通配模式介绍\"></a>ansible 主机清单通配模式介绍</h2><p>可以看到上面执行命令的时候有个ansible -m all ,以上我用的all或指定主机,这里也可以进行通配 ,在/etc/ansible/hosts 进行设置如下</p>\n<pre><code>[web]\n10.10.10.2\n10.10.10.3\n[db]\n10.10.10.4 \n[allhost:children]     #可以把一个组当做另一个组的子成员\nweb\ndb\n例子:\nansible web -m shell -a ‘uptime’     #代表web组中的所有主机\nansible allhost -m shell -a ‘uptime’ #代表allhost组中的所有子成员组\n其它匹配方式\n</code></pre>\n<pre><code>1.1 通配所有主机\nall , *\n\n1.2 通配具有规则特征的主机或者主机名\none.bds.com\n.bds.com\n192.168.10.2\n192.168.10.\n\n1.3 通配俩组的所有主机,组名之间通过冒号分开,表示or的意思\nweb:db\n\n1.4 非模式匹配: 表示在 web组不在db组的主机\nweb:!db\n\n1.5 交集匹配: 表示同时都在 web 和db组的主机\nweb:&amp;db\n\n1.6 匹配一个组的特定编号的主机 从零开始计算\nweb[0]\n\n1.7 匹配 web组的第 1 个到第 25 个主机\nweb [0-25]\n\n1.8 组合匹配\n在web组或者在db组中,必须还存在test1组中,但不在test2组中\nweb:db:&amp;test1:!test2\n\n1.9 大部分人都在patterns应用正则表达式,但你可以.只需要以 ‘~’ 开头即可:\n~(web|db).*.example.com\n\n2.0 同时让我们提前了解一些技能,除了如上,你也可以通过 --limit 标记来添加排除条件,/usr/bin/ansible or /usr/bin/ansible-playbook都支持:\nansible-playbook site.yml --limit datacenter2\n\n2.1 如果你想从文件读取hosts,文件名以@为前缀即可.从Ansible 1.2开始支持该功能:\nansible-playbook site.yml --limit @retry_hosts.txt\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.jianshu.com/p/b9956ea83a78\">https://www.jianshu.com/p/b9956ea83a78</a></li>\n<li><a href=\"http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/\">http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</a></li>\n<li><a href=\"http://ansible-tran.readthedocs.io/en/latest/index.html\">http://ansible-tran.readthedocs.io/en/latest/index.html</a></li>\n<li><a href=\"https://docs.ansible.com/ansible/2.3/index.html\">https://docs.ansible.com/ansible/2.3/index.html</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"自动化运维之Ansible使用指南\"><a href=\"#自动化运维之Ansible使用指南\" class=\"headerlink\" title=\"自动化运维之Ansible使用指南\"></a>自动化运维之Ansible使用指南</h1><h2 id=\"运维自动化工具介绍\"><a href=\"#运维自动化工具介绍\" class=\"headerlink\" title=\"运维自动化工具介绍\"></a>运维自动化工具介绍</h2><p>在日常服务器维护中，从系统安装到程序部署再到发布应用，在大规模的生产环境中，如果需要手动的每台服务器进行安装配置将会给运维人员带来许多繁琐而又重复的工作。这就促使了在每个运维层次中出现了不同的自动化运维工具。<br>常见的自动化运维工具分类有以下几类：</p>\n<h3 id=\"系统安装运维工具（OS-Provisioning）：\"><a href=\"#系统安装运维工具（OS-Provisioning）：\" class=\"headerlink\" title=\"系统安装运维工具（OS Provisioning）：\"></a>系统安装运维工具（OS Provisioning）：</h3><p>常见的有：PXE,Cobbler，Red Hat Satelite(redhat)系统专用等</p>\n<h3 id=\"操作系统的配置运维工具-OS-Config-：\"><a href=\"#操作系统的配置运维工具-OS-Config-：\" class=\"headerlink\" title=\"操作系统的配置运维工具(OS Config)：\"></a>操作系统的配置运维工具(OS Config)：</h3><p>常见的有：cfengine，puppet,saltsack,chef等</p>\n<h3 id=\"应用程序部署工具-Application-Service-Orchestration\"><a href=\"#应用程序部署工具-Application-Service-Orchestration\" class=\"headerlink\" title=\"应用程序部署工具(Application Service Orchestration):\"></a>应用程序部署工具(Application Service Orchestration):</h3><p>常见的有:Func,Fabric,ControITier,Capistrano等</p>\n<h3 id=\"根据工作模式不同上面的运维工具有分为以下两类：\"><a href=\"#根据工作模式不同上面的运维工具有分为以下两类：\" class=\"headerlink\" title=\"根据工作模式不同上面的运维工具有分为以下两类：\"></a>根据工作模式不同上面的运维工具有分为以下两类：</h3><p>agent：基于ssl协议实现，agent工作在被监控端，例如：puppet<br>agentless: 基于ssh key实现，例如：ansible</p>\n<h2 id=\"ansible介绍\"><a href=\"#ansible介绍\" class=\"headerlink\" title=\"ansible介绍\"></a>ansible介绍</h2><p>ansible是一款轻量级自动化运维工具，由Python语言开发，结合了多种自动化运维工具的特性，实现了批量系统配置、批量程序部署、批量命令执行等功能；ansible是基于模块化实现批量操作的。<br><img src=\"https://upload-images.jianshu.io/upload_images/1542757-c4b2d6eede79a975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700\"></p>\n<h2 id=\"ansible组成\"><a href=\"#ansible组成\" class=\"headerlink\" title=\"ansible组成\"></a>ansible组成</h2><p>Ansible： 核心<br>Modules： 包括 Ansible 自带的核心模块及自定义模块<br>Plugins： 完成模块功能的补充，包括连接插件、邮件插件等<br>Playbooks： 网上很多翻译为剧本，个人觉得理解为编排更为合理；定义 Ansible 多任务配置文件，有 Ansible 自动执行<br>Inventory： 定义 Ansible 管理主机的清单<br>ansible特点<br>模块化、部署简单、工作于agentless模式、默认使用ssh协议、支持自定义模块、支持Palybook等</p>\n<h2 id=\"ansible-基本安装介绍\"><a href=\"#ansible-基本安装介绍\" class=\"headerlink\" title=\"ansible 基本安装介绍\"></a>ansible 基本安装介绍</h2><pre><code>### 系统环境\n$ uname -a\nLinux note1 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n$ cat /etc/redhat-release \nCentOS release 6.6 (Final)\n\n### epel源\n$ wget -O /etc/yum.repos.d/epel.repo  http://mirrors.aliyun.com/repo/epel-6.repo\n\n### 安装ansible\n$ yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto ansible\n\n### 配置ansible主机文件\n$ &gt; /etc/ansible/hosts         \n$ cat /etc/ansible/hosts      \n[web]\n192.168.70.51\n[db]\n192.168.70.50\n\n### 配置主机免密钥登陆\n$ ssh-keygen -t rsa -P &#39;&#39;\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.51\n$ ssh-copy-id  -i ~/.ssh/id_rsa.pub root@192.168.70.50\n\n### 测试ping\n$ ansible all -m ping \n\n解决办法:Are you sure you want to continue connecting (yes/no)?\n方法一：\n$ vim /etc/ansible/ansible.cfg 或者 ~/.ansible.cfg\n[defaults]\nhost_key_checking = False\n\n方法一：\n$ export ANSIBLE_HOST_KEY_CHECKING=False\n$ ansible all -m ping                                \n192.168.70.50 | success &gt;&gt; &#123;\n    &quot;changed&quot;: false, \n    &quot;ping&quot;: &quot;pong&quot;\n&#125;\n192.168.70.51 | success &gt;&gt; &#123;\n    &quot;changed&quot;: false, \n    &quot;ping&quot;: &quot;pong&quot;\n&#125;\n</code></pre>\n<h2 id=\"Ansible命令参数介绍\"><a href=\"#Ansible命令参数介绍\" class=\"headerlink\" title=\"Ansible命令参数介绍\"></a>Ansible命令参数介绍</h2><blockquote>\n<ul>\n<li>-v,–verbose   详细模式，如果命令执行成功，输出详细的结果(-vv –vvv -vvvv)</li>\n<li>-i PATH,–inventory=PATH   指定host文件的路径，默认是在/etc/ansible/hosts </li>\n<li>-f NUM,–forks=NU  NUM是指定一个整数，默认是5，指定fork开启同步进程的个数。 </li>\n<li>-m NAME,–module-name=NAME   指定使用的module名称，默认是command</li>\n<li>-m DIRECTORY,–module-path=DIRECTORY   指定module的目录来加载module，默认是/usr/share/ansible, </li>\n<li>-a,MODULE_ARGS   指定module模块的参数 </li>\n<li>-k,-ask-pass     提示输入ssh的密码，而不是使用基于ssh的密钥认证</li>\n<li>-sudo                   指定使用sudo获得root权限</li>\n<li>-K,-ask-sudo-pass       提示输入sudo密码，与–sudo一起使用 </li>\n<li>-u USERNAME,-user=USERNAME  指定移动端的执行用户 </li>\n<li>-C,-check               测试此命令执行会改变什么内容，不会真正的去执行</li>\n</ul>\n</blockquote>\n<h2 id=\"主机清单介绍hosts\"><a href=\"#主机清单介绍hosts\" class=\"headerlink\" title=\"主机清单介绍hosts\"></a>主机清单介绍hosts</h2><p>Ansible 通过读取默认的主机清单配置/etc/ansible/hosts，可以同时连接到多个远程主机上执行任务，默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。</p>\n<pre><code>[dbserver]  []表示主机的分组名,可以按照功能,系统进行分类,便于进行操作\n192.168.10.2 \none.example.com \nwww.bds.com:5309         #支持指定ssh端口5309 \njumper ansible_ssh_port=5309 ansible_ssh_host=192.168.10.2   #设置主机别名为jumper\nwww[01:50].bds.com       #支持通配符匹配www01.bds.com www02.bds.com\n[web]                   #提醒下这里面字母是随便定义的\nweb-[a:f].bds.com        #支持字母匹配 web-a.bds.com ..web-f.bds.com\n为主机指定类型和连接用户\n[bds]\nLocalhost  ansible_connection=local\nother1.example.com ansible_connection=ssh ansible_ssh_user=deploy\nother2.example.com ansible_connection=ssh ansible_ssh_user=deploy\nansible hosts配置文件中支持指令\n注意: 前面如果不配置主机免密钥登录,可以在/etc/ansible/hosts中定义用户和密码,主机ip地址,和ssh端口,这样也可以进行免密码访问,但是这个/hosts文件要保护好,因为所有的密码都写在里面\n</code></pre>\n<h2 id=\"hosts文件配置参数介绍\"><a href=\"#hosts文件配置参数介绍\" class=\"headerlink\" title=\"hosts文件配置参数介绍\"></a>hosts文件配置参数介绍</h2><blockquote>\n<ul>\n<li>ansible_ssh_host : 指定主机别名对应的真实 IP，如：100 ansible_ssh_host=192.168.1.100，随后连接该主机无须指定完整 IP，只需指定 251 就行</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_port : 指定连接到这个主机的 ssh 端口，默认 22</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_user : 连接到该主机的 ssh 用户</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_pass : 连接到该主机的 ssh 密码（连-k 选项都省了），安全考虑还是建议使用私钥或在命令行指定-k 选项输入</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_sudo_pass : sudo 密码</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_sudo_exe : sudo 命令路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_connection : 连接类型，可以是 local、ssh 或 paramiko，ansible1.2 之前默认为 paramiko</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_ssh_private_key_file : 私钥文件路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_shell_type : 目标系统的 shell 类型，默认为 sh,如果设置 csh/fish，那么命令需要遵循它们语法</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible_python_interpreter : python 解释器路径，默认是/usr/bin/python，但是如要要连BSD系统的话，就需要该指令修改 python 路径</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>ansible__interpreter : 这里的”*”可以是 ruby 或 perl 或其他语言的解释器，作用和 ansible_python_interpreter 类似</li>\n</ul>\n</blockquote>\n<h2 id=\"ansible-常用模块介绍\"><a href=\"#ansible-常用模块介绍\" class=\"headerlink\" title=\"ansible 常用模块介绍\"></a>ansible 常用模块介绍</h2><h3 id=\"ansible使用帮助\"><a href=\"#ansible使用帮助\" class=\"headerlink\" title=\"ansible使用帮助\"></a>ansible使用帮助</h3><pre><code>$ ansible-doc  -l                 #查询ansible的所有模块\n$ ansible-doc -s module_name      #查看模块的属性信息\n</code></pre>\n<h3 id=\"ansible语法\"><a href=\"#ansible语法\" class=\"headerlink\" title=\"ansible语法\"></a>ansible语法</h3><pre><code>ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt;\n</code></pre>\n<h3 id=\"raw模块\"><a href=\"#raw模块\" class=\"headerlink\" title=\"raw模块\"></a>raw模块</h3><p>command模块功能相同，但比command的模块功能强大(支持管道和变量)<br>Ansible raw：<a href=\"https://docs.ansible.com/ansible/raw_module.html\">https://docs.ansible.com/ansible/raw_module.html</a></p>\n<pre><code>$ ansible all -m raw -a &quot;hostname&quot;\n</code></pre>\n<h3 id=\"command模块\"><a href=\"#command模块\" class=\"headerlink\" title=\"command模块\"></a>command模块</h3><p>默认模块 ,用于在各个被管理节点运行指定的命令(不支持管道和变量)<br>Ansible command模块：<a href=\"https://docs.ansible.com/ansible/list_of_commands_modules.html\">https://docs.ansible.com/ansible/list_of_commands_modules.html</a></p>\n<pre><code>$ ansible all -m command -a &quot;hostname &quot;\n</code></pre>\n<h3 id=\"shell模块\"><a href=\"#shell模块\" class=\"headerlink\" title=\"shell模块\"></a>shell模块</h3><p>command模块功能相同，但比command的模块功能强大(支持管道和变量)<br>Ansible shell模块：<a href=\"https://docs.ansible.com/ansible/shell_module.html\">https://docs.ansible.com/ansible/shell_module.html</a></p>\n<pre><code>$ ansible all -m shell -a &quot;cat /etc/passwd| grep root &quot;                         \n</code></pre>\n<h3 id=\"user模块\"><a href=\"#user模块\" class=\"headerlink\" title=\"user模块\"></a>user模块</h3><p>用户模块,用于在各管理节点管理用户所使用<br>Ansible User模块：<a href=\"https://docs.ansible.com/ansible/user_module.html\">https://docs.ansible.com/ansible/user_module.html</a></p>\n<pre><code>### 创建一个用户\n$ ansible db -m user -a &#39;name=DBA uid=505 home=/Data/dba shell=/sbin/nologin&#39;    \n        \n### 删除一个用户\n$ ansible db -m user  -a &#39;name=budongshu uid=506  state=absent&#39;\n</code></pre>\n<h3 id=\"group模块\"><a href=\"#group模块\" class=\"headerlink\" title=\"group模块\"></a>group模块</h3><p>Ansible group模块：<a href=\"https://docs.ansible.com/ansible/group_module.html\">https://docs.ansible.com/ansible/group_module.html</a></p>\n<pre><code>ansible db -m group  -a &#39;name=test  gid=1000&#39; \n</code></pre>\n<h3 id=\"cron模块\"><a href=\"#cron模块\" class=\"headerlink\" title=\"cron模块\"></a>cron模块</h3><p>计划定时任务,用于在各管理节点管理计划任务<br>Ansible cron模块：<a href=\"https://docs.ansible.com/ansible/cron_module.html\">https://docs.ansible.com/ansible/cron_module.html</a></p>\n<pre><code>$ ansible all -m cron -a &quot;name=time minute=&#39;*/2&#39; job=&#39;/usr/sbin/ntpdate \n</code></pre>\n<h3 id=\"copy模块\"><a href=\"#copy模块\" class=\"headerlink\" title=\"copy模块\"></a>copy模块</h3><p>复制模块,复制文件到各个节点<br>Ansible copy模块：<a href=\"https://docs.ansible.com/ansible/copy_module.html\">https://docs.ansible.com/ansible/copy_module.html</a></p>\n<pre><code>$ ansible all -m copy -a &quot;src=/etc/hosts dest=/tmp/ mode=600&quot;\n</code></pre>\n<h3 id=\"file模块\"><a href=\"#file模块\" class=\"headerlink\" title=\"file模块\"></a>file模块</h3><p>文件模块 , 修改各个节点指定的文件属性<br>Ansible File模块：<a href=\"https://docs.ansible.com/ansible/list_of_files_modules.html\">https://docs.ansible.com/ansible/list_of_files_modules.html</a></p>\n<pre><code>$ ansible all -m file -a &#39;path=/tmp/hosts mode=644 owner=DBA&#39;  \n\n$ ansible all -m file -a &quot;dest=/tmp/ansible.txt mode=755 owner=root \ngroup=root state=directory&quot;\n\n### file删除文件或者目录\n$ ansible all -m file -a &quot;dest=/tmp/ansible.txt state=absent&quot;   \n注：state的其他选项：link(链接)、hard(硬链接)\n</code></pre>\n<h3 id=\"stat-模块\"><a href=\"#stat-模块\" class=\"headerlink\" title=\"stat 模块\"></a>stat 模块</h3><p>获取远程文件状态信息，包含atime、ctime、mtime、md5、uid、gid等<br>Ansible Setup模块：<a href=\"https://docs.ansible.com/ansible/setup_module.html\">https://docs.ansible.com/ansible/setup_module.html</a></p>\n<pre><code>$ ansible all -m stat -a &quot;path=/etc/passwd &quot;\n</code></pre>\n<h3 id=\"ping-模块\"><a href=\"#ping-模块\" class=\"headerlink\" title=\"ping 模块\"></a>ping 模块</h3><p>测试模块 ,测试各个节点是否正常在线</p>\n<pre><code>$ansible all -m stat -a &#39;path=/etc/passwd&#39;\n</code></pre>\n<h3 id=\"template模块\"><a href=\"#template模块\" class=\"headerlink\" title=\"template模块\"></a>template模块</h3><p>根据官方的翻译是：template使用了Jinjia2格式作为文件模板，进行文档内变量的替换的模块。他的每次使用都会被ansible标记为changed状态。<br>Ansible Template模块：<a href=\"https://docs.ansible.com/ansible/template_module.html\">https://docs.ansible.com/ansible/template_module.html</a></p>\n<h3 id=\"yum模块\"><a href=\"#yum模块\" class=\"headerlink\" title=\"yum模块\"></a>yum模块</h3><p>用于管理节点安装软件所使用<br>Ansible yum模块：<a href=\"https://docs.ansible.com/ansible/yum_module.html\">https://docs.ansible.com/ansible/yum_module.html</a></p>\n<pre><code>$ ansible all -m yum -a &#39;name=ntp state=present&#39;\n</code></pre>\n<blockquote>\n<ul>\n<li>卸载的软件只需要将 name=ntp state=absent </li>\n<li>安装特定版本 name=nginx-1.6.2 state=present</li>\n<li>指定某个源仓库安装软件包name=htop enablerepo=epel state=present</li>\n<li>更新软件到最新版 name=nginx state=latest</li>\n</ul>\n</blockquote>\n<h3 id=\"service模块\"><a href=\"#service模块\" class=\"headerlink\" title=\"service模块\"></a>service模块</h3><p>管理各个节点的服务<br>Ansible service模块：<a href=\"https://docs.ansible.com/ansible/service_module.html\">https://docs.ansible.com/ansible/service_module.html</a></p>\n<pre><code>$ ansible all -m service -a &quot;name=ntpd enabled=true state=started&quot;     state 支持其它选项 started stopped restarted\n</code></pre>\n<h3 id=\"script模块\"><a href=\"#script模块\" class=\"headerlink\" title=\"script模块\"></a>script模块</h3><p>自动复制脚本到远程节点,并运行<br>Ansible script模块：<a href=\"http://docs.ansible.com/ansible/script_module.html\">http://docs.ansible.com/ansible/script_module.html</a></p>\n<pre><code>$ ansible all -m script -a &#39;ansible_test.sh&#39;\n</code></pre>\n<h3 id=\"setup模块\"><a href=\"#setup模块\" class=\"headerlink\" title=\"setup模块\"></a>setup模块</h3><p>收集ansible的facts信息<br>Ansible script模块：<a href=\"http://docs.ansible.com/ansible/script_module.html\">http://docs.ansible.com/ansible/script_module.html</a></p>\n<pre><code>$ ansible all -m setup  #收集主机的facts信息,可以通过变量引用这些信息\n</code></pre>\n<h2 id=\"ansible-主机清单通配模式介绍\"><a href=\"#ansible-主机清单通配模式介绍\" class=\"headerlink\" title=\"ansible 主机清单通配模式介绍\"></a>ansible 主机清单通配模式介绍</h2><p>可以看到上面执行命令的时候有个ansible -m all ,以上我用的all或指定主机,这里也可以进行通配 ,在/etc/ansible/hosts 进行设置如下</p>\n<pre><code>[web]\n10.10.10.2\n10.10.10.3\n[db]\n10.10.10.4 \n[allhost:children]     #可以把一个组当做另一个组的子成员\nweb\ndb\n例子:\nansible web -m shell -a ‘uptime’     #代表web组中的所有主机\nansible allhost -m shell -a ‘uptime’ #代表allhost组中的所有子成员组\n其它匹配方式\n</code></pre>\n<pre><code>1.1 通配所有主机\nall , *\n\n1.2 通配具有规则特征的主机或者主机名\none.bds.com\n.bds.com\n192.168.10.2\n192.168.10.\n\n1.3 通配俩组的所有主机,组名之间通过冒号分开,表示or的意思\nweb:db\n\n1.4 非模式匹配: 表示在 web组不在db组的主机\nweb:!db\n\n1.5 交集匹配: 表示同时都在 web 和db组的主机\nweb:&amp;db\n\n1.6 匹配一个组的特定编号的主机 从零开始计算\nweb[0]\n\n1.7 匹配 web组的第 1 个到第 25 个主机\nweb [0-25]\n\n1.8 组合匹配\n在web组或者在db组中,必须还存在test1组中,但不在test2组中\nweb:db:&amp;test1:!test2\n\n1.9 大部分人都在patterns应用正则表达式,但你可以.只需要以 ‘~’ 开头即可:\n~(web|db).*.example.com\n\n2.0 同时让我们提前了解一些技能,除了如上,你也可以通过 --limit 标记来添加排除条件,/usr/bin/ansible or /usr/bin/ansible-playbook都支持:\nansible-playbook site.yml --limit datacenter2\n\n2.1 如果你想从文件读取hosts,文件名以@为前缀即可.从Ansible 1.2开始支持该功能:\nansible-playbook site.yml --limit @retry_hosts.txt\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.jianshu.com/p/b9956ea83a78\">https://www.jianshu.com/p/b9956ea83a78</a></li>\n<li><a href=\"http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/\">http://www.yfshare.vip/2017/04/05/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</a></li>\n<li><a href=\"http://ansible-tran.readthedocs.io/en/latest/index.html\">http://ansible-tran.readthedocs.io/en/latest/index.html</a></li>\n<li><a href=\"https://docs.ansible.com/ansible/2.3/index.html\">https://docs.ansible.com/ansible/2.3/index.html</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"curl常用命令","date":"2018-08-21T02:41:54.000Z","author":"owelinux","excerpt":"curl常用命令","mathjax":true,"_content":"\n* content\n{:toc}\n\n# curl常用命令\n\n## curl介绍\ncurl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\n\n## 语法\n```\ncurl(选项)(参数)\n```\n\n## 选项       \n* -a/--append\t                    上传文件时，附加到目标文件 \n* -A/--user-agent <string>\t        设置用户代理发送给服务器   \n* -anyauth\t                        可以使用“任何”身份验证方法 \n* -b/--cookie <name=string/file     cookie字符串或文件读取位置 \n*      --basic\t                    使用HTTP基本验证 \n* -B/--use-ascii\t                使用ASCII /文本传输 \n* -c/--cookie-jar <file>\t        操作结束后把cookie写入到这个文件中\n* -C/--continue-at <offset>\t        断点续转 \n*                                                              \n**-d/--data <data>\t                HTTP POST方式传送数据** \n*      --data-ascii <data>\t        以ascii的方式post数据 \n*      --data-binary <data>\t        以二进制的方式post数据\n*      --negotiate\t                使用HTTP身份验证 \n*      --digest\t                    使用数字身份验证 \n*      --disable-eprt\t            禁止使用EPRT或LPRT \n*      --disable-epsv\t            禁止使用EPSV \n* -D/--dump-header <file>\t        把header信息写入到该文件中 \n*      --egd-file <file>\t        为随机数据(SSL)设置EGD socket路径\n*      --tcp-nodelay\t            使用TCP_NODELAY选项 \n* -e/--referer\t                    来源网址 \n* -E/--cert <cert[:passwd]>\t        客户端证书文件和密码\n*      --cert-type <type>\t        证书文件类型\n*      --key <key>\t                私钥文件名\n*      --key-type <type>\t        私钥文件类型 \n*      --pass <pass>\t            私钥密码 \n*      --engine <eng>\t            加密引擎使用 \n*      --cacert <file>\t            CA证书 \n*      --capath <directory>\t        CA目录 \n*      --ciphers <list>\t            SSL密码 \n*      --compressed\t                要求返回是压缩的形势 \n*      --connect-timeout    \t    设置最大请求时间\n*      --create-dirs\t            建立本地目录的目录层次结构\n*      --crlf\t                    上传是把LF转变成CRLF \n* -f/--fail\t                        连接失败时不显示http错误 \n*      --ftp-create-dirs\t        如果远程目录不存在，创建远程目录 \n*      --ftp-method [multicwd/nocwd/singlecwd]\t 控制CWD的使用\n*      --ftp-pasv\t                使用 PASV/EPSV 代替端口 \n*      --ftp-skip-pasv-ip\t        使用PASV的时候,忽略该IP地址 \n*      --ftp-ssl\t                尝试用 SSL/TLS 来进行ftp数据传输 \n*      --ftp-ssl-reqd\t            要求用 SSL/TLS 来进行ftp数据传输 \n* -F/--form <name=content>\t        模拟http表单提交数据\n*      --form-string        \t    模拟http表单提交数据 \n* -g/--globoff\t                    禁用网址序列和范围使用{}和[]   \n*                                                              \n**-G/--get\t                        以get的方式来发送数据**\n*                                                              \n**-H/--header <line>\t            自定义头信息传递给服务器**\n*      --ignore-content-length\t    忽略的HTTP头信息的长度 \n* -i/--include\t                    输出时包括protocol头信息 \n*                                                              \n**-I/--head\t                        只显示请求头信息** \n* -j/--junk-session-cookies\t        读取文件进忽略session cookie \n*      --interface <interface>\t    使用指定网络接口/地址 \n*      --krb4 <level>\t            使用指定安全级别的krb4 \n* -k/--insecure\t                    允许不使用证书到SSL站点 \n* -K/--config\t                    指定的配置文件读取 \n* -l/--list-only\t                列出ftp目录下的文件名称 \n*                                                              \n**--limit-rate <rate>\t        设置传输速度** \n*      --local-port<NUM>\t        强制使用本地端口号 \n*                                                              \n**-m/--max-time <seconds>\t        设置最大传输时间** \n*      --max-redirs <num>\t        设置最大读取的目录数 \n*      --max-filesize <bytes>\t    设置最大下载的文件总量 \n* -M/--manual\t                    显示全手动 \n* -n/--netrc\t                    从netrc文件中读取用户名和密码 \n*      --netrc-optional\t            使用 .netrc 或者 URL来覆盖-n \n*      --ntlm\t                    使用 HTTP NTLM 身份验证 \n* -N/--no-buffer\t                禁用缓冲输出 \n* -o/--output\t                    把输出写到该文件中 \n* -O/--remote-name\t                把输出写到该文件中，保留远程文件的文件名 \n* -p/--proxytunnel\t                使用HTTP代理 \n*      --proxy-anyauth\t            选择任一代理身份验证方法 \n*      --proxy-basic\t            在代理上使用基本身份验证 \n*      --proxy-digest\t            在代理上使用数字身份验证 \n*      --proxy-ntlm\t                在代理上使用ntlm身份验证 \n* -P/--ftp-port <address>\t        使用端口地址，而不是使用PASV \n* -q\t                            作为第一个参数，关闭 .curlrc \n* -Q/--quote <cmd>\t                文件传输前，发送命令到服务器 \n* -r/--range <range>\t            检索来自HTTP/1.1或FTP服务器字节范围 \n* --range-file\t                    读取（SSL）的随机文件 \n* -R/--remote-time\t                在本地生成文件时，保留远程文件时间 \n*      --retry <num>\t            传输出现问题时，重试的次数 \n*      --retry-delay          \t    传输出现问题时，设置重试间隔时间 \n*      --retry-max-time             传输出现问题时，设置最大重试时间\n*                                                              \n**-s/--silent\t                    静默模式。不输出任何东西** \n* -S/--show-error\t                显示错误 \n*      --socks4 <host[:port]>\t    用socks4代理给定主机和端口 \n*      --socks5 <host[:port]>\t    用socks5代理给定主机和端口 \n*      --stderr <file>\t            \n* -t/--telnet-option <OPT=val>\t    Telnet选项设置 \n*      --trace <file>\t            对指定文件进行debug \n*      --trace-ascii <file>\tLike    跟踪但没有hex输出 \n*      --trace-time\t                跟踪/详细输出时，添加时间戳 \n* -T/--upload-file <file>\t        上传文件 \n*      --url <URL>\t                Spet URL to work with \n* -u/--user <user[:password]>\t    设置服务器的用户和密码 \n* -U/--proxy-user <user[:password]> 设置代理用户名和密码 \n* -w/--write-out [format]\t        什么输出完成后 \n*                              \n**-x/--proxy <host[:port]>\t        在给定的端口上使用HTTP代理** \n* -X/--request <command>\t        指定什么命令 \n* -y/--speed-time\t                放弃限速所要的时间，默认为30 \n* -Y/--speed-limit\t                停止传输速度的限制，速度时间 \n\n## 常用举例\n### GET请求(-G/--get/省略)\n```\ncurl http://www.xxxx.com/show?userId=111\n```\n\n### POST请求\n以application/x-www-url-encoded 方式发送数据(-d/--data)：\n```\ncurl -d \"username=sunnyxd&password=12345\" URL\n```\n以multipart/form-data 的方式发送数据(上传文件，-F/--form)：\n```\ncurl -F filename=@/home/sunnyxd/file.tar.gz -F username=sunnyxd URL\n```\n\n### 设置cookie\n使用cookie (-b/--cookie)\n```\ncurl URL -b \"username=sunnyxd;password=12345\"\n```\n保存cookie (-c/--cookie-jar)\n```\ncurl -d \"username=sunnyxd&password=12345\" -c ./cookie.txt URL 操作结束后把cookie写入文件cookie.txt\n```\n### 抓取页面(下载)\n抓取页面保存到test.html：\n```\ncurl -o test.html URL\n或者curl URL > test.html\n```\n* -O 下载特定文件，url需要指定到一个具体的文件\n* -C - 断点续传，- 自动推断出正确的续传位置，或者直接指定相应的字节偏移\n* -f 显示抓取错误信息\n* -x ip:port 使用代理\n* -s 不显示进度信息\n* -e/--referer 伪造来源地址\n* --limit-rate 50k 限制下载速度\n* --max-filesize bytes 指定可下载的最大文件大小\n格式化显示响应信息\n* -w 一次完整且成功的操作后输出指定格式的内容到标准输出。\n\n### 查看接口响应时间\n```\ncurl -o /dev/null -s -w \"%{time_connect}:%{time_starttransfer}:%{time_total}\\n\" URL\n\n第一个字段，是从命令启动到链接上用的时间\n第二个字段，是开始传输数据所用的时间\n第三个字段，是完成传输所用的时间\n```\n\n### 查看页面是否可用\n```\ncurl -o /dev/null -s -w %{http_code} URL\n```\n监控接口可用性的一个简单demo：\n```\n#!/bin/bash\necho \"check result:\"\ncat monitor_url | while read line\ndo\nstatus_code=`curl -o /dev/null -s -w %{http_code} $line`\nif [ $status_code -eq 200 ]\nthen\necho ${line}\"is ok\"\nelse\necho ${line}\"is fail\"\nfi\ndone\ncurl -w详细介绍：http://www.letuknowit.com/post/17.html\n```\n\n### 设置浏览器代理 (-A/--user-agent)\n```\ncurl URL -A \"Mozilla/5.0\n```\n\n### 只打印响应头部信息\n通过-I或者--head可以只打印出HTTP头部信息：\n```\ncurl -I URL\n```\n### 用户认证(-u/--user)\n用于HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\n```\ncurl -u user:pwd URL\ncurl -u user URL\n```\n\n### 通用头部信息传递(-H/--header)\n```\ncurl -H \"Host:127.0.0.1\" -H \"accept-language:zh-cn\" URL\n```\n\n### 自动跳转到新网址\n有的网址是自动跳转的。使用-L参数，curl就会跳转到新的网址。\n```\ncurl -L URL\n```\n\n### 设置请求超时时间\n```\ncurl --connect-timeout seconds URL\n```\n \n### 设置最大传输时间(-m/--max-time)\n```\ncurl -m seconds URL\n```\n\n### 指定host请求\n```\ncurl -H \"Host:URL\" http://192.168.1.1\n```\n\n### 代理请求\n```\ncurl -x 192.168.1.1 URL\n```\n\n## 参考\n> * [http://man.linuxde.net/curl](http://man.linuxde.net/curl)\n> * [https://segmentfault.com/a/1190000005177475](https://segmentfault.com/a/1190000005177475)","source":"_posts/2018-08-21-article15-linux-curl.md","raw":"---\nlayout: post\ntitle:  \"curl常用命令\"\ndate:   2018-08-21 10:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux \nexcerpt: curl常用命令\nmathjax: true\n---\n\n* content\n{:toc}\n\n# curl常用命令\n\n## curl介绍\ncurl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\n\n## 语法\n```\ncurl(选项)(参数)\n```\n\n## 选项       \n* -a/--append\t                    上传文件时，附加到目标文件 \n* -A/--user-agent <string>\t        设置用户代理发送给服务器   \n* -anyauth\t                        可以使用“任何”身份验证方法 \n* -b/--cookie <name=string/file     cookie字符串或文件读取位置 \n*      --basic\t                    使用HTTP基本验证 \n* -B/--use-ascii\t                使用ASCII /文本传输 \n* -c/--cookie-jar <file>\t        操作结束后把cookie写入到这个文件中\n* -C/--continue-at <offset>\t        断点续转 \n*                                                              \n**-d/--data <data>\t                HTTP POST方式传送数据** \n*      --data-ascii <data>\t        以ascii的方式post数据 \n*      --data-binary <data>\t        以二进制的方式post数据\n*      --negotiate\t                使用HTTP身份验证 \n*      --digest\t                    使用数字身份验证 \n*      --disable-eprt\t            禁止使用EPRT或LPRT \n*      --disable-epsv\t            禁止使用EPSV \n* -D/--dump-header <file>\t        把header信息写入到该文件中 \n*      --egd-file <file>\t        为随机数据(SSL)设置EGD socket路径\n*      --tcp-nodelay\t            使用TCP_NODELAY选项 \n* -e/--referer\t                    来源网址 \n* -E/--cert <cert[:passwd]>\t        客户端证书文件和密码\n*      --cert-type <type>\t        证书文件类型\n*      --key <key>\t                私钥文件名\n*      --key-type <type>\t        私钥文件类型 \n*      --pass <pass>\t            私钥密码 \n*      --engine <eng>\t            加密引擎使用 \n*      --cacert <file>\t            CA证书 \n*      --capath <directory>\t        CA目录 \n*      --ciphers <list>\t            SSL密码 \n*      --compressed\t                要求返回是压缩的形势 \n*      --connect-timeout    \t    设置最大请求时间\n*      --create-dirs\t            建立本地目录的目录层次结构\n*      --crlf\t                    上传是把LF转变成CRLF \n* -f/--fail\t                        连接失败时不显示http错误 \n*      --ftp-create-dirs\t        如果远程目录不存在，创建远程目录 \n*      --ftp-method [multicwd/nocwd/singlecwd]\t 控制CWD的使用\n*      --ftp-pasv\t                使用 PASV/EPSV 代替端口 \n*      --ftp-skip-pasv-ip\t        使用PASV的时候,忽略该IP地址 \n*      --ftp-ssl\t                尝试用 SSL/TLS 来进行ftp数据传输 \n*      --ftp-ssl-reqd\t            要求用 SSL/TLS 来进行ftp数据传输 \n* -F/--form <name=content>\t        模拟http表单提交数据\n*      --form-string        \t    模拟http表单提交数据 \n* -g/--globoff\t                    禁用网址序列和范围使用{}和[]   \n*                                                              \n**-G/--get\t                        以get的方式来发送数据**\n*                                                              \n**-H/--header <line>\t            自定义头信息传递给服务器**\n*      --ignore-content-length\t    忽略的HTTP头信息的长度 \n* -i/--include\t                    输出时包括protocol头信息 \n*                                                              \n**-I/--head\t                        只显示请求头信息** \n* -j/--junk-session-cookies\t        读取文件进忽略session cookie \n*      --interface <interface>\t    使用指定网络接口/地址 \n*      --krb4 <level>\t            使用指定安全级别的krb4 \n* -k/--insecure\t                    允许不使用证书到SSL站点 \n* -K/--config\t                    指定的配置文件读取 \n* -l/--list-only\t                列出ftp目录下的文件名称 \n*                                                              \n**--limit-rate <rate>\t        设置传输速度** \n*      --local-port<NUM>\t        强制使用本地端口号 \n*                                                              \n**-m/--max-time <seconds>\t        设置最大传输时间** \n*      --max-redirs <num>\t        设置最大读取的目录数 \n*      --max-filesize <bytes>\t    设置最大下载的文件总量 \n* -M/--manual\t                    显示全手动 \n* -n/--netrc\t                    从netrc文件中读取用户名和密码 \n*      --netrc-optional\t            使用 .netrc 或者 URL来覆盖-n \n*      --ntlm\t                    使用 HTTP NTLM 身份验证 \n* -N/--no-buffer\t                禁用缓冲输出 \n* -o/--output\t                    把输出写到该文件中 \n* -O/--remote-name\t                把输出写到该文件中，保留远程文件的文件名 \n* -p/--proxytunnel\t                使用HTTP代理 \n*      --proxy-anyauth\t            选择任一代理身份验证方法 \n*      --proxy-basic\t            在代理上使用基本身份验证 \n*      --proxy-digest\t            在代理上使用数字身份验证 \n*      --proxy-ntlm\t                在代理上使用ntlm身份验证 \n* -P/--ftp-port <address>\t        使用端口地址，而不是使用PASV \n* -q\t                            作为第一个参数，关闭 .curlrc \n* -Q/--quote <cmd>\t                文件传输前，发送命令到服务器 \n* -r/--range <range>\t            检索来自HTTP/1.1或FTP服务器字节范围 \n* --range-file\t                    读取（SSL）的随机文件 \n* -R/--remote-time\t                在本地生成文件时，保留远程文件时间 \n*      --retry <num>\t            传输出现问题时，重试的次数 \n*      --retry-delay          \t    传输出现问题时，设置重试间隔时间 \n*      --retry-max-time             传输出现问题时，设置最大重试时间\n*                                                              \n**-s/--silent\t                    静默模式。不输出任何东西** \n* -S/--show-error\t                显示错误 \n*      --socks4 <host[:port]>\t    用socks4代理给定主机和端口 \n*      --socks5 <host[:port]>\t    用socks5代理给定主机和端口 \n*      --stderr <file>\t            \n* -t/--telnet-option <OPT=val>\t    Telnet选项设置 \n*      --trace <file>\t            对指定文件进行debug \n*      --trace-ascii <file>\tLike    跟踪但没有hex输出 \n*      --trace-time\t                跟踪/详细输出时，添加时间戳 \n* -T/--upload-file <file>\t        上传文件 \n*      --url <URL>\t                Spet URL to work with \n* -u/--user <user[:password]>\t    设置服务器的用户和密码 \n* -U/--proxy-user <user[:password]> 设置代理用户名和密码 \n* -w/--write-out [format]\t        什么输出完成后 \n*                              \n**-x/--proxy <host[:port]>\t        在给定的端口上使用HTTP代理** \n* -X/--request <command>\t        指定什么命令 \n* -y/--speed-time\t                放弃限速所要的时间，默认为30 \n* -Y/--speed-limit\t                停止传输速度的限制，速度时间 \n\n## 常用举例\n### GET请求(-G/--get/省略)\n```\ncurl http://www.xxxx.com/show?userId=111\n```\n\n### POST请求\n以application/x-www-url-encoded 方式发送数据(-d/--data)：\n```\ncurl -d \"username=sunnyxd&password=12345\" URL\n```\n以multipart/form-data 的方式发送数据(上传文件，-F/--form)：\n```\ncurl -F filename=@/home/sunnyxd/file.tar.gz -F username=sunnyxd URL\n```\n\n### 设置cookie\n使用cookie (-b/--cookie)\n```\ncurl URL -b \"username=sunnyxd;password=12345\"\n```\n保存cookie (-c/--cookie-jar)\n```\ncurl -d \"username=sunnyxd&password=12345\" -c ./cookie.txt URL 操作结束后把cookie写入文件cookie.txt\n```\n### 抓取页面(下载)\n抓取页面保存到test.html：\n```\ncurl -o test.html URL\n或者curl URL > test.html\n```\n* -O 下载特定文件，url需要指定到一个具体的文件\n* -C - 断点续传，- 自动推断出正确的续传位置，或者直接指定相应的字节偏移\n* -f 显示抓取错误信息\n* -x ip:port 使用代理\n* -s 不显示进度信息\n* -e/--referer 伪造来源地址\n* --limit-rate 50k 限制下载速度\n* --max-filesize bytes 指定可下载的最大文件大小\n格式化显示响应信息\n* -w 一次完整且成功的操作后输出指定格式的内容到标准输出。\n\n### 查看接口响应时间\n```\ncurl -o /dev/null -s -w \"%{time_connect}:%{time_starttransfer}:%{time_total}\\n\" URL\n\n第一个字段，是从命令启动到链接上用的时间\n第二个字段，是开始传输数据所用的时间\n第三个字段，是完成传输所用的时间\n```\n\n### 查看页面是否可用\n```\ncurl -o /dev/null -s -w %{http_code} URL\n```\n监控接口可用性的一个简单demo：\n```\n#!/bin/bash\necho \"check result:\"\ncat monitor_url | while read line\ndo\nstatus_code=`curl -o /dev/null -s -w %{http_code} $line`\nif [ $status_code -eq 200 ]\nthen\necho ${line}\"is ok\"\nelse\necho ${line}\"is fail\"\nfi\ndone\ncurl -w详细介绍：http://www.letuknowit.com/post/17.html\n```\n\n### 设置浏览器代理 (-A/--user-agent)\n```\ncurl URL -A \"Mozilla/5.0\n```\n\n### 只打印响应头部信息\n通过-I或者--head可以只打印出HTTP头部信息：\n```\ncurl -I URL\n```\n### 用户认证(-u/--user)\n用于HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\n```\ncurl -u user:pwd URL\ncurl -u user URL\n```\n\n### 通用头部信息传递(-H/--header)\n```\ncurl -H \"Host:127.0.0.1\" -H \"accept-language:zh-cn\" URL\n```\n\n### 自动跳转到新网址\n有的网址是自动跳转的。使用-L参数，curl就会跳转到新的网址。\n```\ncurl -L URL\n```\n\n### 设置请求超时时间\n```\ncurl --connect-timeout seconds URL\n```\n \n### 设置最大传输时间(-m/--max-time)\n```\ncurl -m seconds URL\n```\n\n### 指定host请求\n```\ncurl -H \"Host:URL\" http://192.168.1.1\n```\n\n### 代理请求\n```\ncurl -x 192.168.1.1 URL\n```\n\n## 参考\n> * [http://man.linuxde.net/curl](http://man.linuxde.net/curl)\n> * [https://segmentfault.com/a/1190000005177475](https://segmentfault.com/a/1190000005177475)","slug":"2018-08-21-article15-linux-curl","published":1,"updated":"2021-02-09T02:00:24.567Z","comments":1,"photos":[],"link":"","_id":"ckm1fhpzy000nyc970xljemh7","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"curl常用命令\"><a href=\"#curl常用命令\" class=\"headerlink\" title=\"curl常用命令\"></a>curl常用命令</h1><h2 id=\"curl介绍\"><a href=\"#curl介绍\" class=\"headerlink\" title=\"curl介绍\"></a>curl介绍</h2><p>curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。</p>\n<h2 id=\"语法\"><a href=\"#语法\" class=\"headerlink\" title=\"语法\"></a>语法</h2><pre><code>curl(选项)(参数)\n</code></pre>\n<h2 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h2><ul>\n<li>-a/–append                        上传文件时，附加到目标文件 </li>\n<li>-A/–user-agent <string>            设置用户代理发送给服务器   </li>\n<li>-anyauth                            可以使用“任何”身份验证方法 </li>\n<li>-b/–cookie &lt;name=string/file     cookie字符串或文件读取位置 </li>\n<li><pre><code> --basic                        使用HTTP基本验证 \n</code></pre>\n</li>\n<li>-B/–use-ascii                    使用ASCII /文本传输 </li>\n<li>-c/–cookie-jar <file>            操作结束后把cookie写入到这个文件中</li>\n<li>-C/–continue-at <offset>            断点续转 </li>\n<li></li>\n<li>*-d/–data <data>                    HTTP POST方式传送数据** </li>\n<li><pre><code> --data-ascii &lt;data&gt;            以ascii的方式post数据 \n</code></pre>\n</li>\n<li><pre><code> --data-binary &lt;data&gt;            以二进制的方式post数据\n</code></pre>\n</li>\n<li><pre><code> --negotiate                    使用HTTP身份验证 \n</code></pre>\n</li>\n<li><pre><code> --digest                        使用数字身份验证 \n</code></pre>\n</li>\n<li><pre><code> --disable-eprt                禁止使用EPRT或LPRT \n</code></pre>\n</li>\n<li><pre><code> --disable-epsv                禁止使用EPSV \n</code></pre>\n</li>\n<li>-D/–dump-header <file>            把header信息写入到该文件中 </li>\n<li><pre><code> --egd-file &lt;file&gt;            为随机数据(SSL)设置EGD socket路径\n</code></pre>\n</li>\n<li><pre><code> --tcp-nodelay                使用TCP_NODELAY选项 \n</code></pre>\n</li>\n<li>-e/–referer                        来源网址 </li>\n<li>-E/–cert &lt;cert[:passwd]&gt;            客户端证书文件和密码</li>\n<li><pre><code> --cert-type &lt;type&gt;            证书文件类型\n</code></pre>\n</li>\n<li><pre><code> --key &lt;key&gt;                    私钥文件名\n</code></pre>\n</li>\n<li><pre><code> --key-type &lt;type&gt;            私钥文件类型 \n</code></pre>\n</li>\n<li><pre><code> --pass &lt;pass&gt;                私钥密码 \n</code></pre>\n</li>\n<li><pre><code> --engine &lt;eng&gt;                加密引擎使用 \n</code></pre>\n</li>\n<li><pre><code> --cacert &lt;file&gt;                CA证书 \n</code></pre>\n</li>\n<li><pre><code> --capath &lt;directory&gt;            CA目录 \n</code></pre>\n</li>\n<li><pre><code> --ciphers &lt;list&gt;                SSL密码 \n</code></pre>\n</li>\n<li><pre><code> --compressed                    要求返回是压缩的形势 \n</code></pre>\n</li>\n<li><pre><code> --connect-timeout            设置最大请求时间\n</code></pre>\n</li>\n<li><pre><code> --create-dirs                建立本地目录的目录层次结构\n</code></pre>\n</li>\n<li><pre><code> --crlf                        上传是把LF转变成CRLF \n</code></pre>\n</li>\n<li>-f/–fail                            连接失败时不显示http错误 </li>\n<li><pre><code> --ftp-create-dirs            如果远程目录不存在，创建远程目录 \n</code></pre>\n</li>\n<li><pre><code> --ftp-method [multicwd/nocwd/singlecwd]     控制CWD的使用\n</code></pre>\n</li>\n<li><pre><code> --ftp-pasv                    使用 PASV/EPSV 代替端口 \n</code></pre>\n</li>\n<li><pre><code> --ftp-skip-pasv-ip            使用PASV的时候,忽略该IP地址 \n</code></pre>\n</li>\n<li><pre><code> --ftp-ssl                    尝试用 SSL/TLS 来进行ftp数据传输 \n</code></pre>\n</li>\n<li><pre><code> --ftp-ssl-reqd                要求用 SSL/TLS 来进行ftp数据传输 \n</code></pre>\n</li>\n<li>-F/–form &lt;name=content&gt;            模拟http表单提交数据</li>\n<li><pre><code> --form-string                模拟http表单提交数据 \n</code></pre>\n</li>\n<li>-g/–globoff                        禁用网址序列和范围使用{}和[]   </li>\n<li></li>\n<li>*-G/–get                            以get的方式来发送数据**</li>\n<li></li>\n<li>*-H/–header <line>                自定义头信息传递给服务器**</li>\n<li><pre><code> --ignore-content-length        忽略的HTTP头信息的长度 \n</code></pre>\n</li>\n<li>-i/–include                        输出时包括protocol头信息 </li>\n<li></li>\n<li>*-I/–head                            只显示请求头信息** </li>\n<li>-j/–junk-session-cookies            读取文件进忽略session cookie </li>\n<li><pre><code> --interface &lt;interface&gt;        使用指定网络接口/地址 \n</code></pre>\n</li>\n<li><pre><code> --krb4 &lt;level&gt;                使用指定安全级别的krb4 \n</code></pre>\n</li>\n<li>-k/–insecure                        允许不使用证书到SSL站点 </li>\n<li>-K/–config                        指定的配置文件读取 </li>\n<li>-l/–list-only                    列出ftp目录下的文件名称 </li>\n<li></li>\n<li>*–limit-rate <rate>            设置传输速度** </li>\n<li><pre><code> --local-port&lt;NUM&gt;            强制使用本地端口号 \n</code></pre>\n</li>\n<li></li>\n<li>*-m/–max-time <seconds>            设置最大传输时间** </li>\n<li><pre><code> --max-redirs &lt;num&gt;            设置最大读取的目录数 \n</code></pre>\n</li>\n<li><pre><code> --max-filesize &lt;bytes&gt;        设置最大下载的文件总量 \n</code></pre>\n</li>\n<li>-M/–manual                        显示全手动 </li>\n<li>-n/–netrc                        从netrc文件中读取用户名和密码 </li>\n<li><pre><code> --netrc-optional                使用 .netrc 或者 URL来覆盖-n \n</code></pre>\n</li>\n<li><pre><code> --ntlm                        使用 HTTP NTLM 身份验证 \n</code></pre>\n</li>\n<li>-N/–no-buffer                    禁用缓冲输出 </li>\n<li>-o/–output                        把输出写到该文件中 </li>\n<li>-O/–remote-name                    把输出写到该文件中，保留远程文件的文件名 </li>\n<li>-p/–proxytunnel                    使用HTTP代理 </li>\n<li><pre><code> --proxy-anyauth                选择任一代理身份验证方法 \n</code></pre>\n</li>\n<li><pre><code> --proxy-basic                在代理上使用基本身份验证 \n</code></pre>\n</li>\n<li><pre><code> --proxy-digest                在代理上使用数字身份验证 \n</code></pre>\n</li>\n<li><pre><code> --proxy-ntlm                    在代理上使用ntlm身份验证 \n</code></pre>\n</li>\n<li>-P/–ftp-port <address>            使用端口地址，而不是使用PASV </li>\n<li>-q                                作为第一个参数，关闭 .curlrc </li>\n<li>-Q/–quote <cmd>                    文件传输前，发送命令到服务器 </li>\n<li>-r/–range <range>                检索来自HTTP/1.1或FTP服务器字节范围 </li>\n<li>–range-file                        读取（SSL）的随机文件 </li>\n<li>-R/–remote-time                    在本地生成文件时，保留远程文件时间 </li>\n<li><pre><code> --retry &lt;num&gt;                传输出现问题时，重试的次数 \n</code></pre>\n</li>\n<li><pre><code> --retry-delay                  传输出现问题时，设置重试间隔时间 \n</code></pre>\n</li>\n<li><pre><code> --retry-max-time             传输出现问题时，设置最大重试时间\n</code></pre>\n</li>\n<li></li>\n<li>*-s/–silent                        静默模式。不输出任何东西** </li>\n<li>-S/–show-error                    显示错误 </li>\n<li><pre><code> --socks4 &lt;host[:port]&gt;        用socks4代理给定主机和端口 \n</code></pre>\n</li>\n<li><pre><code> --socks5 &lt;host[:port]&gt;        用socks5代理给定主机和端口 \n</code></pre>\n</li>\n<li><pre><code> --stderr &lt;file&gt;                \n</code></pre>\n</li>\n<li>-t/–telnet-option &lt;OPT=val&gt;        Telnet选项设置 </li>\n<li><pre><code> --trace &lt;file&gt;                对指定文件进行debug \n</code></pre>\n</li>\n<li><pre><code> --trace-ascii &lt;file&gt;    Like    跟踪但没有hex输出 \n</code></pre>\n</li>\n<li><pre><code> --trace-time                    跟踪/详细输出时，添加时间戳 \n</code></pre>\n</li>\n<li>-T/–upload-file <file>            上传文件 </li>\n<li><pre><code> --url &lt;URL&gt;                    Spet URL to work with \n</code></pre>\n</li>\n<li>-u/–user &lt;user[:password]&gt;        设置服务器的用户和密码 </li>\n<li>-U/–proxy-user &lt;user[:password]&gt; 设置代理用户名和密码 </li>\n<li>-w/–write-out [format]            什么输出完成后 </li>\n<li></li>\n<li>*-x/–proxy &lt;host[:port]&gt;            在给定的端口上使用HTTP代理** </li>\n<li>-X/–request <command>            指定什么命令 </li>\n<li>-y/–speed-time                    放弃限速所要的时间，默认为30 </li>\n<li>-Y/–speed-limit                    停止传输速度的限制，速度时间 </li>\n</ul>\n<h2 id=\"常用举例\"><a href=\"#常用举例\" class=\"headerlink\" title=\"常用举例\"></a>常用举例</h2><h3 id=\"GET请求-G-–get-省略\"><a href=\"#GET请求-G-–get-省略\" class=\"headerlink\" title=\"GET请求(-G/–get/省略)\"></a>GET请求(-G/–get/省略)</h3><pre><code>curl http://www.xxxx.com/show?userId=111\n</code></pre>\n<h3 id=\"POST请求\"><a href=\"#POST请求\" class=\"headerlink\" title=\"POST请求\"></a>POST请求</h3><p>以application/x-www-url-encoded 方式发送数据(-d/–data)：</p>\n<pre><code>curl -d &quot;username=sunnyxd&amp;password=12345&quot; URL\n</code></pre>\n<p>以multipart/form-data 的方式发送数据(上传文件，-F/–form)：</p>\n<pre><code>curl -F filename=@/home/sunnyxd/file.tar.gz -F username=sunnyxd URL\n</code></pre>\n<h3 id=\"设置cookie\"><a href=\"#设置cookie\" class=\"headerlink\" title=\"设置cookie\"></a>设置cookie</h3><p>使用cookie (-b/–cookie)</p>\n<pre><code>curl URL -b &quot;username=sunnyxd;password=12345&quot;\n</code></pre>\n<p>保存cookie (-c/–cookie-jar)</p>\n<pre><code>curl -d &quot;username=sunnyxd&amp;password=12345&quot; -c ./cookie.txt URL 操作结束后把cookie写入文件cookie.txt\n</code></pre>\n<h3 id=\"抓取页面-下载\"><a href=\"#抓取页面-下载\" class=\"headerlink\" title=\"抓取页面(下载)\"></a>抓取页面(下载)</h3><p>抓取页面保存到test.html：</p>\n<pre><code>curl -o test.html URL\n或者curl URL &gt; test.html\n</code></pre>\n<ul>\n<li>-O 下载特定文件，url需要指定到一个具体的文件</li>\n<li>-C - 断点续传，- 自动推断出正确的续传位置，或者直接指定相应的字节偏移</li>\n<li>-f 显示抓取错误信息</li>\n<li>-x ip:port 使用代理</li>\n<li>-s 不显示进度信息</li>\n<li>-e/–referer 伪造来源地址</li>\n<li>–limit-rate 50k 限制下载速度</li>\n<li>–max-filesize bytes 指定可下载的最大文件大小<br>格式化显示响应信息</li>\n<li>-w 一次完整且成功的操作后输出指定格式的内容到标准输出。</li>\n</ul>\n<h3 id=\"查看接口响应时间\"><a href=\"#查看接口响应时间\" class=\"headerlink\" title=\"查看接口响应时间\"></a>查看接口响应时间</h3><pre><code>curl -o /dev/null -s -w &quot;%&#123;time_connect&#125;:%&#123;time_starttransfer&#125;:%&#123;time_total&#125;\\n&quot; URL\n\n第一个字段，是从命令启动到链接上用的时间\n第二个字段，是开始传输数据所用的时间\n第三个字段，是完成传输所用的时间\n</code></pre>\n<h3 id=\"查看页面是否可用\"><a href=\"#查看页面是否可用\" class=\"headerlink\" title=\"查看页面是否可用\"></a>查看页面是否可用</h3><pre><code>curl -o /dev/null -s -w %&#123;http_code&#125; URL\n</code></pre>\n<p>监控接口可用性的一个简单demo：</p>\n<pre><code>#!/bin/bash\necho &quot;check result:&quot;\ncat monitor_url | while read line\ndo\nstatus_code=`curl -o /dev/null -s -w %&#123;http_code&#125; $line`\nif [ $status_code -eq 200 ]\nthen\necho $&#123;line&#125;&quot;is ok&quot;\nelse\necho $&#123;line&#125;&quot;is fail&quot;\nfi\ndone\ncurl -w详细介绍：http://www.letuknowit.com/post/17.html\n</code></pre>\n<h3 id=\"设置浏览器代理-A-–user-agent\"><a href=\"#设置浏览器代理-A-–user-agent\" class=\"headerlink\" title=\"设置浏览器代理 (-A/–user-agent)\"></a>设置浏览器代理 (-A/–user-agent)</h3><pre><code>curl URL -A &quot;Mozilla/5.0\n</code></pre>\n<h3 id=\"只打印响应头部信息\"><a href=\"#只打印响应头部信息\" class=\"headerlink\" title=\"只打印响应头部信息\"></a>只打印响应头部信息</h3><p>通过-I或者–head可以只打印出HTTP头部信息：</p>\n<pre><code>curl -I URL\n</code></pre>\n<h3 id=\"用户认证-u-–user\"><a href=\"#用户认证-u-–user\" class=\"headerlink\" title=\"用户认证(-u/–user)\"></a>用户认证(-u/–user)</h3><p>用于HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：</p>\n<pre><code>curl -u user:pwd URL\ncurl -u user URL\n</code></pre>\n<h3 id=\"通用头部信息传递-H-–header\"><a href=\"#通用头部信息传递-H-–header\" class=\"headerlink\" title=\"通用头部信息传递(-H/–header)\"></a>通用头部信息传递(-H/–header)</h3><pre><code>curl -H &quot;Host:127.0.0.1&quot; -H &quot;accept-language:zh-cn&quot; URL\n</code></pre>\n<h3 id=\"自动跳转到新网址\"><a href=\"#自动跳转到新网址\" class=\"headerlink\" title=\"自动跳转到新网址\"></a>自动跳转到新网址</h3><p>有的网址是自动跳转的。使用-L参数，curl就会跳转到新的网址。</p>\n<pre><code>curl -L URL\n</code></pre>\n<h3 id=\"设置请求超时时间\"><a href=\"#设置请求超时时间\" class=\"headerlink\" title=\"设置请求超时时间\"></a>设置请求超时时间</h3><pre><code>curl --connect-timeout seconds URL\n</code></pre>\n<h3 id=\"设置最大传输时间-m-–max-time\"><a href=\"#设置最大传输时间-m-–max-time\" class=\"headerlink\" title=\"设置最大传输时间(-m/–max-time)\"></a>设置最大传输时间(-m/–max-time)</h3><pre><code>curl -m seconds URL\n</code></pre>\n<h3 id=\"指定host请求\"><a href=\"#指定host请求\" class=\"headerlink\" title=\"指定host请求\"></a>指定host请求</h3><pre><code>curl -H &quot;Host:URL&quot; http://192.168.1.1\n</code></pre>\n<h3 id=\"代理请求\"><a href=\"#代理请求\" class=\"headerlink\" title=\"代理请求\"></a>代理请求</h3><pre><code>curl -x 192.168.1.1 URL\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"http://man.linuxde.net/curl\">http://man.linuxde.net/curl</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000005177475\">https://segmentfault.com/a/1190000005177475</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"curl常用命令\"><a href=\"#curl常用命令\" class=\"headerlink\" title=\"curl常用命令\"></a>curl常用命令</h1><h2 id=\"curl介绍\"><a href=\"#curl介绍\" class=\"headerlink\" title=\"curl介绍\"></a>curl介绍</h2><p>curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。</p>\n<h2 id=\"语法\"><a href=\"#语法\" class=\"headerlink\" title=\"语法\"></a>语法</h2><pre><code>curl(选项)(参数)\n</code></pre>\n<h2 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h2><ul>\n<li>-a/–append                        上传文件时，附加到目标文件 </li>\n<li>-A/–user-agent <string>            设置用户代理发送给服务器   </li>\n<li>-anyauth                            可以使用“任何”身份验证方法 </li>\n<li>-b/–cookie &lt;name=string/file     cookie字符串或文件读取位置 </li>\n<li><pre><code> --basic                        使用HTTP基本验证 \n</code></pre>\n</li>\n<li>-B/–use-ascii                    使用ASCII /文本传输 </li>\n<li>-c/–cookie-jar <file>            操作结束后把cookie写入到这个文件中</li>\n<li>-C/–continue-at <offset>            断点续转 </li>\n<li></li>\n<li>*-d/–data <data>                    HTTP POST方式传送数据** </li>\n<li><pre><code> --data-ascii &lt;data&gt;            以ascii的方式post数据 \n</code></pre>\n</li>\n<li><pre><code> --data-binary &lt;data&gt;            以二进制的方式post数据\n</code></pre>\n</li>\n<li><pre><code> --negotiate                    使用HTTP身份验证 \n</code></pre>\n</li>\n<li><pre><code> --digest                        使用数字身份验证 \n</code></pre>\n</li>\n<li><pre><code> --disable-eprt                禁止使用EPRT或LPRT \n</code></pre>\n</li>\n<li><pre><code> --disable-epsv                禁止使用EPSV \n</code></pre>\n</li>\n<li>-D/–dump-header <file>            把header信息写入到该文件中 </li>\n<li><pre><code> --egd-file &lt;file&gt;            为随机数据(SSL)设置EGD socket路径\n</code></pre>\n</li>\n<li><pre><code> --tcp-nodelay                使用TCP_NODELAY选项 \n</code></pre>\n</li>\n<li>-e/–referer                        来源网址 </li>\n<li>-E/–cert &lt;cert[:passwd]&gt;            客户端证书文件和密码</li>\n<li><pre><code> --cert-type &lt;type&gt;            证书文件类型\n</code></pre>\n</li>\n<li><pre><code> --key &lt;key&gt;                    私钥文件名\n</code></pre>\n</li>\n<li><pre><code> --key-type &lt;type&gt;            私钥文件类型 \n</code></pre>\n</li>\n<li><pre><code> --pass &lt;pass&gt;                私钥密码 \n</code></pre>\n</li>\n<li><pre><code> --engine &lt;eng&gt;                加密引擎使用 \n</code></pre>\n</li>\n<li><pre><code> --cacert &lt;file&gt;                CA证书 \n</code></pre>\n</li>\n<li><pre><code> --capath &lt;directory&gt;            CA目录 \n</code></pre>\n</li>\n<li><pre><code> --ciphers &lt;list&gt;                SSL密码 \n</code></pre>\n</li>\n<li><pre><code> --compressed                    要求返回是压缩的形势 \n</code></pre>\n</li>\n<li><pre><code> --connect-timeout            设置最大请求时间\n</code></pre>\n</li>\n<li><pre><code> --create-dirs                建立本地目录的目录层次结构\n</code></pre>\n</li>\n<li><pre><code> --crlf                        上传是把LF转变成CRLF \n</code></pre>\n</li>\n<li>-f/–fail                            连接失败时不显示http错误 </li>\n<li><pre><code> --ftp-create-dirs            如果远程目录不存在，创建远程目录 \n</code></pre>\n</li>\n<li><pre><code> --ftp-method [multicwd/nocwd/singlecwd]     控制CWD的使用\n</code></pre>\n</li>\n<li><pre><code> --ftp-pasv                    使用 PASV/EPSV 代替端口 \n</code></pre>\n</li>\n<li><pre><code> --ftp-skip-pasv-ip            使用PASV的时候,忽略该IP地址 \n</code></pre>\n</li>\n<li><pre><code> --ftp-ssl                    尝试用 SSL/TLS 来进行ftp数据传输 \n</code></pre>\n</li>\n<li><pre><code> --ftp-ssl-reqd                要求用 SSL/TLS 来进行ftp数据传输 \n</code></pre>\n</li>\n<li>-F/–form &lt;name=content&gt;            模拟http表单提交数据</li>\n<li><pre><code> --form-string                模拟http表单提交数据 \n</code></pre>\n</li>\n<li>-g/–globoff                        禁用网址序列和范围使用{}和[]   </li>\n<li></li>\n<li>*-G/–get                            以get的方式来发送数据**</li>\n<li></li>\n<li>*-H/–header <line>                自定义头信息传递给服务器**</li>\n<li><pre><code> --ignore-content-length        忽略的HTTP头信息的长度 \n</code></pre>\n</li>\n<li>-i/–include                        输出时包括protocol头信息 </li>\n<li></li>\n<li>*-I/–head                            只显示请求头信息** </li>\n<li>-j/–junk-session-cookies            读取文件进忽略session cookie </li>\n<li><pre><code> --interface &lt;interface&gt;        使用指定网络接口/地址 \n</code></pre>\n</li>\n<li><pre><code> --krb4 &lt;level&gt;                使用指定安全级别的krb4 \n</code></pre>\n</li>\n<li>-k/–insecure                        允许不使用证书到SSL站点 </li>\n<li>-K/–config                        指定的配置文件读取 </li>\n<li>-l/–list-only                    列出ftp目录下的文件名称 </li>\n<li></li>\n<li>*–limit-rate <rate>            设置传输速度** </li>\n<li><pre><code> --local-port&lt;NUM&gt;            强制使用本地端口号 \n</code></pre>\n</li>\n<li></li>\n<li>*-m/–max-time <seconds>            设置最大传输时间** </li>\n<li><pre><code> --max-redirs &lt;num&gt;            设置最大读取的目录数 \n</code></pre>\n</li>\n<li><pre><code> --max-filesize &lt;bytes&gt;        设置最大下载的文件总量 \n</code></pre>\n</li>\n<li>-M/–manual                        显示全手动 </li>\n<li>-n/–netrc                        从netrc文件中读取用户名和密码 </li>\n<li><pre><code> --netrc-optional                使用 .netrc 或者 URL来覆盖-n \n</code></pre>\n</li>\n<li><pre><code> --ntlm                        使用 HTTP NTLM 身份验证 \n</code></pre>\n</li>\n<li>-N/–no-buffer                    禁用缓冲输出 </li>\n<li>-o/–output                        把输出写到该文件中 </li>\n<li>-O/–remote-name                    把输出写到该文件中，保留远程文件的文件名 </li>\n<li>-p/–proxytunnel                    使用HTTP代理 </li>\n<li><pre><code> --proxy-anyauth                选择任一代理身份验证方法 \n</code></pre>\n</li>\n<li><pre><code> --proxy-basic                在代理上使用基本身份验证 \n</code></pre>\n</li>\n<li><pre><code> --proxy-digest                在代理上使用数字身份验证 \n</code></pre>\n</li>\n<li><pre><code> --proxy-ntlm                    在代理上使用ntlm身份验证 \n</code></pre>\n</li>\n<li>-P/–ftp-port <address>            使用端口地址，而不是使用PASV </li>\n<li>-q                                作为第一个参数，关闭 .curlrc </li>\n<li>-Q/–quote <cmd>                    文件传输前，发送命令到服务器 </li>\n<li>-r/–range <range>                检索来自HTTP/1.1或FTP服务器字节范围 </li>\n<li>–range-file                        读取（SSL）的随机文件 </li>\n<li>-R/–remote-time                    在本地生成文件时，保留远程文件时间 </li>\n<li><pre><code> --retry &lt;num&gt;                传输出现问题时，重试的次数 \n</code></pre>\n</li>\n<li><pre><code> --retry-delay                  传输出现问题时，设置重试间隔时间 \n</code></pre>\n</li>\n<li><pre><code> --retry-max-time             传输出现问题时，设置最大重试时间\n</code></pre>\n</li>\n<li></li>\n<li>*-s/–silent                        静默模式。不输出任何东西** </li>\n<li>-S/–show-error                    显示错误 </li>\n<li><pre><code> --socks4 &lt;host[:port]&gt;        用socks4代理给定主机和端口 \n</code></pre>\n</li>\n<li><pre><code> --socks5 &lt;host[:port]&gt;        用socks5代理给定主机和端口 \n</code></pre>\n</li>\n<li><pre><code> --stderr &lt;file&gt;                \n</code></pre>\n</li>\n<li>-t/–telnet-option &lt;OPT=val&gt;        Telnet选项设置 </li>\n<li><pre><code> --trace &lt;file&gt;                对指定文件进行debug \n</code></pre>\n</li>\n<li><pre><code> --trace-ascii &lt;file&gt;    Like    跟踪但没有hex输出 \n</code></pre>\n</li>\n<li><pre><code> --trace-time                    跟踪/详细输出时，添加时间戳 \n</code></pre>\n</li>\n<li>-T/–upload-file <file>            上传文件 </li>\n<li><pre><code> --url &lt;URL&gt;                    Spet URL to work with \n</code></pre>\n</li>\n<li>-u/–user &lt;user[:password]&gt;        设置服务器的用户和密码 </li>\n<li>-U/–proxy-user &lt;user[:password]&gt; 设置代理用户名和密码 </li>\n<li>-w/–write-out [format]            什么输出完成后 </li>\n<li></li>\n<li>*-x/–proxy &lt;host[:port]&gt;            在给定的端口上使用HTTP代理** </li>\n<li>-X/–request <command>            指定什么命令 </li>\n<li>-y/–speed-time                    放弃限速所要的时间，默认为30 </li>\n<li>-Y/–speed-limit                    停止传输速度的限制，速度时间 </li>\n</ul>\n<h2 id=\"常用举例\"><a href=\"#常用举例\" class=\"headerlink\" title=\"常用举例\"></a>常用举例</h2><h3 id=\"GET请求-G-–get-省略\"><a href=\"#GET请求-G-–get-省略\" class=\"headerlink\" title=\"GET请求(-G/–get/省略)\"></a>GET请求(-G/–get/省略)</h3><pre><code>curl http://www.xxxx.com/show?userId=111\n</code></pre>\n<h3 id=\"POST请求\"><a href=\"#POST请求\" class=\"headerlink\" title=\"POST请求\"></a>POST请求</h3><p>以application/x-www-url-encoded 方式发送数据(-d/–data)：</p>\n<pre><code>curl -d &quot;username=sunnyxd&amp;password=12345&quot; URL\n</code></pre>\n<p>以multipart/form-data 的方式发送数据(上传文件，-F/–form)：</p>\n<pre><code>curl -F filename=@/home/sunnyxd/file.tar.gz -F username=sunnyxd URL\n</code></pre>\n<h3 id=\"设置cookie\"><a href=\"#设置cookie\" class=\"headerlink\" title=\"设置cookie\"></a>设置cookie</h3><p>使用cookie (-b/–cookie)</p>\n<pre><code>curl URL -b &quot;username=sunnyxd;password=12345&quot;\n</code></pre>\n<p>保存cookie (-c/–cookie-jar)</p>\n<pre><code>curl -d &quot;username=sunnyxd&amp;password=12345&quot; -c ./cookie.txt URL 操作结束后把cookie写入文件cookie.txt\n</code></pre>\n<h3 id=\"抓取页面-下载\"><a href=\"#抓取页面-下载\" class=\"headerlink\" title=\"抓取页面(下载)\"></a>抓取页面(下载)</h3><p>抓取页面保存到test.html：</p>\n<pre><code>curl -o test.html URL\n或者curl URL &gt; test.html\n</code></pre>\n<ul>\n<li>-O 下载特定文件，url需要指定到一个具体的文件</li>\n<li>-C - 断点续传，- 自动推断出正确的续传位置，或者直接指定相应的字节偏移</li>\n<li>-f 显示抓取错误信息</li>\n<li>-x ip:port 使用代理</li>\n<li>-s 不显示进度信息</li>\n<li>-e/–referer 伪造来源地址</li>\n<li>–limit-rate 50k 限制下载速度</li>\n<li>–max-filesize bytes 指定可下载的最大文件大小<br>格式化显示响应信息</li>\n<li>-w 一次完整且成功的操作后输出指定格式的内容到标准输出。</li>\n</ul>\n<h3 id=\"查看接口响应时间\"><a href=\"#查看接口响应时间\" class=\"headerlink\" title=\"查看接口响应时间\"></a>查看接口响应时间</h3><pre><code>curl -o /dev/null -s -w &quot;%&#123;time_connect&#125;:%&#123;time_starttransfer&#125;:%&#123;time_total&#125;\\n&quot; URL\n\n第一个字段，是从命令启动到链接上用的时间\n第二个字段，是开始传输数据所用的时间\n第三个字段，是完成传输所用的时间\n</code></pre>\n<h3 id=\"查看页面是否可用\"><a href=\"#查看页面是否可用\" class=\"headerlink\" title=\"查看页面是否可用\"></a>查看页面是否可用</h3><pre><code>curl -o /dev/null -s -w %&#123;http_code&#125; URL\n</code></pre>\n<p>监控接口可用性的一个简单demo：</p>\n<pre><code>#!/bin/bash\necho &quot;check result:&quot;\ncat monitor_url | while read line\ndo\nstatus_code=`curl -o /dev/null -s -w %&#123;http_code&#125; $line`\nif [ $status_code -eq 200 ]\nthen\necho $&#123;line&#125;&quot;is ok&quot;\nelse\necho $&#123;line&#125;&quot;is fail&quot;\nfi\ndone\ncurl -w详细介绍：http://www.letuknowit.com/post/17.html\n</code></pre>\n<h3 id=\"设置浏览器代理-A-–user-agent\"><a href=\"#设置浏览器代理-A-–user-agent\" class=\"headerlink\" title=\"设置浏览器代理 (-A/–user-agent)\"></a>设置浏览器代理 (-A/–user-agent)</h3><pre><code>curl URL -A &quot;Mozilla/5.0\n</code></pre>\n<h3 id=\"只打印响应头部信息\"><a href=\"#只打印响应头部信息\" class=\"headerlink\" title=\"只打印响应头部信息\"></a>只打印响应头部信息</h3><p>通过-I或者–head可以只打印出HTTP头部信息：</p>\n<pre><code>curl -I URL\n</code></pre>\n<h3 id=\"用户认证-u-–user\"><a href=\"#用户认证-u-–user\" class=\"headerlink\" title=\"用户认证(-u/–user)\"></a>用户认证(-u/–user)</h3><p>用于HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：</p>\n<pre><code>curl -u user:pwd URL\ncurl -u user URL\n</code></pre>\n<h3 id=\"通用头部信息传递-H-–header\"><a href=\"#通用头部信息传递-H-–header\" class=\"headerlink\" title=\"通用头部信息传递(-H/–header)\"></a>通用头部信息传递(-H/–header)</h3><pre><code>curl -H &quot;Host:127.0.0.1&quot; -H &quot;accept-language:zh-cn&quot; URL\n</code></pre>\n<h3 id=\"自动跳转到新网址\"><a href=\"#自动跳转到新网址\" class=\"headerlink\" title=\"自动跳转到新网址\"></a>自动跳转到新网址</h3><p>有的网址是自动跳转的。使用-L参数，curl就会跳转到新的网址。</p>\n<pre><code>curl -L URL\n</code></pre>\n<h3 id=\"设置请求超时时间\"><a href=\"#设置请求超时时间\" class=\"headerlink\" title=\"设置请求超时时间\"></a>设置请求超时时间</h3><pre><code>curl --connect-timeout seconds URL\n</code></pre>\n<h3 id=\"设置最大传输时间-m-–max-time\"><a href=\"#设置最大传输时间-m-–max-time\" class=\"headerlink\" title=\"设置最大传输时间(-m/–max-time)\"></a>设置最大传输时间(-m/–max-time)</h3><pre><code>curl -m seconds URL\n</code></pre>\n<h3 id=\"指定host请求\"><a href=\"#指定host请求\" class=\"headerlink\" title=\"指定host请求\"></a>指定host请求</h3><pre><code>curl -H &quot;Host:URL&quot; http://192.168.1.1\n</code></pre>\n<h3 id=\"代理请求\"><a href=\"#代理请求\" class=\"headerlink\" title=\"代理请求\"></a>代理请求</h3><pre><code>curl -x 192.168.1.1 URL\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"http://man.linuxde.net/curl\">http://man.linuxde.net/curl</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000005177475\">https://segmentfault.com/a/1190000005177475</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"ELK(6.x版本)日志分析平台+Granfan可视化","date":"2018-08-22T10:41:54.000Z","author":"owelinux","excerpt":"ELK日志分析平台+Granfan可视化","mathjax":true,"_content":"\n* content\n{:toc}\n\n# ELK(6.x版本)日志分析平台+Granfan可视化\n\n## 系统环境准备\n```\n# 系统版本及内核信息\n[root@test03 config]# uname  -a\nLinux test03 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n# 配置java1.8版本\n[root@test03 local]# wget jdk-8u171-linux-x64.tar.gz\n[root@test03 local]# tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/\n\necho \"JAVA_HOME=/usr/local/jdk1.8.0_171 >> /etc/profile\necho \"CLASSPATH=.:\\$JAVA_HOME/lib/tools.jar:\\$JAVA_HOME/lib/dt.jar\" >> /etc/profile \necho \"PATH=\\$JAVA_HOME/bin:\\$PATH\" >> /etc/profile \nsource /etc/profile\n```\n\n## 采集方案（本教程采用第三种方案）\n\n### 方案一 \nlog_files -> filebeat  -->  logstash -> - elasticsearch -> kibana\n\n### 方案二\nlog_files ->  filebeat -> logstash  -->  redis -> - logstash -> - elasticsearch -> kibana\n\n### 方案三\nlog_files ->  filebeat -> elasticsearch-> kibana\n\n## 配置nginx日志格式log_format\n```\n        log_format  main  '$host $remote_addr - $remote_user [$time_local] \"$request\" '\n                '$status $body_bytes_sent $upstream_response_time \"$http_referer\" '\n                '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$uid_got\" \"$uid_set\" \"$http_x_tencent_ua\" \"$upstream_addr\" \"$upstream_http_x_cached_from\" \"$upstream_http_cache_control\"';\n```\n\n## 配置filebeat（根据官网改造支持nginx日志格式）\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz\n```\n配置filebeat：\n```\n[root@WEB3 include]# cat /etc/filebeat/config.yml  | grep -Ev  '#|^$'\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/nginx/*access.log\n  grok_pattern: '%{USERNAME:domain} %{IPV4:client_ip} (.*) \\[%{HTTPDATE:timestamp}\\] (.*) %{URIPATH:path}(.*)\\\" (?:%{INT:response_status}|-) (?:%{INT:response_bytes}|-) (?:%{NUMBER:response_time}|-)'\n  ignore_older: 1h\nname: 192.168.1.1\noutput.elasticsearch:\n  enabled: true\n  hosts: [\"192.168.1.1:9200\"]\n  index: \"beijing-web-%{+yyyy.MM.dd}\"\n  template.enabled: false\n  template.versions.2x.enabled: false\n  template.versions.6x.enabled: false\noutput.file:\n  enabled: true\n  path: /tmp/filebeat\npath.config: /etc/filebeat\npath.data: /tmp/filebeat/data\npath.logs: /var/log\nlogging.to_files: true\nlogging.files:\n  path: /var/log\n  name: filebeat\n```\n\n## 配置logstash\n\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf logstash-6.3.2.tar.gz\n```\n\n几种插件的使用：\n### 1、grok插件\n\n作用:解析message信息或其他操作\n\n* logstash的grok：    [https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html](https://www.elastic.co/guide/enlogstash/current/plugins-filters-grok.html)\n\n* grok正则测试：[http://grokdebug.herokuapp.com](http://grokdebug.herokuapp.com)\n\n#### nginx日志的正则匹配\n```\nmatch => { \n          \"message\" => \"(?<domain>%{IP:ip}|(?:%{NOTSPACE:subsite}\\.)?(?<site>[-a-zA-Z0-9]+?).com|%{NOTSPACE:unknown}) %{IPORHOST:dayuip} - (?<user>[a-zA-Z\\.\\@\\-\\+_%]+) \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:verb} (?<request_path>(?<biz>\\/[^/?]*)%{URIPATH:}?)(?:%{URIPARAM:request_param})? HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:%{BASE10NUM:request_duration}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\\"(?:%{IPORHOST:clientip}(?:[^\\\"]*)|-)\\\" %{QS:uidgot} %{QS:uidset} \\\"(?:[^\\\" ]* )*(?<upstream>[^ \\\"]*|-)\\\"\"\n      }\n```\n \n\n#### Java的正则匹配\n```\nmatch => {\n      \"message\" => \"\\[entry\\]\\[ts\\](?<ts>.*)\\[/ts\\]\\[lv\\](?<lv>.*)\\[/lv\\]\\[th\\](?<th>.*)\\[/th\\]\\[lg\\](?<lg>.*)\\[/lg\\]\\[cl\\](?<cl>.*)\\[/cl\\]\\[m\\](?<m>.*)\\[/m\\]\\[ln\\](?<ln>.*)\\[/ln\\]\\[bsid\\](?<bsid>.*)\\[/bsid\\]\\[esid\\](?<esid>.*)\\[/esid\\](\\[cmid\\](?<cmid>.*)\\[/cmid\\])?\\[txt\\](?<txt>.*)\\[/txt\\]\\[ex\\](?<ex>.*)\\[/ex\\]\\[/entry\\]\"\n}\n```\n \n\n#### PHP的正则匹配\n```\nmatch => {\n        \"message\" => \"\\[entry\\]\\[ts\\](?<ts>.*)\\[/ts\\]\\[lv\\](?<lv>.*)\\[/lv\\]\\[th\\](?<th>.*)\\[/th\\]\\[lg\\](?<lg>.*)\\[/lg\\]\\[cl\\](?<cl>.*)\\[/cl\\]\\[m\\](?<m>.*)\\[/m\\]\\[ln\\](?<ln>.*)\\[/ln\\]\\[bsid\\](?<bsid>.*)\\[/bsid\\]\\[esid\\](?<esid>.*)\\[/esid\\]\\[txt\\](?<txt>.*)\\[/txt\\]\\[proj\\](?<proj>.*)\\[/proj\\]\\[iid\\](?<iid>.*)\\[/iid\\]\\[file\\](?<file>.*)\\[/file\\]\\[ex\\](?<ex>.*)\\[/ex\\]\\[type\\](?<logtype>.*)\\[/type\\]\\[/entry\\]\"\n}\n```\n \n### 2、date 插件\n\n作用：将解析到的时间作为展示在kibana的time\n\n```   \nfilter {\n        date {\n               match => [ \"logdate\", \"MMM dd yyyy HH:mm:ss\" ]\n             }\n      }\n```\n\n### logstash配置优化\n```\ninput {\n    beats {\n        port => \"5043\"\n    }\n}\nfilter {\n    grok {\n        match => { \"message\" => \"^(?<domain>%{IP:ip}|(?:%{NOTSPACE:subsite}\\.)?(?<site>[-a-zA-Z0-9]+?).com|%{NOTSPACE:unknown}) %{IPORHOST:dayuip} - (?<user>[a-zA-Z\\.\\@\\-\\+_%]+) \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:verb} (?<request_path>(?<biz>\\/[^/?]*)%{URIPATH:}?)(?:%{URIPARAM:request_param})? HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:%{BASE10NUM:request_duration}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\\"(?:%{IPORHOST:clientip}(?:[^\\\"]*)|-)\\\" %{QS:uidgot} %{QS:uidset} %{QS:tencentua} \\\"(?:[^\\\" ]* )*(?<upstream>[^ \\\"]*|-)\\\" %{QS:cachedfrom} %{QS:cachectrl}\"}\n    }\n\n   date {\n      # Try to pull the timestamp from the 'timestamp' field (parsed above with\n      # grok). The apache time format looks like: \"18/Aug/2011:05:44:34 -0700\"\n      locale => \"en\"\n      timezone => \"Asia/Shanghai\"\n      match => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n      add_tag => [ \"tsmatch\" ]\n    }\n\n    if [ip] {\n         mutate { add_field => { \"site\" => \"unknown\" \"subsite\" => \"ip\" } }    \n    } else if [unknown] {\n         mutate { add_field => { \"site\" => \"unknown\" \"subsite\" => \"unknown\" } }    \n    } else if ! [subsite] {\n         mutate { add_field => { \"subsite\" => \"-\" } }    \n    }\n\n    if ![site] {\n         mutate { add_field => { \"site\" => \"unknown\" } }    \n    }\n\n\n    mutate {\n        convert => { \"bytes\" => \"integer\" \"request_duration\" => \"float\"}\n    }\n\n    if [request_path] =~ \"\\/count\\/a682ab23d4b4c95f84c744b2826419cd\" {\n        mutate { add_field => {\"clkstrm\" => \"1\" } }\n    }\n    \n    if [clientip] =~ \".\" {\n        geoip {\n            source => \"clientip\"\n        }\n    }\n}\n\noutput {\n    elasticsearch {\n        hosts => [ \"192.168.1.1:9200\" ]\n    }\n\n#    http {\n#        format=>\"json\"\n#        http_method=>\"post\"\n#        url => \"http://localhost:8989/api/v1/metrics\"\n#    }\n}\n\n```\n\n## elasticsearch配置调优\n\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf elasticsearch-6.3.2.tar.gz\n```\n\n优化文件描述符：\n```\nulimit -n 65536\n\ncat >>/etc/security/limits.conf<<EOF\n# allow user 'elasticsearch' mlockall\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\nEOF\n\nsed -i 's#*          soft    nproc     1024#*          soft    nproc     2048#'g /etc/security/limits.d/90-nproc.conf \n\necho \"vm.max_map_count=655360\" >>/etc/sysctl.conf\nsysctl -p\n\n```\n创建对应目录：\n```\nuseradd -M -s /sbin/nologin elasticsearch\nmkdir -p /var/log/elasticsearch /mnt/elasticsearch /mnt/backups\nchown -R elasticsearch. /var/log/elasticsearch /mnt/elasticsearch /mnt/backups /usr/local/elasticsearch\n\nvim ./bin/elasticsearch\nES_JAVA_OPTS=\"-Xms8g -Xmx8g\" \nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nvim config/elasticsearch.yml\nbootstrap.memory_lock: true\n\nswapoff -a\n```\nes配置文件优化:\n```\n[root@test03 elasticsearch-6.3.2]# cat config/elasticsearch.yml\n\ncluster.name: bill-eye\nnode.name: node-test1\n\nnode.master: true \nnode.data: true \nnode.ingest: true\n\npath.logs: /var/log/elasticsearch\npath.data: /mnt/elasticsearch\npath.repo: /mnt/backups\n\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n\nnetwork.host: [_site_, _local_, _ens160_]\nnetwork.publish_host: [_site_, _local_, _ens160_]\ntransport.tcp.port: 9300\nhttp.port: 9200\nhttp.enabled: true\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\n\ndiscovery.zen.ping_timeout: 60s\ndiscovery.zen.join_timeout: 30s\ndiscovery.zen.fd.ping_timeout: 180s\ndiscovery.zen.fd.ping_retries: 8\ndiscovery.zen.fd.ping_interval: 30s\n\ndiscovery.zen.ping.unicast.hosts: [\"192.168.1.1:9200\"]\ndiscovery.zen.minimum_master_nodes: 2\ndiscovery.zen.commit_timeout: 120s\n\ngateway.expected_nodes: 1\ngateway.recover_after_time: 5m\ngateway.recover_after_nodes: 2\n\nindices.breaker.total.limit: 70%\nindices.breaker.fielddata.limit: 60%  \nindices.breaker.request.limit: 60%\nindices.fielddata.cache.size: 30% \nindices.queries.cache.size: 10%\nindices.requests.cache.size: 2%\nindices.recovery.max_bytes_per_sec: 20mb\n```\n启动es：\n```\nsudo -u elasticsearch ./bin/elasticsearch -d \n```\n\n## 配置kibana    \n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf kibana-6.3.2-linux-x86_64.tar.gz\n```\n配置kibana：\n``` \n[root@test03 kibana-6.3.2-linux-x86_64]# grep -Ev '^$|#' config/kibana.yml\nserver.port: 5601\nserver.host: \"192.168.1.1\"\nelasticsearch.url: \"http://192.168.1.1:9200\"\nkibana.index: \".kibana\"\nelasticsearch.pingTimeout: 2500\nelasticsearch.requestTimeout: 60000\n```\n启动kibana：\n```\nnohup ./bin/kibana &\n```\n\n## 配置granfan\n下载软件：\n```\n[root@test03 local]# wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2.linux-amd64.tar.gz \n[root@test03 local]# tar -zxvf grafana-5.2.2.linux-amd64.tar.gz \n```\n启动：\n```\n[root@test03 grafana-5.2.2]# nohup ./bin/grafana-server  & \n```\n\n## 最终效果\n![](https://owelinux.github.io/images/2018-08-22-article16-linux-elk/kibana-filebeat.png)\n\n## 参考\n> * [https://www.elastic.co/guide/en/beats/filebeat/current/index.html](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)\n> * [https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)","source":"_posts/2018-08-22-article16-linux-elk.md","raw":"---\nlayout: post\ntitle:  \"ELK(6.x版本)日志分析平台+Granfan可视化\"\ndate:   2018-08-22 18:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux  ELK \nexcerpt: ELK日志分析平台+Granfan可视化\nmathjax: true\n---\n\n* content\n{:toc}\n\n# ELK(6.x版本)日志分析平台+Granfan可视化\n\n## 系统环境准备\n```\n# 系统版本及内核信息\n[root@test03 config]# uname  -a\nLinux test03 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n# 配置java1.8版本\n[root@test03 local]# wget jdk-8u171-linux-x64.tar.gz\n[root@test03 local]# tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/\n\necho \"JAVA_HOME=/usr/local/jdk1.8.0_171 >> /etc/profile\necho \"CLASSPATH=.:\\$JAVA_HOME/lib/tools.jar:\\$JAVA_HOME/lib/dt.jar\" >> /etc/profile \necho \"PATH=\\$JAVA_HOME/bin:\\$PATH\" >> /etc/profile \nsource /etc/profile\n```\n\n## 采集方案（本教程采用第三种方案）\n\n### 方案一 \nlog_files -> filebeat  -->  logstash -> - elasticsearch -> kibana\n\n### 方案二\nlog_files ->  filebeat -> logstash  -->  redis -> - logstash -> - elasticsearch -> kibana\n\n### 方案三\nlog_files ->  filebeat -> elasticsearch-> kibana\n\n## 配置nginx日志格式log_format\n```\n        log_format  main  '$host $remote_addr - $remote_user [$time_local] \"$request\" '\n                '$status $body_bytes_sent $upstream_response_time \"$http_referer\" '\n                '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$uid_got\" \"$uid_set\" \"$http_x_tencent_ua\" \"$upstream_addr\" \"$upstream_http_x_cached_from\" \"$upstream_http_cache_control\"';\n```\n\n## 配置filebeat（根据官网改造支持nginx日志格式）\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz\n```\n配置filebeat：\n```\n[root@WEB3 include]# cat /etc/filebeat/config.yml  | grep -Ev  '#|^$'\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/nginx/*access.log\n  grok_pattern: '%{USERNAME:domain} %{IPV4:client_ip} (.*) \\[%{HTTPDATE:timestamp}\\] (.*) %{URIPATH:path}(.*)\\\" (?:%{INT:response_status}|-) (?:%{INT:response_bytes}|-) (?:%{NUMBER:response_time}|-)'\n  ignore_older: 1h\nname: 192.168.1.1\noutput.elasticsearch:\n  enabled: true\n  hosts: [\"192.168.1.1:9200\"]\n  index: \"beijing-web-%{+yyyy.MM.dd}\"\n  template.enabled: false\n  template.versions.2x.enabled: false\n  template.versions.6x.enabled: false\noutput.file:\n  enabled: true\n  path: /tmp/filebeat\npath.config: /etc/filebeat\npath.data: /tmp/filebeat/data\npath.logs: /var/log\nlogging.to_files: true\nlogging.files:\n  path: /var/log\n  name: filebeat\n```\n\n## 配置logstash\n\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf logstash-6.3.2.tar.gz\n```\n\n几种插件的使用：\n### 1、grok插件\n\n作用:解析message信息或其他操作\n\n* logstash的grok：    [https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html](https://www.elastic.co/guide/enlogstash/current/plugins-filters-grok.html)\n\n* grok正则测试：[http://grokdebug.herokuapp.com](http://grokdebug.herokuapp.com)\n\n#### nginx日志的正则匹配\n```\nmatch => { \n          \"message\" => \"(?<domain>%{IP:ip}|(?:%{NOTSPACE:subsite}\\.)?(?<site>[-a-zA-Z0-9]+?).com|%{NOTSPACE:unknown}) %{IPORHOST:dayuip} - (?<user>[a-zA-Z\\.\\@\\-\\+_%]+) \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:verb} (?<request_path>(?<biz>\\/[^/?]*)%{URIPATH:}?)(?:%{URIPARAM:request_param})? HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:%{BASE10NUM:request_duration}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\\"(?:%{IPORHOST:clientip}(?:[^\\\"]*)|-)\\\" %{QS:uidgot} %{QS:uidset} \\\"(?:[^\\\" ]* )*(?<upstream>[^ \\\"]*|-)\\\"\"\n      }\n```\n \n\n#### Java的正则匹配\n```\nmatch => {\n      \"message\" => \"\\[entry\\]\\[ts\\](?<ts>.*)\\[/ts\\]\\[lv\\](?<lv>.*)\\[/lv\\]\\[th\\](?<th>.*)\\[/th\\]\\[lg\\](?<lg>.*)\\[/lg\\]\\[cl\\](?<cl>.*)\\[/cl\\]\\[m\\](?<m>.*)\\[/m\\]\\[ln\\](?<ln>.*)\\[/ln\\]\\[bsid\\](?<bsid>.*)\\[/bsid\\]\\[esid\\](?<esid>.*)\\[/esid\\](\\[cmid\\](?<cmid>.*)\\[/cmid\\])?\\[txt\\](?<txt>.*)\\[/txt\\]\\[ex\\](?<ex>.*)\\[/ex\\]\\[/entry\\]\"\n}\n```\n \n\n#### PHP的正则匹配\n```\nmatch => {\n        \"message\" => \"\\[entry\\]\\[ts\\](?<ts>.*)\\[/ts\\]\\[lv\\](?<lv>.*)\\[/lv\\]\\[th\\](?<th>.*)\\[/th\\]\\[lg\\](?<lg>.*)\\[/lg\\]\\[cl\\](?<cl>.*)\\[/cl\\]\\[m\\](?<m>.*)\\[/m\\]\\[ln\\](?<ln>.*)\\[/ln\\]\\[bsid\\](?<bsid>.*)\\[/bsid\\]\\[esid\\](?<esid>.*)\\[/esid\\]\\[txt\\](?<txt>.*)\\[/txt\\]\\[proj\\](?<proj>.*)\\[/proj\\]\\[iid\\](?<iid>.*)\\[/iid\\]\\[file\\](?<file>.*)\\[/file\\]\\[ex\\](?<ex>.*)\\[/ex\\]\\[type\\](?<logtype>.*)\\[/type\\]\\[/entry\\]\"\n}\n```\n \n### 2、date 插件\n\n作用：将解析到的时间作为展示在kibana的time\n\n```   \nfilter {\n        date {\n               match => [ \"logdate\", \"MMM dd yyyy HH:mm:ss\" ]\n             }\n      }\n```\n\n### logstash配置优化\n```\ninput {\n    beats {\n        port => \"5043\"\n    }\n}\nfilter {\n    grok {\n        match => { \"message\" => \"^(?<domain>%{IP:ip}|(?:%{NOTSPACE:subsite}\\.)?(?<site>[-a-zA-Z0-9]+?).com|%{NOTSPACE:unknown}) %{IPORHOST:dayuip} - (?<user>[a-zA-Z\\.\\@\\-\\+_%]+) \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:verb} (?<request_path>(?<biz>\\/[^/?]*)%{URIPATH:}?)(?:%{URIPARAM:request_param})? HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:%{BASE10NUM:request_duration}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\\"(?:%{IPORHOST:clientip}(?:[^\\\"]*)|-)\\\" %{QS:uidgot} %{QS:uidset} %{QS:tencentua} \\\"(?:[^\\\" ]* )*(?<upstream>[^ \\\"]*|-)\\\" %{QS:cachedfrom} %{QS:cachectrl}\"}\n    }\n\n   date {\n      # Try to pull the timestamp from the 'timestamp' field (parsed above with\n      # grok). The apache time format looks like: \"18/Aug/2011:05:44:34 -0700\"\n      locale => \"en\"\n      timezone => \"Asia/Shanghai\"\n      match => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n      add_tag => [ \"tsmatch\" ]\n    }\n\n    if [ip] {\n         mutate { add_field => { \"site\" => \"unknown\" \"subsite\" => \"ip\" } }    \n    } else if [unknown] {\n         mutate { add_field => { \"site\" => \"unknown\" \"subsite\" => \"unknown\" } }    \n    } else if ! [subsite] {\n         mutate { add_field => { \"subsite\" => \"-\" } }    \n    }\n\n    if ![site] {\n         mutate { add_field => { \"site\" => \"unknown\" } }    \n    }\n\n\n    mutate {\n        convert => { \"bytes\" => \"integer\" \"request_duration\" => \"float\"}\n    }\n\n    if [request_path] =~ \"\\/count\\/a682ab23d4b4c95f84c744b2826419cd\" {\n        mutate { add_field => {\"clkstrm\" => \"1\" } }\n    }\n    \n    if [clientip] =~ \".\" {\n        geoip {\n            source => \"clientip\"\n        }\n    }\n}\n\noutput {\n    elasticsearch {\n        hosts => [ \"192.168.1.1:9200\" ]\n    }\n\n#    http {\n#        format=>\"json\"\n#        http_method=>\"post\"\n#        url => \"http://localhost:8989/api/v1/metrics\"\n#    }\n}\n\n```\n\n## elasticsearch配置调优\n\n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf elasticsearch-6.3.2.tar.gz\n```\n\n优化文件描述符：\n```\nulimit -n 65536\n\ncat >>/etc/security/limits.conf<<EOF\n# allow user 'elasticsearch' mlockall\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\nEOF\n\nsed -i 's#*          soft    nproc     1024#*          soft    nproc     2048#'g /etc/security/limits.d/90-nproc.conf \n\necho \"vm.max_map_count=655360\" >>/etc/sysctl.conf\nsysctl -p\n\n```\n创建对应目录：\n```\nuseradd -M -s /sbin/nologin elasticsearch\nmkdir -p /var/log/elasticsearch /mnt/elasticsearch /mnt/backups\nchown -R elasticsearch. /var/log/elasticsearch /mnt/elasticsearch /mnt/backups /usr/local/elasticsearch\n\nvim ./bin/elasticsearch\nES_JAVA_OPTS=\"-Xms8g -Xmx8g\" \nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nvim config/elasticsearch.yml\nbootstrap.memory_lock: true\n\nswapoff -a\n```\nes配置文件优化:\n```\n[root@test03 elasticsearch-6.3.2]# cat config/elasticsearch.yml\n\ncluster.name: bill-eye\nnode.name: node-test1\n\nnode.master: true \nnode.data: true \nnode.ingest: true\n\npath.logs: /var/log/elasticsearch\npath.data: /mnt/elasticsearch\npath.repo: /mnt/backups\n\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n\nnetwork.host: [_site_, _local_, _ens160_]\nnetwork.publish_host: [_site_, _local_, _ens160_]\ntransport.tcp.port: 9300\nhttp.port: 9200\nhttp.enabled: true\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\n\ndiscovery.zen.ping_timeout: 60s\ndiscovery.zen.join_timeout: 30s\ndiscovery.zen.fd.ping_timeout: 180s\ndiscovery.zen.fd.ping_retries: 8\ndiscovery.zen.fd.ping_interval: 30s\n\ndiscovery.zen.ping.unicast.hosts: [\"192.168.1.1:9200\"]\ndiscovery.zen.minimum_master_nodes: 2\ndiscovery.zen.commit_timeout: 120s\n\ngateway.expected_nodes: 1\ngateway.recover_after_time: 5m\ngateway.recover_after_nodes: 2\n\nindices.breaker.total.limit: 70%\nindices.breaker.fielddata.limit: 60%  \nindices.breaker.request.limit: 60%\nindices.fielddata.cache.size: 30% \nindices.queries.cache.size: 10%\nindices.requests.cache.size: 2%\nindices.recovery.max_bytes_per_sec: 20mb\n```\n启动es：\n```\nsudo -u elasticsearch ./bin/elasticsearch -d \n```\n\n## 配置kibana    \n下载软件：\n```\n[root@test03 local]# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf kibana-6.3.2-linux-x86_64.tar.gz\n```\n配置kibana：\n``` \n[root@test03 kibana-6.3.2-linux-x86_64]# grep -Ev '^$|#' config/kibana.yml\nserver.port: 5601\nserver.host: \"192.168.1.1\"\nelasticsearch.url: \"http://192.168.1.1:9200\"\nkibana.index: \".kibana\"\nelasticsearch.pingTimeout: 2500\nelasticsearch.requestTimeout: 60000\n```\n启动kibana：\n```\nnohup ./bin/kibana &\n```\n\n## 配置granfan\n下载软件：\n```\n[root@test03 local]# wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2.linux-amd64.tar.gz \n[root@test03 local]# tar -zxvf grafana-5.2.2.linux-amd64.tar.gz \n```\n启动：\n```\n[root@test03 grafana-5.2.2]# nohup ./bin/grafana-server  & \n```\n\n## 最终效果\n![](https://owelinux.github.io/images/2018-08-22-article16-linux-elk/kibana-filebeat.png)\n\n## 参考\n> * [https://www.elastic.co/guide/en/beats/filebeat/current/index.html](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)\n> * [https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)","slug":"2018-08-22-article16-linux-elk","published":1,"updated":"2021-02-09T02:00:24.568Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq00000syc976fpidww1","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"ELK-6-x版本-日志分析平台-Granfan可视化\"><a href=\"#ELK-6-x版本-日志分析平台-Granfan可视化\" class=\"headerlink\" title=\"ELK(6.x版本)日志分析平台+Granfan可视化\"></a>ELK(6.x版本)日志分析平台+Granfan可视化</h1><h2 id=\"系统环境准备\"><a href=\"#系统环境准备\" class=\"headerlink\" title=\"系统环境准备\"></a>系统环境准备</h2><pre><code># 系统版本及内核信息\n[root@test03 config]# uname  -a\nLinux test03 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n# 配置java1.8版本\n[root@test03 local]# wget jdk-8u171-linux-x64.tar.gz\n[root@test03 local]# tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/\n\necho &quot;JAVA_HOME=/usr/local/jdk1.8.0_171 &gt;&gt; /etc/profile\necho &quot;CLASSPATH=.:\\$JAVA_HOME/lib/tools.jar:\\$JAVA_HOME/lib/dt.jar&quot; &gt;&gt; /etc/profile \necho &quot;PATH=\\$JAVA_HOME/bin:\\$PATH&quot; &gt;&gt; /etc/profile \nsource /etc/profile\n</code></pre>\n<h2 id=\"采集方案（本教程采用第三种方案）\"><a href=\"#采集方案（本教程采用第三种方案）\" class=\"headerlink\" title=\"采集方案（本教程采用第三种方案）\"></a>采集方案（本教程采用第三种方案）</h2><h3 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h3><p>log_files -&gt; filebeat  –&gt;  logstash -&gt; - elasticsearch -&gt; kibana</p>\n<h3 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h3><p>log_files -&gt;  filebeat -&gt; logstash  –&gt;  redis -&gt; - logstash -&gt; - elasticsearch -&gt; kibana</p>\n<h3 id=\"方案三\"><a href=\"#方案三\" class=\"headerlink\" title=\"方案三\"></a>方案三</h3><p>log_files -&gt;  filebeat -&gt; elasticsearch-&gt; kibana</p>\n<h2 id=\"配置nginx日志格式log-format\"><a href=\"#配置nginx日志格式log-format\" class=\"headerlink\" title=\"配置nginx日志格式log_format\"></a>配置nginx日志格式log_format</h2><pre><code>        log_format  main  &#39;$host $remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;\n                &#39;$status $body_bytes_sent $upstream_response_time &quot;$http_referer&quot; &#39;\n                &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$uid_got&quot; &quot;$uid_set&quot; &quot;$http_x_tencent_ua&quot; &quot;$upstream_addr&quot; &quot;$upstream_http_x_cached_from&quot; &quot;$upstream_http_cache_control&quot;&#39;;\n</code></pre>\n<h2 id=\"配置filebeat（根据官网改造支持nginx日志格式）\"><a href=\"#配置filebeat（根据官网改造支持nginx日志格式）\" class=\"headerlink\" title=\"配置filebeat（根据官网改造支持nginx日志格式）\"></a>配置filebeat（根据官网改造支持nginx日志格式）</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz\n</code></pre>\n<p>配置filebeat：</p>\n<pre><code>[root@WEB3 include]# cat /etc/filebeat/config.yml  | grep -Ev  &#39;#|^$&#39;\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/nginx/*access.log\n  grok_pattern: &#39;%&#123;USERNAME:domain&#125; %&#123;IPV4:client_ip&#125; (.*) \\[%&#123;HTTPDATE:timestamp&#125;\\] (.*) %&#123;URIPATH:path&#125;(.*)\\&quot; (?:%&#123;INT:response_status&#125;|-) (?:%&#123;INT:response_bytes&#125;|-) (?:%&#123;NUMBER:response_time&#125;|-)&#39;\n  ignore_older: 1h\nname: 192.168.1.1\noutput.elasticsearch:\n  enabled: true\n  hosts: [&quot;192.168.1.1:9200&quot;]\n  index: &quot;beijing-web-%&#123;+yyyy.MM.dd&#125;&quot;\n  template.enabled: false\n  template.versions.2x.enabled: false\n  template.versions.6x.enabled: false\noutput.file:\n  enabled: true\n  path: /tmp/filebeat\npath.config: /etc/filebeat\npath.data: /tmp/filebeat/data\npath.logs: /var/log\nlogging.to_files: true\nlogging.files:\n  path: /var/log\n  name: filebeat\n</code></pre>\n<h2 id=\"配置logstash\"><a href=\"#配置logstash\" class=\"headerlink\" title=\"配置logstash\"></a>配置logstash</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf logstash-6.3.2.tar.gz\n</code></pre>\n<p>几种插件的使用：</p>\n<h3 id=\"1、grok插件\"><a href=\"#1、grok插件\" class=\"headerlink\" title=\"1、grok插件\"></a>1、grok插件</h3><p>作用:解析message信息或其他操作</p>\n<ul>\n<li><p>logstash的grok：    <a href=\"https://www.elastic.co/guide/enlogstash/current/plugins-filters-grok.html\">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></p>\n</li>\n<li><p>grok正则测试：<a href=\"http://grokdebug.herokuapp.com/\">http://grokdebug.herokuapp.com</a></p>\n</li>\n</ul>\n<h4 id=\"nginx日志的正则匹配\"><a href=\"#nginx日志的正则匹配\" class=\"headerlink\" title=\"nginx日志的正则匹配\"></a>nginx日志的正则匹配</h4><pre><code>match =&gt; &#123; \n          &quot;message&quot; =&gt; &quot;(?&lt;domain&gt;%&#123;IP:ip&#125;|(?:%&#123;NOTSPACE:subsite&#125;\\.)?(?&lt;site&gt;[-a-zA-Z0-9]+?).com|%&#123;NOTSPACE:unknown&#125;) %&#123;IPORHOST:dayuip&#125; - (?&lt;user&gt;[a-zA-Z\\.\\@\\-\\+_%]+) \\[%&#123;HTTPDATE:timestamp&#125;\\] \\&quot;%&#123;WORD:verb&#125; (?&lt;request_path&gt;(?&lt;biz&gt;\\/[^/?]*)%&#123;URIPATH:&#125;?)(?:%&#123;URIPARAM:request_param&#125;)? HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) (?:%&#123;BASE10NUM:request_duration&#125;|-) (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\&quot;(?:%&#123;IPORHOST:clientip&#125;(?:[^\\&quot;]*)|-)\\&quot; %&#123;QS:uidgot&#125; %&#123;QS:uidset&#125; \\&quot;(?:[^\\&quot; ]* )*(?&lt;upstream&gt;[^ \\&quot;]*|-)\\&quot;&quot;\n      &#125;\n</code></pre>\n<h4 id=\"Java的正则匹配\"><a href=\"#Java的正则匹配\" class=\"headerlink\" title=\"Java的正则匹配\"></a>Java的正则匹配</h4><pre><code>match =&gt; &#123;\n      &quot;message&quot; =&gt; &quot;\\[entry\\]\\[ts\\](?&lt;ts&gt;.*)\\[/ts\\]\\[lv\\](?&lt;lv&gt;.*)\\[/lv\\]\\[th\\](?&lt;th&gt;.*)\\[/th\\]\\[lg\\](?&lt;lg&gt;.*)\\[/lg\\]\\[cl\\](?&lt;cl&gt;.*)\\[/cl\\]\\[m\\](?&lt;m&gt;.*)\\[/m\\]\\[ln\\](?&lt;ln&gt;.*)\\[/ln\\]\\[bsid\\](?&lt;bsid&gt;.*)\\[/bsid\\]\\[esid\\](?&lt;esid&gt;.*)\\[/esid\\](\\[cmid\\](?&lt;cmid&gt;.*)\\[/cmid\\])?\\[txt\\](?&lt;txt&gt;.*)\\[/txt\\]\\[ex\\](?&lt;ex&gt;.*)\\[/ex\\]\\[/entry\\]&quot;\n&#125;\n</code></pre>\n<h4 id=\"PHP的正则匹配\"><a href=\"#PHP的正则匹配\" class=\"headerlink\" title=\"PHP的正则匹配\"></a>PHP的正则匹配</h4><pre><code>match =&gt; &#123;\n        &quot;message&quot; =&gt; &quot;\\[entry\\]\\[ts\\](?&lt;ts&gt;.*)\\[/ts\\]\\[lv\\](?&lt;lv&gt;.*)\\[/lv\\]\\[th\\](?&lt;th&gt;.*)\\[/th\\]\\[lg\\](?&lt;lg&gt;.*)\\[/lg\\]\\[cl\\](?&lt;cl&gt;.*)\\[/cl\\]\\[m\\](?&lt;m&gt;.*)\\[/m\\]\\[ln\\](?&lt;ln&gt;.*)\\[/ln\\]\\[bsid\\](?&lt;bsid&gt;.*)\\[/bsid\\]\\[esid\\](?&lt;esid&gt;.*)\\[/esid\\]\\[txt\\](?&lt;txt&gt;.*)\\[/txt\\]\\[proj\\](?&lt;proj&gt;.*)\\[/proj\\]\\[iid\\](?&lt;iid&gt;.*)\\[/iid\\]\\[file\\](?&lt;file&gt;.*)\\[/file\\]\\[ex\\](?&lt;ex&gt;.*)\\[/ex\\]\\[type\\](?&lt;logtype&gt;.*)\\[/type\\]\\[/entry\\]&quot;\n&#125;\n</code></pre>\n<h3 id=\"2、date-插件\"><a href=\"#2、date-插件\" class=\"headerlink\" title=\"2、date 插件\"></a>2、date 插件</h3><p>作用：将解析到的时间作为展示在kibana的time</p>\n<pre><code>filter &#123;\n        date &#123;\n               match =&gt; [ &quot;logdate&quot;, &quot;MMM dd yyyy HH:mm:ss&quot; ]\n             &#125;\n      &#125;\n</code></pre>\n<h3 id=\"logstash配置优化\"><a href=\"#logstash配置优化\" class=\"headerlink\" title=\"logstash配置优化\"></a>logstash配置优化</h3><pre><code>input &#123;\n    beats &#123;\n        port =&gt; &quot;5043&quot;\n    &#125;\n&#125;\nfilter &#123;\n    grok &#123;\n        match =&gt; &#123; &quot;message&quot; =&gt; &quot;^(?&lt;domain&gt;%&#123;IP:ip&#125;|(?:%&#123;NOTSPACE:subsite&#125;\\.)?(?&lt;site&gt;[-a-zA-Z0-9]+?).com|%&#123;NOTSPACE:unknown&#125;) %&#123;IPORHOST:dayuip&#125; - (?&lt;user&gt;[a-zA-Z\\.\\@\\-\\+_%]+) \\[%&#123;HTTPDATE:timestamp&#125;\\] \\&quot;%&#123;WORD:verb&#125; (?&lt;request_path&gt;(?&lt;biz&gt;\\/[^/?]*)%&#123;URIPATH:&#125;?)(?:%&#123;URIPARAM:request_param&#125;)? HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) (?:%&#123;BASE10NUM:request_duration&#125;|-) (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\&quot;(?:%&#123;IPORHOST:clientip&#125;(?:[^\\&quot;]*)|-)\\&quot; %&#123;QS:uidgot&#125; %&#123;QS:uidset&#125; %&#123;QS:tencentua&#125; \\&quot;(?:[^\\&quot; ]* )*(?&lt;upstream&gt;[^ \\&quot;]*|-)\\&quot; %&#123;QS:cachedfrom&#125; %&#123;QS:cachectrl&#125;&quot;&#125;\n    &#125;\n\n   date &#123;\n      # Try to pull the timestamp from the &#39;timestamp&#39; field (parsed above with\n      # grok). The apache time format looks like: &quot;18/Aug/2011:05:44:34 -0700&quot;\n      locale =&gt; &quot;en&quot;\n      timezone =&gt; &quot;Asia/Shanghai&quot;\n      match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n      add_tag =&gt; [ &quot;tsmatch&quot; ]\n    &#125;\n\n    if [ip] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &quot;subsite&quot; =&gt; &quot;ip&quot; &#125; &#125;    \n    &#125; else if [unknown] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &quot;subsite&quot; =&gt; &quot;unknown&quot; &#125; &#125;    \n    &#125; else if ! [subsite] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;subsite&quot; =&gt; &quot;-&quot; &#125; &#125;    \n    &#125;\n\n    if ![site] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &#125; &#125;    \n    &#125;\n\n\n    mutate &#123;\n        convert =&gt; &#123; &quot;bytes&quot; =&gt; &quot;integer&quot; &quot;request_duration&quot; =&gt; &quot;float&quot;&#125;\n    &#125;\n\n    if [request_path] =~ &quot;\\/count\\/a682ab23d4b4c95f84c744b2826419cd&quot; &#123;\n        mutate &#123; add_field =&gt; &#123;&quot;clkstrm&quot; =&gt; &quot;1&quot; &#125; &#125;\n    &#125;\n    \n    if [clientip] =~ &quot;.&quot; &#123;\n        geoip &#123;\n            source =&gt; &quot;clientip&quot;\n        &#125;\n    &#125;\n&#125;\n\noutput &#123;\n    elasticsearch &#123;\n        hosts =&gt; [ &quot;192.168.1.1:9200&quot; ]\n    &#125;\n\n#    http &#123;\n#        format=&gt;&quot;json&quot;\n#        http_method=&gt;&quot;post&quot;\n#        url =&gt; &quot;http://localhost:8989/api/v1/metrics&quot;\n#    &#125;\n&#125;\n</code></pre>\n<h2 id=\"elasticsearch配置调优\"><a href=\"#elasticsearch配置调优\" class=\"headerlink\" title=\"elasticsearch配置调优\"></a>elasticsearch配置调优</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf elasticsearch-6.3.2.tar.gz\n</code></pre>\n<p>优化文件描述符：</p>\n<pre><code>ulimit -n 65536\n\ncat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF\n# allow user &#39;elasticsearch&#39; mlockall\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\nEOF\n\nsed -i &#39;s#*          soft    nproc     1024#*          soft    nproc     2048#&#39;g /etc/security/limits.d/90-nproc.conf \n\necho &quot;vm.max_map_count=655360&quot; &gt;&gt;/etc/sysctl.conf\nsysctl -p\n</code></pre>\n<p>创建对应目录：</p>\n<pre><code>useradd -M -s /sbin/nologin elasticsearch\nmkdir -p /var/log/elasticsearch /mnt/elasticsearch /mnt/backups\nchown -R elasticsearch. /var/log/elasticsearch /mnt/elasticsearch /mnt/backups /usr/local/elasticsearch\n\nvim ./bin/elasticsearch\nES_JAVA_OPTS=&quot;-Xms8g -Xmx8g&quot; \nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nvim config/elasticsearch.yml\nbootstrap.memory_lock: true\n\nswapoff -a\n</code></pre>\n<p>es配置文件优化:</p>\n<pre><code>[root@test03 elasticsearch-6.3.2]# cat config/elasticsearch.yml\n\ncluster.name: bill-eye\nnode.name: node-test1\n\nnode.master: true \nnode.data: true \nnode.ingest: true\n\npath.logs: /var/log/elasticsearch\npath.data: /mnt/elasticsearch\npath.repo: /mnt/backups\n\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n\nnetwork.host: [_site_, _local_, _ens160_]\nnetwork.publish_host: [_site_, _local_, _ens160_]\ntransport.tcp.port: 9300\nhttp.port: 9200\nhttp.enabled: true\nhttp.cors.enabled: true\nhttp.cors.allow-origin: &quot;*&quot;\n\ndiscovery.zen.ping_timeout: 60s\ndiscovery.zen.join_timeout: 30s\ndiscovery.zen.fd.ping_timeout: 180s\ndiscovery.zen.fd.ping_retries: 8\ndiscovery.zen.fd.ping_interval: 30s\n\ndiscovery.zen.ping.unicast.hosts: [&quot;192.168.1.1:9200&quot;]\ndiscovery.zen.minimum_master_nodes: 2\ndiscovery.zen.commit_timeout: 120s\n\ngateway.expected_nodes: 1\ngateway.recover_after_time: 5m\ngateway.recover_after_nodes: 2\n\nindices.breaker.total.limit: 70%\nindices.breaker.fielddata.limit: 60%  \nindices.breaker.request.limit: 60%\nindices.fielddata.cache.size: 30% \nindices.queries.cache.size: 10%\nindices.requests.cache.size: 2%\nindices.recovery.max_bytes_per_sec: 20mb\n</code></pre>\n<p>启动es：</p>\n<pre><code>sudo -u elasticsearch ./bin/elasticsearch -d \n</code></pre>\n<h2 id=\"配置kibana\"><a href=\"#配置kibana\" class=\"headerlink\" title=\"配置kibana\"></a>配置kibana</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf kibana-6.3.2-linux-x86_64.tar.gz\n</code></pre>\n<p>配置kibana：</p>\n<pre><code>[root@test03 kibana-6.3.2-linux-x86_64]# grep -Ev &#39;^$|#&#39; config/kibana.yml\nserver.port: 5601\nserver.host: &quot;192.168.1.1&quot;\nelasticsearch.url: &quot;http://192.168.1.1:9200&quot;\nkibana.index: &quot;.kibana&quot;\nelasticsearch.pingTimeout: 2500\nelasticsearch.requestTimeout: 60000\n</code></pre>\n<p>启动kibana：</p>\n<pre><code>nohup ./bin/kibana &amp;\n</code></pre>\n<h2 id=\"配置granfan\"><a href=\"#配置granfan\" class=\"headerlink\" title=\"配置granfan\"></a>配置granfan</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2.linux-amd64.tar.gz \n[root@test03 local]# tar -zxvf grafana-5.2.2.linux-amd64.tar.gz \n</code></pre>\n<p>启动：</p>\n<pre><code>[root@test03 grafana-5.2.2]# nohup ./bin/grafana-server  &amp; \n</code></pre>\n<h2 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h2><p><img src=\"https://owelinux.github.io/images/2018-08-22-article16-linux-elk/kibana-filebeat.png\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/beats/filebeat/current/index.html\">https://www.elastic.co/guide/en/beats/filebeat/current/index.html</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"ELK-6-x版本-日志分析平台-Granfan可视化\"><a href=\"#ELK-6-x版本-日志分析平台-Granfan可视化\" class=\"headerlink\" title=\"ELK(6.x版本)日志分析平台+Granfan可视化\"></a>ELK(6.x版本)日志分析平台+Granfan可视化</h1><h2 id=\"系统环境准备\"><a href=\"#系统环境准备\" class=\"headerlink\" title=\"系统环境准备\"></a>系统环境准备</h2><pre><code># 系统版本及内核信息\n[root@test03 config]# uname  -a\nLinux test03 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n# 配置java1.8版本\n[root@test03 local]# wget jdk-8u171-linux-x64.tar.gz\n[root@test03 local]# tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/\n\necho &quot;JAVA_HOME=/usr/local/jdk1.8.0_171 &gt;&gt; /etc/profile\necho &quot;CLASSPATH=.:\\$JAVA_HOME/lib/tools.jar:\\$JAVA_HOME/lib/dt.jar&quot; &gt;&gt; /etc/profile \necho &quot;PATH=\\$JAVA_HOME/bin:\\$PATH&quot; &gt;&gt; /etc/profile \nsource /etc/profile\n</code></pre>\n<h2 id=\"采集方案（本教程采用第三种方案）\"><a href=\"#采集方案（本教程采用第三种方案）\" class=\"headerlink\" title=\"采集方案（本教程采用第三种方案）\"></a>采集方案（本教程采用第三种方案）</h2><h3 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h3><p>log_files -&gt; filebeat  –&gt;  logstash -&gt; - elasticsearch -&gt; kibana</p>\n<h3 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h3><p>log_files -&gt;  filebeat -&gt; logstash  –&gt;  redis -&gt; - logstash -&gt; - elasticsearch -&gt; kibana</p>\n<h3 id=\"方案三\"><a href=\"#方案三\" class=\"headerlink\" title=\"方案三\"></a>方案三</h3><p>log_files -&gt;  filebeat -&gt; elasticsearch-&gt; kibana</p>\n<h2 id=\"配置nginx日志格式log-format\"><a href=\"#配置nginx日志格式log-format\" class=\"headerlink\" title=\"配置nginx日志格式log_format\"></a>配置nginx日志格式log_format</h2><pre><code>        log_format  main  &#39;$host $remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;\n                &#39;$status $body_bytes_sent $upstream_response_time &quot;$http_referer&quot; &#39;\n                &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$uid_got&quot; &quot;$uid_set&quot; &quot;$http_x_tencent_ua&quot; &quot;$upstream_addr&quot; &quot;$upstream_http_x_cached_from&quot; &quot;$upstream_http_cache_control&quot;&#39;;\n</code></pre>\n<h2 id=\"配置filebeat（根据官网改造支持nginx日志格式）\"><a href=\"#配置filebeat（根据官网改造支持nginx日志格式）\" class=\"headerlink\" title=\"配置filebeat（根据官网改造支持nginx日志格式）\"></a>配置filebeat（根据官网改造支持nginx日志格式）</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz\n</code></pre>\n<p>配置filebeat：</p>\n<pre><code>[root@WEB3 include]# cat /etc/filebeat/config.yml  | grep -Ev  &#39;#|^$&#39;\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/nginx/*access.log\n  grok_pattern: &#39;%&#123;USERNAME:domain&#125; %&#123;IPV4:client_ip&#125; (.*) \\[%&#123;HTTPDATE:timestamp&#125;\\] (.*) %&#123;URIPATH:path&#125;(.*)\\&quot; (?:%&#123;INT:response_status&#125;|-) (?:%&#123;INT:response_bytes&#125;|-) (?:%&#123;NUMBER:response_time&#125;|-)&#39;\n  ignore_older: 1h\nname: 192.168.1.1\noutput.elasticsearch:\n  enabled: true\n  hosts: [&quot;192.168.1.1:9200&quot;]\n  index: &quot;beijing-web-%&#123;+yyyy.MM.dd&#125;&quot;\n  template.enabled: false\n  template.versions.2x.enabled: false\n  template.versions.6x.enabled: false\noutput.file:\n  enabled: true\n  path: /tmp/filebeat\npath.config: /etc/filebeat\npath.data: /tmp/filebeat/data\npath.logs: /var/log\nlogging.to_files: true\nlogging.files:\n  path: /var/log\n  name: filebeat\n</code></pre>\n<h2 id=\"配置logstash\"><a href=\"#配置logstash\" class=\"headerlink\" title=\"配置logstash\"></a>配置logstash</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf logstash-6.3.2.tar.gz\n</code></pre>\n<p>几种插件的使用：</p>\n<h3 id=\"1、grok插件\"><a href=\"#1、grok插件\" class=\"headerlink\" title=\"1、grok插件\"></a>1、grok插件</h3><p>作用:解析message信息或其他操作</p>\n<ul>\n<li><p>logstash的grok：    <a href=\"https://www.elastic.co/guide/enlogstash/current/plugins-filters-grok.html\">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></p>\n</li>\n<li><p>grok正则测试：<a href=\"http://grokdebug.herokuapp.com/\">http://grokdebug.herokuapp.com</a></p>\n</li>\n</ul>\n<h4 id=\"nginx日志的正则匹配\"><a href=\"#nginx日志的正则匹配\" class=\"headerlink\" title=\"nginx日志的正则匹配\"></a>nginx日志的正则匹配</h4><pre><code>match =&gt; &#123; \n          &quot;message&quot; =&gt; &quot;(?&lt;domain&gt;%&#123;IP:ip&#125;|(?:%&#123;NOTSPACE:subsite&#125;\\.)?(?&lt;site&gt;[-a-zA-Z0-9]+?).com|%&#123;NOTSPACE:unknown&#125;) %&#123;IPORHOST:dayuip&#125; - (?&lt;user&gt;[a-zA-Z\\.\\@\\-\\+_%]+) \\[%&#123;HTTPDATE:timestamp&#125;\\] \\&quot;%&#123;WORD:verb&#125; (?&lt;request_path&gt;(?&lt;biz&gt;\\/[^/?]*)%&#123;URIPATH:&#125;?)(?:%&#123;URIPARAM:request_param&#125;)? HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) (?:%&#123;BASE10NUM:request_duration&#125;|-) (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\&quot;(?:%&#123;IPORHOST:clientip&#125;(?:[^\\&quot;]*)|-)\\&quot; %&#123;QS:uidgot&#125; %&#123;QS:uidset&#125; \\&quot;(?:[^\\&quot; ]* )*(?&lt;upstream&gt;[^ \\&quot;]*|-)\\&quot;&quot;\n      &#125;\n</code></pre>\n<h4 id=\"Java的正则匹配\"><a href=\"#Java的正则匹配\" class=\"headerlink\" title=\"Java的正则匹配\"></a>Java的正则匹配</h4><pre><code>match =&gt; &#123;\n      &quot;message&quot; =&gt; &quot;\\[entry\\]\\[ts\\](?&lt;ts&gt;.*)\\[/ts\\]\\[lv\\](?&lt;lv&gt;.*)\\[/lv\\]\\[th\\](?&lt;th&gt;.*)\\[/th\\]\\[lg\\](?&lt;lg&gt;.*)\\[/lg\\]\\[cl\\](?&lt;cl&gt;.*)\\[/cl\\]\\[m\\](?&lt;m&gt;.*)\\[/m\\]\\[ln\\](?&lt;ln&gt;.*)\\[/ln\\]\\[bsid\\](?&lt;bsid&gt;.*)\\[/bsid\\]\\[esid\\](?&lt;esid&gt;.*)\\[/esid\\](\\[cmid\\](?&lt;cmid&gt;.*)\\[/cmid\\])?\\[txt\\](?&lt;txt&gt;.*)\\[/txt\\]\\[ex\\](?&lt;ex&gt;.*)\\[/ex\\]\\[/entry\\]&quot;\n&#125;\n</code></pre>\n<h4 id=\"PHP的正则匹配\"><a href=\"#PHP的正则匹配\" class=\"headerlink\" title=\"PHP的正则匹配\"></a>PHP的正则匹配</h4><pre><code>match =&gt; &#123;\n        &quot;message&quot; =&gt; &quot;\\[entry\\]\\[ts\\](?&lt;ts&gt;.*)\\[/ts\\]\\[lv\\](?&lt;lv&gt;.*)\\[/lv\\]\\[th\\](?&lt;th&gt;.*)\\[/th\\]\\[lg\\](?&lt;lg&gt;.*)\\[/lg\\]\\[cl\\](?&lt;cl&gt;.*)\\[/cl\\]\\[m\\](?&lt;m&gt;.*)\\[/m\\]\\[ln\\](?&lt;ln&gt;.*)\\[/ln\\]\\[bsid\\](?&lt;bsid&gt;.*)\\[/bsid\\]\\[esid\\](?&lt;esid&gt;.*)\\[/esid\\]\\[txt\\](?&lt;txt&gt;.*)\\[/txt\\]\\[proj\\](?&lt;proj&gt;.*)\\[/proj\\]\\[iid\\](?&lt;iid&gt;.*)\\[/iid\\]\\[file\\](?&lt;file&gt;.*)\\[/file\\]\\[ex\\](?&lt;ex&gt;.*)\\[/ex\\]\\[type\\](?&lt;logtype&gt;.*)\\[/type\\]\\[/entry\\]&quot;\n&#125;\n</code></pre>\n<h3 id=\"2、date-插件\"><a href=\"#2、date-插件\" class=\"headerlink\" title=\"2、date 插件\"></a>2、date 插件</h3><p>作用：将解析到的时间作为展示在kibana的time</p>\n<pre><code>filter &#123;\n        date &#123;\n               match =&gt; [ &quot;logdate&quot;, &quot;MMM dd yyyy HH:mm:ss&quot; ]\n             &#125;\n      &#125;\n</code></pre>\n<h3 id=\"logstash配置优化\"><a href=\"#logstash配置优化\" class=\"headerlink\" title=\"logstash配置优化\"></a>logstash配置优化</h3><pre><code>input &#123;\n    beats &#123;\n        port =&gt; &quot;5043&quot;\n    &#125;\n&#125;\nfilter &#123;\n    grok &#123;\n        match =&gt; &#123; &quot;message&quot; =&gt; &quot;^(?&lt;domain&gt;%&#123;IP:ip&#125;|(?:%&#123;NOTSPACE:subsite&#125;\\.)?(?&lt;site&gt;[-a-zA-Z0-9]+?).com|%&#123;NOTSPACE:unknown&#125;) %&#123;IPORHOST:dayuip&#125; - (?&lt;user&gt;[a-zA-Z\\.\\@\\-\\+_%]+) \\[%&#123;HTTPDATE:timestamp&#125;\\] \\&quot;%&#123;WORD:verb&#125; (?&lt;request_path&gt;(?&lt;biz&gt;\\/[^/?]*)%&#123;URIPATH:&#125;?)(?:%&#123;URIPARAM:request_param&#125;)? HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) (?:%&#123;BASE10NUM:request_duration&#125;|-) (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\&quot;(?:%&#123;IPORHOST:clientip&#125;(?:[^\\&quot;]*)|-)\\&quot; %&#123;QS:uidgot&#125; %&#123;QS:uidset&#125; %&#123;QS:tencentua&#125; \\&quot;(?:[^\\&quot; ]* )*(?&lt;upstream&gt;[^ \\&quot;]*|-)\\&quot; %&#123;QS:cachedfrom&#125; %&#123;QS:cachectrl&#125;&quot;&#125;\n    &#125;\n\n   date &#123;\n      # Try to pull the timestamp from the &#39;timestamp&#39; field (parsed above with\n      # grok). The apache time format looks like: &quot;18/Aug/2011:05:44:34 -0700&quot;\n      locale =&gt; &quot;en&quot;\n      timezone =&gt; &quot;Asia/Shanghai&quot;\n      match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n      add_tag =&gt; [ &quot;tsmatch&quot; ]\n    &#125;\n\n    if [ip] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &quot;subsite&quot; =&gt; &quot;ip&quot; &#125; &#125;    \n    &#125; else if [unknown] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &quot;subsite&quot; =&gt; &quot;unknown&quot; &#125; &#125;    \n    &#125; else if ! [subsite] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;subsite&quot; =&gt; &quot;-&quot; &#125; &#125;    \n    &#125;\n\n    if ![site] &#123;\n         mutate &#123; add_field =&gt; &#123; &quot;site&quot; =&gt; &quot;unknown&quot; &#125; &#125;    \n    &#125;\n\n\n    mutate &#123;\n        convert =&gt; &#123; &quot;bytes&quot; =&gt; &quot;integer&quot; &quot;request_duration&quot; =&gt; &quot;float&quot;&#125;\n    &#125;\n\n    if [request_path] =~ &quot;\\/count\\/a682ab23d4b4c95f84c744b2826419cd&quot; &#123;\n        mutate &#123; add_field =&gt; &#123;&quot;clkstrm&quot; =&gt; &quot;1&quot; &#125; &#125;\n    &#125;\n    \n    if [clientip] =~ &quot;.&quot; &#123;\n        geoip &#123;\n            source =&gt; &quot;clientip&quot;\n        &#125;\n    &#125;\n&#125;\n\noutput &#123;\n    elasticsearch &#123;\n        hosts =&gt; [ &quot;192.168.1.1:9200&quot; ]\n    &#125;\n\n#    http &#123;\n#        format=&gt;&quot;json&quot;\n#        http_method=&gt;&quot;post&quot;\n#        url =&gt; &quot;http://localhost:8989/api/v1/metrics&quot;\n#    &#125;\n&#125;\n</code></pre>\n<h2 id=\"elasticsearch配置调优\"><a href=\"#elasticsearch配置调优\" class=\"headerlink\" title=\"elasticsearch配置调优\"></a>elasticsearch配置调优</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz\n[root@test03 local]# tar -zxvf elasticsearch-6.3.2.tar.gz\n</code></pre>\n<p>优化文件描述符：</p>\n<pre><code>ulimit -n 65536\n\ncat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF\n# allow user &#39;elasticsearch&#39; mlockall\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\nEOF\n\nsed -i &#39;s#*          soft    nproc     1024#*          soft    nproc     2048#&#39;g /etc/security/limits.d/90-nproc.conf \n\necho &quot;vm.max_map_count=655360&quot; &gt;&gt;/etc/sysctl.conf\nsysctl -p\n</code></pre>\n<p>创建对应目录：</p>\n<pre><code>useradd -M -s /sbin/nologin elasticsearch\nmkdir -p /var/log/elasticsearch /mnt/elasticsearch /mnt/backups\nchown -R elasticsearch. /var/log/elasticsearch /mnt/elasticsearch /mnt/backups /usr/local/elasticsearch\n\nvim ./bin/elasticsearch\nES_JAVA_OPTS=&quot;-Xms8g -Xmx8g&quot; \nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nvim config/elasticsearch.yml\nbootstrap.memory_lock: true\n\nswapoff -a\n</code></pre>\n<p>es配置文件优化:</p>\n<pre><code>[root@test03 elasticsearch-6.3.2]# cat config/elasticsearch.yml\n\ncluster.name: bill-eye\nnode.name: node-test1\n\nnode.master: true \nnode.data: true \nnode.ingest: true\n\npath.logs: /var/log/elasticsearch\npath.data: /mnt/elasticsearch\npath.repo: /mnt/backups\n\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n\nnetwork.host: [_site_, _local_, _ens160_]\nnetwork.publish_host: [_site_, _local_, _ens160_]\ntransport.tcp.port: 9300\nhttp.port: 9200\nhttp.enabled: true\nhttp.cors.enabled: true\nhttp.cors.allow-origin: &quot;*&quot;\n\ndiscovery.zen.ping_timeout: 60s\ndiscovery.zen.join_timeout: 30s\ndiscovery.zen.fd.ping_timeout: 180s\ndiscovery.zen.fd.ping_retries: 8\ndiscovery.zen.fd.ping_interval: 30s\n\ndiscovery.zen.ping.unicast.hosts: [&quot;192.168.1.1:9200&quot;]\ndiscovery.zen.minimum_master_nodes: 2\ndiscovery.zen.commit_timeout: 120s\n\ngateway.expected_nodes: 1\ngateway.recover_after_time: 5m\ngateway.recover_after_nodes: 2\n\nindices.breaker.total.limit: 70%\nindices.breaker.fielddata.limit: 60%  \nindices.breaker.request.limit: 60%\nindices.fielddata.cache.size: 30% \nindices.queries.cache.size: 10%\nindices.requests.cache.size: 2%\nindices.recovery.max_bytes_per_sec: 20mb\n</code></pre>\n<p>启动es：</p>\n<pre><code>sudo -u elasticsearch ./bin/elasticsearch -d \n</code></pre>\n<h2 id=\"配置kibana\"><a href=\"#配置kibana\" class=\"headerlink\" title=\"配置kibana\"></a>配置kibana</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gz\n[root@test03 local]# tar -zxvf kibana-6.3.2-linux-x86_64.tar.gz\n</code></pre>\n<p>配置kibana：</p>\n<pre><code>[root@test03 kibana-6.3.2-linux-x86_64]# grep -Ev &#39;^$|#&#39; config/kibana.yml\nserver.port: 5601\nserver.host: &quot;192.168.1.1&quot;\nelasticsearch.url: &quot;http://192.168.1.1:9200&quot;\nkibana.index: &quot;.kibana&quot;\nelasticsearch.pingTimeout: 2500\nelasticsearch.requestTimeout: 60000\n</code></pre>\n<p>启动kibana：</p>\n<pre><code>nohup ./bin/kibana &amp;\n</code></pre>\n<h2 id=\"配置granfan\"><a href=\"#配置granfan\" class=\"headerlink\" title=\"配置granfan\"></a>配置granfan</h2><p>下载软件：</p>\n<pre><code>[root@test03 local]# wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2.linux-amd64.tar.gz \n[root@test03 local]# tar -zxvf grafana-5.2.2.linux-amd64.tar.gz \n</code></pre>\n<p>启动：</p>\n<pre><code>[root@test03 grafana-5.2.2]# nohup ./bin/grafana-server  &amp; \n</code></pre>\n<h2 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h2><p><img src=\"https://owelinux.github.io/images/2018-08-22-article16-linux-elk/kibana-filebeat.png\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/beats/filebeat/current/index.html\">https://www.elastic.co/guide/en/beats/filebeat/current/index.html</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"Elas2.3.4升级到es5.X","date":"2018-08-23T10:41:54.000Z","author":"owelinux","excerpt":"Elas2.3.4升级到es5.X","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Elas2.3.4升级到es5.X\n\n## 1、Disable shard allocation\n```\ncurl -XPOST http://127.0.0.1:9200/_flush/synced\n\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": \"none\"\n  }\n}'\n```\n\n## 2、Perform a synced flush\n```\ncurl -XPOST http://127.0.0.1:9200/_flush/synced\n```\n\n## 3、Shutdown and upgrade all nodes\n```\ncurl -XPOST http://127.0.0.1:9200/_cluster/nodes/_local/_shutdown\n```\n\n## 4、Upgrade any plugins\n\n\n## 5、Start the cluster\n```\ncurl -XGET  http://127.0.0.1:9200/_cat/health\ncurl -XGET  http://127.0.0.1:9200/_cat/nodes\n```\n\n## 6、Wait for yellow\n\n## 7、Reenable allocation\n```\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": \"all\"\n  }\n}'\n\ncurl -XGET  http://127.0.0.1:9200/_cat/health\n\ncurl -XGET  http://127.0.0.1:9200/_cat/recovery\n```\n\n## 参考\n> * [https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html)","source":"_posts/2018-08-23-article17-linux-update-es.md","raw":"---\nlayout: post\ntitle:  \"Elas2.3.4升级到es5.X\"\ndate:   2018-08-23 18:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux  ELK \nexcerpt: Elas2.3.4升级到es5.X\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Elas2.3.4升级到es5.X\n\n## 1、Disable shard allocation\n```\ncurl -XPOST http://127.0.0.1:9200/_flush/synced\n\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": \"none\"\n  }\n}'\n```\n\n## 2、Perform a synced flush\n```\ncurl -XPOST http://127.0.0.1:9200/_flush/synced\n```\n\n## 3、Shutdown and upgrade all nodes\n```\ncurl -XPOST http://127.0.0.1:9200/_cluster/nodes/_local/_shutdown\n```\n\n## 4、Upgrade any plugins\n\n\n## 5、Start the cluster\n```\ncurl -XGET  http://127.0.0.1:9200/_cat/health\ncurl -XGET  http://127.0.0.1:9200/_cat/nodes\n```\n\n## 6、Wait for yellow\n\n## 7、Reenable allocation\n```\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": \"all\"\n  }\n}'\n\ncurl -XGET  http://127.0.0.1:9200/_cat/health\n\ncurl -XGET  http://127.0.0.1:9200/_cat/recovery\n```\n\n## 参考\n> * [https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html)","slug":"2018-08-23-article17-linux-update-es","published":1,"updated":"2021-02-09T02:00:24.568Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq03000vyc976rlvcz6f","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Elas2-3-4升级到es5-X\"><a href=\"#Elas2-3-4升级到es5-X\" class=\"headerlink\" title=\"Elas2.3.4升级到es5.X\"></a>Elas2.3.4升级到es5.X</h1><h2 id=\"1、Disable-shard-allocation\"><a href=\"#1、Disable-shard-allocation\" class=\"headerlink\" title=\"1、Disable shard allocation\"></a>1、Disable shard allocation</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_flush/synced\n\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d&#39;\n&#123;\n  &quot;persistent&quot;: &#123;\n    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;\n  &#125;\n&#125;&#39;\n</code></pre>\n<h2 id=\"2、Perform-a-synced-flush\"><a href=\"#2、Perform-a-synced-flush\" class=\"headerlink\" title=\"2、Perform a synced flush\"></a>2、Perform a synced flush</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_flush/synced\n</code></pre>\n<h2 id=\"3、Shutdown-and-upgrade-all-nodes\"><a href=\"#3、Shutdown-and-upgrade-all-nodes\" class=\"headerlink\" title=\"3、Shutdown and upgrade all nodes\"></a>3、Shutdown and upgrade all nodes</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_cluster/nodes/_local/_shutdown\n</code></pre>\n<h2 id=\"4、Upgrade-any-plugins\"><a href=\"#4、Upgrade-any-plugins\" class=\"headerlink\" title=\"4、Upgrade any plugins\"></a>4、Upgrade any plugins</h2><h2 id=\"5、Start-the-cluster\"><a href=\"#5、Start-the-cluster\" class=\"headerlink\" title=\"5、Start the cluster\"></a>5、Start the cluster</h2><pre><code>curl -XGET  http://127.0.0.1:9200/_cat/health\ncurl -XGET  http://127.0.0.1:9200/_cat/nodes\n</code></pre>\n<h2 id=\"6、Wait-for-yellow\"><a href=\"#6、Wait-for-yellow\" class=\"headerlink\" title=\"6、Wait for yellow\"></a>6、Wait for yellow</h2><h2 id=\"7、Reenable-allocation\"><a href=\"#7、Reenable-allocation\" class=\"headerlink\" title=\"7、Reenable allocation\"></a>7、Reenable allocation</h2><pre><code>curl -XPUT http://127.0.0.1:9200/_cluster/settings -d&#39;\n&#123;\n  &quot;persistent&quot;: &#123;\n    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;\n  &#125;\n&#125;&#39;\n\ncurl -XGET  http://127.0.0.1:9200/_cat/health\n\ncurl -XGET  http://127.0.0.1:9200/_cat/recovery\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html\">https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Elas2-3-4升级到es5-X\"><a href=\"#Elas2-3-4升级到es5-X\" class=\"headerlink\" title=\"Elas2.3.4升级到es5.X\"></a>Elas2.3.4升级到es5.X</h1><h2 id=\"1、Disable-shard-allocation\"><a href=\"#1、Disable-shard-allocation\" class=\"headerlink\" title=\"1、Disable shard allocation\"></a>1、Disable shard allocation</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_flush/synced\n\ncurl -XPUT http://127.0.0.1:9200/_cluster/settings -d&#39;\n&#123;\n  &quot;persistent&quot;: &#123;\n    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;\n  &#125;\n&#125;&#39;\n</code></pre>\n<h2 id=\"2、Perform-a-synced-flush\"><a href=\"#2、Perform-a-synced-flush\" class=\"headerlink\" title=\"2、Perform a synced flush\"></a>2、Perform a synced flush</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_flush/synced\n</code></pre>\n<h2 id=\"3、Shutdown-and-upgrade-all-nodes\"><a href=\"#3、Shutdown-and-upgrade-all-nodes\" class=\"headerlink\" title=\"3、Shutdown and upgrade all nodes\"></a>3、Shutdown and upgrade all nodes</h2><pre><code>curl -XPOST http://127.0.0.1:9200/_cluster/nodes/_local/_shutdown\n</code></pre>\n<h2 id=\"4、Upgrade-any-plugins\"><a href=\"#4、Upgrade-any-plugins\" class=\"headerlink\" title=\"4、Upgrade any plugins\"></a>4、Upgrade any plugins</h2><h2 id=\"5、Start-the-cluster\"><a href=\"#5、Start-the-cluster\" class=\"headerlink\" title=\"5、Start the cluster\"></a>5、Start the cluster</h2><pre><code>curl -XGET  http://127.0.0.1:9200/_cat/health\ncurl -XGET  http://127.0.0.1:9200/_cat/nodes\n</code></pre>\n<h2 id=\"6、Wait-for-yellow\"><a href=\"#6、Wait-for-yellow\" class=\"headerlink\" title=\"6、Wait for yellow\"></a>6、Wait for yellow</h2><h2 id=\"7、Reenable-allocation\"><a href=\"#7、Reenable-allocation\" class=\"headerlink\" title=\"7、Reenable allocation\"></a>7、Reenable allocation</h2><pre><code>curl -XPUT http://127.0.0.1:9200/_cluster/settings -d&#39;\n&#123;\n  &quot;persistent&quot;: &#123;\n    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;\n  &#125;\n&#125;&#39;\n\ncurl -XGET  http://127.0.0.1:9200/_cat/health\n\ncurl -XGET  http://127.0.0.1:9200/_cat/recovery\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html\">https://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-upgrade.html</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"携程大佬分享es使用心得","date":"2018-08-23T11:41:54.000Z","author":"owelinux","excerpt":"携程大佬分享es使用心得","mathjax":true,"_content":"\n* content\n{:toc}\n\n# 携程大佬分享es使用心得\n\nElasticSearch目前在互联网公司主要用于两种应用场景，其一是用于构建业务的搜索功能模块且多是垂直领域的搜索，数据量级一般在千万至数十亿 这个级别；其二用于大规模数据的实时OLAP，经典的如ELKStack，数据规模可能达到千亿或更多。 这两种场景的数据索引和应用访问模式上差异较大，在硬件选型和集群优化方面侧重点也会有所不同。一般来说后一种场景属于大数据范畴，数据量级和集群规模更 大，在管理方面也更有挑战。\n\n应Medcl大大的邀请，为ES中文社区做今年的Advent开篇，分享一下我在管理自家公司用于日志分析的ES集群方面的一点心得，蜻蜓点水，泛泛而谈，希望大方向上能对大家提供一些帮助。\n\n这里的自家，即是携程旅行网。从2013年开始接触ES，我们团队先后实践过0.9.x -> 5.0.0中间各个版本，从最初只用于运维内部IIS日志的分析，到如今支持IT、呼叫中心、安全、测试、业务研发等多个部门超过200种日志型数据的实 时检索与分析。 一路走来，愉悦了大家，也死磕了自己。\n\n目前我们最大的日志单集群有120个data node，运行于70台物理服务器上。数据规模如下:\n单日索引数据条数600亿，新增索引文件25TB (含一个复制片则为50TB)\n业务高峰期峰值索引速率维持在百万条/秒\n历史数据保留时长根据业务需求制定，从10天 - 90天不等\n集群共3441个索引、17000个分片、数据总量约9300亿, 磁盘总消耗1PB\nKibana用户600多人, 每日来自Kibana和第三方的API调用共63万次\n查询响应时间百分位 75%:0.160s  90%:1.640s 95%:6.691s 99%:14.0039s\n\n运维这样大规模的ES集群，有哪些值得注意的地方？\n\n* 一. 必不可少的工具\n工欲善其事必先利其器，从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提 升会凸显。 官方提供了ES Puppet Module和Chef Cookbook，熟悉这两个工具的同学可以直接拿过来用。 我们自己则是采用的Ansible，编写了一套Playbook来达到类似的效果。 用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。\n第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里 面，sense已经成为一个内置的控制台，无需额外安装。\n\n* 二. 硬件配置\n我们采用的是32vcoreCPU + 128GB RAM的服务器，磁盘配置大部分服务器是12块4TB SATA机械磁盘做的Raid0，少部分机器是刚上了不久的6块800GB SSD raid0，主要目的是想做冷热数据分离，后面谈到集群架构的时候，再进一步解释一下如何利用硬件资源。\n\n* 三. 集群的管理\n首先很有必要对ES的结点做角色划分和隔离。大家知道ES的data node除了放数据以外，也可以兼任master和client的角色，多数同学会将这些角色混入到data node。然而对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的 data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问 题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。\n避免过高的并发，包括控 制shard数量和threadpool的数量。在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。分片过多会带来诸多负面影响，例如：每次 查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢Issue#18776; 过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。 配置过大的threadpool更是会产生很多诡异的性能问题Issue#18161里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。\n冷 热数据最好做分离。对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据， 那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。所以我们用了一部分机器来做冷数据的存储，利用 ES可以给结点配置自定义属性的功能，为冷结点加上\"boxtype\":\"weak\"的标识，每晚通过维护脚本更新冷数据的索引路由设置index.routing.allocation.{require|include|exclude}， 让数据自动向冷结点迁移。 冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引 为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到 10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。\n不同 数据量级的shard最好隔离到不同组别的结点。 大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。其一同一索引下的shard尽量分散到不同的结点;其二每个结点上 的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。 实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就 是如何能比较平衡并充分的利用所有节点的资源。 针对这个问题，我们还是通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制。尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡。\n定 期做索引的force merge，并且最好是每个shard merge成一个segment。前面提到过，heap消耗与segment数量也有关系，force merge可以显著降低这种消耗。 如果merge成一个segment还有一个好处，就是对于terms aggregation，搜索时无需构造Global Ordinals，可以提升聚合速度。\n\n* 四. 版本选择\n我们在2.4版本上稳定跑了很长时间，比较保守的同学可以上2.4，激进有精力折腾的可以考虑最新的5.0。 我们集群两周前从v2.4.0升级到了v5.0.0这个版本，除了升级第一周遇到一个不稳定的问题以外，感觉新版本带来的以下特性还是非常值得去升级的:\n结点启动的Bootstrap过程加入了很多关键系统参数设置的核验，比如Max File Descriptors, Memory Lock, Virtual Memory设置等等，如果设置不正确会拒绝启动并抛出异常。 与其带着错误的系统参数启动，并在日后造成性能问题，不如启动失败告知用户问题，是个很好的设计！\n索引性能提升。升级后在同样索引速率下，我们看到cpu消耗下降非常明显，除了对索引速率提升有帮助，也会一定程度提升搜索速率。\n新的数值型数据结构，存储空间更小，Range和地理位置计算更快速\nInstant Aggregation对于类似now-7d to now这样的范围查询聚合能够做cache了，实际使用下来，效果明显，用户在Kibana上跑个过去一周数据的聚合，头2次刷新慢点，之后有cache了几乎就瞬间刷出！\n更多的保护措施保证集群的稳定，比如对一次搜索hit的shard数量做了限制，增强了circuit breaker的特性，更好的防护集群资源被坏查询耗尽。\n\n升级第一周，我们的冷数据结点出现间歇性不响应问题，从而刨出3个issue提交给官方:\nIssue#21595 Issue#21612 Issue#21611\n第一个问题确认为Bug，将在5.0.2修复，其他两个目前还不清楚根源，看起来也只在我们的应用场景里遇到了。所幸问题都找到了了规避措施，实施这些措施以后，最近一周我们的集群重新回到以前2.4版本时期的稳定状态。\n\n\n* 五. 监控\n不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。 那么多监控指标，最最关键的还是以下几类:\n各类Thread pool的使用情况，active/queue/reject可视化出来。 判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。\nJVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。\nSegment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。 Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。\n很有必要记录用户的访问记录。 我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。\n\n最后就是多上手实践，遇到问题多查官方资料，多Google看是否有其他人遇到同类问题，精力充足有编程背景的同学也可以多刨刨源码。 \n\n# 感谢\n携程xx的分享！！","source":"_posts/2018-08-23-article18-linux-es-think.md","raw":"---\nlayout: post\ntitle:  \"携程大佬分享es使用心得\"\ndate:   2018-08-23 19:41:54\nauthor: owelinux\ncategories: linux \ntags:  linux  ELK \nexcerpt: 携程大佬分享es使用心得\nmathjax: true\n---\n\n* content\n{:toc}\n\n# 携程大佬分享es使用心得\n\nElasticSearch目前在互联网公司主要用于两种应用场景，其一是用于构建业务的搜索功能模块且多是垂直领域的搜索，数据量级一般在千万至数十亿 这个级别；其二用于大规模数据的实时OLAP，经典的如ELKStack，数据规模可能达到千亿或更多。 这两种场景的数据索引和应用访问模式上差异较大，在硬件选型和集群优化方面侧重点也会有所不同。一般来说后一种场景属于大数据范畴，数据量级和集群规模更 大，在管理方面也更有挑战。\n\n应Medcl大大的邀请，为ES中文社区做今年的Advent开篇，分享一下我在管理自家公司用于日志分析的ES集群方面的一点心得，蜻蜓点水，泛泛而谈，希望大方向上能对大家提供一些帮助。\n\n这里的自家，即是携程旅行网。从2013年开始接触ES，我们团队先后实践过0.9.x -> 5.0.0中间各个版本，从最初只用于运维内部IIS日志的分析，到如今支持IT、呼叫中心、安全、测试、业务研发等多个部门超过200种日志型数据的实 时检索与分析。 一路走来，愉悦了大家，也死磕了自己。\n\n目前我们最大的日志单集群有120个data node，运行于70台物理服务器上。数据规模如下:\n单日索引数据条数600亿，新增索引文件25TB (含一个复制片则为50TB)\n业务高峰期峰值索引速率维持在百万条/秒\n历史数据保留时长根据业务需求制定，从10天 - 90天不等\n集群共3441个索引、17000个分片、数据总量约9300亿, 磁盘总消耗1PB\nKibana用户600多人, 每日来自Kibana和第三方的API调用共63万次\n查询响应时间百分位 75%:0.160s  90%:1.640s 95%:6.691s 99%:14.0039s\n\n运维这样大规模的ES集群，有哪些值得注意的地方？\n\n* 一. 必不可少的工具\n工欲善其事必先利其器，从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提 升会凸显。 官方提供了ES Puppet Module和Chef Cookbook，熟悉这两个工具的同学可以直接拿过来用。 我们自己则是采用的Ansible，编写了一套Playbook来达到类似的效果。 用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。\n第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里 面，sense已经成为一个内置的控制台，无需额外安装。\n\n* 二. 硬件配置\n我们采用的是32vcoreCPU + 128GB RAM的服务器，磁盘配置大部分服务器是12块4TB SATA机械磁盘做的Raid0，少部分机器是刚上了不久的6块800GB SSD raid0，主要目的是想做冷热数据分离，后面谈到集群架构的时候，再进一步解释一下如何利用硬件资源。\n\n* 三. 集群的管理\n首先很有必要对ES的结点做角色划分和隔离。大家知道ES的data node除了放数据以外，也可以兼任master和client的角色，多数同学会将这些角色混入到data node。然而对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的 data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问 题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。\n避免过高的并发，包括控 制shard数量和threadpool的数量。在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。分片过多会带来诸多负面影响，例如：每次 查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢Issue#18776; 过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。 配置过大的threadpool更是会产生很多诡异的性能问题Issue#18161里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。\n冷 热数据最好做分离。对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据， 那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。所以我们用了一部分机器来做冷数据的存储，利用 ES可以给结点配置自定义属性的功能，为冷结点加上\"boxtype\":\"weak\"的标识，每晚通过维护脚本更新冷数据的索引路由设置index.routing.allocation.{require|include|exclude}， 让数据自动向冷结点迁移。 冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引 为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到 10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。\n不同 数据量级的shard最好隔离到不同组别的结点。 大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。其一同一索引下的shard尽量分散到不同的结点;其二每个结点上 的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。 实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就 是如何能比较平衡并充分的利用所有节点的资源。 针对这个问题，我们还是通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制。尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡。\n定 期做索引的force merge，并且最好是每个shard merge成一个segment。前面提到过，heap消耗与segment数量也有关系，force merge可以显著降低这种消耗。 如果merge成一个segment还有一个好处，就是对于terms aggregation，搜索时无需构造Global Ordinals，可以提升聚合速度。\n\n* 四. 版本选择\n我们在2.4版本上稳定跑了很长时间，比较保守的同学可以上2.4，激进有精力折腾的可以考虑最新的5.0。 我们集群两周前从v2.4.0升级到了v5.0.0这个版本，除了升级第一周遇到一个不稳定的问题以外，感觉新版本带来的以下特性还是非常值得去升级的:\n结点启动的Bootstrap过程加入了很多关键系统参数设置的核验，比如Max File Descriptors, Memory Lock, Virtual Memory设置等等，如果设置不正确会拒绝启动并抛出异常。 与其带着错误的系统参数启动，并在日后造成性能问题，不如启动失败告知用户问题，是个很好的设计！\n索引性能提升。升级后在同样索引速率下，我们看到cpu消耗下降非常明显，除了对索引速率提升有帮助，也会一定程度提升搜索速率。\n新的数值型数据结构，存储空间更小，Range和地理位置计算更快速\nInstant Aggregation对于类似now-7d to now这样的范围查询聚合能够做cache了，实际使用下来，效果明显，用户在Kibana上跑个过去一周数据的聚合，头2次刷新慢点，之后有cache了几乎就瞬间刷出！\n更多的保护措施保证集群的稳定，比如对一次搜索hit的shard数量做了限制，增强了circuit breaker的特性，更好的防护集群资源被坏查询耗尽。\n\n升级第一周，我们的冷数据结点出现间歇性不响应问题，从而刨出3个issue提交给官方:\nIssue#21595 Issue#21612 Issue#21611\n第一个问题确认为Bug，将在5.0.2修复，其他两个目前还不清楚根源，看起来也只在我们的应用场景里遇到了。所幸问题都找到了了规避措施，实施这些措施以后，最近一周我们的集群重新回到以前2.4版本时期的稳定状态。\n\n\n* 五. 监控\n不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。 那么多监控指标，最最关键的还是以下几类:\n各类Thread pool的使用情况，active/queue/reject可视化出来。 判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。\nJVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。\nSegment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。 Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。\n很有必要记录用户的访问记录。 我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。\n\n最后就是多上手实践，遇到问题多查官方资料，多Google看是否有其他人遇到同类问题，精力充足有编程背景的同学也可以多刨刨源码。 \n\n# 感谢\n携程xx的分享！！","slug":"2018-08-23-article18-linux-es-think","published":1,"updated":"2021-02-09T02:00:24.568Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq04000zyc971c1745wn","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"携程大佬分享es使用心得\"><a href=\"#携程大佬分享es使用心得\" class=\"headerlink\" title=\"携程大佬分享es使用心得\"></a>携程大佬分享es使用心得</h1><p>ElasticSearch目前在互联网公司主要用于两种应用场景，其一是用于构建业务的搜索功能模块且多是垂直领域的搜索，数据量级一般在千万至数十亿 这个级别；其二用于大规模数据的实时OLAP，经典的如ELKStack，数据规模可能达到千亿或更多。 这两种场景的数据索引和应用访问模式上差异较大，在硬件选型和集群优化方面侧重点也会有所不同。一般来说后一种场景属于大数据范畴，数据量级和集群规模更 大，在管理方面也更有挑战。</p>\n<p>应Medcl大大的邀请，为ES中文社区做今年的Advent开篇，分享一下我在管理自家公司用于日志分析的ES集群方面的一点心得，蜻蜓点水，泛泛而谈，希望大方向上能对大家提供一些帮助。</p>\n<p>这里的自家，即是携程旅行网。从2013年开始接触ES，我们团队先后实践过0.9.x -&gt; 5.0.0中间各个版本，从最初只用于运维内部IIS日志的分析，到如今支持IT、呼叫中心、安全、测试、业务研发等多个部门超过200种日志型数据的实 时检索与分析。 一路走来，愉悦了大家，也死磕了自己。</p>\n<p>目前我们最大的日志单集群有120个data node，运行于70台物理服务器上。数据规模如下:<br>单日索引数据条数600亿，新增索引文件25TB (含一个复制片则为50TB)<br>业务高峰期峰值索引速率维持在百万条/秒<br>历史数据保留时长根据业务需求制定，从10天 - 90天不等<br>集群共3441个索引、17000个分片、数据总量约9300亿, 磁盘总消耗1PB<br>Kibana用户600多人, 每日来自Kibana和第三方的API调用共63万次<br>查询响应时间百分位 75%:0.160s  90%:1.640s 95%:6.691s 99%:14.0039s</p>\n<p>运维这样大规模的ES集群，有哪些值得注意的地方？</p>\n<ul>\n<li><p>一. 必不可少的工具<br>工欲善其事必先利其器，从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提 升会凸显。 官方提供了ES Puppet Module和Chef Cookbook，熟悉这两个工具的同学可以直接拿过来用。 我们自己则是采用的Ansible，编写了一套Playbook来达到类似的效果。 用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。<br>第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里 面，sense已经成为一个内置的控制台，无需额外安装。</p>\n</li>\n<li><p>二. 硬件配置<br>我们采用的是32vcoreCPU + 128GB RAM的服务器，磁盘配置大部分服务器是12块4TB SATA机械磁盘做的Raid0，少部分机器是刚上了不久的6块800GB SSD raid0，主要目的是想做冷热数据分离，后面谈到集群架构的时候，再进一步解释一下如何利用硬件资源。</p>\n</li>\n<li><p>三. 集群的管理<br>首先很有必要对ES的结点做角色划分和隔离。大家知道ES的data node除了放数据以外，也可以兼任master和client的角色，多数同学会将这些角色混入到data node。然而对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的 data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问 题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。<br>避免过高的并发，包括控 制shard数量和threadpool的数量。在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。分片过多会带来诸多负面影响，例如：每次 查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢Issue#18776; 过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。 配置过大的threadpool更是会产生很多诡异的性能问题Issue#18161里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。<br>冷 热数据最好做分离。对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据， 那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。所以我们用了一部分机器来做冷数据的存储，利用 ES可以给结点配置自定义属性的功能，为冷结点加上”boxtype”:”weak”的标识，每晚通过维护脚本更新冷数据的索引路由设置index.routing.allocation.{require|include|exclude}， 让数据自动向冷结点迁移。 冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引 为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到 10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。<br>不同 数据量级的shard最好隔离到不同组别的结点。 大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。其一同一索引下的shard尽量分散到不同的结点;其二每个结点上 的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。 实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就 是如何能比较平衡并充分的利用所有节点的资源。 针对这个问题，我们还是通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制。尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡。<br>定 期做索引的force merge，并且最好是每个shard merge成一个segment。前面提到过，heap消耗与segment数量也有关系，force merge可以显著降低这种消耗。 如果merge成一个segment还有一个好处，就是对于terms aggregation，搜索时无需构造Global Ordinals，可以提升聚合速度。</p>\n</li>\n<li><p>四. 版本选择<br>我们在2.4版本上稳定跑了很长时间，比较保守的同学可以上2.4，激进有精力折腾的可以考虑最新的5.0。 我们集群两周前从v2.4.0升级到了v5.0.0这个版本，除了升级第一周遇到一个不稳定的问题以外，感觉新版本带来的以下特性还是非常值得去升级的:<br>结点启动的Bootstrap过程加入了很多关键系统参数设置的核验，比如Max File Descriptors, Memory Lock, Virtual Memory设置等等，如果设置不正确会拒绝启动并抛出异常。 与其带着错误的系统参数启动，并在日后造成性能问题，不如启动失败告知用户问题，是个很好的设计！<br>索引性能提升。升级后在同样索引速率下，我们看到cpu消耗下降非常明显，除了对索引速率提升有帮助，也会一定程度提升搜索速率。<br>新的数值型数据结构，存储空间更小，Range和地理位置计算更快速<br>Instant Aggregation对于类似now-7d to now这样的范围查询聚合能够做cache了，实际使用下来，效果明显，用户在Kibana上跑个过去一周数据的聚合，头2次刷新慢点，之后有cache了几乎就瞬间刷出！<br>更多的保护措施保证集群的稳定，比如对一次搜索hit的shard数量做了限制，增强了circuit breaker的特性，更好的防护集群资源被坏查询耗尽。</p>\n</li>\n</ul>\n<p>升级第一周，我们的冷数据结点出现间歇性不响应问题，从而刨出3个issue提交给官方:<br>Issue#21595 Issue#21612 Issue#21611<br>第一个问题确认为Bug，将在5.0.2修复，其他两个目前还不清楚根源，看起来也只在我们的应用场景里遇到了。所幸问题都找到了了规避措施，实施这些措施以后，最近一周我们的集群重新回到以前2.4版本时期的稳定状态。</p>\n<ul>\n<li>五. 监控<br>不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。 那么多监控指标，最最关键的还是以下几类:<br>各类Thread pool的使用情况，active/queue/reject可视化出来。 判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。<br>JVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。<br>Segment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。 Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。<br>很有必要记录用户的访问记录。 我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。</li>\n</ul>\n<p>最后就是多上手实践，遇到问题多查官方资料，多Google看是否有其他人遇到同类问题，精力充足有编程背景的同学也可以多刨刨源码。 </p>\n<h1 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h1><p>携程xx的分享！！</p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"携程大佬分享es使用心得\"><a href=\"#携程大佬分享es使用心得\" class=\"headerlink\" title=\"携程大佬分享es使用心得\"></a>携程大佬分享es使用心得</h1><p>ElasticSearch目前在互联网公司主要用于两种应用场景，其一是用于构建业务的搜索功能模块且多是垂直领域的搜索，数据量级一般在千万至数十亿 这个级别；其二用于大规模数据的实时OLAP，经典的如ELKStack，数据规模可能达到千亿或更多。 这两种场景的数据索引和应用访问模式上差异较大，在硬件选型和集群优化方面侧重点也会有所不同。一般来说后一种场景属于大数据范畴，数据量级和集群规模更 大，在管理方面也更有挑战。</p>\n<p>应Medcl大大的邀请，为ES中文社区做今年的Advent开篇，分享一下我在管理自家公司用于日志分析的ES集群方面的一点心得，蜻蜓点水，泛泛而谈，希望大方向上能对大家提供一些帮助。</p>\n<p>这里的自家，即是携程旅行网。从2013年开始接触ES，我们团队先后实践过0.9.x -&gt; 5.0.0中间各个版本，从最初只用于运维内部IIS日志的分析，到如今支持IT、呼叫中心、安全、测试、业务研发等多个部门超过200种日志型数据的实 时检索与分析。 一路走来，愉悦了大家，也死磕了自己。</p>\n<p>目前我们最大的日志单集群有120个data node，运行于70台物理服务器上。数据规模如下:<br>单日索引数据条数600亿，新增索引文件25TB (含一个复制片则为50TB)<br>业务高峰期峰值索引速率维持在百万条/秒<br>历史数据保留时长根据业务需求制定，从10天 - 90天不等<br>集群共3441个索引、17000个分片、数据总量约9300亿, 磁盘总消耗1PB<br>Kibana用户600多人, 每日来自Kibana和第三方的API调用共63万次<br>查询响应时间百分位 75%:0.160s  90%:1.640s 95%:6.691s 99%:14.0039s</p>\n<p>运维这样大规模的ES集群，有哪些值得注意的地方？</p>\n<ul>\n<li><p>一. 必不可少的工具<br>工欲善其事必先利其器，从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提 升会凸显。 官方提供了ES Puppet Module和Chef Cookbook，熟悉这两个工具的同学可以直接拿过来用。 我们自己则是采用的Ansible，编写了一套Playbook来达到类似的效果。 用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。<br>第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里 面，sense已经成为一个内置的控制台，无需额外安装。</p>\n</li>\n<li><p>二. 硬件配置<br>我们采用的是32vcoreCPU + 128GB RAM的服务器，磁盘配置大部分服务器是12块4TB SATA机械磁盘做的Raid0，少部分机器是刚上了不久的6块800GB SSD raid0，主要目的是想做冷热数据分离，后面谈到集群架构的时候，再进一步解释一下如何利用硬件资源。</p>\n</li>\n<li><p>三. 集群的管理<br>首先很有必要对ES的结点做角色划分和隔离。大家知道ES的data node除了放数据以外，也可以兼任master和client的角色，多数同学会将这些角色混入到data node。然而对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的 data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问 题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。<br>避免过高的并发，包括控 制shard数量和threadpool的数量。在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。分片过多会带来诸多负面影响，例如：每次 查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢Issue#18776; 过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。 配置过大的threadpool更是会产生很多诡异的性能问题Issue#18161里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。<br>冷 热数据最好做分离。对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据， 那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。所以我们用了一部分机器来做冷数据的存储，利用 ES可以给结点配置自定义属性的功能，为冷结点加上”boxtype”:”weak”的标识，每晚通过维护脚本更新冷数据的索引路由设置index.routing.allocation.{require|include|exclude}， 让数据自动向冷结点迁移。 冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引 为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到 10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。<br>不同 数据量级的shard最好隔离到不同组别的结点。 大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。其一同一索引下的shard尽量分散到不同的结点;其二每个结点上 的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。 实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就 是如何能比较平衡并充分的利用所有节点的资源。 针对这个问题，我们还是通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制。尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡。<br>定 期做索引的force merge，并且最好是每个shard merge成一个segment。前面提到过，heap消耗与segment数量也有关系，force merge可以显著降低这种消耗。 如果merge成一个segment还有一个好处，就是对于terms aggregation，搜索时无需构造Global Ordinals，可以提升聚合速度。</p>\n</li>\n<li><p>四. 版本选择<br>我们在2.4版本上稳定跑了很长时间，比较保守的同学可以上2.4，激进有精力折腾的可以考虑最新的5.0。 我们集群两周前从v2.4.0升级到了v5.0.0这个版本，除了升级第一周遇到一个不稳定的问题以外，感觉新版本带来的以下特性还是非常值得去升级的:<br>结点启动的Bootstrap过程加入了很多关键系统参数设置的核验，比如Max File Descriptors, Memory Lock, Virtual Memory设置等等，如果设置不正确会拒绝启动并抛出异常。 与其带着错误的系统参数启动，并在日后造成性能问题，不如启动失败告知用户问题，是个很好的设计！<br>索引性能提升。升级后在同样索引速率下，我们看到cpu消耗下降非常明显，除了对索引速率提升有帮助，也会一定程度提升搜索速率。<br>新的数值型数据结构，存储空间更小，Range和地理位置计算更快速<br>Instant Aggregation对于类似now-7d to now这样的范围查询聚合能够做cache了，实际使用下来，效果明显，用户在Kibana上跑个过去一周数据的聚合，头2次刷新慢点，之后有cache了几乎就瞬间刷出！<br>更多的保护措施保证集群的稳定，比如对一次搜索hit的shard数量做了限制，增强了circuit breaker的特性，更好的防护集群资源被坏查询耗尽。</p>\n</li>\n</ul>\n<p>升级第一周，我们的冷数据结点出现间歇性不响应问题，从而刨出3个issue提交给官方:<br>Issue#21595 Issue#21612 Issue#21611<br>第一个问题确认为Bug，将在5.0.2修复，其他两个目前还不清楚根源，看起来也只在我们的应用场景里遇到了。所幸问题都找到了了规避措施，实施这些措施以后，最近一周我们的集群重新回到以前2.4版本时期的稳定状态。</p>\n<ul>\n<li>五. 监控<br>不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。 那么多监控指标，最最关键的还是以下几类:<br>各类Thread pool的使用情况，active/queue/reject可视化出来。 判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。<br>JVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。<br>Segment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。 Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。<br>很有必要记录用户的访问记录。 我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。</li>\n</ul>\n<p>最后就是多上手实践，遇到问题多查官方资料，多Google看是否有其他人遇到同类问题，精力充足有编程背景的同学也可以多刨刨源码。 </p>\n<h1 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h1><p>携程xx的分享！！</p>\n"},{"layout":"post","title":"Telegraf+Infludb+Grafana构建可视化监控系统","date":"2018-08-24T07:37:54.000Z","author":"owelinux","excerpt":"Telegraf+Infludb+Grafana构建可视化监控系统","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Telegraf+Infludb+Grafana构建可视化监控系统\n\n## telegraf介绍\nTelegraf是TICK Stack的一部分，是一个插件驱动的服务器代理，用于收集和报告指标。 Telegraf集成了直接从其运行的容器和系统中提取各种指标，事件和日志，从第三方API提取指标，甚至通过StatsD和Kafka消费者服务监听指标。它还具有输出插件，可将指标发送到各种其他数据存储，服务和消息队列，包括InfluxDB，Graphite，OpenTSDB，Datadog，Librato，Kafka，MQTT，NSQ等等。\n\n![](https://2bjee8bvp8y263sjpl3xui1a-wpengine.netdna-ssl.com/wp-content/uploads/Tick-Stack-Telegraf-2.png)\n\n### telegraf部署\n```\n$ wget https://dl.influxdata.com/telegraf/releases/telegraf-1.7.3_linux_amd64.tar.gz\n$ tar xf telegraf-1.7.3_linux_amd64.tar.gz\n```\n\n### telegraf配置及优化\n```\n[global_tags]\n[agent]\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n  debug = false\n  quiet = false\n  logfile = \"\"\n  hostname = \"192.168.1.1\"\n  omit_hostname = false\n\n[[outputs.influxdb]]\n  urls = [\"http://192.168.1.1:8086\"]\n  database = \"telegraf\"\n  precision = \"s\"\n  timeout = \"5s\"\n  username = \"monitor\"\n  password = \"EMZ1LdVUu0pMXbkaoPzpCO9S1J2bqvPi\"\n\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = true\n  collect_cpu_time = false\n  report_active = false\n\n[[inputs.disk]]\n  ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\"]\n\n[[inputs.diskio]]\n\n[[inputs.kernel]]\n\n[[inputs.mem]]\n\n[[inputs.processes]]\n\n[[inputs.swap]]\n\n[[inputs.system]]\n\n[[inputs.netstat]]\n\n[[inputs.net]]\n  interfaces = [\"eth0\"]\n\n#[[inputs.zookeeper]]\n# servers = [\"192.168.1.1:2181\"]\n```\n\n### telegraf启动\n```\n$ nohup /usr/local/telegraf/usr/bin/telegraf --config /usr/local/telegraf/etc/telegraf/telegraf.conf & \n```\n\n## infludb介绍\n聆听翻译 InfluxDB用作涉及大量带时间戳数据的任何用例的数据存储，包括DevOps监控，日志数据，应用程序指标，物联网传感器数据和实时分析。通过配置InfluxDB来保存机器上的空间，以便将数据保留一段定义的时间，自动使系统中不需要的数据到期和删除。 InfluxDB还提供类似SQL的查询语言，用于与数据交互。\n\n### infludb部署\n```\n$ wget https://dl.influxdata.com/influxdb/releases/influxdb-1.6.1_linux_amd64.tar.gz\n$ tar xvfz influxdb-1.6.1_linux_amd64.tar.gz\n```\n### influbd启动\n```\n$ nohup /usr/local/influxdb/usr/bin/influxd &\n```\n\n### 创建数据库及配置权限\n```\n$ influx\n$ create database telegraf\n\n# 显示用户\n$ SHOW USERS\n\n# 创建用户\n$ CREATE USER \"username\" WITH PASSWORD 'password'\n\n# 创建管理员权限的用户\n$ CREATE USER \"username\" WITH PASSWORD 'password' WITH ALL PRIVILEGES\n\n# 删除用户\n$ DROP USER \"username\"\n```\n\n### 数据保存策略\n\n查看当前数据库的Retention Policies\n```\n$ SHOW RETENTION POLICIES ON \"testDB\"\n```\n\n创建新的Retention Policies\n```\n$ CREATE RETENTION POLICY \"rp_name\" ON \"db_name\" DURATION 30d REPLICATION 1 DEFAULT\n```\n\n其中：\n* 1. rp_name：策略名\n* 2. db_name：具体的数据库名\n* 3. 30d：保存30天，30天之前的数据将被删除,它具有各种时间参数，比如：h（小时），w（星期）\n* 4. REPLICATION 1：副本个数，这里填1就可以了\n* 5. DEFAULT 设为默认的策略\n\n修改Retention Policies\n```\n$ ALTER RETENTION POLICY \"rp_name\" ON \"db_name\" DURATION 3w DEFAULT\n```\n\n删除Retention Policies\n```\n$ DROP RETENTION POLICY \"rp_name\" ON \"db_name\"\n```\n\n### 最终效果\n![](https://owelinux.github.io/images/2018-08-24-article19-linux-telegraf-infludb/telegraf-Infludb.png)\n\n模板采用：[https://grafana.com/dashboards/914](https://grafana.com/dashboards/914)\n\n## 参考\n> * [https://www.influxdata.com/time-series-platform/telegraf/](https://www.influxdata.com/time-series-platform/telegraf/)\n> * [https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/](https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/)\n> * [https://kiswo.com/article/1020](https://kiswo.com/article/1020)\n> * [https://www.linuxdaxue.com/series/influxdb-series/](https://www.linuxdaxue.com/series/influxdb-series/)","source":"_posts/2018-08-24-article19-linux-telegraf-infludb.md","raw":"---\nlayout: post\ntitle:  \"Telegraf+Infludb+Grafana构建可视化监控系统\"\ndate:   2018-08-24 15:37:54\nauthor: owelinux\ncategories: linux \ntags:  linux  telegraf infludb granfan\nexcerpt: Telegraf+Infludb+Grafana构建可视化监控系统\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Telegraf+Infludb+Grafana构建可视化监控系统\n\n## telegraf介绍\nTelegraf是TICK Stack的一部分，是一个插件驱动的服务器代理，用于收集和报告指标。 Telegraf集成了直接从其运行的容器和系统中提取各种指标，事件和日志，从第三方API提取指标，甚至通过StatsD和Kafka消费者服务监听指标。它还具有输出插件，可将指标发送到各种其他数据存储，服务和消息队列，包括InfluxDB，Graphite，OpenTSDB，Datadog，Librato，Kafka，MQTT，NSQ等等。\n\n![](https://2bjee8bvp8y263sjpl3xui1a-wpengine.netdna-ssl.com/wp-content/uploads/Tick-Stack-Telegraf-2.png)\n\n### telegraf部署\n```\n$ wget https://dl.influxdata.com/telegraf/releases/telegraf-1.7.3_linux_amd64.tar.gz\n$ tar xf telegraf-1.7.3_linux_amd64.tar.gz\n```\n\n### telegraf配置及优化\n```\n[global_tags]\n[agent]\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n  debug = false\n  quiet = false\n  logfile = \"\"\n  hostname = \"192.168.1.1\"\n  omit_hostname = false\n\n[[outputs.influxdb]]\n  urls = [\"http://192.168.1.1:8086\"]\n  database = \"telegraf\"\n  precision = \"s\"\n  timeout = \"5s\"\n  username = \"monitor\"\n  password = \"EMZ1LdVUu0pMXbkaoPzpCO9S1J2bqvPi\"\n\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = true\n  collect_cpu_time = false\n  report_active = false\n\n[[inputs.disk]]\n  ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\"]\n\n[[inputs.diskio]]\n\n[[inputs.kernel]]\n\n[[inputs.mem]]\n\n[[inputs.processes]]\n\n[[inputs.swap]]\n\n[[inputs.system]]\n\n[[inputs.netstat]]\n\n[[inputs.net]]\n  interfaces = [\"eth0\"]\n\n#[[inputs.zookeeper]]\n# servers = [\"192.168.1.1:2181\"]\n```\n\n### telegraf启动\n```\n$ nohup /usr/local/telegraf/usr/bin/telegraf --config /usr/local/telegraf/etc/telegraf/telegraf.conf & \n```\n\n## infludb介绍\n聆听翻译 InfluxDB用作涉及大量带时间戳数据的任何用例的数据存储，包括DevOps监控，日志数据，应用程序指标，物联网传感器数据和实时分析。通过配置InfluxDB来保存机器上的空间，以便将数据保留一段定义的时间，自动使系统中不需要的数据到期和删除。 InfluxDB还提供类似SQL的查询语言，用于与数据交互。\n\n### infludb部署\n```\n$ wget https://dl.influxdata.com/influxdb/releases/influxdb-1.6.1_linux_amd64.tar.gz\n$ tar xvfz influxdb-1.6.1_linux_amd64.tar.gz\n```\n### influbd启动\n```\n$ nohup /usr/local/influxdb/usr/bin/influxd &\n```\n\n### 创建数据库及配置权限\n```\n$ influx\n$ create database telegraf\n\n# 显示用户\n$ SHOW USERS\n\n# 创建用户\n$ CREATE USER \"username\" WITH PASSWORD 'password'\n\n# 创建管理员权限的用户\n$ CREATE USER \"username\" WITH PASSWORD 'password' WITH ALL PRIVILEGES\n\n# 删除用户\n$ DROP USER \"username\"\n```\n\n### 数据保存策略\n\n查看当前数据库的Retention Policies\n```\n$ SHOW RETENTION POLICIES ON \"testDB\"\n```\n\n创建新的Retention Policies\n```\n$ CREATE RETENTION POLICY \"rp_name\" ON \"db_name\" DURATION 30d REPLICATION 1 DEFAULT\n```\n\n其中：\n* 1. rp_name：策略名\n* 2. db_name：具体的数据库名\n* 3. 30d：保存30天，30天之前的数据将被删除,它具有各种时间参数，比如：h（小时），w（星期）\n* 4. REPLICATION 1：副本个数，这里填1就可以了\n* 5. DEFAULT 设为默认的策略\n\n修改Retention Policies\n```\n$ ALTER RETENTION POLICY \"rp_name\" ON \"db_name\" DURATION 3w DEFAULT\n```\n\n删除Retention Policies\n```\n$ DROP RETENTION POLICY \"rp_name\" ON \"db_name\"\n```\n\n### 最终效果\n![](https://owelinux.github.io/images/2018-08-24-article19-linux-telegraf-infludb/telegraf-Infludb.png)\n\n模板采用：[https://grafana.com/dashboards/914](https://grafana.com/dashboards/914)\n\n## 参考\n> * [https://www.influxdata.com/time-series-platform/telegraf/](https://www.influxdata.com/time-series-platform/telegraf/)\n> * [https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/](https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/)\n> * [https://kiswo.com/article/1020](https://kiswo.com/article/1020)\n> * [https://www.linuxdaxue.com/series/influxdb-series/](https://www.linuxdaxue.com/series/influxdb-series/)","slug":"2018-08-24-article19-linux-telegraf-infludb","published":1,"updated":"2021-02-09T02:00:24.569Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq050012yc97bfg04ddz","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Telegraf-Infludb-Grafana构建可视化监控系统\"><a href=\"#Telegraf-Infludb-Grafana构建可视化监控系统\" class=\"headerlink\" title=\"Telegraf+Infludb+Grafana构建可视化监控系统\"></a>Telegraf+Infludb+Grafana构建可视化监控系统</h1><h2 id=\"telegraf介绍\"><a href=\"#telegraf介绍\" class=\"headerlink\" title=\"telegraf介绍\"></a>telegraf介绍</h2><p>Telegraf是TICK Stack的一部分，是一个插件驱动的服务器代理，用于收集和报告指标。 Telegraf集成了直接从其运行的容器和系统中提取各种指标，事件和日志，从第三方API提取指标，甚至通过StatsD和Kafka消费者服务监听指标。它还具有输出插件，可将指标发送到各种其他数据存储，服务和消息队列，包括InfluxDB，Graphite，OpenTSDB，Datadog，Librato，Kafka，MQTT，NSQ等等。</p>\n<p><img src=\"https://2bjee8bvp8y263sjpl3xui1a-wpengine.netdna-ssl.com/wp-content/uploads/Tick-Stack-Telegraf-2.png\"></p>\n<h3 id=\"telegraf部署\"><a href=\"#telegraf部署\" class=\"headerlink\" title=\"telegraf部署\"></a>telegraf部署</h3><pre><code>$ wget https://dl.influxdata.com/telegraf/releases/telegraf-1.7.3_linux_amd64.tar.gz\n$ tar xf telegraf-1.7.3_linux_amd64.tar.gz\n</code></pre>\n<h3 id=\"telegraf配置及优化\"><a href=\"#telegraf配置及优化\" class=\"headerlink\" title=\"telegraf配置及优化\"></a>telegraf配置及优化</h3><pre><code>[global_tags]\n[agent]\n  interval = &quot;10s&quot;\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = &quot;0s&quot;\n  flush_interval = &quot;10s&quot;\n  flush_jitter = &quot;0s&quot;\n  precision = &quot;&quot;\n  debug = false\n  quiet = false\n  logfile = &quot;&quot;\n  hostname = &quot;192.168.1.1&quot;\n  omit_hostname = false\n\n[[outputs.influxdb]]\n  urls = [&quot;http://192.168.1.1:8086&quot;]\n  database = &quot;telegraf&quot;\n  precision = &quot;s&quot;\n  timeout = &quot;5s&quot;\n  username = &quot;monitor&quot;\n  password = &quot;EMZ1LdVUu0pMXbkaoPzpCO9S1J2bqvPi&quot;\n\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = true\n  collect_cpu_time = false\n  report_active = false\n\n[[inputs.disk]]\n  ignore_fs = [&quot;tmpfs&quot;, &quot;devtmpfs&quot;, &quot;devfs&quot;]\n\n[[inputs.diskio]]\n\n[[inputs.kernel]]\n\n[[inputs.mem]]\n\n[[inputs.processes]]\n\n[[inputs.swap]]\n\n[[inputs.system]]\n\n[[inputs.netstat]]\n\n[[inputs.net]]\n  interfaces = [&quot;eth0&quot;]\n\n#[[inputs.zookeeper]]\n# servers = [&quot;192.168.1.1:2181&quot;]\n</code></pre>\n<h3 id=\"telegraf启动\"><a href=\"#telegraf启动\" class=\"headerlink\" title=\"telegraf启动\"></a>telegraf启动</h3><pre><code>$ nohup /usr/local/telegraf/usr/bin/telegraf --config /usr/local/telegraf/etc/telegraf/telegraf.conf &amp; \n</code></pre>\n<h2 id=\"infludb介绍\"><a href=\"#infludb介绍\" class=\"headerlink\" title=\"infludb介绍\"></a>infludb介绍</h2><p>聆听翻译 InfluxDB用作涉及大量带时间戳数据的任何用例的数据存储，包括DevOps监控，日志数据，应用程序指标，物联网传感器数据和实时分析。通过配置InfluxDB来保存机器上的空间，以便将数据保留一段定义的时间，自动使系统中不需要的数据到期和删除。 InfluxDB还提供类似SQL的查询语言，用于与数据交互。</p>\n<h3 id=\"infludb部署\"><a href=\"#infludb部署\" class=\"headerlink\" title=\"infludb部署\"></a>infludb部署</h3><pre><code>$ wget https://dl.influxdata.com/influxdb/releases/influxdb-1.6.1_linux_amd64.tar.gz\n$ tar xvfz influxdb-1.6.1_linux_amd64.tar.gz\n</code></pre>\n<h3 id=\"influbd启动\"><a href=\"#influbd启动\" class=\"headerlink\" title=\"influbd启动\"></a>influbd启动</h3><pre><code>$ nohup /usr/local/influxdb/usr/bin/influxd &amp;\n</code></pre>\n<h3 id=\"创建数据库及配置权限\"><a href=\"#创建数据库及配置权限\" class=\"headerlink\" title=\"创建数据库及配置权限\"></a>创建数据库及配置权限</h3><pre><code>$ influx\n$ create database telegraf\n\n# 显示用户\n$ SHOW USERS\n\n# 创建用户\n$ CREATE USER &quot;username&quot; WITH PASSWORD &#39;password&#39;\n\n# 创建管理员权限的用户\n$ CREATE USER &quot;username&quot; WITH PASSWORD &#39;password&#39; WITH ALL PRIVILEGES\n\n# 删除用户\n$ DROP USER &quot;username&quot;\n</code></pre>\n<h3 id=\"数据保存策略\"><a href=\"#数据保存策略\" class=\"headerlink\" title=\"数据保存策略\"></a>数据保存策略</h3><p>查看当前数据库的Retention Policies</p>\n<pre><code>$ SHOW RETENTION POLICIES ON &quot;testDB&quot;\n</code></pre>\n<p>创建新的Retention Policies</p>\n<pre><code>$ CREATE RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot; DURATION 30d REPLICATION 1 DEFAULT\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><ol>\n<li>rp_name：策略名</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>db_name：具体的数据库名</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>30d：保存30天，30天之前的数据将被删除,它具有各种时间参数，比如：h（小时），w（星期）</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>REPLICATION 1：副本个数，这里填1就可以了</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>DEFAULT 设为默认的策略</li>\n</ol>\n</li>\n</ul>\n<p>修改Retention Policies</p>\n<pre><code>$ ALTER RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot; DURATION 3w DEFAULT\n</code></pre>\n<p>删除Retention Policies</p>\n<pre><code>$ DROP RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot;\n</code></pre>\n<h3 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h3><p><img src=\"https://owelinux.github.io/images/2018-08-24-article19-linux-telegraf-infludb/telegraf-Infludb.png\"></p>\n<p>模板采用：<a href=\"https://grafana.com/dashboards/914\">https://grafana.com/dashboards/914</a></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.influxdata.com/time-series-platform/telegraf/\">https://www.influxdata.com/time-series-platform/telegraf/</a></li>\n<li><a href=\"https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/\">https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/</a></li>\n<li><a href=\"https://kiswo.com/article/1020\">https://kiswo.com/article/1020</a></li>\n<li><a href=\"https://www.linuxdaxue.com/series/influxdb-series/\">https://www.linuxdaxue.com/series/influxdb-series/</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Telegraf-Infludb-Grafana构建可视化监控系统\"><a href=\"#Telegraf-Infludb-Grafana构建可视化监控系统\" class=\"headerlink\" title=\"Telegraf+Infludb+Grafana构建可视化监控系统\"></a>Telegraf+Infludb+Grafana构建可视化监控系统</h1><h2 id=\"telegraf介绍\"><a href=\"#telegraf介绍\" class=\"headerlink\" title=\"telegraf介绍\"></a>telegraf介绍</h2><p>Telegraf是TICK Stack的一部分，是一个插件驱动的服务器代理，用于收集和报告指标。 Telegraf集成了直接从其运行的容器和系统中提取各种指标，事件和日志，从第三方API提取指标，甚至通过StatsD和Kafka消费者服务监听指标。它还具有输出插件，可将指标发送到各种其他数据存储，服务和消息队列，包括InfluxDB，Graphite，OpenTSDB，Datadog，Librato，Kafka，MQTT，NSQ等等。</p>\n<p><img src=\"https://2bjee8bvp8y263sjpl3xui1a-wpengine.netdna-ssl.com/wp-content/uploads/Tick-Stack-Telegraf-2.png\"></p>\n<h3 id=\"telegraf部署\"><a href=\"#telegraf部署\" class=\"headerlink\" title=\"telegraf部署\"></a>telegraf部署</h3><pre><code>$ wget https://dl.influxdata.com/telegraf/releases/telegraf-1.7.3_linux_amd64.tar.gz\n$ tar xf telegraf-1.7.3_linux_amd64.tar.gz\n</code></pre>\n<h3 id=\"telegraf配置及优化\"><a href=\"#telegraf配置及优化\" class=\"headerlink\" title=\"telegraf配置及优化\"></a>telegraf配置及优化</h3><pre><code>[global_tags]\n[agent]\n  interval = &quot;10s&quot;\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = &quot;0s&quot;\n  flush_interval = &quot;10s&quot;\n  flush_jitter = &quot;0s&quot;\n  precision = &quot;&quot;\n  debug = false\n  quiet = false\n  logfile = &quot;&quot;\n  hostname = &quot;192.168.1.1&quot;\n  omit_hostname = false\n\n[[outputs.influxdb]]\n  urls = [&quot;http://192.168.1.1:8086&quot;]\n  database = &quot;telegraf&quot;\n  precision = &quot;s&quot;\n  timeout = &quot;5s&quot;\n  username = &quot;monitor&quot;\n  password = &quot;EMZ1LdVUu0pMXbkaoPzpCO9S1J2bqvPi&quot;\n\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = true\n  collect_cpu_time = false\n  report_active = false\n\n[[inputs.disk]]\n  ignore_fs = [&quot;tmpfs&quot;, &quot;devtmpfs&quot;, &quot;devfs&quot;]\n\n[[inputs.diskio]]\n\n[[inputs.kernel]]\n\n[[inputs.mem]]\n\n[[inputs.processes]]\n\n[[inputs.swap]]\n\n[[inputs.system]]\n\n[[inputs.netstat]]\n\n[[inputs.net]]\n  interfaces = [&quot;eth0&quot;]\n\n#[[inputs.zookeeper]]\n# servers = [&quot;192.168.1.1:2181&quot;]\n</code></pre>\n<h3 id=\"telegraf启动\"><a href=\"#telegraf启动\" class=\"headerlink\" title=\"telegraf启动\"></a>telegraf启动</h3><pre><code>$ nohup /usr/local/telegraf/usr/bin/telegraf --config /usr/local/telegraf/etc/telegraf/telegraf.conf &amp; \n</code></pre>\n<h2 id=\"infludb介绍\"><a href=\"#infludb介绍\" class=\"headerlink\" title=\"infludb介绍\"></a>infludb介绍</h2><p>聆听翻译 InfluxDB用作涉及大量带时间戳数据的任何用例的数据存储，包括DevOps监控，日志数据，应用程序指标，物联网传感器数据和实时分析。通过配置InfluxDB来保存机器上的空间，以便将数据保留一段定义的时间，自动使系统中不需要的数据到期和删除。 InfluxDB还提供类似SQL的查询语言，用于与数据交互。</p>\n<h3 id=\"infludb部署\"><a href=\"#infludb部署\" class=\"headerlink\" title=\"infludb部署\"></a>infludb部署</h3><pre><code>$ wget https://dl.influxdata.com/influxdb/releases/influxdb-1.6.1_linux_amd64.tar.gz\n$ tar xvfz influxdb-1.6.1_linux_amd64.tar.gz\n</code></pre>\n<h3 id=\"influbd启动\"><a href=\"#influbd启动\" class=\"headerlink\" title=\"influbd启动\"></a>influbd启动</h3><pre><code>$ nohup /usr/local/influxdb/usr/bin/influxd &amp;\n</code></pre>\n<h3 id=\"创建数据库及配置权限\"><a href=\"#创建数据库及配置权限\" class=\"headerlink\" title=\"创建数据库及配置权限\"></a>创建数据库及配置权限</h3><pre><code>$ influx\n$ create database telegraf\n\n# 显示用户\n$ SHOW USERS\n\n# 创建用户\n$ CREATE USER &quot;username&quot; WITH PASSWORD &#39;password&#39;\n\n# 创建管理员权限的用户\n$ CREATE USER &quot;username&quot; WITH PASSWORD &#39;password&#39; WITH ALL PRIVILEGES\n\n# 删除用户\n$ DROP USER &quot;username&quot;\n</code></pre>\n<h3 id=\"数据保存策略\"><a href=\"#数据保存策略\" class=\"headerlink\" title=\"数据保存策略\"></a>数据保存策略</h3><p>查看当前数据库的Retention Policies</p>\n<pre><code>$ SHOW RETENTION POLICIES ON &quot;testDB&quot;\n</code></pre>\n<p>创建新的Retention Policies</p>\n<pre><code>$ CREATE RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot; DURATION 30d REPLICATION 1 DEFAULT\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><ol>\n<li>rp_name：策略名</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>db_name：具体的数据库名</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>30d：保存30天，30天之前的数据将被删除,它具有各种时间参数，比如：h（小时），w（星期）</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>REPLICATION 1：副本个数，这里填1就可以了</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>DEFAULT 设为默认的策略</li>\n</ol>\n</li>\n</ul>\n<p>修改Retention Policies</p>\n<pre><code>$ ALTER RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot; DURATION 3w DEFAULT\n</code></pre>\n<p>删除Retention Policies</p>\n<pre><code>$ DROP RETENTION POLICY &quot;rp_name&quot; ON &quot;db_name&quot;\n</code></pre>\n<h3 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h3><p><img src=\"https://owelinux.github.io/images/2018-08-24-article19-linux-telegraf-infludb/telegraf-Infludb.png\"></p>\n<p>模板采用：<a href=\"https://grafana.com/dashboards/914\">https://grafana.com/dashboards/914</a></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://www.influxdata.com/time-series-platform/telegraf/\">https://www.influxdata.com/time-series-platform/telegraf/</a></li>\n<li><a href=\"https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/\">https://docs.influxdata.com/chronograf/v1.6/introduction/getting-started/</a></li>\n<li><a href=\"https://kiswo.com/article/1020\">https://kiswo.com/article/1020</a></li>\n<li><a href=\"https://www.linuxdaxue.com/series/influxdb-series/\">https://www.linuxdaxue.com/series/influxdb-series/</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"git部署及常用配置","date":"2018-08-28T09:37:54.000Z","author":"owelinux","excerpt":"git部署及常用配置","mathjax":true,"_content":"\n* content\n{:toc}\n\n# git部署及常用配置\n\n## 安装git\n\n### 在 Linux 上安装：\n```\n$ sudo yum install git\n```\n\n### 在Mac上安装：\n\n[官方下载](http://git-scm.com/download/mac)\n\n### 在 Windows 上安装：\n* a.[官方下载](http://git-scm.com/download/win)\n* b.[GitHub for Windows](http://windows.github.com)\n\n\n### 从源代码安装：\n```\n# 最小化的依赖包来编译和安装 Git 的二进制版：\n$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel\n\n# 为了能够添加更多格式的文档（如 doc, html, info），你需要安装以下的依赖包：\n$ sudo yum install asciidoc xmlto docbook2x\n\n# 编译并安装：\n$ tar -zxf git-2.0.0.tar.gz\n$ cd git-2.0.0\n$ make configure\n$ ./configure --prefix=/usr\n$ make all doc info\n$ sudo make install install-doc install-html install-info\n```\n\n## 初次运行 Git 前的配置\nGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n\n*  /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。\n\n* ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。\n\n* 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n\n每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n\n详细配置请参考：[https://git-scm.com/docs/git-config](https://git-scm.com/docs/git-config)\n\n### 用户信息\n```\n$ git config --global user.name \"John Doe\"\n\n$ git config --global user.email johndoe@example.com\n```\n\n### 文本编辑器\n```\n$ git config --global core.editor emacs/vim/nodepad++\n```\n\n### 代理配置\n```\n$ git config --global http.proxy socks5://127.0.0.1:1080\n\n$ git config --global https.proxy socks5://127.0.0.1:1080\n\n$ git config --global http.sslVerify false\n``` \n\n## 报错解决\n```\n$ git clone https://github.com/xxxx/xxxx.git\nCloning into 'xxxx...\nfatal: unable to access 'https://github.com/xxxx/xxxx.git': OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443\n\n如遇到以上错误，是由于连接不上远程git仓库，配置代理即可解决！\n\n```\n\n\n## 参考\n> * [https://git-scm.com/book/zh/v2](https://git-scm.com/book/zh/v2)","source":"_posts/2018-08-28-article20-linux-git-proxy.md","raw":"---\nlayout: post\ntitle:  \"git部署及常用配置\"\ndate:   2018-08-28 17:37:54\nauthor: owelinux\ncategories: linux \ntags:  linux  git\nexcerpt: git部署及常用配置\nmathjax: true\n---\n\n* content\n{:toc}\n\n# git部署及常用配置\n\n## 安装git\n\n### 在 Linux 上安装：\n```\n$ sudo yum install git\n```\n\n### 在Mac上安装：\n\n[官方下载](http://git-scm.com/download/mac)\n\n### 在 Windows 上安装：\n* a.[官方下载](http://git-scm.com/download/win)\n* b.[GitHub for Windows](http://windows.github.com)\n\n\n### 从源代码安装：\n```\n# 最小化的依赖包来编译和安装 Git 的二进制版：\n$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel\n\n# 为了能够添加更多格式的文档（如 doc, html, info），你需要安装以下的依赖包：\n$ sudo yum install asciidoc xmlto docbook2x\n\n# 编译并安装：\n$ tar -zxf git-2.0.0.tar.gz\n$ cd git-2.0.0\n$ make configure\n$ ./configure --prefix=/usr\n$ make all doc info\n$ sudo make install install-doc install-html install-info\n```\n\n## 初次运行 Git 前的配置\nGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n\n*  /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。\n\n* ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。\n\n* 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n\n每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n\n详细配置请参考：[https://git-scm.com/docs/git-config](https://git-scm.com/docs/git-config)\n\n### 用户信息\n```\n$ git config --global user.name \"John Doe\"\n\n$ git config --global user.email johndoe@example.com\n```\n\n### 文本编辑器\n```\n$ git config --global core.editor emacs/vim/nodepad++\n```\n\n### 代理配置\n```\n$ git config --global http.proxy socks5://127.0.0.1:1080\n\n$ git config --global https.proxy socks5://127.0.0.1:1080\n\n$ git config --global http.sslVerify false\n``` \n\n## 报错解决\n```\n$ git clone https://github.com/xxxx/xxxx.git\nCloning into 'xxxx...\nfatal: unable to access 'https://github.com/xxxx/xxxx.git': OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443\n\n如遇到以上错误，是由于连接不上远程git仓库，配置代理即可解决！\n\n```\n\n\n## 参考\n> * [https://git-scm.com/book/zh/v2](https://git-scm.com/book/zh/v2)","slug":"2018-08-28-article20-linux-git-proxy","published":1,"updated":"2021-02-09T02:00:24.569Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq060014yc97glu50axg","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"git部署及常用配置\"><a href=\"#git部署及常用配置\" class=\"headerlink\" title=\"git部署及常用配置\"></a>git部署及常用配置</h1><h2 id=\"安装git\"><a href=\"#安装git\" class=\"headerlink\" title=\"安装git\"></a>安装git</h2><h3 id=\"在-Linux-上安装：\"><a href=\"#在-Linux-上安装：\" class=\"headerlink\" title=\"在 Linux 上安装：\"></a>在 Linux 上安装：</h3><pre><code>$ sudo yum install git\n</code></pre>\n<h3 id=\"在Mac上安装：\"><a href=\"#在Mac上安装：\" class=\"headerlink\" title=\"在Mac上安装：\"></a>在Mac上安装：</h3><p><a href=\"http://git-scm.com/download/mac\">官方下载</a></p>\n<h3 id=\"在-Windows-上安装：\"><a href=\"#在-Windows-上安装：\" class=\"headerlink\" title=\"在 Windows 上安装：\"></a>在 Windows 上安装：</h3><ul>\n<li>a.<a href=\"http://git-scm.com/download/win\">官方下载</a></li>\n<li>b.<a href=\"http://windows.github.com/\">GitHub for Windows</a></li>\n</ul>\n<h3 id=\"从源代码安装：\"><a href=\"#从源代码安装：\" class=\"headerlink\" title=\"从源代码安装：\"></a>从源代码安装：</h3><pre><code># 最小化的依赖包来编译和安装 Git 的二进制版：\n$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel\n\n# 为了能够添加更多格式的文档（如 doc, html, info），你需要安装以下的依赖包：\n$ sudo yum install asciidoc xmlto docbook2x\n\n# 编译并安装：\n$ tar -zxf git-2.0.0.tar.gz\n$ cd git-2.0.0\n$ make configure\n$ ./configure --prefix=/usr\n$ make all doc info\n$ sudo make install install-doc install-html install-info\n</code></pre>\n<h2 id=\"初次运行-Git-前的配置\"><a href=\"#初次运行-Git-前的配置\" class=\"headerlink\" title=\"初次运行 Git 前的配置\"></a>初次运行 Git 前的配置</h2><p>Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：</p>\n<ul>\n<li><p> /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 –system 选项的 git config 时，它会从此文件读写配置变量。</p>\n</li>\n<li><p>~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 –global 选项让 Git 读写此文件。</p>\n</li>\n<li><p>当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。</p>\n</li>\n</ul>\n<p>每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。</p>\n<p>在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。</p>\n<p>详细配置请参考：<a href=\"https://git-scm.com/docs/git-config\">https://git-scm.com/docs/git-config</a></p>\n<h3 id=\"用户信息\"><a href=\"#用户信息\" class=\"headerlink\" title=\"用户信息\"></a>用户信息</h3><pre><code>$ git config --global user.name &quot;John Doe&quot;\n\n$ git config --global user.email johndoe@example.com\n</code></pre>\n<h3 id=\"文本编辑器\"><a href=\"#文本编辑器\" class=\"headerlink\" title=\"文本编辑器\"></a>文本编辑器</h3><pre><code>$ git config --global core.editor emacs/vim/nodepad++\n</code></pre>\n<h3 id=\"代理配置\"><a href=\"#代理配置\" class=\"headerlink\" title=\"代理配置\"></a>代理配置</h3><pre><code>$ git config --global http.proxy socks5://127.0.0.1:1080\n\n$ git config --global https.proxy socks5://127.0.0.1:1080\n\n$ git config --global http.sslVerify false\n</code></pre>\n<h2 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h2><pre><code>$ git clone https://github.com/xxxx/xxxx.git\nCloning into &#39;xxxx...\nfatal: unable to access &#39;https://github.com/xxxx/xxxx.git&#39;: OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443\n\n如遇到以上错误，是由于连接不上远程git仓库，配置代理即可解决！\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://git-scm.com/book/zh/v2\">https://git-scm.com/book/zh/v2</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"git部署及常用配置\"><a href=\"#git部署及常用配置\" class=\"headerlink\" title=\"git部署及常用配置\"></a>git部署及常用配置</h1><h2 id=\"安装git\"><a href=\"#安装git\" class=\"headerlink\" title=\"安装git\"></a>安装git</h2><h3 id=\"在-Linux-上安装：\"><a href=\"#在-Linux-上安装：\" class=\"headerlink\" title=\"在 Linux 上安装：\"></a>在 Linux 上安装：</h3><pre><code>$ sudo yum install git\n</code></pre>\n<h3 id=\"在Mac上安装：\"><a href=\"#在Mac上安装：\" class=\"headerlink\" title=\"在Mac上安装：\"></a>在Mac上安装：</h3><p><a href=\"http://git-scm.com/download/mac\">官方下载</a></p>\n<h3 id=\"在-Windows-上安装：\"><a href=\"#在-Windows-上安装：\" class=\"headerlink\" title=\"在 Windows 上安装：\"></a>在 Windows 上安装：</h3><ul>\n<li>a.<a href=\"http://git-scm.com/download/win\">官方下载</a></li>\n<li>b.<a href=\"http://windows.github.com/\">GitHub for Windows</a></li>\n</ul>\n<h3 id=\"从源代码安装：\"><a href=\"#从源代码安装：\" class=\"headerlink\" title=\"从源代码安装：\"></a>从源代码安装：</h3><pre><code># 最小化的依赖包来编译和安装 Git 的二进制版：\n$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel\n\n# 为了能够添加更多格式的文档（如 doc, html, info），你需要安装以下的依赖包：\n$ sudo yum install asciidoc xmlto docbook2x\n\n# 编译并安装：\n$ tar -zxf git-2.0.0.tar.gz\n$ cd git-2.0.0\n$ make configure\n$ ./configure --prefix=/usr\n$ make all doc info\n$ sudo make install install-doc install-html install-info\n</code></pre>\n<h2 id=\"初次运行-Git-前的配置\"><a href=\"#初次运行-Git-前的配置\" class=\"headerlink\" title=\"初次运行 Git 前的配置\"></a>初次运行 Git 前的配置</h2><p>Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：</p>\n<ul>\n<li><p> /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 –system 选项的 git config 时，它会从此文件读写配置变量。</p>\n</li>\n<li><p>~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 –global 选项让 Git 读写此文件。</p>\n</li>\n<li><p>当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。</p>\n</li>\n</ul>\n<p>每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。</p>\n<p>在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。</p>\n<p>详细配置请参考：<a href=\"https://git-scm.com/docs/git-config\">https://git-scm.com/docs/git-config</a></p>\n<h3 id=\"用户信息\"><a href=\"#用户信息\" class=\"headerlink\" title=\"用户信息\"></a>用户信息</h3><pre><code>$ git config --global user.name &quot;John Doe&quot;\n\n$ git config --global user.email johndoe@example.com\n</code></pre>\n<h3 id=\"文本编辑器\"><a href=\"#文本编辑器\" class=\"headerlink\" title=\"文本编辑器\"></a>文本编辑器</h3><pre><code>$ git config --global core.editor emacs/vim/nodepad++\n</code></pre>\n<h3 id=\"代理配置\"><a href=\"#代理配置\" class=\"headerlink\" title=\"代理配置\"></a>代理配置</h3><pre><code>$ git config --global http.proxy socks5://127.0.0.1:1080\n\n$ git config --global https.proxy socks5://127.0.0.1:1080\n\n$ git config --global http.sslVerify false\n</code></pre>\n<h2 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h2><pre><code>$ git clone https://github.com/xxxx/xxxx.git\nCloning into &#39;xxxx...\nfatal: unable to access &#39;https://github.com/xxxx/xxxx.git&#39;: OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443\n\n如遇到以上错误，是由于连接不上远程git仓库，配置代理即可解决！\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://git-scm.com/book/zh/v2\">https://git-scm.com/book/zh/v2</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"linux下pip安装的几种方式","date":"2018-08-29T09:37:54.000Z","author":"owelinux","excerpt":"linux下pip安装的几种方式","mathjax":true,"_content":"\n* content\n{:toc}\n\n# linux下pip安装的几种方式\n\n## 安装方式1\n```\nwget  http://python-distribute.org/distribute_setup.py  \nsudo python distribute_setup.py  \nwget  https://github.com/pypa/pip/raw/master/contrib/get-pip.py  \nsudo python get-pip.py\n```  \n## 安装方式2\n```\nwget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificate   \ntar xvf pip-1.3.1.tar.gz  \npython pip-1.3.1/setup.py install  \n```\n## 安装方式3\n```\nwget https://bootstrap.pypa.io/get-pip.py  \npython get-pip.py  \n```\n\n## 设置其他源\n```\nvim ~/.pip/pip.conf\n[global]\n\nindex-url=http://pypi.hustunique.com/simple\n\n其他源：index-url=http://mirrors.tuna.tsinghua.edu.cn/pypi/simple  这个比较快一点\n\n```\n\n## 参考\n> * [https://pypi.Python.org/pypi/setuptools#unix-wget](https://pypi.Python.org/pypi/setuptools#unix-wget)\n> * [https://pip.pypa.io/en/latest/installing.html](https://pip.pypa.io/en/latest/installing.html)\n> * [https://blog.csdn.net/jinruoyanxu/article/details/53947570](https://blog.csdn.net/jinruoyanxu/article/details/53947570)","source":"_posts/2018-08-29-article21-linux-pip.md","raw":"---\nlayout: post\ntitle:  \"linux下pip安装的几种方式\"\ndate:   2018-08-29 17:37:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: linux下pip安装的几种方式\nmathjax: true\n---\n\n* content\n{:toc}\n\n# linux下pip安装的几种方式\n\n## 安装方式1\n```\nwget  http://python-distribute.org/distribute_setup.py  \nsudo python distribute_setup.py  \nwget  https://github.com/pypa/pip/raw/master/contrib/get-pip.py  \nsudo python get-pip.py\n```  \n## 安装方式2\n```\nwget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificate   \ntar xvf pip-1.3.1.tar.gz  \npython pip-1.3.1/setup.py install  \n```\n## 安装方式3\n```\nwget https://bootstrap.pypa.io/get-pip.py  \npython get-pip.py  \n```\n\n## 设置其他源\n```\nvim ~/.pip/pip.conf\n[global]\n\nindex-url=http://pypi.hustunique.com/simple\n\n其他源：index-url=http://mirrors.tuna.tsinghua.edu.cn/pypi/simple  这个比较快一点\n\n```\n\n## 参考\n> * [https://pypi.Python.org/pypi/setuptools#unix-wget](https://pypi.Python.org/pypi/setuptools#unix-wget)\n> * [https://pip.pypa.io/en/latest/installing.html](https://pip.pypa.io/en/latest/installing.html)\n> * [https://blog.csdn.net/jinruoyanxu/article/details/53947570](https://blog.csdn.net/jinruoyanxu/article/details/53947570)","slug":"2018-08-29-article21-linux-pip","published":1,"updated":"2021-02-09T02:00:24.569Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq080018yc97ck6p9dhj","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux下pip安装的几种方式\"><a href=\"#linux下pip安装的几种方式\" class=\"headerlink\" title=\"linux下pip安装的几种方式\"></a>linux下pip安装的几种方式</h1><h2 id=\"安装方式1\"><a href=\"#安装方式1\" class=\"headerlink\" title=\"安装方式1\"></a>安装方式1</h2><pre><code>wget  http://python-distribute.org/distribute_setup.py  \nsudo python distribute_setup.py  \nwget  https://github.com/pypa/pip/raw/master/contrib/get-pip.py  \nsudo python get-pip.py\n</code></pre>\n<h2 id=\"安装方式2\"><a href=\"#安装方式2\" class=\"headerlink\" title=\"安装方式2\"></a>安装方式2</h2><pre><code>wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificate   \ntar xvf pip-1.3.1.tar.gz  \npython pip-1.3.1/setup.py install  \n</code></pre>\n<h2 id=\"安装方式3\"><a href=\"#安装方式3\" class=\"headerlink\" title=\"安装方式3\"></a>安装方式3</h2><pre><code>wget https://bootstrap.pypa.io/get-pip.py  \npython get-pip.py  \n</code></pre>\n<h2 id=\"设置其他源\"><a href=\"#设置其他源\" class=\"headerlink\" title=\"设置其他源\"></a>设置其他源</h2><pre><code>vim ~/.pip/pip.conf\n[global]\n\nindex-url=http://pypi.hustunique.com/simple\n\n其他源：index-url=http://mirrors.tuna.tsinghua.edu.cn/pypi/simple  这个比较快一点\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/setuptools#unix-wget\">https://pypi.Python.org/pypi/setuptools#unix-wget</a></li>\n<li><a href=\"https://pip.pypa.io/en/latest/installing.html\">https://pip.pypa.io/en/latest/installing.html</a></li>\n<li><a href=\"https://blog.csdn.net/jinruoyanxu/article/details/53947570\">https://blog.csdn.net/jinruoyanxu/article/details/53947570</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux下pip安装的几种方式\"><a href=\"#linux下pip安装的几种方式\" class=\"headerlink\" title=\"linux下pip安装的几种方式\"></a>linux下pip安装的几种方式</h1><h2 id=\"安装方式1\"><a href=\"#安装方式1\" class=\"headerlink\" title=\"安装方式1\"></a>安装方式1</h2><pre><code>wget  http://python-distribute.org/distribute_setup.py  \nsudo python distribute_setup.py  \nwget  https://github.com/pypa/pip/raw/master/contrib/get-pip.py  \nsudo python get-pip.py\n</code></pre>\n<h2 id=\"安装方式2\"><a href=\"#安装方式2\" class=\"headerlink\" title=\"安装方式2\"></a>安装方式2</h2><pre><code>wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificate   \ntar xvf pip-1.3.1.tar.gz  \npython pip-1.3.1/setup.py install  \n</code></pre>\n<h2 id=\"安装方式3\"><a href=\"#安装方式3\" class=\"headerlink\" title=\"安装方式3\"></a>安装方式3</h2><pre><code>wget https://bootstrap.pypa.io/get-pip.py  \npython get-pip.py  \n</code></pre>\n<h2 id=\"设置其他源\"><a href=\"#设置其他源\" class=\"headerlink\" title=\"设置其他源\"></a>设置其他源</h2><pre><code>vim ~/.pip/pip.conf\n[global]\n\nindex-url=http://pypi.hustunique.com/simple\n\n其他源：index-url=http://mirrors.tuna.tsinghua.edu.cn/pypi/simple  这个比较快一点\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/setuptools#unix-wget\">https://pypi.Python.org/pypi/setuptools#unix-wget</a></li>\n<li><a href=\"https://pip.pypa.io/en/latest/installing.html\">https://pip.pypa.io/en/latest/installing.html</a></li>\n<li><a href=\"https://blog.csdn.net/jinruoyanxu/article/details/53947570\">https://blog.csdn.net/jinruoyanxu/article/details/53947570</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"convirt2.5安装及报错解决","date":"2018-08-30T09:37:54.000Z","author":"owelinux","excerpt":"convirt2.5安装及报错解决","mathjax":true,"_content":"\n* content\n{:toc}\n\n# convirt2.5安装及报错解决\n\n## 1.配置convirt源\n```\ncd/etc/yum.repos.d;\nwget   --no-cache http://www.convirture.com/repos/definitions/rhel/6.x/convirt.repo\n```\n\n## 2.安装socat\n```\nyum install socat\n```\n\n## 3.配置代理服务器，没有的话就跳过这一步\n```\nexport http_proxy=\"http://company-proxy-server:80\"\n```\n## 4.Convirt网站下载所需要的包\n```\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-install-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.5/convirture-tools-2.5.tar.gz\n$ tar -xzf convirt-install-2.5.tar.gz\n```\n## 5.下载virtualenv和python\n```\nwget --no-check-certificate https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.6.tar.gz\nwget --no-check-certificate https://www.python.org/ftp/python/2.6.6/Python-2.6.6.tgz\ntar zxvf virtualenv-1.11.6.tar.gz=\ncd virtualenv-1.11.6\npython setup.py install\ncd /root\ntar zxvf Python-2.6.6.tgz\ncd Python-2.6.6\n./configure\nmake && make install\n```\n## 6.安装依赖\n```\ncd  ~/convirt-install/install/cms/scripts/;\n./install_dependencies\n```\n\n## 7.配置数据库\nCentos6下自动安装的是mysql，centos7下自动安装的是mariadb数据库，需要替换掉，看”Centos7下安装mysql”文档\n 执行到后面会启动mysqld服务，需要用户密码，因为预先安装的mysql，没有设置root密码，直接按enter键。设置root密码，重复两次（例密码：root）。\n\n然后系统询问是否删除匿名用户（Y/N），“Y“！\n\n不允许root远程连接(Y/N)，”Y”.\n\n删除预置的test数据库(Y/N),”Y”.\n\n马上重新载入特权表(Y/N),”Y”.\n\n### 设置 innodb 缓存和内存池\n```\nvim /etc/my.cnf\n[mysqld]下添加下面两行\n\ninnodb_buffer_pool_size=1G\ninnodb_additional_mem_pool_size=20M\n```\n### 重启mysql服务\n```\n/etc/init.d/mysqld   restart\n```\n\n## 8.安装ConVirt\n```\ncd  ~/convirt-install/install/cms/scripts\nvim install_config\n\n# 将CONVIRT-BASE=~改为CONVIRT-BASE=/usr/local\n\nsource  ~/convirt-install/install/cms/scripts/install_config\n \ntar  -xzf   convirt-2.5.tar.gz  -C $CONVIRT_BASE\n```\n## 9.设置 TurboGears (python的轻量级框架)\n```\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n\n~/convirt-install/install/cms/scripts/setup_tg2\n```\n\n## 10.设置 ConVirt\n```\nvim /usr/local/convirt/src/convirt/web/convirt/development.ini \n\n“/sqlalchemy.url”命令查找其位置\n#sqlalchemy.url=postgres://username:password@hostname:port/databasename?charset=utf8\n\nsqlalchemy.url=mysql://root:root@localhost:3306/convirt?charset=utf8\n```\n\n注：后台收集的cpu、内存等信息都会保存到数据库中，默认为365天，数据量非常大，造成后期mysql查询很慢，磁盘IO很高，如果机器性能不好，应该修改下面的参数，来减少数据保存的时间：\n```\npurge_hr_data = 60\n\npurge_day_data = 30\n\npurge_week_data = 30\n\npurge_month_data =30\n\npurge_raw_data = 30\n\ntask_results_purge_interval=30\n\nTaskPaneLimit=7\n\ntask_panel_row_limit=200\n\nnotifications_row_limit=200\n```\n \n\n刚才设置的mysql密码为root。\n\n然后执行$~/convirt-install/install/cms/scripts/setup_convirt\n\n会要求输入passPhrase。\n\nEnterpassphrase(empty for no passphrase):记住密语以后会用到（例：testOS）\n\nEntersame  passphrase again: 记住密语以后会用到（例：testOS）\n\n在cms启动时也会用到，通过密语来连接cms和managed server\n\nPS：\n\n如果在这里出现 convirt-ctl   setup error 同意思的字样，可能得删除数据库中的convirt数据库，然后重新执行\n\n```\n~/convirt-install/install/cms/scripts/setup_convirt\n```\n\n有时候mysql数据库是用root用户启动的，那么cms也必须用root用户启动\n\n##11.使CMS设置生效\n\n### a)启动cms服务\n```\n/usr/local/convirt/convirt-ctl  start\n```\n\n服务名称为：paster  代理服务:ssh-agent\n```\nps  -e | grep paster\n```\n\n### b)如果开启着防火墙，配置访问策略（root权限）\n```\niptables -I INPUT -p tcp --dport 8081 -j  ACCEPT\n```\n\n### c)验证是否运行成功\n不成功就重启下cms服务和防火墙，返回a).b)\n\n如果多次启动仍然不成功，切换到root用户再次重试\n\n在另一台机器上浏览器中输入：http://192.168.108.83:8081\n\n\n###  d)错误\n```\na.\nNo local packages or download links found for funcsigs\nerror: Could not find suitable distribution for Requirement.parse('funcsigs')\nERROR: installing TG2 (2.0.3).\nERROR: Failed creating Turbogears2 environment.\n解决：\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n```\nb.\n```\nls: cannot access /usr/local/convirt/tg2env/lib/python2.4/site-packages/Beaker-*py2.4.egg/beaker/ext/google.py: No such file or directory\nTurboGears environmnet setup successfully.\n解决：\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n```\n## 部署Managed Servers\n\n### Centos中安装KVM。\n```\nyum -y groupinstall 'Virtualization' 'Virtualization Client' 'VirtualizationPlatform' 'Virtualization Tools'\n```\n\n### 修改网络设置\n```\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 \nDEVICE=eth0\nTYPE=Ethernet\nONBOOT=yes\nBOOTPROTO=none\nBRIDGE=br0\n\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 \nDEVICE=br0\nONBOOT=yes\nTYPE=Bridge\nBOOTPROTO=none\nIPADDR=192.168.1.1\nPREFIX=24\nGATEWAY=192.168.1.1\n```\n重启网络\n```\n/etc/init.d/network restart\n```\n### 检查系统cpu是否支持KVM虚拟化\n```\negrep -c ‘(vmx|svm)’ /proc/cpuinfo\n\n0 表示不支持，1 表示支持。\n```\n### 加载kvm模块\n```\nmodprobe  kvm\nmodprobe  kvm_amd\nmodprobe  kvm_intel\n```\n\n## 配置convirt-tool\n```\n[root@cms ~]# cd /usr/local/cms\n\n[root@cms cms]#wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.0.1/convirture-tools-2.0.1.tar.gz\n\n[root@cms cms]# scp convirture-tools-2.0.1.tar.gz root@192.168.5.7:/root/\n\n[root@ cms ~]# ssh root@192.168.5.7\n\n[root@ kvm-test ~]# tar zxvf convirture-tools-2.0.1.tar.gz\n\n[root@ kvm-test ~]# cd convirture-tools/install/managed_server/scripts\n\n[root@ kvm-test scripts]# ./convirt-tool –h    查看帮助\n\n[root@ kvm-test scripts]# ./convirt-tool --detect_only setup   验证platform（平台）而不做更改\n\n[root@kvm-test scripts]# ./convirt-tool install_dependencies 安装所需依赖\n```\n\n桥接已经配置过，且没有开启iptables，就执行以下命令：\n```\n[root@kvm-test scripts]# ./convirt-tool --skip_bridge --skip_firewall setup\n```\n \n然后，在CMS主机上启动convirt：\n\n其中的输出信息中，/root/.ssh/cms_id_rsa这个东西很重要，涉及之后虚拟机的vnc连接问题。\n\n至此，安装成功！\n\n## 添加Managed Server\n\n登录http://192.168.9.21：:8081，用户名admin，密码admin\n\n\n## 配置VNC管理\n\n在CMS主机上配置ssh代理，注意回显是否成功\n\n一般，convirt_ctl启动的时候，会创建~/.ssh/cms_id_rsa文件\n\n如果没有，就手动创建：\n```\n[root@cms ~]# ssh-keygen -t rsa -f ~/.ssh/cms_id_rsa\n\n[root@cms ~]# chmod 0600 ~/.ssh/cms_id_rsa*\n\n[root@cms ~]# eval `ssh-agent -s`\n\nAgent pid 16323\n\n[root@cms ~]# ssh-add .ssh/cms_id_rsa\n\nIdentity added: .ssh/cms_id_rsa (.ssh/cms_id_rsa)\n\n[root@cms .ssh]# ssh root@kvm-test\n\nLast login: Tue Apr 24 17:20:35 2012 from cms\n```\n \n再登陆kvm-test主机，就无需输入密码了，如果还需要输入密码，可以执行：\n```\n[root@cms ~]# scp ~/.ssh/cms_id_rsa.pub root@kvm-test:/root/.ssh/vnc_proxy_id_rsa.pub\n\n[root@cms ~]# ssh root@kvm-test\n\n[root@kvm-test ~]# cat vnc_proxy_id_rsa.pub >> authorized_keys\n```\n\n启动VCN代理转发：\n```\n[root@cms ~]# socat -d -d -d -d TCP-LISTEN:6900 EXEC:’/usr/bin/ssh root@kvm-test socat - TCP\\:127.0.0.1\\:5902’ > /tmp/6900_5902_qKhAFc.log 2>&1 &\n```\n\n使用命令创建convirt虚拟机：\n```\n[root@kvm-test ~]# /usr/libexec/qemu-kvm -hda \"/data/kvm/c2_appliance.disk.xm\" -net \"nic,vlan=0,macaddr=00:16:3e:20:d4:44\" -net \"user,vlan=0\"  -boot \"c\" -m \"512\" -vnc \":25\" -name \"convirt_appliance\" -smp \"2\" -redir tcp:2222::22 -redir tcp:8888::8081 -daemonize\n```\n\n## 登录web管理\n\n管理虚拟机时通过VNC applet来实现，所以必需浏览器中有java的支持：\n\n## 参考\n> * [https://blog.csdn.net/kisssun0608/article/details/44885635](https://blog.csdn.net/kisssun0608/article/details/44885635)\n> * [https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS](https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS)\n> * [https://blog.csdn.net/kobe283734280/article/details/7827482](https://blog.csdn.net/kobe283734280/article/details/7827482)","source":"_posts/2018-08-30-article22-linux-convirt.md","raw":"---\nlayout: post\ntitle:  \"convirt2.5安装及报错解决\"\ndate:   2018-08-30 17:37:54\nauthor: owelinux\ncategories: linux \ntags:  linux  convirt\nexcerpt: convirt2.5安装及报错解决\nmathjax: true\n---\n\n* content\n{:toc}\n\n# convirt2.5安装及报错解决\n\n## 1.配置convirt源\n```\ncd/etc/yum.repos.d;\nwget   --no-cache http://www.convirture.com/repos/definitions/rhel/6.x/convirt.repo\n```\n\n## 2.安装socat\n```\nyum install socat\n```\n\n## 3.配置代理服务器，没有的话就跳过这一步\n```\nexport http_proxy=\"http://company-proxy-server:80\"\n```\n## 4.Convirt网站下载所需要的包\n```\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-install-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.5/convirture-tools-2.5.tar.gz\n$ tar -xzf convirt-install-2.5.tar.gz\n```\n## 5.下载virtualenv和python\n```\nwget --no-check-certificate https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.6.tar.gz\nwget --no-check-certificate https://www.python.org/ftp/python/2.6.6/Python-2.6.6.tgz\ntar zxvf virtualenv-1.11.6.tar.gz=\ncd virtualenv-1.11.6\npython setup.py install\ncd /root\ntar zxvf Python-2.6.6.tgz\ncd Python-2.6.6\n./configure\nmake && make install\n```\n## 6.安装依赖\n```\ncd  ~/convirt-install/install/cms/scripts/;\n./install_dependencies\n```\n\n## 7.配置数据库\nCentos6下自动安装的是mysql，centos7下自动安装的是mariadb数据库，需要替换掉，看”Centos7下安装mysql”文档\n 执行到后面会启动mysqld服务，需要用户密码，因为预先安装的mysql，没有设置root密码，直接按enter键。设置root密码，重复两次（例密码：root）。\n\n然后系统询问是否删除匿名用户（Y/N），“Y“！\n\n不允许root远程连接(Y/N)，”Y”.\n\n删除预置的test数据库(Y/N),”Y”.\n\n马上重新载入特权表(Y/N),”Y”.\n\n### 设置 innodb 缓存和内存池\n```\nvim /etc/my.cnf\n[mysqld]下添加下面两行\n\ninnodb_buffer_pool_size=1G\ninnodb_additional_mem_pool_size=20M\n```\n### 重启mysql服务\n```\n/etc/init.d/mysqld   restart\n```\n\n## 8.安装ConVirt\n```\ncd  ~/convirt-install/install/cms/scripts\nvim install_config\n\n# 将CONVIRT-BASE=~改为CONVIRT-BASE=/usr/local\n\nsource  ~/convirt-install/install/cms/scripts/install_config\n \ntar  -xzf   convirt-2.5.tar.gz  -C $CONVIRT_BASE\n```\n## 9.设置 TurboGears (python的轻量级框架)\n```\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n\n~/convirt-install/install/cms/scripts/setup_tg2\n```\n\n## 10.设置 ConVirt\n```\nvim /usr/local/convirt/src/convirt/web/convirt/development.ini \n\n“/sqlalchemy.url”命令查找其位置\n#sqlalchemy.url=postgres://username:password@hostname:port/databasename?charset=utf8\n\nsqlalchemy.url=mysql://root:root@localhost:3306/convirt?charset=utf8\n```\n\n注：后台收集的cpu、内存等信息都会保存到数据库中，默认为365天，数据量非常大，造成后期mysql查询很慢，磁盘IO很高，如果机器性能不好，应该修改下面的参数，来减少数据保存的时间：\n```\npurge_hr_data = 60\n\npurge_day_data = 30\n\npurge_week_data = 30\n\npurge_month_data =30\n\npurge_raw_data = 30\n\ntask_results_purge_interval=30\n\nTaskPaneLimit=7\n\ntask_panel_row_limit=200\n\nnotifications_row_limit=200\n```\n \n\n刚才设置的mysql密码为root。\n\n然后执行$~/convirt-install/install/cms/scripts/setup_convirt\n\n会要求输入passPhrase。\n\nEnterpassphrase(empty for no passphrase):记住密语以后会用到（例：testOS）\n\nEntersame  passphrase again: 记住密语以后会用到（例：testOS）\n\n在cms启动时也会用到，通过密语来连接cms和managed server\n\nPS：\n\n如果在这里出现 convirt-ctl   setup error 同意思的字样，可能得删除数据库中的convirt数据库，然后重新执行\n\n```\n~/convirt-install/install/cms/scripts/setup_convirt\n```\n\n有时候mysql数据库是用root用户启动的，那么cms也必须用root用户启动\n\n##11.使CMS设置生效\n\n### a)启动cms服务\n```\n/usr/local/convirt/convirt-ctl  start\n```\n\n服务名称为：paster  代理服务:ssh-agent\n```\nps  -e | grep paster\n```\n\n### b)如果开启着防火墙，配置访问策略（root权限）\n```\niptables -I INPUT -p tcp --dport 8081 -j  ACCEPT\n```\n\n### c)验证是否运行成功\n不成功就重启下cms服务和防火墙，返回a).b)\n\n如果多次启动仍然不成功，切换到root用户再次重试\n\n在另一台机器上浏览器中输入：http://192.168.108.83:8081\n\n\n###  d)错误\n```\na.\nNo local packages or download links found for funcsigs\nerror: Could not find suitable distribution for Requirement.parse('funcsigs')\nERROR: installing TG2 (2.0.3).\nERROR: Failed creating Turbogears2 environment.\n解决：\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n```\nb.\n```\nls: cannot access /usr/local/convirt/tg2env/lib/python2.4/site-packages/Beaker-*py2.4.egg/beaker/ext/google.py: No such file or directory\nTurboGears environmnet setup successfully.\n解决：\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n```\n## 部署Managed Servers\n\n### Centos中安装KVM。\n```\nyum -y groupinstall 'Virtualization' 'Virtualization Client' 'VirtualizationPlatform' 'Virtualization Tools'\n```\n\n### 修改网络设置\n```\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 \nDEVICE=eth0\nTYPE=Ethernet\nONBOOT=yes\nBOOTPROTO=none\nBRIDGE=br0\n\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 \nDEVICE=br0\nONBOOT=yes\nTYPE=Bridge\nBOOTPROTO=none\nIPADDR=192.168.1.1\nPREFIX=24\nGATEWAY=192.168.1.1\n```\n重启网络\n```\n/etc/init.d/network restart\n```\n### 检查系统cpu是否支持KVM虚拟化\n```\negrep -c ‘(vmx|svm)’ /proc/cpuinfo\n\n0 表示不支持，1 表示支持。\n```\n### 加载kvm模块\n```\nmodprobe  kvm\nmodprobe  kvm_amd\nmodprobe  kvm_intel\n```\n\n## 配置convirt-tool\n```\n[root@cms ~]# cd /usr/local/cms\n\n[root@cms cms]#wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.0.1/convirture-tools-2.0.1.tar.gz\n\n[root@cms cms]# scp convirture-tools-2.0.1.tar.gz root@192.168.5.7:/root/\n\n[root@ cms ~]# ssh root@192.168.5.7\n\n[root@ kvm-test ~]# tar zxvf convirture-tools-2.0.1.tar.gz\n\n[root@ kvm-test ~]# cd convirture-tools/install/managed_server/scripts\n\n[root@ kvm-test scripts]# ./convirt-tool –h    查看帮助\n\n[root@ kvm-test scripts]# ./convirt-tool --detect_only setup   验证platform（平台）而不做更改\n\n[root@kvm-test scripts]# ./convirt-tool install_dependencies 安装所需依赖\n```\n\n桥接已经配置过，且没有开启iptables，就执行以下命令：\n```\n[root@kvm-test scripts]# ./convirt-tool --skip_bridge --skip_firewall setup\n```\n \n然后，在CMS主机上启动convirt：\n\n其中的输出信息中，/root/.ssh/cms_id_rsa这个东西很重要，涉及之后虚拟机的vnc连接问题。\n\n至此，安装成功！\n\n## 添加Managed Server\n\n登录http://192.168.9.21：:8081，用户名admin，密码admin\n\n\n## 配置VNC管理\n\n在CMS主机上配置ssh代理，注意回显是否成功\n\n一般，convirt_ctl启动的时候，会创建~/.ssh/cms_id_rsa文件\n\n如果没有，就手动创建：\n```\n[root@cms ~]# ssh-keygen -t rsa -f ~/.ssh/cms_id_rsa\n\n[root@cms ~]# chmod 0600 ~/.ssh/cms_id_rsa*\n\n[root@cms ~]# eval `ssh-agent -s`\n\nAgent pid 16323\n\n[root@cms ~]# ssh-add .ssh/cms_id_rsa\n\nIdentity added: .ssh/cms_id_rsa (.ssh/cms_id_rsa)\n\n[root@cms .ssh]# ssh root@kvm-test\n\nLast login: Tue Apr 24 17:20:35 2012 from cms\n```\n \n再登陆kvm-test主机，就无需输入密码了，如果还需要输入密码，可以执行：\n```\n[root@cms ~]# scp ~/.ssh/cms_id_rsa.pub root@kvm-test:/root/.ssh/vnc_proxy_id_rsa.pub\n\n[root@cms ~]# ssh root@kvm-test\n\n[root@kvm-test ~]# cat vnc_proxy_id_rsa.pub >> authorized_keys\n```\n\n启动VCN代理转发：\n```\n[root@cms ~]# socat -d -d -d -d TCP-LISTEN:6900 EXEC:’/usr/bin/ssh root@kvm-test socat - TCP\\:127.0.0.1\\:5902’ > /tmp/6900_5902_qKhAFc.log 2>&1 &\n```\n\n使用命令创建convirt虚拟机：\n```\n[root@kvm-test ~]# /usr/libexec/qemu-kvm -hda \"/data/kvm/c2_appliance.disk.xm\" -net \"nic,vlan=0,macaddr=00:16:3e:20:d4:44\" -net \"user,vlan=0\"  -boot \"c\" -m \"512\" -vnc \":25\" -name \"convirt_appliance\" -smp \"2\" -redir tcp:2222::22 -redir tcp:8888::8081 -daemonize\n```\n\n## 登录web管理\n\n管理虚拟机时通过VNC applet来实现，所以必需浏览器中有java的支持：\n\n## 参考\n> * [https://blog.csdn.net/kisssun0608/article/details/44885635](https://blog.csdn.net/kisssun0608/article/details/44885635)\n> * [https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS](https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS)\n> * [https://blog.csdn.net/kobe283734280/article/details/7827482](https://blog.csdn.net/kobe283734280/article/details/7827482)","slug":"2018-08-30-article22-linux-convirt","published":1,"updated":"2021-02-09T02:00:24.570Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0a001ayc979ahndp4q","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"convirt2-5安装及报错解决\"><a href=\"#convirt2-5安装及报错解决\" class=\"headerlink\" title=\"convirt2.5安装及报错解决\"></a>convirt2.5安装及报错解决</h1><h2 id=\"1-配置convirt源\"><a href=\"#1-配置convirt源\" class=\"headerlink\" title=\"1.配置convirt源\"></a>1.配置convirt源</h2><pre><code>cd/etc/yum.repos.d;\nwget   --no-cache http://www.convirture.com/repos/definitions/rhel/6.x/convirt.repo\n</code></pre>\n<h2 id=\"2-安装socat\"><a href=\"#2-安装socat\" class=\"headerlink\" title=\"2.安装socat\"></a>2.安装socat</h2><pre><code>yum install socat\n</code></pre>\n<h2 id=\"3-配置代理服务器，没有的话就跳过这一步\"><a href=\"#3-配置代理服务器，没有的话就跳过这一步\" class=\"headerlink\" title=\"3.配置代理服务器，没有的话就跳过这一步\"></a>3.配置代理服务器，没有的话就跳过这一步</h2><pre><code>export http_proxy=&quot;http://company-proxy-server:80&quot;\n</code></pre>\n<h2 id=\"4-Convirt网站下载所需要的包\"><a href=\"#4-Convirt网站下载所需要的包\" class=\"headerlink\" title=\"4.Convirt网站下载所需要的包\"></a>4.Convirt网站下载所需要的包</h2><pre><code>$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-install-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.5/convirture-tools-2.5.tar.gz\n$ tar -xzf convirt-install-2.5.tar.gz\n</code></pre>\n<h2 id=\"5-下载virtualenv和python\"><a href=\"#5-下载virtualenv和python\" class=\"headerlink\" title=\"5.下载virtualenv和python\"></a>5.下载virtualenv和python</h2><pre><code>wget --no-check-certificate https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.6.tar.gz\nwget --no-check-certificate https://www.python.org/ftp/python/2.6.6/Python-2.6.6.tgz\ntar zxvf virtualenv-1.11.6.tar.gz=\ncd virtualenv-1.11.6\npython setup.py install\ncd /root\ntar zxvf Python-2.6.6.tgz\ncd Python-2.6.6\n./configure\nmake &amp;&amp; make install\n</code></pre>\n<h2 id=\"6-安装依赖\"><a href=\"#6-安装依赖\" class=\"headerlink\" title=\"6.安装依赖\"></a>6.安装依赖</h2><pre><code>cd  ~/convirt-install/install/cms/scripts/;\n./install_dependencies\n</code></pre>\n<h2 id=\"7-配置数据库\"><a href=\"#7-配置数据库\" class=\"headerlink\" title=\"7.配置数据库\"></a>7.配置数据库</h2><p>Centos6下自动安装的是mysql，centos7下自动安装的是mariadb数据库，需要替换掉，看”Centos7下安装mysql”文档<br> 执行到后面会启动mysqld服务，需要用户密码，因为预先安装的mysql，没有设置root密码，直接按enter键。设置root密码，重复两次（例密码：root）。</p>\n<p>然后系统询问是否删除匿名用户（Y/N），“Y“！</p>\n<p>不允许root远程连接(Y/N)，”Y”.</p>\n<p>删除预置的test数据库(Y/N),”Y”.</p>\n<p>马上重新载入特权表(Y/N),”Y”.</p>\n<h3 id=\"设置-innodb-缓存和内存池\"><a href=\"#设置-innodb-缓存和内存池\" class=\"headerlink\" title=\"设置 innodb 缓存和内存池\"></a>设置 innodb 缓存和内存池</h3><pre><code>vim /etc/my.cnf\n[mysqld]下添加下面两行\n\ninnodb_buffer_pool_size=1G\ninnodb_additional_mem_pool_size=20M\n</code></pre>\n<h3 id=\"重启mysql服务\"><a href=\"#重启mysql服务\" class=\"headerlink\" title=\"重启mysql服务\"></a>重启mysql服务</h3><pre><code>/etc/init.d/mysqld   restart\n</code></pre>\n<h2 id=\"8-安装ConVirt\"><a href=\"#8-安装ConVirt\" class=\"headerlink\" title=\"8.安装ConVirt\"></a>8.安装ConVirt</h2><pre><code>cd  ~/convirt-install/install/cms/scripts\nvim install_config\n\n# 将CONVIRT-BASE=~改为CONVIRT-BASE=/usr/local\n\nsource  ~/convirt-install/install/cms/scripts/install_config\n \ntar  -xzf   convirt-2.5.tar.gz  -C $CONVIRT_BASE\n</code></pre>\n<h2 id=\"9-设置-TurboGears-python的轻量级框架\"><a href=\"#9-设置-TurboGears-python的轻量级框架\" class=\"headerlink\" title=\"9.设置 TurboGears (python的轻量级框架)\"></a>9.设置 TurboGears (python的轻量级框架)</h2><pre><code>/usr/local/convirt/tg2env/bin/pip install funcsigs\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n\n~/convirt-install/install/cms/scripts/setup_tg2\n</code></pre>\n<h2 id=\"10-设置-ConVirt\"><a href=\"#10-设置-ConVirt\" class=\"headerlink\" title=\"10.设置 ConVirt\"></a>10.设置 ConVirt</h2><pre><code>vim /usr/local/convirt/src/convirt/web/convirt/development.ini \n\n“/sqlalchemy.url”命令查找其位置\n#sqlalchemy.url=postgres://username:password@hostname:port/databasename?charset=utf8\n\nsqlalchemy.url=mysql://root:root@localhost:3306/convirt?charset=utf8\n</code></pre>\n<p>注：后台收集的cpu、内存等信息都会保存到数据库中，默认为365天，数据量非常大，造成后期mysql查询很慢，磁盘IO很高，如果机器性能不好，应该修改下面的参数，来减少数据保存的时间：</p>\n<pre><code>purge_hr_data = 60\n\npurge_day_data = 30\n\npurge_week_data = 30\n\npurge_month_data =30\n\npurge_raw_data = 30\n\ntask_results_purge_interval=30\n\nTaskPaneLimit=7\n\ntask_panel_row_limit=200\n\nnotifications_row_limit=200\n</code></pre>\n<p>刚才设置的mysql密码为root。</p>\n<p>然后执行$~/convirt-install/install/cms/scripts/setup_convirt</p>\n<p>会要求输入passPhrase。</p>\n<p>Enterpassphrase(empty for no passphrase):记住密语以后会用到（例：testOS）</p>\n<p>Entersame  passphrase again: 记住密语以后会用到（例：testOS）</p>\n<p>在cms启动时也会用到，通过密语来连接cms和managed server</p>\n<p>PS：</p>\n<p>如果在这里出现 convirt-ctl   setup error 同意思的字样，可能得删除数据库中的convirt数据库，然后重新执行</p>\n<pre><code>~/convirt-install/install/cms/scripts/setup_convirt\n</code></pre>\n<p>有时候mysql数据库是用root用户启动的，那么cms也必须用root用户启动</p>\n<p>##11.使CMS设置生效</p>\n<h3 id=\"a-启动cms服务\"><a href=\"#a-启动cms服务\" class=\"headerlink\" title=\"a)启动cms服务\"></a>a)启动cms服务</h3><pre><code>/usr/local/convirt/convirt-ctl  start\n</code></pre>\n<p>服务名称为：paster  代理服务:ssh-agent</p>\n<pre><code>ps  -e | grep paster\n</code></pre>\n<h3 id=\"b-如果开启着防火墙，配置访问策略（root权限）\"><a href=\"#b-如果开启着防火墙，配置访问策略（root权限）\" class=\"headerlink\" title=\"b)如果开启着防火墙，配置访问策略（root权限）\"></a>b)如果开启着防火墙，配置访问策略（root权限）</h3><pre><code>iptables -I INPUT -p tcp --dport 8081 -j  ACCEPT\n</code></pre>\n<h3 id=\"c-验证是否运行成功\"><a href=\"#c-验证是否运行成功\" class=\"headerlink\" title=\"c)验证是否运行成功\"></a>c)验证是否运行成功</h3><p>不成功就重启下cms服务和防火墙，返回a).b)</p>\n<p>如果多次启动仍然不成功，切换到root用户再次重试</p>\n<p>在另一台机器上浏览器中输入：<a href=\"http://192.168.108.83:8081/\">http://192.168.108.83:8081</a></p>\n<h3 id=\"d-错误\"><a href=\"#d-错误\" class=\"headerlink\" title=\"d)错误\"></a>d)错误</h3><pre><code>a.\nNo local packages or download links found for funcsigs\nerror: Could not find suitable distribution for Requirement.parse(&#39;funcsigs&#39;)\nERROR: installing TG2 (2.0.3).\nERROR: Failed creating Turbogears2 environment.\n解决：\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n</code></pre>\n<p>b.</p>\n<pre><code>ls: cannot access /usr/local/convirt/tg2env/lib/python2.4/site-packages/Beaker-*py2.4.egg/beaker/ext/google.py: No such file or directory\nTurboGears environmnet setup successfully.\n解决：\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n</code></pre>\n<h2 id=\"部署Managed-Servers\"><a href=\"#部署Managed-Servers\" class=\"headerlink\" title=\"部署Managed Servers\"></a>部署Managed Servers</h2><h3 id=\"Centos中安装KVM。\"><a href=\"#Centos中安装KVM。\" class=\"headerlink\" title=\"Centos中安装KVM。\"></a>Centos中安装KVM。</h3><pre><code>yum -y groupinstall &#39;Virtualization&#39; &#39;Virtualization Client&#39; &#39;VirtualizationPlatform&#39; &#39;Virtualization Tools&#39;\n</code></pre>\n<h3 id=\"修改网络设置\"><a href=\"#修改网络设置\" class=\"headerlink\" title=\"修改网络设置\"></a>修改网络设置</h3><pre><code>[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 \nDEVICE=eth0\nTYPE=Ethernet\nONBOOT=yes\nBOOTPROTO=none\nBRIDGE=br0\n\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 \nDEVICE=br0\nONBOOT=yes\nTYPE=Bridge\nBOOTPROTO=none\nIPADDR=192.168.1.1\nPREFIX=24\nGATEWAY=192.168.1.1\n</code></pre>\n<p>重启网络</p>\n<pre><code>/etc/init.d/network restart\n</code></pre>\n<h3 id=\"检查系统cpu是否支持KVM虚拟化\"><a href=\"#检查系统cpu是否支持KVM虚拟化\" class=\"headerlink\" title=\"检查系统cpu是否支持KVM虚拟化\"></a>检查系统cpu是否支持KVM虚拟化</h3><pre><code>egrep -c ‘(vmx|svm)’ /proc/cpuinfo\n\n0 表示不支持，1 表示支持。\n</code></pre>\n<h3 id=\"加载kvm模块\"><a href=\"#加载kvm模块\" class=\"headerlink\" title=\"加载kvm模块\"></a>加载kvm模块</h3><pre><code>modprobe  kvm\nmodprobe  kvm_amd\nmodprobe  kvm_intel\n</code></pre>\n<h2 id=\"配置convirt-tool\"><a href=\"#配置convirt-tool\" class=\"headerlink\" title=\"配置convirt-tool\"></a>配置convirt-tool</h2><pre><code>[root@cms ~]# cd /usr/local/cms\n\n[root@cms cms]#wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.0.1/convirture-tools-2.0.1.tar.gz\n\n[root@cms cms]# scp convirture-tools-2.0.1.tar.gz root@192.168.5.7:/root/\n\n[root@ cms ~]# ssh root@192.168.5.7\n\n[root@ kvm-test ~]# tar zxvf convirture-tools-2.0.1.tar.gz\n\n[root@ kvm-test ~]# cd convirture-tools/install/managed_server/scripts\n\n[root@ kvm-test scripts]# ./convirt-tool –h    查看帮助\n\n[root@ kvm-test scripts]# ./convirt-tool --detect_only setup   验证platform（平台）而不做更改\n\n[root@kvm-test scripts]# ./convirt-tool install_dependencies 安装所需依赖\n</code></pre>\n<p>桥接已经配置过，且没有开启iptables，就执行以下命令：</p>\n<pre><code>[root@kvm-test scripts]# ./convirt-tool --skip_bridge --skip_firewall setup\n</code></pre>\n<p>然后，在CMS主机上启动convirt：</p>\n<p>其中的输出信息中，/root/.ssh/cms_id_rsa这个东西很重要，涉及之后虚拟机的vnc连接问题。</p>\n<p>至此，安装成功！</p>\n<h2 id=\"添加Managed-Server\"><a href=\"#添加Managed-Server\" class=\"headerlink\" title=\"添加Managed Server\"></a>添加Managed Server</h2><p>登录<a href=\"http://192.168.9.21：:8081，用户名admin，密码admin\">http://192.168.9.21：:8081，用户名admin，密码admin</a></p>\n<h2 id=\"配置VNC管理\"><a href=\"#配置VNC管理\" class=\"headerlink\" title=\"配置VNC管理\"></a>配置VNC管理</h2><p>在CMS主机上配置ssh代理，注意回显是否成功</p>\n<p>一般，convirt_ctl启动的时候，会创建~/.ssh/cms_id_rsa文件</p>\n<p>如果没有，就手动创建：</p>\n<pre><code>[root@cms ~]# ssh-keygen -t rsa -f ~/.ssh/cms_id_rsa\n\n[root@cms ~]# chmod 0600 ~/.ssh/cms_id_rsa*\n\n[root@cms ~]# eval `ssh-agent -s`\n\nAgent pid 16323\n\n[root@cms ~]# ssh-add .ssh/cms_id_rsa\n\nIdentity added: .ssh/cms_id_rsa (.ssh/cms_id_rsa)\n\n[root@cms .ssh]# ssh root@kvm-test\n\nLast login: Tue Apr 24 17:20:35 2012 from cms\n</code></pre>\n<p>再登陆kvm-test主机，就无需输入密码了，如果还需要输入密码，可以执行：</p>\n<pre><code>[root@cms ~]# scp ~/.ssh/cms_id_rsa.pub root@kvm-test:/root/.ssh/vnc_proxy_id_rsa.pub\n\n[root@cms ~]# ssh root@kvm-test\n\n[root@kvm-test ~]# cat vnc_proxy_id_rsa.pub &gt;&gt; authorized_keys\n</code></pre>\n<p>启动VCN代理转发：</p>\n<pre><code>[root@cms ~]# socat -d -d -d -d TCP-LISTEN:6900 EXEC:’/usr/bin/ssh root@kvm-test socat - TCP\\:127.0.0.1\\:5902’ &gt; /tmp/6900_5902_qKhAFc.log 2&gt;&amp;1 &amp;\n</code></pre>\n<p>使用命令创建convirt虚拟机：</p>\n<pre><code>[root@kvm-test ~]# /usr/libexec/qemu-kvm -hda &quot;/data/kvm/c2_appliance.disk.xm&quot; -net &quot;nic,vlan=0,macaddr=00:16:3e:20:d4:44&quot; -net &quot;user,vlan=0&quot;  -boot &quot;c&quot; -m &quot;512&quot; -vnc &quot;:25&quot; -name &quot;convirt_appliance&quot; -smp &quot;2&quot; -redir tcp:2222::22 -redir tcp:8888::8081 -daemonize\n</code></pre>\n<h2 id=\"登录web管理\"><a href=\"#登录web管理\" class=\"headerlink\" title=\"登录web管理\"></a>登录web管理</h2><p>管理虚拟机时通过VNC applet来实现，所以必需浏览器中有java的支持：</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/kisssun0608/article/details/44885635\">https://blog.csdn.net/kisssun0608/article/details/44885635</a></li>\n<li><a href=\"https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS\">https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS</a></li>\n<li><a href=\"https://blog.csdn.net/kobe283734280/article/details/7827482\">https://blog.csdn.net/kobe283734280/article/details/7827482</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"convirt2-5安装及报错解决\"><a href=\"#convirt2-5安装及报错解决\" class=\"headerlink\" title=\"convirt2.5安装及报错解决\"></a>convirt2.5安装及报错解决</h1><h2 id=\"1-配置convirt源\"><a href=\"#1-配置convirt源\" class=\"headerlink\" title=\"1.配置convirt源\"></a>1.配置convirt源</h2><pre><code>cd/etc/yum.repos.d;\nwget   --no-cache http://www.convirture.com/repos/definitions/rhel/6.x/convirt.repo\n</code></pre>\n<h2 id=\"2-安装socat\"><a href=\"#2-安装socat\" class=\"headerlink\" title=\"2.安装socat\"></a>2.安装socat</h2><pre><code>yum install socat\n</code></pre>\n<h2 id=\"3-配置代理服务器，没有的话就跳过这一步\"><a href=\"#3-配置代理服务器，没有的话就跳过这一步\" class=\"headerlink\" title=\"3.配置代理服务器，没有的话就跳过这一步\"></a>3.配置代理服务器，没有的话就跳过这一步</h2><pre><code>export http_proxy=&quot;http://company-proxy-server:80&quot;\n</code></pre>\n<h2 id=\"4-Convirt网站下载所需要的包\"><a href=\"#4-Convirt网站下载所需要的包\" class=\"headerlink\" title=\"4.Convirt网站下载所需要的包\"></a>4.Convirt网站下载所需要的包</h2><pre><code>$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-install-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirt/2.5/convirt-2.5.tar.gz;\n$ wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.5/convirture-tools-2.5.tar.gz\n$ tar -xzf convirt-install-2.5.tar.gz\n</code></pre>\n<h2 id=\"5-下载virtualenv和python\"><a href=\"#5-下载virtualenv和python\" class=\"headerlink\" title=\"5.下载virtualenv和python\"></a>5.下载virtualenv和python</h2><pre><code>wget --no-check-certificate https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.6.tar.gz\nwget --no-check-certificate https://www.python.org/ftp/python/2.6.6/Python-2.6.6.tgz\ntar zxvf virtualenv-1.11.6.tar.gz=\ncd virtualenv-1.11.6\npython setup.py install\ncd /root\ntar zxvf Python-2.6.6.tgz\ncd Python-2.6.6\n./configure\nmake &amp;&amp; make install\n</code></pre>\n<h2 id=\"6-安装依赖\"><a href=\"#6-安装依赖\" class=\"headerlink\" title=\"6.安装依赖\"></a>6.安装依赖</h2><pre><code>cd  ~/convirt-install/install/cms/scripts/;\n./install_dependencies\n</code></pre>\n<h2 id=\"7-配置数据库\"><a href=\"#7-配置数据库\" class=\"headerlink\" title=\"7.配置数据库\"></a>7.配置数据库</h2><p>Centos6下自动安装的是mysql，centos7下自动安装的是mariadb数据库，需要替换掉，看”Centos7下安装mysql”文档<br> 执行到后面会启动mysqld服务，需要用户密码，因为预先安装的mysql，没有设置root密码，直接按enter键。设置root密码，重复两次（例密码：root）。</p>\n<p>然后系统询问是否删除匿名用户（Y/N），“Y“！</p>\n<p>不允许root远程连接(Y/N)，”Y”.</p>\n<p>删除预置的test数据库(Y/N),”Y”.</p>\n<p>马上重新载入特权表(Y/N),”Y”.</p>\n<h3 id=\"设置-innodb-缓存和内存池\"><a href=\"#设置-innodb-缓存和内存池\" class=\"headerlink\" title=\"设置 innodb 缓存和内存池\"></a>设置 innodb 缓存和内存池</h3><pre><code>vim /etc/my.cnf\n[mysqld]下添加下面两行\n\ninnodb_buffer_pool_size=1G\ninnodb_additional_mem_pool_size=20M\n</code></pre>\n<h3 id=\"重启mysql服务\"><a href=\"#重启mysql服务\" class=\"headerlink\" title=\"重启mysql服务\"></a>重启mysql服务</h3><pre><code>/etc/init.d/mysqld   restart\n</code></pre>\n<h2 id=\"8-安装ConVirt\"><a href=\"#8-安装ConVirt\" class=\"headerlink\" title=\"8.安装ConVirt\"></a>8.安装ConVirt</h2><pre><code>cd  ~/convirt-install/install/cms/scripts\nvim install_config\n\n# 将CONVIRT-BASE=~改为CONVIRT-BASE=/usr/local\n\nsource  ~/convirt-install/install/cms/scripts/install_config\n \ntar  -xzf   convirt-2.5.tar.gz  -C $CONVIRT_BASE\n</code></pre>\n<h2 id=\"9-设置-TurboGears-python的轻量级框架\"><a href=\"#9-设置-TurboGears-python的轻量级框架\" class=\"headerlink\" title=\"9.设置 TurboGears (python的轻量级框架)\"></a>9.设置 TurboGears (python的轻量级框架)</h2><pre><code>/usr/local/convirt/tg2env/bin/pip install funcsigs\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n\n~/convirt-install/install/cms/scripts/setup_tg2\n</code></pre>\n<h2 id=\"10-设置-ConVirt\"><a href=\"#10-设置-ConVirt\" class=\"headerlink\" title=\"10.设置 ConVirt\"></a>10.设置 ConVirt</h2><pre><code>vim /usr/local/convirt/src/convirt/web/convirt/development.ini \n\n“/sqlalchemy.url”命令查找其位置\n#sqlalchemy.url=postgres://username:password@hostname:port/databasename?charset=utf8\n\nsqlalchemy.url=mysql://root:root@localhost:3306/convirt?charset=utf8\n</code></pre>\n<p>注：后台收集的cpu、内存等信息都会保存到数据库中，默认为365天，数据量非常大，造成后期mysql查询很慢，磁盘IO很高，如果机器性能不好，应该修改下面的参数，来减少数据保存的时间：</p>\n<pre><code>purge_hr_data = 60\n\npurge_day_data = 30\n\npurge_week_data = 30\n\npurge_month_data =30\n\npurge_raw_data = 30\n\ntask_results_purge_interval=30\n\nTaskPaneLimit=7\n\ntask_panel_row_limit=200\n\nnotifications_row_limit=200\n</code></pre>\n<p>刚才设置的mysql密码为root。</p>\n<p>然后执行$~/convirt-install/install/cms/scripts/setup_convirt</p>\n<p>会要求输入passPhrase。</p>\n<p>Enterpassphrase(empty for no passphrase):记住密语以后会用到（例：testOS）</p>\n<p>Entersame  passphrase again: 记住密语以后会用到（例：testOS）</p>\n<p>在cms启动时也会用到，通过密语来连接cms和managed server</p>\n<p>PS：</p>\n<p>如果在这里出现 convirt-ctl   setup error 同意思的字样，可能得删除数据库中的convirt数据库，然后重新执行</p>\n<pre><code>~/convirt-install/install/cms/scripts/setup_convirt\n</code></pre>\n<p>有时候mysql数据库是用root用户启动的，那么cms也必须用root用户启动</p>\n<p>##11.使CMS设置生效</p>\n<h3 id=\"a-启动cms服务\"><a href=\"#a-启动cms服务\" class=\"headerlink\" title=\"a)启动cms服务\"></a>a)启动cms服务</h3><pre><code>/usr/local/convirt/convirt-ctl  start\n</code></pre>\n<p>服务名称为：paster  代理服务:ssh-agent</p>\n<pre><code>ps  -e | grep paster\n</code></pre>\n<h3 id=\"b-如果开启着防火墙，配置访问策略（root权限）\"><a href=\"#b-如果开启着防火墙，配置访问策略（root权限）\" class=\"headerlink\" title=\"b)如果开启着防火墙，配置访问策略（root权限）\"></a>b)如果开启着防火墙，配置访问策略（root权限）</h3><pre><code>iptables -I INPUT -p tcp --dport 8081 -j  ACCEPT\n</code></pre>\n<h3 id=\"c-验证是否运行成功\"><a href=\"#c-验证是否运行成功\" class=\"headerlink\" title=\"c)验证是否运行成功\"></a>c)验证是否运行成功</h3><p>不成功就重启下cms服务和防火墙，返回a).b)</p>\n<p>如果多次启动仍然不成功，切换到root用户再次重试</p>\n<p>在另一台机器上浏览器中输入：<a href=\"http://192.168.108.83:8081/\">http://192.168.108.83:8081</a></p>\n<h3 id=\"d-错误\"><a href=\"#d-错误\" class=\"headerlink\" title=\"d)错误\"></a>d)错误</h3><pre><code>a.\nNo local packages or download links found for funcsigs\nerror: Could not find suitable distribution for Requirement.parse(&#39;funcsigs&#39;)\nERROR: installing TG2 (2.0.3).\nERROR: Failed creating Turbogears2 environment.\n解决：\n/usr/local/convirt/tg2env/bin/pip install funcsigs\n</code></pre>\n<p>b.</p>\n<pre><code>ls: cannot access /usr/local/convirt/tg2env/lib/python2.4/site-packages/Beaker-*py2.4.egg/beaker/ext/google.py: No such file or directory\nTurboGears environmnet setup successfully.\n解决：\n\ncd /usr/local/convirt/tg2env/lib\nln -s python2.6/ python2.4\n\ncd python2.6/site-packages/\nln -s Beaker-1.3-py2.6.egg Beaker-1.3-py2.4.egg\nln -s Beaker-1.10.0-py2.6.egg Beaker-1.10.0-py2.4.egg\n</code></pre>\n<h2 id=\"部署Managed-Servers\"><a href=\"#部署Managed-Servers\" class=\"headerlink\" title=\"部署Managed Servers\"></a>部署Managed Servers</h2><h3 id=\"Centos中安装KVM。\"><a href=\"#Centos中安装KVM。\" class=\"headerlink\" title=\"Centos中安装KVM。\"></a>Centos中安装KVM。</h3><pre><code>yum -y groupinstall &#39;Virtualization&#39; &#39;Virtualization Client&#39; &#39;VirtualizationPlatform&#39; &#39;Virtualization Tools&#39;\n</code></pre>\n<h3 id=\"修改网络设置\"><a href=\"#修改网络设置\" class=\"headerlink\" title=\"修改网络设置\"></a>修改网络设置</h3><pre><code>[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 \nDEVICE=eth0\nTYPE=Ethernet\nONBOOT=yes\nBOOTPROTO=none\nBRIDGE=br0\n\n[root@centos244 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 \nDEVICE=br0\nONBOOT=yes\nTYPE=Bridge\nBOOTPROTO=none\nIPADDR=192.168.1.1\nPREFIX=24\nGATEWAY=192.168.1.1\n</code></pre>\n<p>重启网络</p>\n<pre><code>/etc/init.d/network restart\n</code></pre>\n<h3 id=\"检查系统cpu是否支持KVM虚拟化\"><a href=\"#检查系统cpu是否支持KVM虚拟化\" class=\"headerlink\" title=\"检查系统cpu是否支持KVM虚拟化\"></a>检查系统cpu是否支持KVM虚拟化</h3><pre><code>egrep -c ‘(vmx|svm)’ /proc/cpuinfo\n\n0 表示不支持，1 表示支持。\n</code></pre>\n<h3 id=\"加载kvm模块\"><a href=\"#加载kvm模块\" class=\"headerlink\" title=\"加载kvm模块\"></a>加载kvm模块</h3><pre><code>modprobe  kvm\nmodprobe  kvm_amd\nmodprobe  kvm_intel\n</code></pre>\n<h2 id=\"配置convirt-tool\"><a href=\"#配置convirt-tool\" class=\"headerlink\" title=\"配置convirt-tool\"></a>配置convirt-tool</h2><pre><code>[root@cms ~]# cd /usr/local/cms\n\n[root@cms cms]#wget --no-cache http://www.convirture.com/downloads/convirture-tools/2.0.1/convirture-tools-2.0.1.tar.gz\n\n[root@cms cms]# scp convirture-tools-2.0.1.tar.gz root@192.168.5.7:/root/\n\n[root@ cms ~]# ssh root@192.168.5.7\n\n[root@ kvm-test ~]# tar zxvf convirture-tools-2.0.1.tar.gz\n\n[root@ kvm-test ~]# cd convirture-tools/install/managed_server/scripts\n\n[root@ kvm-test scripts]# ./convirt-tool –h    查看帮助\n\n[root@ kvm-test scripts]# ./convirt-tool --detect_only setup   验证platform（平台）而不做更改\n\n[root@kvm-test scripts]# ./convirt-tool install_dependencies 安装所需依赖\n</code></pre>\n<p>桥接已经配置过，且没有开启iptables，就执行以下命令：</p>\n<pre><code>[root@kvm-test scripts]# ./convirt-tool --skip_bridge --skip_firewall setup\n</code></pre>\n<p>然后，在CMS主机上启动convirt：</p>\n<p>其中的输出信息中，/root/.ssh/cms_id_rsa这个东西很重要，涉及之后虚拟机的vnc连接问题。</p>\n<p>至此，安装成功！</p>\n<h2 id=\"添加Managed-Server\"><a href=\"#添加Managed-Server\" class=\"headerlink\" title=\"添加Managed Server\"></a>添加Managed Server</h2><p>登录<a href=\"http://192.168.9.21：:8081，用户名admin，密码admin\">http://192.168.9.21：:8081，用户名admin，密码admin</a></p>\n<h2 id=\"配置VNC管理\"><a href=\"#配置VNC管理\" class=\"headerlink\" title=\"配置VNC管理\"></a>配置VNC管理</h2><p>在CMS主机上配置ssh代理，注意回显是否成功</p>\n<p>一般，convirt_ctl启动的时候，会创建~/.ssh/cms_id_rsa文件</p>\n<p>如果没有，就手动创建：</p>\n<pre><code>[root@cms ~]# ssh-keygen -t rsa -f ~/.ssh/cms_id_rsa\n\n[root@cms ~]# chmod 0600 ~/.ssh/cms_id_rsa*\n\n[root@cms ~]# eval `ssh-agent -s`\n\nAgent pid 16323\n\n[root@cms ~]# ssh-add .ssh/cms_id_rsa\n\nIdentity added: .ssh/cms_id_rsa (.ssh/cms_id_rsa)\n\n[root@cms .ssh]# ssh root@kvm-test\n\nLast login: Tue Apr 24 17:20:35 2012 from cms\n</code></pre>\n<p>再登陆kvm-test主机，就无需输入密码了，如果还需要输入密码，可以执行：</p>\n<pre><code>[root@cms ~]# scp ~/.ssh/cms_id_rsa.pub root@kvm-test:/root/.ssh/vnc_proxy_id_rsa.pub\n\n[root@cms ~]# ssh root@kvm-test\n\n[root@kvm-test ~]# cat vnc_proxy_id_rsa.pub &gt;&gt; authorized_keys\n</code></pre>\n<p>启动VCN代理转发：</p>\n<pre><code>[root@cms ~]# socat -d -d -d -d TCP-LISTEN:6900 EXEC:’/usr/bin/ssh root@kvm-test socat - TCP\\:127.0.0.1\\:5902’ &gt; /tmp/6900_5902_qKhAFc.log 2&gt;&amp;1 &amp;\n</code></pre>\n<p>使用命令创建convirt虚拟机：</p>\n<pre><code>[root@kvm-test ~]# /usr/libexec/qemu-kvm -hda &quot;/data/kvm/c2_appliance.disk.xm&quot; -net &quot;nic,vlan=0,macaddr=00:16:3e:20:d4:44&quot; -net &quot;user,vlan=0&quot;  -boot &quot;c&quot; -m &quot;512&quot; -vnc &quot;:25&quot; -name &quot;convirt_appliance&quot; -smp &quot;2&quot; -redir tcp:2222::22 -redir tcp:8888::8081 -daemonize\n</code></pre>\n<h2 id=\"登录web管理\"><a href=\"#登录web管理\" class=\"headerlink\" title=\"登录web管理\"></a>登录web管理</h2><p>管理虚拟机时通过VNC applet来实现，所以必需浏览器中有java的支持：</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/kisssun0608/article/details/44885635\">https://blog.csdn.net/kisssun0608/article/details/44885635</a></li>\n<li><a href=\"https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS\">https://support.accelerite.com/hc/en-us/articles/206179510-ConVirt-Enterprise-3-4-5-Setup-for-Fedora-RHEL-CentOS</a></li>\n<li><a href=\"https://blog.csdn.net/kobe283734280/article/details/7827482\">https://blog.csdn.net/kobe283734280/article/details/7827482</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"虚拟机磁盘扩容(适合所有lvm类型)","date":"2018-08-31T03:37:54.000Z","author":"owelinux","excerpt":"虚拟机磁盘扩容(适合所有lvm类型)","mathjax":true,"_content":"\n* content\n{:toc}\n\n# 虚拟机磁盘扩容(适合所有lvm类型)\n这里以convirt为例！\n\n## 1.物理机新建磁盘\n```\n[root@sz-145-centos24 ~]# cd /data/convirt/vm_disks\n[root@sz-145-centos24 vm_disks]# qemu-img create -f raw sz-145-centos177-2.xm 10G\n```\n\n## 2.convirt平台修改虚拟机配置\n关机后修改为如下配置\n\n![](https://owelinux.github.io/images/2018-08-31-article23-linux-convirt-create/convirt-lvm.png)\n\n修改完成后重启虚拟机，生效配置。\n\n## 3.登陆虚拟机配置lvm\n\n### 1、查看是否有新增的磁盘(这里为/dev/sdb)\n```\n[root@sz-145-centos177 ~]# fdisk  -l | grep Disk\nDisk /dev/sda: 125.8 GB, 125829120512 bytes\nDisk identifier: 0x0000ec73\nDisk /dev/sdb: 10.7 GB, 10737418240 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_root: 116.9 GB, 116912029696 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_swap: 8388 MB, 8388608000 bytes\nDisk identifier: 0x00000000\n```\n### 2、创建pv\n```\n[root@sz-145-centos177 ~]# pvcreate /dev/sdb\n  Physical volume \"/dev/sdb\" successfully created\n```\n### 3、查看vg name \n```\n[root@sz-145-centos177 ~]# vgdisplay \n  --- Volume group ---\n  VG Name               vg_templet\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  3\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               116.70 GiB\n  PE Size               4.00 MiB\n  Total PE              29874\n  Alloc PE / Size       29874 / 116.70 GiB\n  Free  PE / Size       0 / 0   \n  VG UUID               kC3k3E-kTBv-isC7-7c7F-VhJu-YBHH-JinGkb\n```\n### 4、扩容vg\n```   \n[root@sz-145-centos177 ~]# vgextend vg_templet /dev/sdb \n  Volume group \"vg_templet\" successfully extended\n``` \n\n### 5、扩容lv\n```\n[root@sz-145-centos177 ~]# num=`vgdisplay |grep \"Free\" |awk '{print $5}'`\n[root@sz-145-centos177 ~]# lvresize -l +$num /dev/vg_templet/lv_root \n  Size of logical volume vg_templet/lv_root changed from 108.88 GiB (27874 extents) to 118.88 GiB (30433 extents).\n  Logical volume lv_root successfully resized.\n```\n### 6、LV分区重设大小\n```\n[root@sz-145-centos177 ~]# resize2fs /dev/mapper/vg_templet-lv_root \nresize2fs 1.41.12 (17-May-2010)\nFilesystem at /dev/mapper/vg_templet-lv_root is mounted on /; on-line resizing required\nold desc_blocks = 7, new_desc_blocks = 8\nPerforming an on-line resize of /dev/mapper/vg_templet-lv_root to 31163392 (4k) blocks.\nThe filesystem on /dev/mapper/vg_templet-lv_root is now 31163392 blocks long.\n```\n\n### 7.检查扩容后磁盘情况\n```\n[root@sz-145-centos177 ~]# df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/mapper/vg_templet-lv_root\n                      117G  2.9G  109G   3% /\ntmpfs                 1.9G     0  1.9G   0% /dev/shm\n/dev/sda1             477M   39M  413M   9% /boot\n```\n","source":"_posts/2018-08-31-article23-linux-convirt-create.md","raw":"---\nlayout: post\ntitle:  \"虚拟机磁盘扩容(适合所有lvm类型)\"\ndate:   2018-08-31 11:37:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: 虚拟机磁盘扩容(适合所有lvm类型)\nmathjax: true\n---\n\n* content\n{:toc}\n\n# 虚拟机磁盘扩容(适合所有lvm类型)\n这里以convirt为例！\n\n## 1.物理机新建磁盘\n```\n[root@sz-145-centos24 ~]# cd /data/convirt/vm_disks\n[root@sz-145-centos24 vm_disks]# qemu-img create -f raw sz-145-centos177-2.xm 10G\n```\n\n## 2.convirt平台修改虚拟机配置\n关机后修改为如下配置\n\n![](https://owelinux.github.io/images/2018-08-31-article23-linux-convirt-create/convirt-lvm.png)\n\n修改完成后重启虚拟机，生效配置。\n\n## 3.登陆虚拟机配置lvm\n\n### 1、查看是否有新增的磁盘(这里为/dev/sdb)\n```\n[root@sz-145-centos177 ~]# fdisk  -l | grep Disk\nDisk /dev/sda: 125.8 GB, 125829120512 bytes\nDisk identifier: 0x0000ec73\nDisk /dev/sdb: 10.7 GB, 10737418240 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_root: 116.9 GB, 116912029696 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_swap: 8388 MB, 8388608000 bytes\nDisk identifier: 0x00000000\n```\n### 2、创建pv\n```\n[root@sz-145-centos177 ~]# pvcreate /dev/sdb\n  Physical volume \"/dev/sdb\" successfully created\n```\n### 3、查看vg name \n```\n[root@sz-145-centos177 ~]# vgdisplay \n  --- Volume group ---\n  VG Name               vg_templet\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  3\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               116.70 GiB\n  PE Size               4.00 MiB\n  Total PE              29874\n  Alloc PE / Size       29874 / 116.70 GiB\n  Free  PE / Size       0 / 0   \n  VG UUID               kC3k3E-kTBv-isC7-7c7F-VhJu-YBHH-JinGkb\n```\n### 4、扩容vg\n```   \n[root@sz-145-centos177 ~]# vgextend vg_templet /dev/sdb \n  Volume group \"vg_templet\" successfully extended\n``` \n\n### 5、扩容lv\n```\n[root@sz-145-centos177 ~]# num=`vgdisplay |grep \"Free\" |awk '{print $5}'`\n[root@sz-145-centos177 ~]# lvresize -l +$num /dev/vg_templet/lv_root \n  Size of logical volume vg_templet/lv_root changed from 108.88 GiB (27874 extents) to 118.88 GiB (30433 extents).\n  Logical volume lv_root successfully resized.\n```\n### 6、LV分区重设大小\n```\n[root@sz-145-centos177 ~]# resize2fs /dev/mapper/vg_templet-lv_root \nresize2fs 1.41.12 (17-May-2010)\nFilesystem at /dev/mapper/vg_templet-lv_root is mounted on /; on-line resizing required\nold desc_blocks = 7, new_desc_blocks = 8\nPerforming an on-line resize of /dev/mapper/vg_templet-lv_root to 31163392 (4k) blocks.\nThe filesystem on /dev/mapper/vg_templet-lv_root is now 31163392 blocks long.\n```\n\n### 7.检查扩容后磁盘情况\n```\n[root@sz-145-centos177 ~]# df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/mapper/vg_templet-lv_root\n                      117G  2.9G  109G   3% /\ntmpfs                 1.9G     0  1.9G   0% /dev/shm\n/dev/sda1             477M   39M  413M   9% /boot\n```\n","slug":"2018-08-31-article23-linux-convirt-create","published":1,"updated":"2021-02-09T02:00:24.570Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0b001eyc975ud51z2y","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"虚拟机磁盘扩容-适合所有lvm类型\"><a href=\"#虚拟机磁盘扩容-适合所有lvm类型\" class=\"headerlink\" title=\"虚拟机磁盘扩容(适合所有lvm类型)\"></a>虚拟机磁盘扩容(适合所有lvm类型)</h1><p>这里以convirt为例！</p>\n<h2 id=\"1-物理机新建磁盘\"><a href=\"#1-物理机新建磁盘\" class=\"headerlink\" title=\"1.物理机新建磁盘\"></a>1.物理机新建磁盘</h2><pre><code>[root@sz-145-centos24 ~]# cd /data/convirt/vm_disks\n[root@sz-145-centos24 vm_disks]# qemu-img create -f raw sz-145-centos177-2.xm 10G\n</code></pre>\n<h2 id=\"2-convirt平台修改虚拟机配置\"><a href=\"#2-convirt平台修改虚拟机配置\" class=\"headerlink\" title=\"2.convirt平台修改虚拟机配置\"></a>2.convirt平台修改虚拟机配置</h2><p>关机后修改为如下配置</p>\n<p><img src=\"https://owelinux.github.io/images/2018-08-31-article23-linux-convirt-create/convirt-lvm.png\"></p>\n<p>修改完成后重启虚拟机，生效配置。</p>\n<h2 id=\"3-登陆虚拟机配置lvm\"><a href=\"#3-登陆虚拟机配置lvm\" class=\"headerlink\" title=\"3.登陆虚拟机配置lvm\"></a>3.登陆虚拟机配置lvm</h2><h3 id=\"1、查看是否有新增的磁盘-这里为-dev-sdb\"><a href=\"#1、查看是否有新增的磁盘-这里为-dev-sdb\" class=\"headerlink\" title=\"1、查看是否有新增的磁盘(这里为/dev/sdb)\"></a>1、查看是否有新增的磁盘(这里为/dev/sdb)</h3><pre><code>[root@sz-145-centos177 ~]# fdisk  -l | grep Disk\nDisk /dev/sda: 125.8 GB, 125829120512 bytes\nDisk identifier: 0x0000ec73\nDisk /dev/sdb: 10.7 GB, 10737418240 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_root: 116.9 GB, 116912029696 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_swap: 8388 MB, 8388608000 bytes\nDisk identifier: 0x00000000\n</code></pre>\n<h3 id=\"2、创建pv\"><a href=\"#2、创建pv\" class=\"headerlink\" title=\"2、创建pv\"></a>2、创建pv</h3><pre><code>[root@sz-145-centos177 ~]# pvcreate /dev/sdb\n  Physical volume &quot;/dev/sdb&quot; successfully created\n</code></pre>\n<h3 id=\"3、查看vg-name\"><a href=\"#3、查看vg-name\" class=\"headerlink\" title=\"3、查看vg name\"></a>3、查看vg name</h3><pre><code>[root@sz-145-centos177 ~]# vgdisplay \n  --- Volume group ---\n  VG Name               vg_templet\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  3\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               116.70 GiB\n  PE Size               4.00 MiB\n  Total PE              29874\n  Alloc PE / Size       29874 / 116.70 GiB\n  Free  PE / Size       0 / 0   \n  VG UUID               kC3k3E-kTBv-isC7-7c7F-VhJu-YBHH-JinGkb\n</code></pre>\n<h3 id=\"4、扩容vg\"><a href=\"#4、扩容vg\" class=\"headerlink\" title=\"4、扩容vg\"></a>4、扩容vg</h3><pre><code>[root@sz-145-centos177 ~]# vgextend vg_templet /dev/sdb \n  Volume group &quot;vg_templet&quot; successfully extended\n</code></pre>\n<h3 id=\"5、扩容lv\"><a href=\"#5、扩容lv\" class=\"headerlink\" title=\"5、扩容lv\"></a>5、扩容lv</h3><pre><code>[root@sz-145-centos177 ~]# num=`vgdisplay |grep &quot;Free&quot; |awk &#39;&#123;print $5&#125;&#39;`\n[root@sz-145-centos177 ~]# lvresize -l +$num /dev/vg_templet/lv_root \n  Size of logical volume vg_templet/lv_root changed from 108.88 GiB (27874 extents) to 118.88 GiB (30433 extents).\n  Logical volume lv_root successfully resized.\n</code></pre>\n<h3 id=\"6、LV分区重设大小\"><a href=\"#6、LV分区重设大小\" class=\"headerlink\" title=\"6、LV分区重设大小\"></a>6、LV分区重设大小</h3><pre><code>[root@sz-145-centos177 ~]# resize2fs /dev/mapper/vg_templet-lv_root \nresize2fs 1.41.12 (17-May-2010)\nFilesystem at /dev/mapper/vg_templet-lv_root is mounted on /; on-line resizing required\nold desc_blocks = 7, new_desc_blocks = 8\nPerforming an on-line resize of /dev/mapper/vg_templet-lv_root to 31163392 (4k) blocks.\nThe filesystem on /dev/mapper/vg_templet-lv_root is now 31163392 blocks long.\n</code></pre>\n<h3 id=\"7-检查扩容后磁盘情况\"><a href=\"#7-检查扩容后磁盘情况\" class=\"headerlink\" title=\"7.检查扩容后磁盘情况\"></a>7.检查扩容后磁盘情况</h3><pre><code>[root@sz-145-centos177 ~]# df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/mapper/vg_templet-lv_root\n                      117G  2.9G  109G   3% /\ntmpfs                 1.9G     0  1.9G   0% /dev/shm\n/dev/sda1             477M   39M  413M   9% /boot\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"虚拟机磁盘扩容-适合所有lvm类型\"><a href=\"#虚拟机磁盘扩容-适合所有lvm类型\" class=\"headerlink\" title=\"虚拟机磁盘扩容(适合所有lvm类型)\"></a>虚拟机磁盘扩容(适合所有lvm类型)</h1><p>这里以convirt为例！</p>\n<h2 id=\"1-物理机新建磁盘\"><a href=\"#1-物理机新建磁盘\" class=\"headerlink\" title=\"1.物理机新建磁盘\"></a>1.物理机新建磁盘</h2><pre><code>[root@sz-145-centos24 ~]# cd /data/convirt/vm_disks\n[root@sz-145-centos24 vm_disks]# qemu-img create -f raw sz-145-centos177-2.xm 10G\n</code></pre>\n<h2 id=\"2-convirt平台修改虚拟机配置\"><a href=\"#2-convirt平台修改虚拟机配置\" class=\"headerlink\" title=\"2.convirt平台修改虚拟机配置\"></a>2.convirt平台修改虚拟机配置</h2><p>关机后修改为如下配置</p>\n<p><img src=\"https://owelinux.github.io/images/2018-08-31-article23-linux-convirt-create/convirt-lvm.png\"></p>\n<p>修改完成后重启虚拟机，生效配置。</p>\n<h2 id=\"3-登陆虚拟机配置lvm\"><a href=\"#3-登陆虚拟机配置lvm\" class=\"headerlink\" title=\"3.登陆虚拟机配置lvm\"></a>3.登陆虚拟机配置lvm</h2><h3 id=\"1、查看是否有新增的磁盘-这里为-dev-sdb\"><a href=\"#1、查看是否有新增的磁盘-这里为-dev-sdb\" class=\"headerlink\" title=\"1、查看是否有新增的磁盘(这里为/dev/sdb)\"></a>1、查看是否有新增的磁盘(这里为/dev/sdb)</h3><pre><code>[root@sz-145-centos177 ~]# fdisk  -l | grep Disk\nDisk /dev/sda: 125.8 GB, 125829120512 bytes\nDisk identifier: 0x0000ec73\nDisk /dev/sdb: 10.7 GB, 10737418240 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_root: 116.9 GB, 116912029696 bytes\nDisk identifier: 0x00000000\nDisk /dev/mapper/vg_templet-lv_swap: 8388 MB, 8388608000 bytes\nDisk identifier: 0x00000000\n</code></pre>\n<h3 id=\"2、创建pv\"><a href=\"#2、创建pv\" class=\"headerlink\" title=\"2、创建pv\"></a>2、创建pv</h3><pre><code>[root@sz-145-centos177 ~]# pvcreate /dev/sdb\n  Physical volume &quot;/dev/sdb&quot; successfully created\n</code></pre>\n<h3 id=\"3、查看vg-name\"><a href=\"#3、查看vg-name\" class=\"headerlink\" title=\"3、查看vg name\"></a>3、查看vg name</h3><pre><code>[root@sz-145-centos177 ~]# vgdisplay \n  --- Volume group ---\n  VG Name               vg_templet\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  3\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               116.70 GiB\n  PE Size               4.00 MiB\n  Total PE              29874\n  Alloc PE / Size       29874 / 116.70 GiB\n  Free  PE / Size       0 / 0   \n  VG UUID               kC3k3E-kTBv-isC7-7c7F-VhJu-YBHH-JinGkb\n</code></pre>\n<h3 id=\"4、扩容vg\"><a href=\"#4、扩容vg\" class=\"headerlink\" title=\"4、扩容vg\"></a>4、扩容vg</h3><pre><code>[root@sz-145-centos177 ~]# vgextend vg_templet /dev/sdb \n  Volume group &quot;vg_templet&quot; successfully extended\n</code></pre>\n<h3 id=\"5、扩容lv\"><a href=\"#5、扩容lv\" class=\"headerlink\" title=\"5、扩容lv\"></a>5、扩容lv</h3><pre><code>[root@sz-145-centos177 ~]# num=`vgdisplay |grep &quot;Free&quot; |awk &#39;&#123;print $5&#125;&#39;`\n[root@sz-145-centos177 ~]# lvresize -l +$num /dev/vg_templet/lv_root \n  Size of logical volume vg_templet/lv_root changed from 108.88 GiB (27874 extents) to 118.88 GiB (30433 extents).\n  Logical volume lv_root successfully resized.\n</code></pre>\n<h3 id=\"6、LV分区重设大小\"><a href=\"#6、LV分区重设大小\" class=\"headerlink\" title=\"6、LV分区重设大小\"></a>6、LV分区重设大小</h3><pre><code>[root@sz-145-centos177 ~]# resize2fs /dev/mapper/vg_templet-lv_root \nresize2fs 1.41.12 (17-May-2010)\nFilesystem at /dev/mapper/vg_templet-lv_root is mounted on /; on-line resizing required\nold desc_blocks = 7, new_desc_blocks = 8\nPerforming an on-line resize of /dev/mapper/vg_templet-lv_root to 31163392 (4k) blocks.\nThe filesystem on /dev/mapper/vg_templet-lv_root is now 31163392 blocks long.\n</code></pre>\n<h3 id=\"7-检查扩容后磁盘情况\"><a href=\"#7-检查扩容后磁盘情况\" class=\"headerlink\" title=\"7.检查扩容后磁盘情况\"></a>7.检查扩容后磁盘情况</h3><pre><code>[root@sz-145-centos177 ~]# df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/mapper/vg_templet-lv_root\n                      117G  2.9G  109G   3% /\ntmpfs                 1.9G     0  1.9G   0% /dev/shm\n/dev/sda1             477M   39M  413M   9% /boot\n</code></pre>\n"},{"layout":"post","title":"适合职场写总结周报","date":"2018-08-31T08:37:54.000Z","author":"owelinux","excerpt":"适合职场写总结周报","mathjax":true,"_content":"\n* content\n{:toc}\n\n\n# 适合职场写总结周报\n\n## 总结两套适合职场新人写总结套路（知乎作者：文明汪）\n\n学会基本可以应付职场初期的总结报告，当然，也要适合自己的岗位来写\n\n### 第一套：刚进入职场的总结写作套路\n由于这时候的自己是刚刚进入职场，对周围环境、人群、工作内容都不太熟悉，而熟悉这些内容尽量在一个月内搞定，这样才会让领导觉得你成熟。不过要记住，掌握这些也不必觉得自己怎么样，适应职场也是一个逐渐学习、涨经验的过程，你刚开始掌握的东西也仅仅是毛罢了。\n这一个月内的周总结，可以这样写：\n\n* 1、自己在公司内学习了什么？\n\n这就是等于梳理自己的工作内容，因为刚刚进入职场必须对自己的工作内容了解清楚，不然等过些阵子忙起来，不知道自己要干什么，就会产生一种瞎忙，没有方向的迷茫感，所以，将自己的工作梳理清楚十分重要。\n\n* 2、自己在哪些方面得到提高？\n\n刚进入工作岗位，领导肯定是要重点观察你的，尤其是你在前一两个月内有没有进步，但是一般情况下，领导看到的也只是表面，如果自己将自己的进步写出来，那么对领导来说再好不过了。当然，在写自己哪方面提高的时候，也要分条儿来写，不能胡写一通，而要根据真实情况来描述。\n\n* 3、自己有哪些不足，将如何提升？\n\n工作总结也不能光写自己哪方面提高了，还要写出自己在工作中的不足之处，比如沟通、专业知识欠缺、实操经验欠缺等等。说完自己的不足，再写出自己将要从哪方面提升自己，这样也相当于为自己定了一个计划，一举两得。这样，也会让领导觉得你很有上进心。刚进入职场前一个月，写这样的报告，领导还是比较满意的。\n\n### 第二套：适应职场后的总结写作套路\n入职一两个月后，自己的总结报告就要上升一个档次了！因为企业雇佣我们是来为企业解决问题的，不是来学习提升能力的，所以这时候自己应该像一个职场人一样，写一份成熟的总结报告。\n\n这份总结报告应该这样写：\n\n* 1、描述自己在工作中遇到的问题。\n\n一名出色的职工都具有一双善于发现问题的眼睛，而为企业解决问题的前提就是先要发现问题。所以，报告的开头要先描述自己发现的问题，要描述清楚。而清晰呈现的方法也有很多，比如图表，照片等等。\n\n* 2、分析问题产生的原因。\n\n凡事有因有果，出现问题必定有原因，这原因就有的写了。首先学习一下方法，这个方法是鱼刺图分析法。![](https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"600\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg)\n\n鱼头：表示工作中遇到的问题\n\n鱼刺：利用头脑风暴写出导致这个问题出现的所有原因，之后将原因进行整理分类，分别写到对应鱼刺上。\n\n当然，还有其他分析方法，比如数据对比、数学模型等等。\n\n* 3、制定对应措施。\n\n针对出现的问题，制定对应的措施，并对每个措施进行效果监测，如果效果不好，则需要不断优化，这也会是你报告中写的一部分。注意：制定完措施，也要对措施进行计划，必要的话要有一个记录表，这根据自己实际工作来安排。\n\n* 4、说出效果也就是结果怎样。\n\n最后就是总结部分，说出通过实施什么措施，解决了什么问题，效果如何。必要的话对结果进行展示或者前后对比。\n\n* 5、下周或者下月工作计划\n\n这部分根据工作来写，有计划总比没有好！哇，这样一份总结报告写出来，我都觉得很不错。\n\n### 第三套：符合自己工作实情的总结写作套路\n\n这就没什么套路了，这个套路就是在工作中自己总结了~逐渐形成自己的总结风格！什么是最好的总结报告，当然有实质内容，能够解决问题的报告最好了。但是由于我们工作的原因，大部分报告都是写写就得了。但是，万一遇到事情了呢？总之，先把方法学会，就什么都不怕了。\n\n## 个人总结思路分享\n\n复盘一般从两个方面进行:一是项目本身,二是你自己。\n\n从项目本身来说，更多的是工作知识及工作技巧的归纳\n\n* 你从这个项目中得出来了哪些经验?\n* 下一次遇到类似项目时你该怎么做?\n* 这一次在做这个项目时，中间有哪些问题疏漏，下一次应该如何解决？\n* 或者这一次有哪些方法用的很是好，下一次可以采纳的？\n* 从自身来说，就是自己在这次项目中扮演的什么角色，自己哪些做法很好，哪些做法很不成熟？\n* 为人处世方面的也算上。一块合作的队友他们做的怎么样？如果你们进行角色互换或者下一次整个项目都交给你你会怎么做？\n\n总之，就是学习长处，改进不足。\n\n因为：我们只注重了自己想表达什么？而忽略了读者/用户想看什么？我们忽略了用户真正的需求，用户想要什么？忽略了周报的可用性，是否对用户有意义和价值？忽略了周报的易用性，是否方便用户阅读，是否简单易懂，结构清晰，一目了然？如果作为一个读者/用户，看到的周报内容对自己没有任何意义和价值，且结构复杂，内容繁冗，更没有时间和精力去阅读，更不要谈反馈了。\n\n所以对于一份好的工作周报需要具备以下几个条件：\n\n一、搞清真正的用户是谁？哪些是你的汇报对象？\n\n二、内容需要是用户关注的，且对用户有价值与意义的三、内容简洁清晰，形式可视化具有结构性，提供多种查看方式，降低用户阅读成本\n\n\n### 知乎作者：郑喜月\n1.做周总结的时候先把本周做的事情分好类，每个类别下面分别做了什么事，不要12345这样零散的罗列，因为分类会让Boss觉得你对做的事情比较清晰，在分类的过程中你自己梳理了思路，别人看你的报告也比较清晰。\n\n2.要把每件事情的完成进度写出来，这样你的领导好知道接下来你还将花多少时间做这件事，好评估你的工作量给你指派任务。\n\n3.取得的成绩要用数据表达出来，这样看起来比较有说服力，尽量不要用“完成得很好”“已经超额完成”这样虚词。\n\n4.做的不好的不要直接写作的不好，首先分析客观原因，再分析主观原因，并给出积极解决的态度。\n\n5.未做完的事情要把你下一步准备怎么做简要写一下，让Boss知道你对这件事情是有想法的，而不是因为不会做才拖延。\n\n6.做完周总结要把下周计划写上去，这样说明你做事是有规划的。\n\n7.做周规划的时候记得把预期目标写上去，尤其是你要争取公司资源支持的时候，你要告诉领导你做这件事将会带来哪些好处，他才会放心的把资源交给你。\n\n## 感谢\n\n> * [https://www.zhihu.com/question/28852404/answer/457003101](https://www.zhihu.com/question/28852404/answer/457003101)","source":"_posts/2018-08-31-article24-life-work.md","raw":"---\nlayout: post\ntitle:  \"适合职场写总结周报\"\ndate:   2018-08-31 16:37:54\nauthor: owelinux\ncategories: 生活 \ntags:  生活  \nexcerpt: 适合职场写总结周报\nmathjax: true\n---\n\n* content\n{:toc}\n\n\n# 适合职场写总结周报\n\n## 总结两套适合职场新人写总结套路（知乎作者：文明汪）\n\n学会基本可以应付职场初期的总结报告，当然，也要适合自己的岗位来写\n\n### 第一套：刚进入职场的总结写作套路\n由于这时候的自己是刚刚进入职场，对周围环境、人群、工作内容都不太熟悉，而熟悉这些内容尽量在一个月内搞定，这样才会让领导觉得你成熟。不过要记住，掌握这些也不必觉得自己怎么样，适应职场也是一个逐渐学习、涨经验的过程，你刚开始掌握的东西也仅仅是毛罢了。\n这一个月内的周总结，可以这样写：\n\n* 1、自己在公司内学习了什么？\n\n这就是等于梳理自己的工作内容，因为刚刚进入职场必须对自己的工作内容了解清楚，不然等过些阵子忙起来，不知道自己要干什么，就会产生一种瞎忙，没有方向的迷茫感，所以，将自己的工作梳理清楚十分重要。\n\n* 2、自己在哪些方面得到提高？\n\n刚进入工作岗位，领导肯定是要重点观察你的，尤其是你在前一两个月内有没有进步，但是一般情况下，领导看到的也只是表面，如果自己将自己的进步写出来，那么对领导来说再好不过了。当然，在写自己哪方面提高的时候，也要分条儿来写，不能胡写一通，而要根据真实情况来描述。\n\n* 3、自己有哪些不足，将如何提升？\n\n工作总结也不能光写自己哪方面提高了，还要写出自己在工作中的不足之处，比如沟通、专业知识欠缺、实操经验欠缺等等。说完自己的不足，再写出自己将要从哪方面提升自己，这样也相当于为自己定了一个计划，一举两得。这样，也会让领导觉得你很有上进心。刚进入职场前一个月，写这样的报告，领导还是比较满意的。\n\n### 第二套：适应职场后的总结写作套路\n入职一两个月后，自己的总结报告就要上升一个档次了！因为企业雇佣我们是来为企业解决问题的，不是来学习提升能力的，所以这时候自己应该像一个职场人一样，写一份成熟的总结报告。\n\n这份总结报告应该这样写：\n\n* 1、描述自己在工作中遇到的问题。\n\n一名出色的职工都具有一双善于发现问题的眼睛，而为企业解决问题的前提就是先要发现问题。所以，报告的开头要先描述自己发现的问题，要描述清楚。而清晰呈现的方法也有很多，比如图表，照片等等。\n\n* 2、分析问题产生的原因。\n\n凡事有因有果，出现问题必定有原因，这原因就有的写了。首先学习一下方法，这个方法是鱼刺图分析法。![](https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"600\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg)\n\n鱼头：表示工作中遇到的问题\n\n鱼刺：利用头脑风暴写出导致这个问题出现的所有原因，之后将原因进行整理分类，分别写到对应鱼刺上。\n\n当然，还有其他分析方法，比如数据对比、数学模型等等。\n\n* 3、制定对应措施。\n\n针对出现的问题，制定对应的措施，并对每个措施进行效果监测，如果效果不好，则需要不断优化，这也会是你报告中写的一部分。注意：制定完措施，也要对措施进行计划，必要的话要有一个记录表，这根据自己实际工作来安排。\n\n* 4、说出效果也就是结果怎样。\n\n最后就是总结部分，说出通过实施什么措施，解决了什么问题，效果如何。必要的话对结果进行展示或者前后对比。\n\n* 5、下周或者下月工作计划\n\n这部分根据工作来写，有计划总比没有好！哇，这样一份总结报告写出来，我都觉得很不错。\n\n### 第三套：符合自己工作实情的总结写作套路\n\n这就没什么套路了，这个套路就是在工作中自己总结了~逐渐形成自己的总结风格！什么是最好的总结报告，当然有实质内容，能够解决问题的报告最好了。但是由于我们工作的原因，大部分报告都是写写就得了。但是，万一遇到事情了呢？总之，先把方法学会，就什么都不怕了。\n\n## 个人总结思路分享\n\n复盘一般从两个方面进行:一是项目本身,二是你自己。\n\n从项目本身来说，更多的是工作知识及工作技巧的归纳\n\n* 你从这个项目中得出来了哪些经验?\n* 下一次遇到类似项目时你该怎么做?\n* 这一次在做这个项目时，中间有哪些问题疏漏，下一次应该如何解决？\n* 或者这一次有哪些方法用的很是好，下一次可以采纳的？\n* 从自身来说，就是自己在这次项目中扮演的什么角色，自己哪些做法很好，哪些做法很不成熟？\n* 为人处世方面的也算上。一块合作的队友他们做的怎么样？如果你们进行角色互换或者下一次整个项目都交给你你会怎么做？\n\n总之，就是学习长处，改进不足。\n\n因为：我们只注重了自己想表达什么？而忽略了读者/用户想看什么？我们忽略了用户真正的需求，用户想要什么？忽略了周报的可用性，是否对用户有意义和价值？忽略了周报的易用性，是否方便用户阅读，是否简单易懂，结构清晰，一目了然？如果作为一个读者/用户，看到的周报内容对自己没有任何意义和价值，且结构复杂，内容繁冗，更没有时间和精力去阅读，更不要谈反馈了。\n\n所以对于一份好的工作周报需要具备以下几个条件：\n\n一、搞清真正的用户是谁？哪些是你的汇报对象？\n\n二、内容需要是用户关注的，且对用户有价值与意义的三、内容简洁清晰，形式可视化具有结构性，提供多种查看方式，降低用户阅读成本\n\n\n### 知乎作者：郑喜月\n1.做周总结的时候先把本周做的事情分好类，每个类别下面分别做了什么事，不要12345这样零散的罗列，因为分类会让Boss觉得你对做的事情比较清晰，在分类的过程中你自己梳理了思路，别人看你的报告也比较清晰。\n\n2.要把每件事情的完成进度写出来，这样你的领导好知道接下来你还将花多少时间做这件事，好评估你的工作量给你指派任务。\n\n3.取得的成绩要用数据表达出来，这样看起来比较有说服力，尽量不要用“完成得很好”“已经超额完成”这样虚词。\n\n4.做的不好的不要直接写作的不好，首先分析客观原因，再分析主观原因，并给出积极解决的态度。\n\n5.未做完的事情要把你下一步准备怎么做简要写一下，让Boss知道你对这件事情是有想法的，而不是因为不会做才拖延。\n\n6.做完周总结要把下周计划写上去，这样说明你做事是有规划的。\n\n7.做周规划的时候记得把预期目标写上去，尤其是你要争取公司资源支持的时候，你要告诉领导你做这件事将会带来哪些好处，他才会放心的把资源交给你。\n\n## 感谢\n\n> * [https://www.zhihu.com/question/28852404/answer/457003101](https://www.zhihu.com/question/28852404/answer/457003101)","slug":"2018-08-31-article24-life-work","published":1,"updated":"2021-02-09T02:00:24.571Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0c001hyc97g9nf0fqz","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"适合职场写总结周报\"><a href=\"#适合职场写总结周报\" class=\"headerlink\" title=\"适合职场写总结周报\"></a>适合职场写总结周报</h1><h2 id=\"总结两套适合职场新人写总结套路（知乎作者：文明汪）\"><a href=\"#总结两套适合职场新人写总结套路（知乎作者：文明汪）\" class=\"headerlink\" title=\"总结两套适合职场新人写总结套路（知乎作者：文明汪）\"></a>总结两套适合职场新人写总结套路（知乎作者：文明汪）</h2><p>学会基本可以应付职场初期的总结报告，当然，也要适合自己的岗位来写</p>\n<h3 id=\"第一套：刚进入职场的总结写作套路\"><a href=\"#第一套：刚进入职场的总结写作套路\" class=\"headerlink\" title=\"第一套：刚进入职场的总结写作套路\"></a>第一套：刚进入职场的总结写作套路</h3><p>由于这时候的自己是刚刚进入职场，对周围环境、人群、工作内容都不太熟悉，而熟悉这些内容尽量在一个月内搞定，这样才会让领导觉得你成熟。不过要记住，掌握这些也不必觉得自己怎么样，适应职场也是一个逐渐学习、涨经验的过程，你刚开始掌握的东西也仅仅是毛罢了。<br>这一个月内的周总结，可以这样写：</p>\n<ul>\n<li>1、自己在公司内学习了什么？</li>\n</ul>\n<p>这就是等于梳理自己的工作内容，因为刚刚进入职场必须对自己的工作内容了解清楚，不然等过些阵子忙起来，不知道自己要干什么，就会产生一种瞎忙，没有方向的迷茫感，所以，将自己的工作梳理清楚十分重要。</p>\n<ul>\n<li>2、自己在哪些方面得到提高？</li>\n</ul>\n<p>刚进入工作岗位，领导肯定是要重点观察你的，尤其是你在前一两个月内有没有进步，但是一般情况下，领导看到的也只是表面，如果自己将自己的进步写出来，那么对领导来说再好不过了。当然，在写自己哪方面提高的时候，也要分条儿来写，不能胡写一通，而要根据真实情况来描述。</p>\n<ul>\n<li>3、自己有哪些不足，将如何提升？</li>\n</ul>\n<p>工作总结也不能光写自己哪方面提高了，还要写出自己在工作中的不足之处，比如沟通、专业知识欠缺、实操经验欠缺等等。说完自己的不足，再写出自己将要从哪方面提升自己，这样也相当于为自己定了一个计划，一举两得。这样，也会让领导觉得你很有上进心。刚进入职场前一个月，写这样的报告，领导还是比较满意的。</p>\n<h3 id=\"第二套：适应职场后的总结写作套路\"><a href=\"#第二套：适应职场后的总结写作套路\" class=\"headerlink\" title=\"第二套：适应职场后的总结写作套路\"></a>第二套：适应职场后的总结写作套路</h3><p>入职一两个月后，自己的总结报告就要上升一个档次了！因为企业雇佣我们是来为企业解决问题的，不是来学习提升能力的，所以这时候自己应该像一个职场人一样，写一份成熟的总结报告。</p>\n<p>这份总结报告应该这样写：</p>\n<ul>\n<li>1、描述自己在工作中遇到的问题。</li>\n</ul>\n<p>一名出色的职工都具有一双善于发现问题的眼睛，而为企业解决问题的前提就是先要发现问题。所以，报告的开头要先描述自己发现的问题，要描述清楚。而清晰呈现的方法也有很多，比如图表，照片等等。</p>\n<ul>\n<li>2、分析问题产生的原因。</li>\n</ul>\n<p>凡事有因有果，出现问题必定有原因，这原因就有的写了。首先学习一下方法，这个方法是鱼刺图分析法。![](<a href=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg&quot;\">https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg&quot;</a> data-caption=”” data-size=”normal” data-rawwidth=”960” data-rawheight=”600” data-default-watermark-src=”<a href=\"https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg&quot;\">https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg&quot;</a> class=”origin_image zh-lightbox-thumb” width=”960” data-original=”<a href=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg\">https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg</a>)</p>\n<p>鱼头：表示工作中遇到的问题</p>\n<p>鱼刺：利用头脑风暴写出导致这个问题出现的所有原因，之后将原因进行整理分类，分别写到对应鱼刺上。</p>\n<p>当然，还有其他分析方法，比如数据对比、数学模型等等。</p>\n<ul>\n<li>3、制定对应措施。</li>\n</ul>\n<p>针对出现的问题，制定对应的措施，并对每个措施进行效果监测，如果效果不好，则需要不断优化，这也会是你报告中写的一部分。注意：制定完措施，也要对措施进行计划，必要的话要有一个记录表，这根据自己实际工作来安排。</p>\n<ul>\n<li>4、说出效果也就是结果怎样。</li>\n</ul>\n<p>最后就是总结部分，说出通过实施什么措施，解决了什么问题，效果如何。必要的话对结果进行展示或者前后对比。</p>\n<ul>\n<li>5、下周或者下月工作计划</li>\n</ul>\n<p>这部分根据工作来写，有计划总比没有好！哇，这样一份总结报告写出来，我都觉得很不错。</p>\n<h3 id=\"第三套：符合自己工作实情的总结写作套路\"><a href=\"#第三套：符合自己工作实情的总结写作套路\" class=\"headerlink\" title=\"第三套：符合自己工作实情的总结写作套路\"></a>第三套：符合自己工作实情的总结写作套路</h3><p>这就没什么套路了，这个套路就是在工作中自己总结了~逐渐形成自己的总结风格！什么是最好的总结报告，当然有实质内容，能够解决问题的报告最好了。但是由于我们工作的原因，大部分报告都是写写就得了。但是，万一遇到事情了呢？总之，先把方法学会，就什么都不怕了。</p>\n<h2 id=\"个人总结思路分享\"><a href=\"#个人总结思路分享\" class=\"headerlink\" title=\"个人总结思路分享\"></a>个人总结思路分享</h2><p>复盘一般从两个方面进行:一是项目本身,二是你自己。</p>\n<p>从项目本身来说，更多的是工作知识及工作技巧的归纳</p>\n<ul>\n<li>你从这个项目中得出来了哪些经验?</li>\n<li>下一次遇到类似项目时你该怎么做?</li>\n<li>这一次在做这个项目时，中间有哪些问题疏漏，下一次应该如何解决？</li>\n<li>或者这一次有哪些方法用的很是好，下一次可以采纳的？</li>\n<li>从自身来说，就是自己在这次项目中扮演的什么角色，自己哪些做法很好，哪些做法很不成熟？</li>\n<li>为人处世方面的也算上。一块合作的队友他们做的怎么样？如果你们进行角色互换或者下一次整个项目都交给你你会怎么做？</li>\n</ul>\n<p>总之，就是学习长处，改进不足。</p>\n<p>因为：我们只注重了自己想表达什么？而忽略了读者/用户想看什么？我们忽略了用户真正的需求，用户想要什么？忽略了周报的可用性，是否对用户有意义和价值？忽略了周报的易用性，是否方便用户阅读，是否简单易懂，结构清晰，一目了然？如果作为一个读者/用户，看到的周报内容对自己没有任何意义和价值，且结构复杂，内容繁冗，更没有时间和精力去阅读，更不要谈反馈了。</p>\n<p>所以对于一份好的工作周报需要具备以下几个条件：</p>\n<p>一、搞清真正的用户是谁？哪些是你的汇报对象？</p>\n<p>二、内容需要是用户关注的，且对用户有价值与意义的三、内容简洁清晰，形式可视化具有结构性，提供多种查看方式，降低用户阅读成本</p>\n<h3 id=\"知乎作者：郑喜月\"><a href=\"#知乎作者：郑喜月\" class=\"headerlink\" title=\"知乎作者：郑喜月\"></a>知乎作者：郑喜月</h3><p>1.做周总结的时候先把本周做的事情分好类，每个类别下面分别做了什么事，不要12345这样零散的罗列，因为分类会让Boss觉得你对做的事情比较清晰，在分类的过程中你自己梳理了思路，别人看你的报告也比较清晰。</p>\n<p>2.要把每件事情的完成进度写出来，这样你的领导好知道接下来你还将花多少时间做这件事，好评估你的工作量给你指派任务。</p>\n<p>3.取得的成绩要用数据表达出来，这样看起来比较有说服力，尽量不要用“完成得很好”“已经超额完成”这样虚词。</p>\n<p>4.做的不好的不要直接写作的不好，首先分析客观原因，再分析主观原因，并给出积极解决的态度。</p>\n<p>5.未做完的事情要把你下一步准备怎么做简要写一下，让Boss知道你对这件事情是有想法的，而不是因为不会做才拖延。</p>\n<p>6.做完周总结要把下周计划写上去，这样说明你做事是有规划的。</p>\n<p>7.做周规划的时候记得把预期目标写上去，尤其是你要争取公司资源支持的时候，你要告诉领导你做这件事将会带来哪些好处，他才会放心的把资源交给你。</p>\n<h2 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h2><blockquote>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/28852404/answer/457003101\">https://www.zhihu.com/question/28852404/answer/457003101</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"适合职场写总结周报\"><a href=\"#适合职场写总结周报\" class=\"headerlink\" title=\"适合职场写总结周报\"></a>适合职场写总结周报</h1><h2 id=\"总结两套适合职场新人写总结套路（知乎作者：文明汪）\"><a href=\"#总结两套适合职场新人写总结套路（知乎作者：文明汪）\" class=\"headerlink\" title=\"总结两套适合职场新人写总结套路（知乎作者：文明汪）\"></a>总结两套适合职场新人写总结套路（知乎作者：文明汪）</h2><p>学会基本可以应付职场初期的总结报告，当然，也要适合自己的岗位来写</p>\n<h3 id=\"第一套：刚进入职场的总结写作套路\"><a href=\"#第一套：刚进入职场的总结写作套路\" class=\"headerlink\" title=\"第一套：刚进入职场的总结写作套路\"></a>第一套：刚进入职场的总结写作套路</h3><p>由于这时候的自己是刚刚进入职场，对周围环境、人群、工作内容都不太熟悉，而熟悉这些内容尽量在一个月内搞定，这样才会让领导觉得你成熟。不过要记住，掌握这些也不必觉得自己怎么样，适应职场也是一个逐渐学习、涨经验的过程，你刚开始掌握的东西也仅仅是毛罢了。<br>这一个月内的周总结，可以这样写：</p>\n<ul>\n<li>1、自己在公司内学习了什么？</li>\n</ul>\n<p>这就是等于梳理自己的工作内容，因为刚刚进入职场必须对自己的工作内容了解清楚，不然等过些阵子忙起来，不知道自己要干什么，就会产生一种瞎忙，没有方向的迷茫感，所以，将自己的工作梳理清楚十分重要。</p>\n<ul>\n<li>2、自己在哪些方面得到提高？</li>\n</ul>\n<p>刚进入工作岗位，领导肯定是要重点观察你的，尤其是你在前一两个月内有没有进步，但是一般情况下，领导看到的也只是表面，如果自己将自己的进步写出来，那么对领导来说再好不过了。当然，在写自己哪方面提高的时候，也要分条儿来写，不能胡写一通，而要根据真实情况来描述。</p>\n<ul>\n<li>3、自己有哪些不足，将如何提升？</li>\n</ul>\n<p>工作总结也不能光写自己哪方面提高了，还要写出自己在工作中的不足之处，比如沟通、专业知识欠缺、实操经验欠缺等等。说完自己的不足，再写出自己将要从哪方面提升自己，这样也相当于为自己定了一个计划，一举两得。这样，也会让领导觉得你很有上进心。刚进入职场前一个月，写这样的报告，领导还是比较满意的。</p>\n<h3 id=\"第二套：适应职场后的总结写作套路\"><a href=\"#第二套：适应职场后的总结写作套路\" class=\"headerlink\" title=\"第二套：适应职场后的总结写作套路\"></a>第二套：适应职场后的总结写作套路</h3><p>入职一两个月后，自己的总结报告就要上升一个档次了！因为企业雇佣我们是来为企业解决问题的，不是来学习提升能力的，所以这时候自己应该像一个职场人一样，写一份成熟的总结报告。</p>\n<p>这份总结报告应该这样写：</p>\n<ul>\n<li>1、描述自己在工作中遇到的问题。</li>\n</ul>\n<p>一名出色的职工都具有一双善于发现问题的眼睛，而为企业解决问题的前提就是先要发现问题。所以，报告的开头要先描述自己发现的问题，要描述清楚。而清晰呈现的方法也有很多，比如图表，照片等等。</p>\n<ul>\n<li>2、分析问题产生的原因。</li>\n</ul>\n<p>凡事有因有果，出现问题必定有原因，这原因就有的写了。首先学习一下方法，这个方法是鱼刺图分析法。![](<a href=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg&quot;\">https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_b.jpg&quot;</a> data-caption=”” data-size=”normal” data-rawwidth=”960” data-rawheight=”600” data-default-watermark-src=”<a href=\"https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg&quot;\">https://pic3.zhimg.com/v2-a228b1abc84d59f42ff7a14f921eb696_b.jpg&quot;</a> class=”origin_image zh-lightbox-thumb” width=”960” data-original=”<a href=\"https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg\">https://pic3.zhimg.com/v2-b9dc48983685a495e9520d43904539f6_r.jpg</a>)</p>\n<p>鱼头：表示工作中遇到的问题</p>\n<p>鱼刺：利用头脑风暴写出导致这个问题出现的所有原因，之后将原因进行整理分类，分别写到对应鱼刺上。</p>\n<p>当然，还有其他分析方法，比如数据对比、数学模型等等。</p>\n<ul>\n<li>3、制定对应措施。</li>\n</ul>\n<p>针对出现的问题，制定对应的措施，并对每个措施进行效果监测，如果效果不好，则需要不断优化，这也会是你报告中写的一部分。注意：制定完措施，也要对措施进行计划，必要的话要有一个记录表，这根据自己实际工作来安排。</p>\n<ul>\n<li>4、说出效果也就是结果怎样。</li>\n</ul>\n<p>最后就是总结部分，说出通过实施什么措施，解决了什么问题，效果如何。必要的话对结果进行展示或者前后对比。</p>\n<ul>\n<li>5、下周或者下月工作计划</li>\n</ul>\n<p>这部分根据工作来写，有计划总比没有好！哇，这样一份总结报告写出来，我都觉得很不错。</p>\n<h3 id=\"第三套：符合自己工作实情的总结写作套路\"><a href=\"#第三套：符合自己工作实情的总结写作套路\" class=\"headerlink\" title=\"第三套：符合自己工作实情的总结写作套路\"></a>第三套：符合自己工作实情的总结写作套路</h3><p>这就没什么套路了，这个套路就是在工作中自己总结了~逐渐形成自己的总结风格！什么是最好的总结报告，当然有实质内容，能够解决问题的报告最好了。但是由于我们工作的原因，大部分报告都是写写就得了。但是，万一遇到事情了呢？总之，先把方法学会，就什么都不怕了。</p>\n<h2 id=\"个人总结思路分享\"><a href=\"#个人总结思路分享\" class=\"headerlink\" title=\"个人总结思路分享\"></a>个人总结思路分享</h2><p>复盘一般从两个方面进行:一是项目本身,二是你自己。</p>\n<p>从项目本身来说，更多的是工作知识及工作技巧的归纳</p>\n<ul>\n<li>你从这个项目中得出来了哪些经验?</li>\n<li>下一次遇到类似项目时你该怎么做?</li>\n<li>这一次在做这个项目时，中间有哪些问题疏漏，下一次应该如何解决？</li>\n<li>或者这一次有哪些方法用的很是好，下一次可以采纳的？</li>\n<li>从自身来说，就是自己在这次项目中扮演的什么角色，自己哪些做法很好，哪些做法很不成熟？</li>\n<li>为人处世方面的也算上。一块合作的队友他们做的怎么样？如果你们进行角色互换或者下一次整个项目都交给你你会怎么做？</li>\n</ul>\n<p>总之，就是学习长处，改进不足。</p>\n<p>因为：我们只注重了自己想表达什么？而忽略了读者/用户想看什么？我们忽略了用户真正的需求，用户想要什么？忽略了周报的可用性，是否对用户有意义和价值？忽略了周报的易用性，是否方便用户阅读，是否简单易懂，结构清晰，一目了然？如果作为一个读者/用户，看到的周报内容对自己没有任何意义和价值，且结构复杂，内容繁冗，更没有时间和精力去阅读，更不要谈反馈了。</p>\n<p>所以对于一份好的工作周报需要具备以下几个条件：</p>\n<p>一、搞清真正的用户是谁？哪些是你的汇报对象？</p>\n<p>二、内容需要是用户关注的，且对用户有价值与意义的三、内容简洁清晰，形式可视化具有结构性，提供多种查看方式，降低用户阅读成本</p>\n<h3 id=\"知乎作者：郑喜月\"><a href=\"#知乎作者：郑喜月\" class=\"headerlink\" title=\"知乎作者：郑喜月\"></a>知乎作者：郑喜月</h3><p>1.做周总结的时候先把本周做的事情分好类，每个类别下面分别做了什么事，不要12345这样零散的罗列，因为分类会让Boss觉得你对做的事情比较清晰，在分类的过程中你自己梳理了思路，别人看你的报告也比较清晰。</p>\n<p>2.要把每件事情的完成进度写出来，这样你的领导好知道接下来你还将花多少时间做这件事，好评估你的工作量给你指派任务。</p>\n<p>3.取得的成绩要用数据表达出来，这样看起来比较有说服力，尽量不要用“完成得很好”“已经超额完成”这样虚词。</p>\n<p>4.做的不好的不要直接写作的不好，首先分析客观原因，再分析主观原因，并给出积极解决的态度。</p>\n<p>5.未做完的事情要把你下一步准备怎么做简要写一下，让Boss知道你对这件事情是有想法的，而不是因为不会做才拖延。</p>\n<p>6.做完周总结要把下周计划写上去，这样说明你做事是有规划的。</p>\n<p>7.做周规划的时候记得把预期目标写上去，尤其是你要争取公司资源支持的时候，你要告诉领导你做这件事将会带来哪些好处，他才会放心的把资源交给你。</p>\n<h2 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h2><blockquote>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/28852404/answer/457003101\">https://www.zhihu.com/question/28852404/answer/457003101</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"文件系统（一）linux文件系统的选择","date":"2018-09-03T02:37:54.000Z","author":"owelinux","excerpt":"linux文件系统的选择","mathjax":true,"_content":"\n* content\n{:toc}\n\n\n# linux文件系统的选择\n\n通过综合使用多种标准文件系统Benchmarks对Ext3, Ext4, Reiserfs, XFS, JFS, Reiser4的性能测试对比，\n对不同应用选择合适的文件系统给出以下方案，供大家参考。文件系统性能测试数据见附表。\n\n\n## 1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)\nReiserfs(首选), Ext4文件系统适合这类负载特征，IO调度算法选择deadline，block size = 4096, ext4关闭日志功能。\n\nreiserfs mount参数：-o defaults, async, noatime, nodiratime, notail, data=writeback\n\next4 mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0关闭ext4日志：tune2fs -O as_journal /dev/sdXX \n\n## 2、大文件I/O应用(如视频下载、流媒体)\nEXT4文件系统适合此类负载特征，IO调度算法选择anticipatory, block size = 4096, 关闭日志功能，启用extent(default)。\n\nmount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0\n\n关闭ext4日志：tune2fs -O as_journal /dev/sdXX \n\n## 3、SSD文件系统选择\nEXT4/Reiserfs可以作为SSD文件系统，但未对SSD做优化，不能充分发挥SSD性能，并影响SSD使用时间。\n\nBtrfs对SSD作了优化，mount通过参数启用。但Btrfs仍处于实验阶段，生产环境谨慎使用。\n\nJFFS2/Nilfs2/YAFFS是常用的flash file system，在嵌入式环境广泛应用，建议使用。性能目前还未作测试评估。\n\n## 简单分析一下选择Reiserfs和ext4文件系统的原因：\n\n### 1、Reiserfs　\n大量小文件访问，衡量指标是IOPS，文件系统性能瓶颈在于文件元数据操作、目录操作、数据寻址。\n\nreiserfs对小文件作了优化，并使用B+ tree组织数据，加速了数据寻址，大大降低了\nopen/create/delete/close等系统调用开销。mount时指定noatime, nodiratime, notail，减少不必要的inode\n操作，notail关闭tail package功能，以空间换取更高性能。因此，对于随机的小I/O读写，reiserfs是很好的选择。\n\n### 2、Ext4　\n大文件顺序访问，衡量指标是IO吞吐量，文件系统性能瓶颈在于数据块布局(layout)、数据寻址。Ext4对\next3主要作了两方面的优化:　\n\n*  一是inode预分配。这使得inode具有很好的局部性特征，同一目录文件inode尽量放在一起，加速了目录寻\n址与操作性能。因此在小文件应用方面也具有很好的性能表现。　\n\n*  二是extent/delay/multi的数据块分配策略。这些策略使得大文件的数据块保持连续存储在磁盘上，数据寻\n址次数大大减少，显著提高I/O吞吐量。\n因此，对于顺序大I/O读写，EXT4是很好的选择。另外，XFS性能在大文件方面也相当不错。 \n\n\n## 感谢\n\n> * 老男孩教育第19期课堂讲解","source":"_posts/2018-09-03-article25-linux-fastdfs-1.md","raw":"---\nlayout: post\ntitle:  \"文件系统（一）linux文件系统的选择\"\ndate:   2018-09-03 10:37:54\nauthor: owelinux\ncategories: linux\ntags:  fastdfs  \nexcerpt: linux文件系统的选择\nmathjax: true\n---\n\n* content\n{:toc}\n\n\n# linux文件系统的选择\n\n通过综合使用多种标准文件系统Benchmarks对Ext3, Ext4, Reiserfs, XFS, JFS, Reiser4的性能测试对比，\n对不同应用选择合适的文件系统给出以下方案，供大家参考。文件系统性能测试数据见附表。\n\n\n## 1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)\nReiserfs(首选), Ext4文件系统适合这类负载特征，IO调度算法选择deadline，block size = 4096, ext4关闭日志功能。\n\nreiserfs mount参数：-o defaults, async, noatime, nodiratime, notail, data=writeback\n\next4 mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0关闭ext4日志：tune2fs -O as_journal /dev/sdXX \n\n## 2、大文件I/O应用(如视频下载、流媒体)\nEXT4文件系统适合此类负载特征，IO调度算法选择anticipatory, block size = 4096, 关闭日志功能，启用extent(default)。\n\nmount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0\n\n关闭ext4日志：tune2fs -O as_journal /dev/sdXX \n\n## 3、SSD文件系统选择\nEXT4/Reiserfs可以作为SSD文件系统，但未对SSD做优化，不能充分发挥SSD性能，并影响SSD使用时间。\n\nBtrfs对SSD作了优化，mount通过参数启用。但Btrfs仍处于实验阶段，生产环境谨慎使用。\n\nJFFS2/Nilfs2/YAFFS是常用的flash file system，在嵌入式环境广泛应用，建议使用。性能目前还未作测试评估。\n\n## 简单分析一下选择Reiserfs和ext4文件系统的原因：\n\n### 1、Reiserfs　\n大量小文件访问，衡量指标是IOPS，文件系统性能瓶颈在于文件元数据操作、目录操作、数据寻址。\n\nreiserfs对小文件作了优化，并使用B+ tree组织数据，加速了数据寻址，大大降低了\nopen/create/delete/close等系统调用开销。mount时指定noatime, nodiratime, notail，减少不必要的inode\n操作，notail关闭tail package功能，以空间换取更高性能。因此，对于随机的小I/O读写，reiserfs是很好的选择。\n\n### 2、Ext4　\n大文件顺序访问，衡量指标是IO吞吐量，文件系统性能瓶颈在于数据块布局(layout)、数据寻址。Ext4对\next3主要作了两方面的优化:　\n\n*  一是inode预分配。这使得inode具有很好的局部性特征，同一目录文件inode尽量放在一起，加速了目录寻\n址与操作性能。因此在小文件应用方面也具有很好的性能表现。　\n\n*  二是extent/delay/multi的数据块分配策略。这些策略使得大文件的数据块保持连续存储在磁盘上，数据寻\n址次数大大减少，显著提高I/O吞吐量。\n因此，对于顺序大I/O读写，EXT4是很好的选择。另外，XFS性能在大文件方面也相当不错。 \n\n\n## 感谢\n\n> * 老男孩教育第19期课堂讲解","slug":"2018-09-03-article25-linux-fastdfs-1","published":1,"updated":"2021-02-09T02:00:24.571Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0e001lyc97dl1r1hqt","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux文件系统的选择\"><a href=\"#linux文件系统的选择\" class=\"headerlink\" title=\"linux文件系统的选择\"></a>linux文件系统的选择</h1><p>通过综合使用多种标准文件系统Benchmarks对Ext3, Ext4, Reiserfs, XFS, JFS, Reiser4的性能测试对比，<br>对不同应用选择合适的文件系统给出以下方案，供大家参考。文件系统性能测试数据见附表。</p>\n<h2 id=\"1、大量小文件（LOSF-Lost-of-small-files）I-O应用-如小图片\"><a href=\"#1、大量小文件（LOSF-Lost-of-small-files）I-O应用-如小图片\" class=\"headerlink\" title=\"1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)\"></a>1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)</h2><p>Reiserfs(首选), Ext4文件系统适合这类负载特征，IO调度算法选择deadline，block size = 4096, ext4关闭日志功能。</p>\n<p>reiserfs mount参数：-o defaults, async, noatime, nodiratime, notail, data=writeback</p>\n<p>ext4 mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0关闭ext4日志：tune2fs -O as_journal /dev/sdXX </p>\n<h2 id=\"2、大文件I-O应用-如视频下载、流媒体\"><a href=\"#2、大文件I-O应用-如视频下载、流媒体\" class=\"headerlink\" title=\"2、大文件I/O应用(如视频下载、流媒体)\"></a>2、大文件I/O应用(如视频下载、流媒体)</h2><p>EXT4文件系统适合此类负载特征，IO调度算法选择anticipatory, block size = 4096, 关闭日志功能，启用extent(default)。</p>\n<p>mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0</p>\n<p>关闭ext4日志：tune2fs -O as_journal /dev/sdXX </p>\n<h2 id=\"3、SSD文件系统选择\"><a href=\"#3、SSD文件系统选择\" class=\"headerlink\" title=\"3、SSD文件系统选择\"></a>3、SSD文件系统选择</h2><p>EXT4/Reiserfs可以作为SSD文件系统，但未对SSD做优化，不能充分发挥SSD性能，并影响SSD使用时间。</p>\n<p>Btrfs对SSD作了优化，mount通过参数启用。但Btrfs仍处于实验阶段，生产环境谨慎使用。</p>\n<p>JFFS2/Nilfs2/YAFFS是常用的flash file system，在嵌入式环境广泛应用，建议使用。性能目前还未作测试评估。</p>\n<h2 id=\"简单分析一下选择Reiserfs和ext4文件系统的原因：\"><a href=\"#简单分析一下选择Reiserfs和ext4文件系统的原因：\" class=\"headerlink\" title=\"简单分析一下选择Reiserfs和ext4文件系统的原因：\"></a>简单分析一下选择Reiserfs和ext4文件系统的原因：</h2><h3 id=\"1、Reiserfs\"><a href=\"#1、Reiserfs\" class=\"headerlink\" title=\"1、Reiserfs\"></a>1、Reiserfs</h3><p>大量小文件访问，衡量指标是IOPS，文件系统性能瓶颈在于文件元数据操作、目录操作、数据寻址。</p>\n<p>reiserfs对小文件作了优化，并使用B+ tree组织数据，加速了数据寻址，大大降低了<br>open/create/delete/close等系统调用开销。mount时指定noatime, nodiratime, notail，减少不必要的inode<br>操作，notail关闭tail package功能，以空间换取更高性能。因此，对于随机的小I/O读写，reiserfs是很好的选择。</p>\n<h3 id=\"2、Ext4\"><a href=\"#2、Ext4\" class=\"headerlink\" title=\"2、Ext4\"></a>2、Ext4</h3><p>大文件顺序访问，衡量指标是IO吞吐量，文件系统性能瓶颈在于数据块布局(layout)、数据寻址。Ext4对<br>ext3主要作了两方面的优化:　</p>\n<ul>\n<li><p> 一是inode预分配。这使得inode具有很好的局部性特征，同一目录文件inode尽量放在一起，加速了目录寻<br>址与操作性能。因此在小文件应用方面也具有很好的性能表现。　</p>\n</li>\n<li><p> 二是extent/delay/multi的数据块分配策略。这些策略使得大文件的数据块保持连续存储在磁盘上，数据寻<br>址次数大大减少，显著提高I/O吞吐量。<br>因此，对于顺序大I/O读写，EXT4是很好的选择。另外，XFS性能在大文件方面也相当不错。 </p>\n</li>\n</ul>\n<h2 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h2><blockquote>\n<ul>\n<li>老男孩教育第19期课堂讲解</li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux文件系统的选择\"><a href=\"#linux文件系统的选择\" class=\"headerlink\" title=\"linux文件系统的选择\"></a>linux文件系统的选择</h1><p>通过综合使用多种标准文件系统Benchmarks对Ext3, Ext4, Reiserfs, XFS, JFS, Reiser4的性能测试对比，<br>对不同应用选择合适的文件系统给出以下方案，供大家参考。文件系统性能测试数据见附表。</p>\n<h2 id=\"1、大量小文件（LOSF-Lost-of-small-files）I-O应用-如小图片\"><a href=\"#1、大量小文件（LOSF-Lost-of-small-files）I-O应用-如小图片\" class=\"headerlink\" title=\"1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)\"></a>1、大量小文件（LOSF, Lost of small files）I/O应用(如小图片)</h2><p>Reiserfs(首选), Ext4文件系统适合这类负载特征，IO调度算法选择deadline，block size = 4096, ext4关闭日志功能。</p>\n<p>reiserfs mount参数：-o defaults, async, noatime, nodiratime, notail, data=writeback</p>\n<p>ext4 mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0关闭ext4日志：tune2fs -O as_journal /dev/sdXX </p>\n<h2 id=\"2、大文件I-O应用-如视频下载、流媒体\"><a href=\"#2、大文件I-O应用-如视频下载、流媒体\" class=\"headerlink\" title=\"2、大文件I/O应用(如视频下载、流媒体)\"></a>2、大文件I/O应用(如视频下载、流媒体)</h2><p>EXT4文件系统适合此类负载特征，IO调度算法选择anticipatory, block size = 4096, 关闭日志功能，启用extent(default)。</p>\n<p>mount参数：-o defaults, async, noatime, nodiratime, data=writeback, barrier=0</p>\n<p>关闭ext4日志：tune2fs -O as_journal /dev/sdXX </p>\n<h2 id=\"3、SSD文件系统选择\"><a href=\"#3、SSD文件系统选择\" class=\"headerlink\" title=\"3、SSD文件系统选择\"></a>3、SSD文件系统选择</h2><p>EXT4/Reiserfs可以作为SSD文件系统，但未对SSD做优化，不能充分发挥SSD性能，并影响SSD使用时间。</p>\n<p>Btrfs对SSD作了优化，mount通过参数启用。但Btrfs仍处于实验阶段，生产环境谨慎使用。</p>\n<p>JFFS2/Nilfs2/YAFFS是常用的flash file system，在嵌入式环境广泛应用，建议使用。性能目前还未作测试评估。</p>\n<h2 id=\"简单分析一下选择Reiserfs和ext4文件系统的原因：\"><a href=\"#简单分析一下选择Reiserfs和ext4文件系统的原因：\" class=\"headerlink\" title=\"简单分析一下选择Reiserfs和ext4文件系统的原因：\"></a>简单分析一下选择Reiserfs和ext4文件系统的原因：</h2><h3 id=\"1、Reiserfs\"><a href=\"#1、Reiserfs\" class=\"headerlink\" title=\"1、Reiserfs\"></a>1、Reiserfs</h3><p>大量小文件访问，衡量指标是IOPS，文件系统性能瓶颈在于文件元数据操作、目录操作、数据寻址。</p>\n<p>reiserfs对小文件作了优化，并使用B+ tree组织数据，加速了数据寻址，大大降低了<br>open/create/delete/close等系统调用开销。mount时指定noatime, nodiratime, notail，减少不必要的inode<br>操作，notail关闭tail package功能，以空间换取更高性能。因此，对于随机的小I/O读写，reiserfs是很好的选择。</p>\n<h3 id=\"2、Ext4\"><a href=\"#2、Ext4\" class=\"headerlink\" title=\"2、Ext4\"></a>2、Ext4</h3><p>大文件顺序访问，衡量指标是IO吞吐量，文件系统性能瓶颈在于数据块布局(layout)、数据寻址。Ext4对<br>ext3主要作了两方面的优化:　</p>\n<ul>\n<li><p> 一是inode预分配。这使得inode具有很好的局部性特征，同一目录文件inode尽量放在一起，加速了目录寻<br>址与操作性能。因此在小文件应用方面也具有很好的性能表现。　</p>\n</li>\n<li><p> 二是extent/delay/multi的数据块分配策略。这些策略使得大文件的数据块保持连续存储在磁盘上，数据寻<br>址次数大大减少，显著提高I/O吞吐量。<br>因此，对于顺序大I/O读写，EXT4是很好的选择。另外，XFS性能在大文件方面也相当不错。 </p>\n</li>\n</ul>\n<h2 id=\"感谢\"><a href=\"#感谢\" class=\"headerlink\" title=\"感谢\"></a>感谢</h2><blockquote>\n<ul>\n<li>老男孩教育第19期课堂讲解</li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"文件系统（二）fastdfs是什么? ","date":"2018-09-03T02:43:54.000Z","author":"owelinux","excerpt":"本来想写点fastdfs内容，发现有总结非常好的博文，这里拿出来分享给大家","mathjax":true,"_content":"\n* content\n{:toc}\n\n# fastdfs是什么? \n\n## 一、FastDFS概述\n\nFastDFS是阿里巴巴开源的一套轻量级,天生就是分布式设计的文件系统，FastDFS的源代码由C语言开发，目前可运行在Linux,FreeBSD，Unix等类操作系统上，FastDFS解决了大数据量文件存储和读写分离,备份容错,负载均衡,动态扩容等问题，这也就是原作者所描述的高性能和高扩展性的文件系统。适合存储4KB~500MB之间的小文件，如图片网站、短视频网站、文档、app下载站等。\n\n## 二、FastDFS作者简介\n\nFastDFS的作者是余庆(happyfish100)，github地址[https://github.com/happyfish100](https://github.com/happyfish100)\n\n## 三、FastDFS主要特性\n\n1.为互联网量身定制，海量数据文件存储。\n\n2.高可用(同组备份机制)。\n\n3.FastDFS不是通用的文件系统，只能通过api来访问，目前提供c,java,php客户端。phtyon由第三方开发者提供。\n\n4;FastDFS可以看作是基于key/value pair存储系统，也许称为分布式文件存储服务更合适。\n\n5;支持高并发(这个好像没体现出支持什么高并发,这个是nginx的功劳吧)\n\n## 四、主要用户\n\n* 京东(http://www.jd.com/),主要商品图片存储,可以看出来这是fastdfs典型路径\n  http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg\n\n* UC(http://www.uc.cn/),主要提供网盘服务\n\n* 支付宝(https://www.alipay.com/)\n\n* Lockbur高清壁纸分享网站(http://www.lockbur.com/),主要提供小图片存储服务。\n\n## 参考\n\n> * [https://blog.csdn.net/wk313753744/article/details/49943155](https://blog.csdn.net/wk313753744/article/details/49943155)","source":"_posts/2018-09-03-article26-linux-fastdfs-2.md","raw":"---\nlayout: post\ntitle:  \"文件系统（二）fastdfs是什么? \"\ndate:   2018-09-03 10:43:54\nauthor: owelinux\ncategories: linux \ntags:  fastdfs  \nexcerpt: 本来想写点fastdfs内容，发现有总结非常好的博文，这里拿出来分享给大家\nmathjax: true\n---\n\n* content\n{:toc}\n\n# fastdfs是什么? \n\n## 一、FastDFS概述\n\nFastDFS是阿里巴巴开源的一套轻量级,天生就是分布式设计的文件系统，FastDFS的源代码由C语言开发，目前可运行在Linux,FreeBSD，Unix等类操作系统上，FastDFS解决了大数据量文件存储和读写分离,备份容错,负载均衡,动态扩容等问题，这也就是原作者所描述的高性能和高扩展性的文件系统。适合存储4KB~500MB之间的小文件，如图片网站、短视频网站、文档、app下载站等。\n\n## 二、FastDFS作者简介\n\nFastDFS的作者是余庆(happyfish100)，github地址[https://github.com/happyfish100](https://github.com/happyfish100)\n\n## 三、FastDFS主要特性\n\n1.为互联网量身定制，海量数据文件存储。\n\n2.高可用(同组备份机制)。\n\n3.FastDFS不是通用的文件系统，只能通过api来访问，目前提供c,java,php客户端。phtyon由第三方开发者提供。\n\n4;FastDFS可以看作是基于key/value pair存储系统，也许称为分布式文件存储服务更合适。\n\n5;支持高并发(这个好像没体现出支持什么高并发,这个是nginx的功劳吧)\n\n## 四、主要用户\n\n* 京东(http://www.jd.com/),主要商品图片存储,可以看出来这是fastdfs典型路径\n  http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg\n\n* UC(http://www.uc.cn/),主要提供网盘服务\n\n* 支付宝(https://www.alipay.com/)\n\n* Lockbur高清壁纸分享网站(http://www.lockbur.com/),主要提供小图片存储服务。\n\n## 参考\n\n> * [https://blog.csdn.net/wk313753744/article/details/49943155](https://blog.csdn.net/wk313753744/article/details/49943155)","slug":"2018-09-03-article26-linux-fastdfs-2","published":1,"updated":"2021-02-09T02:00:24.571Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0f001pyc97hilv3vxh","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs是什么\"><a href=\"#fastdfs是什么\" class=\"headerlink\" title=\"fastdfs是什么?\"></a>fastdfs是什么?</h1><h2 id=\"一、FastDFS概述\"><a href=\"#一、FastDFS概述\" class=\"headerlink\" title=\"一、FastDFS概述\"></a>一、FastDFS概述</h2><p>FastDFS是阿里巴巴开源的一套轻量级,天生就是分布式设计的文件系统，FastDFS的源代码由C语言开发，目前可运行在Linux,FreeBSD，Unix等类操作系统上，FastDFS解决了大数据量文件存储和读写分离,备份容错,负载均衡,动态扩容等问题，这也就是原作者所描述的高性能和高扩展性的文件系统。适合存储4KB~500MB之间的小文件，如图片网站、短视频网站、文档、app下载站等。</p>\n<h2 id=\"二、FastDFS作者简介\"><a href=\"#二、FastDFS作者简介\" class=\"headerlink\" title=\"二、FastDFS作者简介\"></a>二、FastDFS作者简介</h2><p>FastDFS的作者是余庆(happyfish100)，github地址<a href=\"https://github.com/happyfish100\">https://github.com/happyfish100</a></p>\n<h2 id=\"三、FastDFS主要特性\"><a href=\"#三、FastDFS主要特性\" class=\"headerlink\" title=\"三、FastDFS主要特性\"></a>三、FastDFS主要特性</h2><p>1.为互联网量身定制，海量数据文件存储。</p>\n<p>2.高可用(同组备份机制)。</p>\n<p>3.FastDFS不是通用的文件系统，只能通过api来访问，目前提供c,java,php客户端。phtyon由第三方开发者提供。</p>\n<p>4;FastDFS可以看作是基于key/value pair存储系统，也许称为分布式文件存储服务更合适。</p>\n<p>5;支持高并发(这个好像没体现出支持什么高并发,这个是nginx的功劳吧)</p>\n<h2 id=\"四、主要用户\"><a href=\"#四、主要用户\" class=\"headerlink\" title=\"四、主要用户\"></a>四、主要用户</h2><ul>\n<li><p>京东(<a href=\"http://www.jd.com/),%E4%B8%BB%E8%A6%81%E5%95%86%E5%93%81%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8,%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%E6%9D%A5%E8%BF%99%E6%98%AFfastdfs%E5%85%B8%E5%9E%8B%E8%B7%AF%E5%BE%84\">http://www.jd.com/),主要商品图片存储,可以看出来这是fastdfs典型路径</a><br><a href=\"http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg\">http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg</a></p>\n</li>\n<li><p>UC(<a href=\"http://www.uc.cn/),%E4%B8%BB%E8%A6%81%E6%8F%90%E4%BE%9B%E7%BD%91%E7%9B%98%E6%9C%8D%E5%8A%A1\">http://www.uc.cn/),主要提供网盘服务</a></p>\n</li>\n<li><p>支付宝(<a href=\"https://www.alipay.com/\">https://www.alipay.com/</a>)</p>\n</li>\n<li><p>Lockbur高清壁纸分享网站(<a href=\"http://www.lockbur.com/),%E4%B8%BB%E8%A6%81%E6%8F%90%E4%BE%9B%E5%B0%8F%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E3%80%82\">http://www.lockbur.com/),主要提供小图片存储服务。</a></p>\n</li>\n</ul>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/wk313753744/article/details/49943155\">https://blog.csdn.net/wk313753744/article/details/49943155</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs是什么\"><a href=\"#fastdfs是什么\" class=\"headerlink\" title=\"fastdfs是什么?\"></a>fastdfs是什么?</h1><h2 id=\"一、FastDFS概述\"><a href=\"#一、FastDFS概述\" class=\"headerlink\" title=\"一、FastDFS概述\"></a>一、FastDFS概述</h2><p>FastDFS是阿里巴巴开源的一套轻量级,天生就是分布式设计的文件系统，FastDFS的源代码由C语言开发，目前可运行在Linux,FreeBSD，Unix等类操作系统上，FastDFS解决了大数据量文件存储和读写分离,备份容错,负载均衡,动态扩容等问题，这也就是原作者所描述的高性能和高扩展性的文件系统。适合存储4KB~500MB之间的小文件，如图片网站、短视频网站、文档、app下载站等。</p>\n<h2 id=\"二、FastDFS作者简介\"><a href=\"#二、FastDFS作者简介\" class=\"headerlink\" title=\"二、FastDFS作者简介\"></a>二、FastDFS作者简介</h2><p>FastDFS的作者是余庆(happyfish100)，github地址<a href=\"https://github.com/happyfish100\">https://github.com/happyfish100</a></p>\n<h2 id=\"三、FastDFS主要特性\"><a href=\"#三、FastDFS主要特性\" class=\"headerlink\" title=\"三、FastDFS主要特性\"></a>三、FastDFS主要特性</h2><p>1.为互联网量身定制，海量数据文件存储。</p>\n<p>2.高可用(同组备份机制)。</p>\n<p>3.FastDFS不是通用的文件系统，只能通过api来访问，目前提供c,java,php客户端。phtyon由第三方开发者提供。</p>\n<p>4;FastDFS可以看作是基于key/value pair存储系统，也许称为分布式文件存储服务更合适。</p>\n<p>5;支持高并发(这个好像没体现出支持什么高并发,这个是nginx的功劳吧)</p>\n<h2 id=\"四、主要用户\"><a href=\"#四、主要用户\" class=\"headerlink\" title=\"四、主要用户\"></a>四、主要用户</h2><ul>\n<li><p>京东(<a href=\"http://www.jd.com/),%E4%B8%BB%E8%A6%81%E5%95%86%E5%93%81%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8,%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%E6%9D%A5%E8%BF%99%E6%98%AFfastdfs%E5%85%B8%E5%9E%8B%E8%B7%AF%E5%BE%84\">http://www.jd.com/),主要商品图片存储,可以看出来这是fastdfs典型路径</a><br><a href=\"http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg\">http://img12.360buyimg.com/n9/g15/M08/0B/19/rBEhWVMdbUMIAAAAAAEo7QHfEvoAAJwzAC7VvkAASkF751.jpg</a></p>\n</li>\n<li><p>UC(<a href=\"http://www.uc.cn/),%E4%B8%BB%E8%A6%81%E6%8F%90%E4%BE%9B%E7%BD%91%E7%9B%98%E6%9C%8D%E5%8A%A1\">http://www.uc.cn/),主要提供网盘服务</a></p>\n</li>\n<li><p>支付宝(<a href=\"https://www.alipay.com/\">https://www.alipay.com/</a>)</p>\n</li>\n<li><p>Lockbur高清壁纸分享网站(<a href=\"http://www.lockbur.com/),%E4%B8%BB%E8%A6%81%E6%8F%90%E4%BE%9B%E5%B0%8F%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E3%80%82\">http://www.lockbur.com/),主要提供小图片存储服务。</a></p>\n</li>\n</ul>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/wk313753744/article/details/49943155\">https://blog.csdn.net/wk313753744/article/details/49943155</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"文件系统（三）fastdfs和其他文件系统区别 ","date":"2018-09-03T03:43:54.000Z","author":"owelinux","excerpt":"本来想写点fastdfs内容，发现有总结非常好的博文，这里拿出来分享给大家","mathjax":true,"_content":"\n* content\n{:toc}\n\n# fastdfs和其他文件系统区别\n\n## 一、概述\n\n普通存储方案：Rsync、DAS(IDE/SATA/SAS/SCSI等块)、NAS(NFS、CIFS、SAMBA等文件系统)、SAN(FibreChannel, iSCSI, FoE存储网络块)，Openfiler、FreeNas(ZFS快照复制)由于生产环境中往往由于对存储数据量很大，而SAN存储价格又比较昂贵，因此大多会选择分布式\n存储来解决一下问题：\n\n* 海量数据存储问题\n* 数据高可用问题(冗余备份)问题\n* 较高的读写性能和负载均衡问题\n* 支持多平台多语言问题\n* 高并发问题\n\n主要对别指标 csdn这表格太难用了，我还是word整理后搬到这儿来的。\n\n![](https://owelinux.github.io/images/2018-09-03-article27-linux-fastdfs-3/fastdfs3.png)\n\n## 二、常用的分布式文件系统\n\n常见的分布式文件系统有FastDFS，GFS、HDFS、Ceph 、GridFS 、mogileFS、TFS等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。\n\n### FastDFS介绍\n请参照FastDFS文件系统(一) fastdfs是什么? \n\n### GFS（Google File System）\nGoogle公司为了满足本公司需求而开发的基于Linux的专有分布式文件系统。。尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。\n下面分布式文件系统都是类 GFS的产品。\n\n### HDFS（Hadoop Distributed File System）\nHadoop 实现了一个分布式文件系统，主要用于大数据计算存储，简称HDFS。 Hadoop是Apache Lucene创始人Doug Cutting开发的使用广泛的文本搜索库。它起源于Apache Nutch，后者是一个开源的网络搜索引擎，本身也是Luene项目的一部分。Aapche Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。\n\n### Ceph\n\ngithub：[https://github.com/ceph/ceph](https://github.com/ceph/ceph)\n\n是加州大学圣克鲁兹分校的Sage weil攻读博士时开发的分布式文件系统。Ceph能够在维护 POSIX 兼容性的同时加入了复制和容错功能。Sage weil并使用Ceph完成了他的论文。说 ceph 性能最高，C++编写的代码，支持Fuse，并且没有单点故障依赖， 于是下载安装， 由于 ceph 使用 btrfs 文件系统， 而btrfs 文件系统需要 Linux 2.6.34 以上的内核才支持。\n\n### GridFS文件系统\nMongoDB是一种知名的NoSql数据库，GridFS是MongoDB的一个内置功能，它提供一组文件操作的API以利用MongoDB存储文件，GridFS的基本原理是将文件保存在两个Collection中，一个保存文件索引，一个保存文件内容，文件内容按一定大小分成若干块，每一块存在一个Document中，这种方法不仅提供了文件存储，还提供了对文件相关的一些附加属性（比如MD5值，文件名等等）的存储。文件在GridFS中会按4MB为单位进行分块存储。\n\n### MogileFS\n由memcahed的开发公司danga一款perl开发的产品，目前国内使用mogielFS的有图片托管网站yupoo等。\nMogileFS是一套高效的文件自动备份组件，由Six Apart开发，广泛应用在包括LiveJournal等web2.0站点上。\nMogileFS由3个部分组成：\n\n* 第1个部分是server端，包括mogilefsd和mogstored两个程序。前者即是 mogilefsd的tracker，它将一些全局信息保存在数据库里，例如站点domain,class,host等。后者即是存储节点(store node)，它其实是个HTTP Daemon，默认侦听在7500端口，接受客户端的文件备份请求。在安装完后，要运行mogadm工具将所有的store node注册到mogilefsd的数据库里，mogilefsd会对这些节点进行管理和监控。\n\n* 第2个部分是utils（工具集），主要是MogileFS的一些管理工具，例如mogadm等。\n　　\n* 第3个部分是客户端API，目前只有Perl API(MogileFS.pm)、PHP，用这个模块可以编写客户端程序，实现文件的备份管理功能。\n\n\n### TFS\nTFS（Taobao !FileSystem）是一个高可扩展、高可用、高性能、面向互联网服务的分布式文件系统，主要针对海量的非结构化数据，它构筑在普通的Linux机器 集群上，可为外部提供高可靠和高并发的存储访问。TFS为淘宝提供海量小文件存储，通常文件大小不超过1M，满足了淘宝对小文件存储的需求，被广泛地应用 在淘宝各项应用中。它采用了HA架构和平滑扩容，保证了整个文件系统的可用性和扩展性。同时扁平化的数据组织结构，可将文件名映射到文件的物理地址，简化 了文件的访问流程，一定程度上为TFS提供了良好的读写性能。\n\n官网 ： [http://code.taobao.org/p/tfs/wiki/index/](http://code.taobao.org/p/tfs/wiki/index/)\n\n## 参考\n\n> * [https://blog.csdn.net/wk313753744/article/details/49943835](https://blog.csdn.net/wk313753744/article/details/49943835)","source":"_posts/2018-09-03-article27-linux-fastdfs-3.md","raw":"---\nlayout: post\ntitle:  \"文件系统（三）fastdfs和其他文件系统区别 \"\ndate:   2018-09-03 11:43:54\nauthor: owelinux\ncategories: linux \ntags:  fastdfs  \nexcerpt: 本来想写点fastdfs内容，发现有总结非常好的博文，这里拿出来分享给大家\nmathjax: true\n---\n\n* content\n{:toc}\n\n# fastdfs和其他文件系统区别\n\n## 一、概述\n\n普通存储方案：Rsync、DAS(IDE/SATA/SAS/SCSI等块)、NAS(NFS、CIFS、SAMBA等文件系统)、SAN(FibreChannel, iSCSI, FoE存储网络块)，Openfiler、FreeNas(ZFS快照复制)由于生产环境中往往由于对存储数据量很大，而SAN存储价格又比较昂贵，因此大多会选择分布式\n存储来解决一下问题：\n\n* 海量数据存储问题\n* 数据高可用问题(冗余备份)问题\n* 较高的读写性能和负载均衡问题\n* 支持多平台多语言问题\n* 高并发问题\n\n主要对别指标 csdn这表格太难用了，我还是word整理后搬到这儿来的。\n\n![](https://owelinux.github.io/images/2018-09-03-article27-linux-fastdfs-3/fastdfs3.png)\n\n## 二、常用的分布式文件系统\n\n常见的分布式文件系统有FastDFS，GFS、HDFS、Ceph 、GridFS 、mogileFS、TFS等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。\n\n### FastDFS介绍\n请参照FastDFS文件系统(一) fastdfs是什么? \n\n### GFS（Google File System）\nGoogle公司为了满足本公司需求而开发的基于Linux的专有分布式文件系统。。尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。\n下面分布式文件系统都是类 GFS的产品。\n\n### HDFS（Hadoop Distributed File System）\nHadoop 实现了一个分布式文件系统，主要用于大数据计算存储，简称HDFS。 Hadoop是Apache Lucene创始人Doug Cutting开发的使用广泛的文本搜索库。它起源于Apache Nutch，后者是一个开源的网络搜索引擎，本身也是Luene项目的一部分。Aapche Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。\n\n### Ceph\n\ngithub：[https://github.com/ceph/ceph](https://github.com/ceph/ceph)\n\n是加州大学圣克鲁兹分校的Sage weil攻读博士时开发的分布式文件系统。Ceph能够在维护 POSIX 兼容性的同时加入了复制和容错功能。Sage weil并使用Ceph完成了他的论文。说 ceph 性能最高，C++编写的代码，支持Fuse，并且没有单点故障依赖， 于是下载安装， 由于 ceph 使用 btrfs 文件系统， 而btrfs 文件系统需要 Linux 2.6.34 以上的内核才支持。\n\n### GridFS文件系统\nMongoDB是一种知名的NoSql数据库，GridFS是MongoDB的一个内置功能，它提供一组文件操作的API以利用MongoDB存储文件，GridFS的基本原理是将文件保存在两个Collection中，一个保存文件索引，一个保存文件内容，文件内容按一定大小分成若干块，每一块存在一个Document中，这种方法不仅提供了文件存储，还提供了对文件相关的一些附加属性（比如MD5值，文件名等等）的存储。文件在GridFS中会按4MB为单位进行分块存储。\n\n### MogileFS\n由memcahed的开发公司danga一款perl开发的产品，目前国内使用mogielFS的有图片托管网站yupoo等。\nMogileFS是一套高效的文件自动备份组件，由Six Apart开发，广泛应用在包括LiveJournal等web2.0站点上。\nMogileFS由3个部分组成：\n\n* 第1个部分是server端，包括mogilefsd和mogstored两个程序。前者即是 mogilefsd的tracker，它将一些全局信息保存在数据库里，例如站点domain,class,host等。后者即是存储节点(store node)，它其实是个HTTP Daemon，默认侦听在7500端口，接受客户端的文件备份请求。在安装完后，要运行mogadm工具将所有的store node注册到mogilefsd的数据库里，mogilefsd会对这些节点进行管理和监控。\n\n* 第2个部分是utils（工具集），主要是MogileFS的一些管理工具，例如mogadm等。\n　　\n* 第3个部分是客户端API，目前只有Perl API(MogileFS.pm)、PHP，用这个模块可以编写客户端程序，实现文件的备份管理功能。\n\n\n### TFS\nTFS（Taobao !FileSystem）是一个高可扩展、高可用、高性能、面向互联网服务的分布式文件系统，主要针对海量的非结构化数据，它构筑在普通的Linux机器 集群上，可为外部提供高可靠和高并发的存储访问。TFS为淘宝提供海量小文件存储，通常文件大小不超过1M，满足了淘宝对小文件存储的需求，被广泛地应用 在淘宝各项应用中。它采用了HA架构和平滑扩容，保证了整个文件系统的可用性和扩展性。同时扁平化的数据组织结构，可将文件名映射到文件的物理地址，简化 了文件的访问流程，一定程度上为TFS提供了良好的读写性能。\n\n官网 ： [http://code.taobao.org/p/tfs/wiki/index/](http://code.taobao.org/p/tfs/wiki/index/)\n\n## 参考\n\n> * [https://blog.csdn.net/wk313753744/article/details/49943835](https://blog.csdn.net/wk313753744/article/details/49943835)","slug":"2018-09-03-article27-linux-fastdfs-3","published":1,"updated":"2021-02-09T02:00:24.572Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0g001syc970u8seiuy","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs和其他文件系统区别\"><a href=\"#fastdfs和其他文件系统区别\" class=\"headerlink\" title=\"fastdfs和其他文件系统区别\"></a>fastdfs和其他文件系统区别</h1><h2 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h2><p>普通存储方案：Rsync、DAS(IDE/SATA/SAS/SCSI等块)、NAS(NFS、CIFS、SAMBA等文件系统)、SAN(FibreChannel, iSCSI, FoE存储网络块)，Openfiler、FreeNas(ZFS快照复制)由于生产环境中往往由于对存储数据量很大，而SAN存储价格又比较昂贵，因此大多会选择分布式<br>存储来解决一下问题：</p>\n<ul>\n<li>海量数据存储问题</li>\n<li>数据高可用问题(冗余备份)问题</li>\n<li>较高的读写性能和负载均衡问题</li>\n<li>支持多平台多语言问题</li>\n<li>高并发问题</li>\n</ul>\n<p>主要对别指标 csdn这表格太难用了，我还是word整理后搬到这儿来的。</p>\n<p><img src=\"https://owelinux.github.io/images/2018-09-03-article27-linux-fastdfs-3/fastdfs3.png\"></p>\n<h2 id=\"二、常用的分布式文件系统\"><a href=\"#二、常用的分布式文件系统\" class=\"headerlink\" title=\"二、常用的分布式文件系统\"></a>二、常用的分布式文件系统</h2><p>常见的分布式文件系统有FastDFS，GFS、HDFS、Ceph 、GridFS 、mogileFS、TFS等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。</p>\n<h3 id=\"FastDFS介绍\"><a href=\"#FastDFS介绍\" class=\"headerlink\" title=\"FastDFS介绍\"></a>FastDFS介绍</h3><p>请参照FastDFS文件系统(一) fastdfs是什么? </p>\n<h3 id=\"GFS（Google-File-System）\"><a href=\"#GFS（Google-File-System）\" class=\"headerlink\" title=\"GFS（Google File System）\"></a>GFS（Google File System）</h3><p>Google公司为了满足本公司需求而开发的基于Linux的专有分布式文件系统。。尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。<br>下面分布式文件系统都是类 GFS的产品。</p>\n<h3 id=\"HDFS（Hadoop-Distributed-File-System）\"><a href=\"#HDFS（Hadoop-Distributed-File-System）\" class=\"headerlink\" title=\"HDFS（Hadoop Distributed File System）\"></a>HDFS（Hadoop Distributed File System）</h3><p>Hadoop 实现了一个分布式文件系统，主要用于大数据计算存储，简称HDFS。 Hadoop是Apache Lucene创始人Doug Cutting开发的使用广泛的文本搜索库。它起源于Apache Nutch，后者是一个开源的网络搜索引擎，本身也是Luene项目的一部分。Aapche Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。</p>\n<h3 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h3><p>github：<a href=\"https://github.com/ceph/ceph\">https://github.com/ceph/ceph</a></p>\n<p>是加州大学圣克鲁兹分校的Sage weil攻读博士时开发的分布式文件系统。Ceph能够在维护 POSIX 兼容性的同时加入了复制和容错功能。Sage weil并使用Ceph完成了他的论文。说 ceph 性能最高，C++编写的代码，支持Fuse，并且没有单点故障依赖， 于是下载安装， 由于 ceph 使用 btrfs 文件系统， 而btrfs 文件系统需要 Linux 2.6.34 以上的内核才支持。</p>\n<h3 id=\"GridFS文件系统\"><a href=\"#GridFS文件系统\" class=\"headerlink\" title=\"GridFS文件系统\"></a>GridFS文件系统</h3><p>MongoDB是一种知名的NoSql数据库，GridFS是MongoDB的一个内置功能，它提供一组文件操作的API以利用MongoDB存储文件，GridFS的基本原理是将文件保存在两个Collection中，一个保存文件索引，一个保存文件内容，文件内容按一定大小分成若干块，每一块存在一个Document中，这种方法不仅提供了文件存储，还提供了对文件相关的一些附加属性（比如MD5值，文件名等等）的存储。文件在GridFS中会按4MB为单位进行分块存储。</p>\n<h3 id=\"MogileFS\"><a href=\"#MogileFS\" class=\"headerlink\" title=\"MogileFS\"></a>MogileFS</h3><p>由memcahed的开发公司danga一款perl开发的产品，目前国内使用mogielFS的有图片托管网站yupoo等。<br>MogileFS是一套高效的文件自动备份组件，由Six Apart开发，广泛应用在包括LiveJournal等web2.0站点上。<br>MogileFS由3个部分组成：</p>\n<ul>\n<li><p>第1个部分是server端，包括mogilefsd和mogstored两个程序。前者即是 mogilefsd的tracker，它将一些全局信息保存在数据库里，例如站点domain,class,host等。后者即是存储节点(store node)，它其实是个HTTP Daemon，默认侦听在7500端口，接受客户端的文件备份请求。在安装完后，要运行mogadm工具将所有的store node注册到mogilefsd的数据库里，mogilefsd会对这些节点进行管理和监控。</p>\n</li>\n<li><p>第2个部分是utils（工具集），主要是MogileFS的一些管理工具，例如mogadm等。\n　　</p>\n</li>\n<li><p>第3个部分是客户端API，目前只有Perl API(MogileFS.pm)、PHP，用这个模块可以编写客户端程序，实现文件的备份管理功能。</p>\n</li>\n</ul>\n<h3 id=\"TFS\"><a href=\"#TFS\" class=\"headerlink\" title=\"TFS\"></a>TFS</h3><p>TFS（Taobao !FileSystem）是一个高可扩展、高可用、高性能、面向互联网服务的分布式文件系统，主要针对海量的非结构化数据，它构筑在普通的Linux机器 集群上，可为外部提供高可靠和高并发的存储访问。TFS为淘宝提供海量小文件存储，通常文件大小不超过1M，满足了淘宝对小文件存储的需求，被广泛地应用 在淘宝各项应用中。它采用了HA架构和平滑扩容，保证了整个文件系统的可用性和扩展性。同时扁平化的数据组织结构，可将文件名映射到文件的物理地址，简化 了文件的访问流程，一定程度上为TFS提供了良好的读写性能。</p>\n<p>官网 ： <a href=\"http://code.taobao.org/p/tfs/wiki/index/\">http://code.taobao.org/p/tfs/wiki/index/</a></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/wk313753744/article/details/49943835\">https://blog.csdn.net/wk313753744/article/details/49943835</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs和其他文件系统区别\"><a href=\"#fastdfs和其他文件系统区别\" class=\"headerlink\" title=\"fastdfs和其他文件系统区别\"></a>fastdfs和其他文件系统区别</h1><h2 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h2><p>普通存储方案：Rsync、DAS(IDE/SATA/SAS/SCSI等块)、NAS(NFS、CIFS、SAMBA等文件系统)、SAN(FibreChannel, iSCSI, FoE存储网络块)，Openfiler、FreeNas(ZFS快照复制)由于生产环境中往往由于对存储数据量很大，而SAN存储价格又比较昂贵，因此大多会选择分布式<br>存储来解决一下问题：</p>\n<ul>\n<li>海量数据存储问题</li>\n<li>数据高可用问题(冗余备份)问题</li>\n<li>较高的读写性能和负载均衡问题</li>\n<li>支持多平台多语言问题</li>\n<li>高并发问题</li>\n</ul>\n<p>主要对别指标 csdn这表格太难用了，我还是word整理后搬到这儿来的。</p>\n<p><img src=\"https://owelinux.github.io/images/2018-09-03-article27-linux-fastdfs-3/fastdfs3.png\"></p>\n<h2 id=\"二、常用的分布式文件系统\"><a href=\"#二、常用的分布式文件系统\" class=\"headerlink\" title=\"二、常用的分布式文件系统\"></a>二、常用的分布式文件系统</h2><p>常见的分布式文件系统有FastDFS，GFS、HDFS、Ceph 、GridFS 、mogileFS、TFS等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。</p>\n<h3 id=\"FastDFS介绍\"><a href=\"#FastDFS介绍\" class=\"headerlink\" title=\"FastDFS介绍\"></a>FastDFS介绍</h3><p>请参照FastDFS文件系统(一) fastdfs是什么? </p>\n<h3 id=\"GFS（Google-File-System）\"><a href=\"#GFS（Google-File-System）\" class=\"headerlink\" title=\"GFS（Google File System）\"></a>GFS（Google File System）</h3><p>Google公司为了满足本公司需求而开发的基于Linux的专有分布式文件系统。。尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。<br>下面分布式文件系统都是类 GFS的产品。</p>\n<h3 id=\"HDFS（Hadoop-Distributed-File-System）\"><a href=\"#HDFS（Hadoop-Distributed-File-System）\" class=\"headerlink\" title=\"HDFS（Hadoop Distributed File System）\"></a>HDFS（Hadoop Distributed File System）</h3><p>Hadoop 实现了一个分布式文件系统，主要用于大数据计算存储，简称HDFS。 Hadoop是Apache Lucene创始人Doug Cutting开发的使用广泛的文本搜索库。它起源于Apache Nutch，后者是一个开源的网络搜索引擎，本身也是Luene项目的一部分。Aapche Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。</p>\n<h3 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h3><p>github：<a href=\"https://github.com/ceph/ceph\">https://github.com/ceph/ceph</a></p>\n<p>是加州大学圣克鲁兹分校的Sage weil攻读博士时开发的分布式文件系统。Ceph能够在维护 POSIX 兼容性的同时加入了复制和容错功能。Sage weil并使用Ceph完成了他的论文。说 ceph 性能最高，C++编写的代码，支持Fuse，并且没有单点故障依赖， 于是下载安装， 由于 ceph 使用 btrfs 文件系统， 而btrfs 文件系统需要 Linux 2.6.34 以上的内核才支持。</p>\n<h3 id=\"GridFS文件系统\"><a href=\"#GridFS文件系统\" class=\"headerlink\" title=\"GridFS文件系统\"></a>GridFS文件系统</h3><p>MongoDB是一种知名的NoSql数据库，GridFS是MongoDB的一个内置功能，它提供一组文件操作的API以利用MongoDB存储文件，GridFS的基本原理是将文件保存在两个Collection中，一个保存文件索引，一个保存文件内容，文件内容按一定大小分成若干块，每一块存在一个Document中，这种方法不仅提供了文件存储，还提供了对文件相关的一些附加属性（比如MD5值，文件名等等）的存储。文件在GridFS中会按4MB为单位进行分块存储。</p>\n<h3 id=\"MogileFS\"><a href=\"#MogileFS\" class=\"headerlink\" title=\"MogileFS\"></a>MogileFS</h3><p>由memcahed的开发公司danga一款perl开发的产品，目前国内使用mogielFS的有图片托管网站yupoo等。<br>MogileFS是一套高效的文件自动备份组件，由Six Apart开发，广泛应用在包括LiveJournal等web2.0站点上。<br>MogileFS由3个部分组成：</p>\n<ul>\n<li><p>第1个部分是server端，包括mogilefsd和mogstored两个程序。前者即是 mogilefsd的tracker，它将一些全局信息保存在数据库里，例如站点domain,class,host等。后者即是存储节点(store node)，它其实是个HTTP Daemon，默认侦听在7500端口，接受客户端的文件备份请求。在安装完后，要运行mogadm工具将所有的store node注册到mogilefsd的数据库里，mogilefsd会对这些节点进行管理和监控。</p>\n</li>\n<li><p>第2个部分是utils（工具集），主要是MogileFS的一些管理工具，例如mogadm等。\n　　</p>\n</li>\n<li><p>第3个部分是客户端API，目前只有Perl API(MogileFS.pm)、PHP，用这个模块可以编写客户端程序，实现文件的备份管理功能。</p>\n</li>\n</ul>\n<h3 id=\"TFS\"><a href=\"#TFS\" class=\"headerlink\" title=\"TFS\"></a>TFS</h3><p>TFS（Taobao !FileSystem）是一个高可扩展、高可用、高性能、面向互联网服务的分布式文件系统，主要针对海量的非结构化数据，它构筑在普通的Linux机器 集群上，可为外部提供高可靠和高并发的存储访问。TFS为淘宝提供海量小文件存储，通常文件大小不超过1M，满足了淘宝对小文件存储的需求，被广泛地应用 在淘宝各项应用中。它采用了HA架构和平滑扩容，保证了整个文件系统的可用性和扩展性。同时扁平化的数据组织结构，可将文件名映射到文件的物理地址，简化 了文件的访问流程，一定程度上为TFS提供了良好的读写性能。</p>\n<p>官网 ： <a href=\"http://code.taobao.org/p/tfs/wiki/index/\">http://code.taobao.org/p/tfs/wiki/index/</a></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://blog.csdn.net/wk313753744/article/details/49943835\">https://blog.csdn.net/wk313753744/article/details/49943835</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"文件系统（四）fastdfs部署及使用","date":"2018-09-03T03:43:54.000Z","author":"owelinux","excerpt":"由于业务需求，采用fastdfs作为文件存储，写这篇文章记录点滴","mathjax":true,"_content":"\n* content\n{:toc}\n\n# fastdfs部署及使用\n\n在之前文章，我们了解到几个类型的文件系统优缺点，本文将详细介绍fastdfs的部署及测试使用\n\nFastDFS is an open source high performance distributed file system (DFS). It's major functions include: file storing, file syncing and file accessing, and design for high capacity and load balance.\n\nFastDFS是一个开源高性能分布式文件系统（DFS）。它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡的设计。\n\n## 一、环境准备\n### 系统环境\n```\n[root@sz-145-centos177 ~]# cat /etc/redhat-release \nCentOS release 6.8 (Final)\n\n[root@sz-145-centos177 ~]# uname -a\nLinux sz-145-centos177 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n### 编译环境\n```\nyum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel -y\n```\n### 目录\n说明 | 位置\n------------- | -------------\n所有安装包 | /usr/local/\ntracker跟踪服务器数据 | /fastdfs/tracker\nstorage存储服务器数据 | /fastdfs/storage\n\n```\nmkdir -p /fastdfs/tracker  #创建跟踪服务器数据目录\nmkdir -p /fastdfs/storage  #创建存储服务器数据目录\n# 切换到安装目录准备下载安装包\ncd /usr/local/ \n```\n\n### 安装libfatscommon\n```\ngit clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh && ./make.sh install\n```\n\n### 安装FastDFS\n```\ngit clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh && ./make.sh install\n```\n\n#配置文件准备\n```\ncp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n```\n\n### 安装fastdfs-nginx-module\n```\ngit clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n安装nginx\nwget http://nginx.org/download/nginx-1.12.2.tar.gz\ntar -zxvf nginx-1.12.2.tar.gz\ncd nginx-1.12.2/\n# 修改配置文件，解决报错问题\nsed -i 's#ngx_module_incs=\"/usr/local/include\"#ngx_module_incs=\"/usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \nsed -i 's#CORE_INCS=\"$CORE_INCS /usr/local/include\"#CORE_INCS=\"$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \n\nsed -i 's#(pContext->range_count > 1 && !g_http_params.support_multi_range))#(pContext->range_count > 1))#g' /usr/local/fastdfs-nginx-module/src/common.c | grep '(pContext->range_count > 1))'\n\n# 添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/fastdfs-nginx-module/src/\nmake && make install\n```\n\n### 单机部署\n#### tracker配置\n```\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/fastdfs/tracker  # 存储日志和数据的根目录\n#保存后启动\n/etc/init.d/fdfs_trackerd start #启动tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n```\n#### storage配置\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/fastdfs/storage  # 数据和日志文件存储根目录\nstore_path0=/fastdfs/storage  # 第一个存储目录\ntracker_server=192.168.0.xxx:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n#保存后启动\n/etc/init.d/fdfs_storaged start #启动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n```\n#### 验证storage是否登记到tracker服务器\n\n使用fdfs_monitor /etc/fdfs/storage.conf，运行fdfs_monitor查看storage服务器是否已经登记到tracker服务器。\n\n可以在任一存储节点上使用如下命令查看集群的状态信息\n```\nfdfs_monitor /etc/fdfs/storage.conf\n```\n如果出现ip_addr = Active, 则表明storage服务器已经登记到tracker服务器，如下：\n```\nStorage 1:\n        id = 192.168.53.90\n        ip_addr = 192.168.53.90 (localhost)  ACTIVE\n```\n#### 文件上传下载进行测试：\n\n文件上传\n```\n/usr/bin/fdfs_test /etc/fdfs/client.conf upload /var/log/yum.log\n```\n\n文件下载\n```\n/usr/bin/fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/CnBYbVc8AaOAL78UAAADvvLPPRA782_big.log\n```\n\n#### client测试\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/fastdfs/tracker\ntracker_server=192.168.1.xxx:22122    #tracker IP地址\n#保存后测试,返回ID表示成功 eg:group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.12.2.tar.gz\n```\n#### 配置nginx访问\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\nbase_path=/fastdfs/storage           #保存日志目录\ntracker_server=192.168.53.85:22122 \nstorage_server_port=23000         #storage服务器的端口号\ngroup_name=group1                 #当前服务器的group名\nurl_have_group_name = true        #文件url中是否有group名\nstore_path_count=1                #存储路径个数，需要和store_path个数匹配\nstore_path0=/fastdfs/storage         #存储路径\ngroup_count = 1                   #设置组的个数\n\n#配置nginx.config\nvi /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/M00 {\n\t\troot /fastdfs/storage/data\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    }\n}\n# 测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.0.xxx:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n# 弹出下载单机部署全部跑通，否则首先检查防火墙，再检查其他配置。\n```\n\n#### 后续扩容\n在tracker上安装nginx，并且配置upstream 负载均衡到group组机器\n\n### 报错解决\n报错一：\n```\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/root/nginx-1.12.2'\nmake: *** [build] Error 2\n```\n解决：\n```\nsed -i 's#ngx_module_incs=\"/usr/local/include\"#ngx_module_incs=\"/usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \nsed -i 's#CORE_INCS=\"$CORE_INCS /usr/local/include\"#CORE_INCS=\"$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \n```\n报错二：\n```\nIn file included from /usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:6:\n/usr/local/fastdfs-nginx-module/src/common.c: In function ‘fdfs_http_request_handler’:\n/usr/local/fastdfs-nginx-module/src/common.c:1245: error: ‘FDFSHTTPParams’ has no member named ‘support_multi_range’\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/usr/local/nginx-1.12.2'\nmake: *** [build] Error 2\n```\n解决：\n```\nsed -i 's#(pContext->range_count > 1 && !g_http_params.support_multi_range))#(pContext->range_count > 1))#g' /usr/local/fastdfs-nginx-module/src/common.c | grep '(pContext->range_count > 1))'\n```\n报错三：\n```\n[root@sz-145-centos177 data]# curl 'http://172.22.145.177:8888/group1/M00/00/00/rBaRsVuM9uCAEKkSAA76tz-dVgg.tar.gz'\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.12.2</center>\n</body>\n</html>\n```\n解决\n```\nvim /etc/fdfs/mod_fastdfs.conf\nurl_have_group_name = false改为true\n```\n\n## 参考\n> * [https://github.com/happyfish100/fastdfs/wiki](https://github.com/happyfish100/fastdfs/wiki)","source":"_posts/2018-09-03-article28-linux-fastdfs-4.md","raw":"---\nlayout: post\ntitle:  \"文件系统（四）fastdfs部署及使用\"\ndate:   2018-09-03 11:43:54\nauthor: owelinux\ncategories: linux \ntags:  fastdfs  \nexcerpt: 由于业务需求，采用fastdfs作为文件存储，写这篇文章记录点滴\nmathjax: true\n---\n\n* content\n{:toc}\n\n# fastdfs部署及使用\n\n在之前文章，我们了解到几个类型的文件系统优缺点，本文将详细介绍fastdfs的部署及测试使用\n\nFastDFS is an open source high performance distributed file system (DFS). It's major functions include: file storing, file syncing and file accessing, and design for high capacity and load balance.\n\nFastDFS是一个开源高性能分布式文件系统（DFS）。它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡的设计。\n\n## 一、环境准备\n### 系统环境\n```\n[root@sz-145-centos177 ~]# cat /etc/redhat-release \nCentOS release 6.8 (Final)\n\n[root@sz-145-centos177 ~]# uname -a\nLinux sz-145-centos177 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n### 编译环境\n```\nyum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel -y\n```\n### 目录\n说明 | 位置\n------------- | -------------\n所有安装包 | /usr/local/\ntracker跟踪服务器数据 | /fastdfs/tracker\nstorage存储服务器数据 | /fastdfs/storage\n\n```\nmkdir -p /fastdfs/tracker  #创建跟踪服务器数据目录\nmkdir -p /fastdfs/storage  #创建存储服务器数据目录\n# 切换到安装目录准备下载安装包\ncd /usr/local/ \n```\n\n### 安装libfatscommon\n```\ngit clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh && ./make.sh install\n```\n\n### 安装FastDFS\n```\ngit clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh && ./make.sh install\n```\n\n#配置文件准备\n```\ncp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n```\n\n### 安装fastdfs-nginx-module\n```\ngit clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n安装nginx\nwget http://nginx.org/download/nginx-1.12.2.tar.gz\ntar -zxvf nginx-1.12.2.tar.gz\ncd nginx-1.12.2/\n# 修改配置文件，解决报错问题\nsed -i 's#ngx_module_incs=\"/usr/local/include\"#ngx_module_incs=\"/usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \nsed -i 's#CORE_INCS=\"$CORE_INCS /usr/local/include\"#CORE_INCS=\"$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \n\nsed -i 's#(pContext->range_count > 1 && !g_http_params.support_multi_range))#(pContext->range_count > 1))#g' /usr/local/fastdfs-nginx-module/src/common.c | grep '(pContext->range_count > 1))'\n\n# 添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/fastdfs-nginx-module/src/\nmake && make install\n```\n\n### 单机部署\n#### tracker配置\n```\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/fastdfs/tracker  # 存储日志和数据的根目录\n#保存后启动\n/etc/init.d/fdfs_trackerd start #启动tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n```\n#### storage配置\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/fastdfs/storage  # 数据和日志文件存储根目录\nstore_path0=/fastdfs/storage  # 第一个存储目录\ntracker_server=192.168.0.xxx:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n#保存后启动\n/etc/init.d/fdfs_storaged start #启动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n```\n#### 验证storage是否登记到tracker服务器\n\n使用fdfs_monitor /etc/fdfs/storage.conf，运行fdfs_monitor查看storage服务器是否已经登记到tracker服务器。\n\n可以在任一存储节点上使用如下命令查看集群的状态信息\n```\nfdfs_monitor /etc/fdfs/storage.conf\n```\n如果出现ip_addr = Active, 则表明storage服务器已经登记到tracker服务器，如下：\n```\nStorage 1:\n        id = 192.168.53.90\n        ip_addr = 192.168.53.90 (localhost)  ACTIVE\n```\n#### 文件上传下载进行测试：\n\n文件上传\n```\n/usr/bin/fdfs_test /etc/fdfs/client.conf upload /var/log/yum.log\n```\n\n文件下载\n```\n/usr/bin/fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/CnBYbVc8AaOAL78UAAADvvLPPRA782_big.log\n```\n\n#### client测试\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/fastdfs/tracker\ntracker_server=192.168.1.xxx:22122    #tracker IP地址\n#保存后测试,返回ID表示成功 eg:group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.12.2.tar.gz\n```\n#### 配置nginx访问\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\nbase_path=/fastdfs/storage           #保存日志目录\ntracker_server=192.168.53.85:22122 \nstorage_server_port=23000         #storage服务器的端口号\ngroup_name=group1                 #当前服务器的group名\nurl_have_group_name = true        #文件url中是否有group名\nstore_path_count=1                #存储路径个数，需要和store_path个数匹配\nstore_path0=/fastdfs/storage         #存储路径\ngroup_count = 1                   #设置组的个数\n\n#配置nginx.config\nvi /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/M00 {\n\t\troot /fastdfs/storage/data\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    }\n}\n# 测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.0.xxx:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n# 弹出下载单机部署全部跑通，否则首先检查防火墙，再检查其他配置。\n```\n\n#### 后续扩容\n在tracker上安装nginx，并且配置upstream 负载均衡到group组机器\n\n### 报错解决\n报错一：\n```\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/root/nginx-1.12.2'\nmake: *** [build] Error 2\n```\n解决：\n```\nsed -i 's#ngx_module_incs=\"/usr/local/include\"#ngx_module_incs=\"/usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \nsed -i 's#CORE_INCS=\"$CORE_INCS /usr/local/include\"#CORE_INCS=\"$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/\"#'g /usr/local/fastdfs-nginx-module/src/config \n```\n报错二：\n```\nIn file included from /usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:6:\n/usr/local/fastdfs-nginx-module/src/common.c: In function ‘fdfs_http_request_handler’:\n/usr/local/fastdfs-nginx-module/src/common.c:1245: error: ‘FDFSHTTPParams’ has no member named ‘support_multi_range’\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/usr/local/nginx-1.12.2'\nmake: *** [build] Error 2\n```\n解决：\n```\nsed -i 's#(pContext->range_count > 1 && !g_http_params.support_multi_range))#(pContext->range_count > 1))#g' /usr/local/fastdfs-nginx-module/src/common.c | grep '(pContext->range_count > 1))'\n```\n报错三：\n```\n[root@sz-145-centos177 data]# curl 'http://172.22.145.177:8888/group1/M00/00/00/rBaRsVuM9uCAEKkSAA76tz-dVgg.tar.gz'\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.12.2</center>\n</body>\n</html>\n```\n解决\n```\nvim /etc/fdfs/mod_fastdfs.conf\nurl_have_group_name = false改为true\n```\n\n## 参考\n> * [https://github.com/happyfish100/fastdfs/wiki](https://github.com/happyfish100/fastdfs/wiki)","slug":"2018-09-03-article28-linux-fastdfs-4","published":1,"updated":"2021-02-09T02:00:24.572Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0i001vyc9722087wdx","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs部署及使用\"><a href=\"#fastdfs部署及使用\" class=\"headerlink\" title=\"fastdfs部署及使用\"></a>fastdfs部署及使用</h1><p>在之前文章，我们了解到几个类型的文件系统优缺点，本文将详细介绍fastdfs的部署及测试使用</p>\n<p>FastDFS is an open source high performance distributed file system (DFS). It’s major functions include: file storing, file syncing and file accessing, and design for high capacity and load balance.</p>\n<p>FastDFS是一个开源高性能分布式文件系统（DFS）。它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡的设计。</p>\n<h2 id=\"一、环境准备\"><a href=\"#一、环境准备\" class=\"headerlink\" title=\"一、环境准备\"></a>一、环境准备</h2><h3 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h3><pre><code>[root@sz-145-centos177 ~]# cat /etc/redhat-release \nCentOS release 6.8 (Final)\n\n[root@sz-145-centos177 ~]# uname -a\nLinux sz-145-centos177 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre>\n<h3 id=\"编译环境\"><a href=\"#编译环境\" class=\"headerlink\" title=\"编译环境\"></a>编译环境</h3><pre><code>yum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel -y\n</code></pre>\n<h3 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h3><table>\n<thead>\n<tr>\n<th>说明</th>\n<th>位置</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>所有安装包</td>\n<td>/usr/local/</td>\n</tr>\n<tr>\n<td>tracker跟踪服务器数据</td>\n<td>/fastdfs/tracker</td>\n</tr>\n<tr>\n<td>storage存储服务器数据</td>\n<td>/fastdfs/storage</td>\n</tr>\n</tbody></table>\n<pre><code>mkdir -p /fastdfs/tracker  #创建跟踪服务器数据目录\nmkdir -p /fastdfs/storage  #创建存储服务器数据目录\n# 切换到安装目录准备下载安装包\ncd /usr/local/ \n</code></pre>\n<h3 id=\"安装libfatscommon\"><a href=\"#安装libfatscommon\" class=\"headerlink\" title=\"安装libfatscommon\"></a>安装libfatscommon</h3><pre><code>git clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh &amp;&amp; ./make.sh install\n</code></pre>\n<h3 id=\"安装FastDFS\"><a href=\"#安装FastDFS\" class=\"headerlink\" title=\"安装FastDFS\"></a>安装FastDFS</h3><pre><code>git clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh &amp;&amp; ./make.sh install\n</code></pre>\n<p>#配置文件准备</p>\n<pre><code>cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n</code></pre>\n<h3 id=\"安装fastdfs-nginx-module\"><a href=\"#安装fastdfs-nginx-module\" class=\"headerlink\" title=\"安装fastdfs-nginx-module\"></a>安装fastdfs-nginx-module</h3><pre><code>git clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n安装nginx\nwget http://nginx.org/download/nginx-1.12.2.tar.gz\ntar -zxvf nginx-1.12.2.tar.gz\ncd nginx-1.12.2/\n# 修改配置文件，解决报错问题\nsed -i &#39;s#ngx_module_incs=&quot;/usr/local/include&quot;#ngx_module_incs=&quot;/usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \nsed -i &#39;s#CORE_INCS=&quot;$CORE_INCS /usr/local/include&quot;#CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \n\nsed -i &#39;s#(pContext-&gt;range_count &gt; 1 &amp;&amp; !g_http_params.support_multi_range))#(pContext-&gt;range_count &gt; 1))#g&#39; /usr/local/fastdfs-nginx-module/src/common.c | grep &#39;(pContext-&gt;range_count &gt; 1))&#39;\n\n# 添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/fastdfs-nginx-module/src/\nmake &amp;&amp; make install\n</code></pre>\n<h3 id=\"单机部署\"><a href=\"#单机部署\" class=\"headerlink\" title=\"单机部署\"></a>单机部署</h3><h4 id=\"tracker配置\"><a href=\"#tracker配置\" class=\"headerlink\" title=\"tracker配置\"></a>tracker配置</h4><pre><code>vim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/fastdfs/tracker  # 存储日志和数据的根目录\n#保存后启动\n/etc/init.d/fdfs_trackerd start #启动tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n</code></pre>\n<h4 id=\"storage配置\"><a href=\"#storage配置\" class=\"headerlink\" title=\"storage配置\"></a>storage配置</h4><pre><code>vim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/fastdfs/storage  # 数据和日志文件存储根目录\nstore_path0=/fastdfs/storage  # 第一个存储目录\ntracker_server=192.168.0.xxx:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n#保存后启动\n/etc/init.d/fdfs_storaged start #启动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n</code></pre>\n<h4 id=\"验证storage是否登记到tracker服务器\"><a href=\"#验证storage是否登记到tracker服务器\" class=\"headerlink\" title=\"验证storage是否登记到tracker服务器\"></a>验证storage是否登记到tracker服务器</h4><p>使用fdfs_monitor /etc/fdfs/storage.conf，运行fdfs_monitor查看storage服务器是否已经登记到tracker服务器。</p>\n<p>可以在任一存储节点上使用如下命令查看集群的状态信息</p>\n<pre><code>fdfs_monitor /etc/fdfs/storage.conf\n</code></pre>\n<p>如果出现ip_addr = Active, 则表明storage服务器已经登记到tracker服务器，如下：</p>\n<pre><code>Storage 1:\n        id = 192.168.53.90\n        ip_addr = 192.168.53.90 (localhost)  ACTIVE\n</code></pre>\n<h4 id=\"文件上传下载进行测试：\"><a href=\"#文件上传下载进行测试：\" class=\"headerlink\" title=\"文件上传下载进行测试：\"></a>文件上传下载进行测试：</h4><p>文件上传</p>\n<pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /var/log/yum.log\n</code></pre>\n<p>文件下载</p>\n<pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/CnBYbVc8AaOAL78UAAADvvLPPRA782_big.log\n</code></pre>\n<h4 id=\"client测试\"><a href=\"#client测试\" class=\"headerlink\" title=\"client测试\"></a>client测试</h4><pre><code>vim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/fastdfs/tracker\ntracker_server=192.168.1.xxx:22122    #tracker IP地址\n#保存后测试,返回ID表示成功 eg:group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.12.2.tar.gz\n</code></pre>\n<h4 id=\"配置nginx访问\"><a href=\"#配置nginx访问\" class=\"headerlink\" title=\"配置nginx访问\"></a>配置nginx访问</h4><pre><code>vim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\nbase_path=/fastdfs/storage           #保存日志目录\ntracker_server=192.168.53.85:22122 \nstorage_server_port=23000         #storage服务器的端口号\ngroup_name=group1                 #当前服务器的group名\nurl_have_group_name = true        #文件url中是否有group名\nstore_path_count=1                #存储路径个数，需要和store_path个数匹配\nstore_path0=/fastdfs/storage         #存储路径\ngroup_count = 1                   #设置组的个数\n\n#配置nginx.config\nvi /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver &#123;\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/M00 &#123;\n        root /fastdfs/storage/data\n        ngx_fastdfs_module;\n    &#125;\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html &#123;\n    &#125;\n&#125;\n# 测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.0.xxx:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n# 弹出下载单机部署全部跑通，否则首先检查防火墙，再检查其他配置。\n</code></pre>\n<h4 id=\"后续扩容\"><a href=\"#后续扩容\" class=\"headerlink\" title=\"后续扩容\"></a>后续扩容</h4><p>在tracker上安装nginx，并且配置upstream 负载均衡到group组机器</p>\n<h3 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h3><p>报错一：</p>\n<pre><code>make[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/root/nginx-1.12.2&#39;\nmake: *** [build] Error 2\n</code></pre>\n<p>解决：</p>\n<pre><code>sed -i &#39;s#ngx_module_incs=&quot;/usr/local/include&quot;#ngx_module_incs=&quot;/usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \nsed -i &#39;s#CORE_INCS=&quot;$CORE_INCS /usr/local/include&quot;#CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \n</code></pre>\n<p>报错二：</p>\n<pre><code>In file included from /usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:6:\n/usr/local/fastdfs-nginx-module/src/common.c: In function ‘fdfs_http_request_handler’:\n/usr/local/fastdfs-nginx-module/src/common.c:1245: error: ‘FDFSHTTPParams’ has no member named ‘support_multi_range’\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/usr/local/nginx-1.12.2&#39;\nmake: *** [build] Error 2\n</code></pre>\n<p>解决：</p>\n<pre><code>sed -i &#39;s#(pContext-&gt;range_count &gt; 1 &amp;&amp; !g_http_params.support_multi_range))#(pContext-&gt;range_count &gt; 1))#g&#39; /usr/local/fastdfs-nginx-module/src/common.c | grep &#39;(pContext-&gt;range_count &gt; 1))&#39;\n</code></pre>\n<p>报错三：</p>\n<pre><code>[root@sz-145-centos177 data]# curl &#39;http://172.22.145.177:8888/group1/M00/00/00/rBaRsVuM9uCAEKkSAA76tz-dVgg.tar.gz&#39;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;\n&lt;body bgcolor=&quot;white&quot;&gt;\n&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;\n&lt;hr&gt;&lt;center&gt;nginx/1.12.2&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>解决</p>\n<pre><code>vim /etc/fdfs/mod_fastdfs.conf\nurl_have_group_name = false改为true\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://github.com/happyfish100/fastdfs/wiki\">https://github.com/happyfish100/fastdfs/wiki</a></li>\n</ul>\n</blockquote>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"fastdfs部署及使用\"><a href=\"#fastdfs部署及使用\" class=\"headerlink\" title=\"fastdfs部署及使用\"></a>fastdfs部署及使用</h1><p>在之前文章，我们了解到几个类型的文件系统优缺点，本文将详细介绍fastdfs的部署及测试使用</p>\n<p>FastDFS is an open source high performance distributed file system (DFS). It’s major functions include: file storing, file syncing and file accessing, and design for high capacity and load balance.</p>\n<p>FastDFS是一个开源高性能分布式文件系统（DFS）。它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡的设计。</p>\n<h2 id=\"一、环境准备\"><a href=\"#一、环境准备\" class=\"headerlink\" title=\"一、环境准备\"></a>一、环境准备</h2><h3 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h3><pre><code>[root@sz-145-centos177 ~]# cat /etc/redhat-release \nCentOS release 6.8 (Final)\n\n[root@sz-145-centos177 ~]# uname -a\nLinux sz-145-centos177 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre>\n<h3 id=\"编译环境\"><a href=\"#编译环境\" class=\"headerlink\" title=\"编译环境\"></a>编译环境</h3><pre><code>yum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel -y\n</code></pre>\n<h3 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h3><table>\n<thead>\n<tr>\n<th>说明</th>\n<th>位置</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>所有安装包</td>\n<td>/usr/local/</td>\n</tr>\n<tr>\n<td>tracker跟踪服务器数据</td>\n<td>/fastdfs/tracker</td>\n</tr>\n<tr>\n<td>storage存储服务器数据</td>\n<td>/fastdfs/storage</td>\n</tr>\n</tbody></table>\n<pre><code>mkdir -p /fastdfs/tracker  #创建跟踪服务器数据目录\nmkdir -p /fastdfs/storage  #创建存储服务器数据目录\n# 切换到安装目录准备下载安装包\ncd /usr/local/ \n</code></pre>\n<h3 id=\"安装libfatscommon\"><a href=\"#安装libfatscommon\" class=\"headerlink\" title=\"安装libfatscommon\"></a>安装libfatscommon</h3><pre><code>git clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh &amp;&amp; ./make.sh install\n</code></pre>\n<h3 id=\"安装FastDFS\"><a href=\"#安装FastDFS\" class=\"headerlink\" title=\"安装FastDFS\"></a>安装FastDFS</h3><pre><code>git clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh &amp;&amp; ./make.sh install\n</code></pre>\n<p>#配置文件准备</p>\n<pre><code>cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n</code></pre>\n<h3 id=\"安装fastdfs-nginx-module\"><a href=\"#安装fastdfs-nginx-module\" class=\"headerlink\" title=\"安装fastdfs-nginx-module\"></a>安装fastdfs-nginx-module</h3><pre><code>git clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n安装nginx\nwget http://nginx.org/download/nginx-1.12.2.tar.gz\ntar -zxvf nginx-1.12.2.tar.gz\ncd nginx-1.12.2/\n# 修改配置文件，解决报错问题\nsed -i &#39;s#ngx_module_incs=&quot;/usr/local/include&quot;#ngx_module_incs=&quot;/usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \nsed -i &#39;s#CORE_INCS=&quot;$CORE_INCS /usr/local/include&quot;#CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \n\nsed -i &#39;s#(pContext-&gt;range_count &gt; 1 &amp;&amp; !g_http_params.support_multi_range))#(pContext-&gt;range_count &gt; 1))#g&#39; /usr/local/fastdfs-nginx-module/src/common.c | grep &#39;(pContext-&gt;range_count &gt; 1))&#39;\n\n# 添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/fastdfs-nginx-module/src/\nmake &amp;&amp; make install\n</code></pre>\n<h3 id=\"单机部署\"><a href=\"#单机部署\" class=\"headerlink\" title=\"单机部署\"></a>单机部署</h3><h4 id=\"tracker配置\"><a href=\"#tracker配置\" class=\"headerlink\" title=\"tracker配置\"></a>tracker配置</h4><pre><code>vim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/fastdfs/tracker  # 存储日志和数据的根目录\n#保存后启动\n/etc/init.d/fdfs_trackerd start #启动tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n</code></pre>\n<h4 id=\"storage配置\"><a href=\"#storage配置\" class=\"headerlink\" title=\"storage配置\"></a>storage配置</h4><pre><code>vim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/fastdfs/storage  # 数据和日志文件存储根目录\nstore_path0=/fastdfs/storage  # 第一个存储目录\ntracker_server=192.168.0.xxx:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n#保存后启动\n/etc/init.d/fdfs_storaged start #启动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n</code></pre>\n<h4 id=\"验证storage是否登记到tracker服务器\"><a href=\"#验证storage是否登记到tracker服务器\" class=\"headerlink\" title=\"验证storage是否登记到tracker服务器\"></a>验证storage是否登记到tracker服务器</h4><p>使用fdfs_monitor /etc/fdfs/storage.conf，运行fdfs_monitor查看storage服务器是否已经登记到tracker服务器。</p>\n<p>可以在任一存储节点上使用如下命令查看集群的状态信息</p>\n<pre><code>fdfs_monitor /etc/fdfs/storage.conf\n</code></pre>\n<p>如果出现ip_addr = Active, 则表明storage服务器已经登记到tracker服务器，如下：</p>\n<pre><code>Storage 1:\n        id = 192.168.53.90\n        ip_addr = 192.168.53.90 (localhost)  ACTIVE\n</code></pre>\n<h4 id=\"文件上传下载进行测试：\"><a href=\"#文件上传下载进行测试：\" class=\"headerlink\" title=\"文件上传下载进行测试：\"></a>文件上传下载进行测试：</h4><p>文件上传</p>\n<pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /var/log/yum.log\n</code></pre>\n<p>文件下载</p>\n<pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/CnBYbVc8AaOAL78UAAADvvLPPRA782_big.log\n</code></pre>\n<h4 id=\"client测试\"><a href=\"#client测试\" class=\"headerlink\" title=\"client测试\"></a>client测试</h4><pre><code>vim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/fastdfs/tracker\ntracker_server=192.168.1.xxx:22122    #tracker IP地址\n#保存后测试,返回ID表示成功 eg:group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.12.2.tar.gz\n</code></pre>\n<h4 id=\"配置nginx访问\"><a href=\"#配置nginx访问\" class=\"headerlink\" title=\"配置nginx访问\"></a>配置nginx访问</h4><pre><code>vim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\nbase_path=/fastdfs/storage           #保存日志目录\ntracker_server=192.168.53.85:22122 \nstorage_server_port=23000         #storage服务器的端口号\ngroup_name=group1                 #当前服务器的group名\nurl_have_group_name = true        #文件url中是否有group名\nstore_path_count=1                #存储路径个数，需要和store_path个数匹配\nstore_path0=/fastdfs/storage         #存储路径\ngroup_count = 1                   #设置组的个数\n\n#配置nginx.config\nvi /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver &#123;\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/M00 &#123;\n        root /fastdfs/storage/data\n        ngx_fastdfs_module;\n    &#125;\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html &#123;\n    &#125;\n&#125;\n# 测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.0.xxx:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n# 弹出下载单机部署全部跑通，否则首先检查防火墙，再检查其他配置。\n</code></pre>\n<h4 id=\"后续扩容\"><a href=\"#后续扩容\" class=\"headerlink\" title=\"后续扩容\"></a>后续扩容</h4><p>在tracker上安装nginx，并且配置upstream 负载均衡到group组机器</p>\n<h3 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h3><p>报错一：</p>\n<pre><code>make[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/root/nginx-1.12.2&#39;\nmake: *** [build] Error 2\n</code></pre>\n<p>解决：</p>\n<pre><code>sed -i &#39;s#ngx_module_incs=&quot;/usr/local/include&quot;#ngx_module_incs=&quot;/usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \nsed -i &#39;s#CORE_INCS=&quot;$CORE_INCS /usr/local/include&quot;#CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/local/include/fastcommon/&quot;#&#39;g /usr/local/fastdfs-nginx-module/src/config \n</code></pre>\n<p>报错二：</p>\n<pre><code>In file included from /usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:6:\n/usr/local/fastdfs-nginx-module/src/common.c: In function ‘fdfs_http_request_handler’:\n/usr/local/fastdfs-nginx-module/src/common.c:1245: error: ‘FDFSHTTPParams’ has no member named ‘support_multi_range’\nmake[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] Error 1\nmake[1]: Leaving directory `/usr/local/nginx-1.12.2&#39;\nmake: *** [build] Error 2\n</code></pre>\n<p>解决：</p>\n<pre><code>sed -i &#39;s#(pContext-&gt;range_count &gt; 1 &amp;&amp; !g_http_params.support_multi_range))#(pContext-&gt;range_count &gt; 1))#g&#39; /usr/local/fastdfs-nginx-module/src/common.c | grep &#39;(pContext-&gt;range_count &gt; 1))&#39;\n</code></pre>\n<p>报错三：</p>\n<pre><code>[root@sz-145-centos177 data]# curl &#39;http://172.22.145.177:8888/group1/M00/00/00/rBaRsVuM9uCAEKkSAA76tz-dVgg.tar.gz&#39;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;\n&lt;body bgcolor=&quot;white&quot;&gt;\n&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;\n&lt;hr&gt;&lt;center&gt;nginx/1.12.2&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>解决</p>\n<pre><code>vim /etc/fdfs/mod_fastdfs.conf\nurl_have_group_name = false改为true\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<ul>\n<li><a href=\"https://github.com/happyfish100/fastdfs/wiki\">https://github.com/happyfish100/fastdfs/wiki</a></li>\n</ul>\n</blockquote>\n"},{"layout":"post","title":"centos yum安装mysql5.7","date":"2018-09-04T08:02:54.000Z","author":"owelinux","excerpt":"centos yum安装mysql5.7","mathjax":true,"_content":"\n* content\n{:toc}\n\n#centos yum安装mysql5.7\n\n在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理\n\n## 系统环境\ncentos6或者centos7\n\n## 查看系统是否已经安装mysql\n\n```\nrpm -qa | grep mysql\nyum list installed | grep mysql\n```\n## 卸载当前数据库\ncentos6.x或者centos7.x ：\n```\nyum -y remove mysql*\n```\n\n## mysql数据源下载\ncentos6.x\n```\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\n```\ncentos7.x\n```\nyum install -y http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm\n```\n\n## mysql安装\n```\nyum install -y mysql-community-server\n```\n\n## mysqlroot密码修改\n```\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep \"password\" | grep \"generated\" \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD('your new password');\nALTER USER 'root'@'localhost' PASSWORD EXPIRE NEVER;\nflush privileges;\n```\n\n## mysql常用操作\n\n设置字符集：\n```\n# 在 [mysqld] 前添加如下代码：\n[client]\ndefault-character-set=utf8\n\n# 在 [mysqld] 后添加如下代码：\ncharacter_set_server=utf8\n\n# 重启mysql后再登录，看看字符集，6个utf8就算OK\nshow variables like '%character%';\n```\n\n忘记密码时，重置密码：\n```\nservice mysqld stop\nmysqld_safe --user=root --skip-grant-tables --skip-networking &\nmysql -u root\n进入MySQL后\n\nuse mysql;\nupdate user set password=password(\"new_password\") where user=\"root\"; \nflush privileges;\n```\n\n数据库授权：\n```\ngrant all privileges on *.* to uaername@\"%\" identified by \"new password\";\n```\n\n数据库设置密码复杂度：\n\n* validate_password_dictionary_file: 插件用于验证密码强度的字典文件路径。\n\n* validate_password_length: 密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)\n\n* validate_password_mixed_case_count: 密码至少要包含的小写字母个数和大写字母个数。\n\n* validate_password_number_count: 密码至少要包含的数字个数。\n\n* validate_password_policy: 密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG\n\n```\n修改mysql参数配置\n\nmysql> set global validate_password_policy=0;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> set global validate_password_mixed_case_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_number_count=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_special_char_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_length=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> SHOW VARIABLES LIKE 'validate_password%';\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| validate_password_dictionary_file    |       |\n| validate_password_length             | 3     |\n| validate_password_mixed_case_count   | 0     |\n| validate_password_number_count       | 3     |\n| validate_password_policy             | LOW   |\n| validate_password_special_char_count | 0     |\n+--------------------------------------+-------+\n6 rows in set (0.00 sec)\n\n# 修改简单密码：\nmysql> SET PASSWORD =PASSWORD('root');\nmysql> SET PASSWORD FOR username=PASSWORD('new password');\n```","source":"_posts/2018-09-04-article29-linux-yum-mysql.md","raw":"---\nlayout: post\ntitle:  \"centos yum安装mysql5.7\"\ndate:   2018-09-04 16:02:54\nauthor: owelinux\ncategories: linux \ntags:  mysql  \nexcerpt: centos yum安装mysql5.7\nmathjax: true\n---\n\n* content\n{:toc}\n\n#centos yum安装mysql5.7\n\n在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理\n\n## 系统环境\ncentos6或者centos7\n\n## 查看系统是否已经安装mysql\n\n```\nrpm -qa | grep mysql\nyum list installed | grep mysql\n```\n## 卸载当前数据库\ncentos6.x或者centos7.x ：\n```\nyum -y remove mysql*\n```\n\n## mysql数据源下载\ncentos6.x\n```\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\n```\ncentos7.x\n```\nyum install -y http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm\n```\n\n## mysql安装\n```\nyum install -y mysql-community-server\n```\n\n## mysqlroot密码修改\n```\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep \"password\" | grep \"generated\" \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD('your new password');\nALTER USER 'root'@'localhost' PASSWORD EXPIRE NEVER;\nflush privileges;\n```\n\n## mysql常用操作\n\n设置字符集：\n```\n# 在 [mysqld] 前添加如下代码：\n[client]\ndefault-character-set=utf8\n\n# 在 [mysqld] 后添加如下代码：\ncharacter_set_server=utf8\n\n# 重启mysql后再登录，看看字符集，6个utf8就算OK\nshow variables like '%character%';\n```\n\n忘记密码时，重置密码：\n```\nservice mysqld stop\nmysqld_safe --user=root --skip-grant-tables --skip-networking &\nmysql -u root\n进入MySQL后\n\nuse mysql;\nupdate user set password=password(\"new_password\") where user=\"root\"; \nflush privileges;\n```\n\n数据库授权：\n```\ngrant all privileges on *.* to uaername@\"%\" identified by \"new password\";\n```\n\n数据库设置密码复杂度：\n\n* validate_password_dictionary_file: 插件用于验证密码强度的字典文件路径。\n\n* validate_password_length: 密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)\n\n* validate_password_mixed_case_count: 密码至少要包含的小写字母个数和大写字母个数。\n\n* validate_password_number_count: 密码至少要包含的数字个数。\n\n* validate_password_policy: 密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG\n\n```\n修改mysql参数配置\n\nmysql> set global validate_password_policy=0;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> set global validate_password_mixed_case_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_number_count=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_special_char_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> set global validate_password_length=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql> SHOW VARIABLES LIKE 'validate_password%';\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| validate_password_dictionary_file    |       |\n| validate_password_length             | 3     |\n| validate_password_mixed_case_count   | 0     |\n| validate_password_number_count       | 3     |\n| validate_password_policy             | LOW   |\n| validate_password_special_char_count | 0     |\n+--------------------------------------+-------+\n6 rows in set (0.00 sec)\n\n# 修改简单密码：\nmysql> SET PASSWORD =PASSWORD('root');\nmysql> SET PASSWORD FOR username=PASSWORD('new password');\n```","slug":"2018-09-04-article29-linux-yum-mysql","published":1,"updated":"2021-02-09T02:00:24.573Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0j001xyc97d1c6fapv","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<p>#centos yum安装mysql5.7</p>\n<p>在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理</p>\n<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><p>centos6或者centos7</p>\n<h2 id=\"查看系统是否已经安装mysql\"><a href=\"#查看系统是否已经安装mysql\" class=\"headerlink\" title=\"查看系统是否已经安装mysql\"></a>查看系统是否已经安装mysql</h2><pre><code>rpm -qa | grep mysql\nyum list installed | grep mysql\n</code></pre>\n<h2 id=\"卸载当前数据库\"><a href=\"#卸载当前数据库\" class=\"headerlink\" title=\"卸载当前数据库\"></a>卸载当前数据库</h2><p>centos6.x或者centos7.x ：</p>\n<pre><code>yum -y remove mysql*\n</code></pre>\n<h2 id=\"mysql数据源下载\"><a href=\"#mysql数据源下载\" class=\"headerlink\" title=\"mysql数据源下载\"></a>mysql数据源下载</h2><p>centos6.x</p>\n<pre><code>yum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\n</code></pre>\n<p>centos7.x</p>\n<pre><code>yum install -y http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm\n</code></pre>\n<h2 id=\"mysql安装\"><a href=\"#mysql安装\" class=\"headerlink\" title=\"mysql安装\"></a>mysql安装</h2><pre><code>yum install -y mysql-community-server\n</code></pre>\n<h2 id=\"mysqlroot密码修改\"><a href=\"#mysqlroot密码修改\" class=\"headerlink\" title=\"mysqlroot密码修改\"></a>mysqlroot密码修改</h2><pre><code># 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep &quot;password&quot; | grep &quot;generated&quot; \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD(&#39;your new password&#39;);\nALTER USER &#39;root&#39;@&#39;localhost&#39; PASSWORD EXPIRE NEVER;\nflush privileges;\n</code></pre>\n<h2 id=\"mysql常用操作\"><a href=\"#mysql常用操作\" class=\"headerlink\" title=\"mysql常用操作\"></a>mysql常用操作</h2><p>设置字符集：</p>\n<pre><code># 在 [mysqld] 前添加如下代码：\n[client]\ndefault-character-set=utf8\n\n# 在 [mysqld] 后添加如下代码：\ncharacter_set_server=utf8\n\n# 重启mysql后再登录，看看字符集，6个utf8就算OK\nshow variables like &#39;%character%&#39;;\n</code></pre>\n<p>忘记密码时，重置密码：</p>\n<pre><code>service mysqld stop\nmysqld_safe --user=root --skip-grant-tables --skip-networking &amp;\nmysql -u root\n进入MySQL后\n\nuse mysql;\nupdate user set password=password(&quot;new_password&quot;) where user=&quot;root&quot;; \nflush privileges;\n</code></pre>\n<p>数据库授权：</p>\n<pre><code>grant all privileges on *.* to uaername@&quot;%&quot; identified by &quot;new password&quot;;\n</code></pre>\n<p>数据库设置密码复杂度：</p>\n<ul>\n<li><p>validate_password_dictionary_file: 插件用于验证密码强度的字典文件路径。</p>\n</li>\n<li><p>validate_password_length: 密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)</p>\n</li>\n<li><p>validate_password_mixed_case_count: 密码至少要包含的小写字母个数和大写字母个数。</p>\n</li>\n<li><p>validate_password_number_count: 密码至少要包含的数字个数。</p>\n</li>\n<li><p>validate_password_policy: 密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG</p>\n</li>\n</ul>\n<pre><code>修改mysql参数配置\n\nmysql&gt; set global validate_password_policy=0;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql&gt; set global validate_password_mixed_case_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_number_count=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_special_char_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_length=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;;\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| validate_password_dictionary_file    |       |\n| validate_password_length             | 3     |\n| validate_password_mixed_case_count   | 0     |\n| validate_password_number_count       | 3     |\n| validate_password_policy             | LOW   |\n| validate_password_special_char_count | 0     |\n+--------------------------------------+-------+\n6 rows in set (0.00 sec)\n\n# 修改简单密码：\nmysql&gt; SET PASSWORD =PASSWORD(&#39;root&#39;);\nmysql&gt; SET PASSWORD FOR username=PASSWORD(&#39;new password&#39;);\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<p>#centos yum安装mysql5.7</p>\n<p>在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理</p>\n<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><p>centos6或者centos7</p>\n<h2 id=\"查看系统是否已经安装mysql\"><a href=\"#查看系统是否已经安装mysql\" class=\"headerlink\" title=\"查看系统是否已经安装mysql\"></a>查看系统是否已经安装mysql</h2><pre><code>rpm -qa | grep mysql\nyum list installed | grep mysql\n</code></pre>\n<h2 id=\"卸载当前数据库\"><a href=\"#卸载当前数据库\" class=\"headerlink\" title=\"卸载当前数据库\"></a>卸载当前数据库</h2><p>centos6.x或者centos7.x ：</p>\n<pre><code>yum -y remove mysql*\n</code></pre>\n<h2 id=\"mysql数据源下载\"><a href=\"#mysql数据源下载\" class=\"headerlink\" title=\"mysql数据源下载\"></a>mysql数据源下载</h2><p>centos6.x</p>\n<pre><code>yum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\n</code></pre>\n<p>centos7.x</p>\n<pre><code>yum install -y http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm\n</code></pre>\n<h2 id=\"mysql安装\"><a href=\"#mysql安装\" class=\"headerlink\" title=\"mysql安装\"></a>mysql安装</h2><pre><code>yum install -y mysql-community-server\n</code></pre>\n<h2 id=\"mysqlroot密码修改\"><a href=\"#mysqlroot密码修改\" class=\"headerlink\" title=\"mysqlroot密码修改\"></a>mysqlroot密码修改</h2><pre><code># 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep &quot;password&quot; | grep &quot;generated&quot; \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD(&#39;your new password&#39;);\nALTER USER &#39;root&#39;@&#39;localhost&#39; PASSWORD EXPIRE NEVER;\nflush privileges;\n</code></pre>\n<h2 id=\"mysql常用操作\"><a href=\"#mysql常用操作\" class=\"headerlink\" title=\"mysql常用操作\"></a>mysql常用操作</h2><p>设置字符集：</p>\n<pre><code># 在 [mysqld] 前添加如下代码：\n[client]\ndefault-character-set=utf8\n\n# 在 [mysqld] 后添加如下代码：\ncharacter_set_server=utf8\n\n# 重启mysql后再登录，看看字符集，6个utf8就算OK\nshow variables like &#39;%character%&#39;;\n</code></pre>\n<p>忘记密码时，重置密码：</p>\n<pre><code>service mysqld stop\nmysqld_safe --user=root --skip-grant-tables --skip-networking &amp;\nmysql -u root\n进入MySQL后\n\nuse mysql;\nupdate user set password=password(&quot;new_password&quot;) where user=&quot;root&quot;; \nflush privileges;\n</code></pre>\n<p>数据库授权：</p>\n<pre><code>grant all privileges on *.* to uaername@&quot;%&quot; identified by &quot;new password&quot;;\n</code></pre>\n<p>数据库设置密码复杂度：</p>\n<ul>\n<li><p>validate_password_dictionary_file: 插件用于验证密码强度的字典文件路径。</p>\n</li>\n<li><p>validate_password_length: 密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)</p>\n</li>\n<li><p>validate_password_mixed_case_count: 密码至少要包含的小写字母个数和大写字母个数。</p>\n</li>\n<li><p>validate_password_number_count: 密码至少要包含的数字个数。</p>\n</li>\n<li><p>validate_password_policy: 密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG</p>\n</li>\n</ul>\n<pre><code>修改mysql参数配置\n\nmysql&gt; set global validate_password_policy=0;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql&gt; set global validate_password_mixed_case_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_number_count=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_special_char_count=0;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; set global validate_password_length=3;\nQuery OK, 0 rows affected (0.00 sec)\n \nmysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;;\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| validate_password_dictionary_file    |       |\n| validate_password_length             | 3     |\n| validate_password_mixed_case_count   | 0     |\n| validate_password_number_count       | 3     |\n| validate_password_policy             | LOW   |\n| validate_password_special_char_count | 0     |\n+--------------------------------------+-------+\n6 rows in set (0.00 sec)\n\n# 修改简单密码：\nmysql&gt; SET PASSWORD =PASSWORD(&#39;root&#39;);\nmysql&gt; SET PASSWORD FOR username=PASSWORD(&#39;new password&#39;);\n</code></pre>\n"},{"layout":"post","title":"CDH 5.15安装文档","date":"2018-09-04T08:02:54.000Z","author":"owelinux","excerpt":"CDH 5.15安装文档","mathjax":true,"_content":"\n* content\n{:toc}\n\n# CDH 5.15安装文档\n\n在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理\n\n## 系统环境\n操作系统：centos6.8\n\n数据库：mysql5.7，编码utf-8\n\njava：jdk1.8\n\n\n## 安装包下载\n\n* cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\n* CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\n* CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\n* manifest.json\n\n```\nwget https://archive.cloudera.com/cm5/cm/5/cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/manifest.json\n```\n\nCHD5 相关的 Parcel 包放到主节点的/opt/cloudera/parcel-repo/目录中\nCDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1 重命名为 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha\n\n这点必须注意，否则，系统会重新下载 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel 文件\n\n本文采用离线安装方式，在线安装方式请参照官方文\n\n\n主机名\tip地址\t安装服务\nnode1 (Master)\t172.22.145.177\tjdk、cloudera-manager、MySql\n\nnode2 (Agents)\t172.22.145.178\tjdk、cloudera-manager\n\nnode3 (Agents)\t172.22.145.179\tjdk、cloudera-manager\n\n## 系统环境搭建\n\n### 配置系统环境\n```\necho 0 > /proc/sys/vm/swappiness\n\necho never > /sys/kernel/mm/transparent_hugepage/defrag echo never > /sys/kernel/mm/transparent_hugepage/enabled\n```\n\n\n### 配置hostname\n```\nvim /etc/sysconfig/network\nhostname node1\n```\n\n### 配置hosts\n```\nvim /etc/hosts\n172.22.145.177 node1\n172.22.145.178 node2\n172.22.145.179 node3\n```\n\n### 配置免密码登陆\n```\nvim /etc/ssh/sshd_config\nRSAAuthentication yes      #开启私钥验证PubkeyAuthentication yes   #开启公钥验证\nservice sshd reload\n\n生成公钥，私钥\nssh-keygen -t rsa -P ''\n\n每个节点的公钥放入认证文件\ncat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys\n\n以上步骤每台机器需要配置，配置完成严重免密登陆\n```\n### 关闭防火墙和selinux\n```\nservice iptables stop\nsetenforce 0\nvi /etc/selinux/config\n将 SELINUX=enforcing 改为 SELINUX=disabled\n```\n\n### 安装jdk环境\n```\nwget http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz\ntar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr\nvim /etc/profile\n\nJAVA_HOME=/usr/jdk1.8.0_51\nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport JAVA_HOME\nexport PATH\nexport CLASSPATH\n```\n\n### 配置ntp时间同步\n```\nntpdate -d 182.92.12.11\n```\n\n## mysql安装及配置\n```\n# yum安装mysql5.7\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\nyum install -y mysql-community-server\ngroupadd mysql\nuseradd mysql -g mysql\n\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep \"password\" | grep \"generated\" \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD('your new password');\ngrant all privileges on *.*  to  'root'@'%'  identified by 'your new password'  with grant option;\nflush privileges;\nexit;\n```\n### MySQL新建数据库\n```\n# amon\ncreate database amon DEFAULT CHARACTER SET utf8; \ngrant all on amon.* TO 'amon'@'%' IDENTIFIED BY 'amon';\n\n#hive\ncreate database hive DEFAULT CHARACTER SET utf8; \ngrant all on hive.* TO 'hive'@'%' IDENTIFIED BY 'hive';\n\n#oozie\ncreate database oozie DEFAULT CHARACTER SET utf8; \ngrant all on oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';\n```\n\n## 安装依赖包\n```\nyum -y install chkconfig bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs redhat-lsb\n```\n\n## cloudera manager Server & Agent 安装\n\n### 安装 CM Server & Agent\n\n在所有节点，创建/opt/cloudera-manager\n```\nmkdir /opt/cloudera-manager\ncd /opt/\ntar -zxvf cloudera-manager-el6-cm5.15.1_x86_64.tar.gz -C /opt/cloudera-manager\n```\n\n### 创建用户(所有节点)\n```\nuseradd --system --home=/opt/cloudera-manager/cm-5.15.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment \"Cloudera SCM User\" cloudera-scm\n```\n\n### 配置CM Agent\n修改 node1 节点\n```\nvi /opt/cloudera-manager/cm-5.15.1/etc/cloudera-scm-agent/config.ini\n将server_host改为为主节点的主机名。\n在node1 操作将 node1 节点修改后的 (复制到所有节点)\n```\n### 配置CM Server的数据库\n在主节点 node1 初始化CM5的数据库：\n\n下载 mysql 驱动包\n\n地址：[https://downloads.mysql.com/archives/c-j/](https://downloads.mysql.com/archives/c-j/)\n\n```\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/lib\nwget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.46.tar.gz\ntar -zxvf mysql-connector-java-5.1.46.tar.gz && mv mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar . && rm -rf mysql-connector-java-5.1.46.tar.gz mysql-connector-java-5.1.46\n```\n\n启动MySQL服务\n```\nservice mysql.server start\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/schema/\n./scm_prepare_database.sh mysql cm -h master -uroot -proot --scm-host master scm scm scm  \n\n以下信息为正常：\n[                          main] DbCommandExecutor              INFO  Successfully connected to database.\nAll done, your SCM database is configured correctly!\n```\n### 创建Parcel目录\n\nManager 节点创建目录/opt/cloudera/parcel-repo\n```\nmkdir -p /opt/cloudera/parcel-repo\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcel-repo\ncd /opt/cloudera/parcel-repo\nmv CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha1  CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha\nmv /opt/manifest.json /opt/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel .\n```\n\nAgent 节点创建目录/opt/cloudera/parcels，执行：\n```\nmkdir -p /opt/cloudera/parcels\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcels\n```\n\n### 启动 CM Manager&Agent 服务\n\n在 node1 (master) 执行：\nServer\n```\n/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-server start\n```\n\n在 node2-7 (Agents) 执行：\nAgents\n```\n/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-agent start\n```\n访问 http://Master:7180 若可以访问（用户名、密码：admin），则安装成功。\n\nManager 启动成功需要等待一段时间，过程中会在数据库中创建对应的表需要耗费一些时间。\n\n## CDH5 安装\nCM Manager && Agent 成功启动后，登录前端页面进行 CDH 安装配置。\n\n\n## 参考\n*  [https://yq.aliyun.com/articles/341408](https://yq.aliyun.com/articles/341408)","source":"_posts/2018-09-04-article30-linux-CDH.md","raw":"---\nlayout: post\ntitle:  \"CDH 5.15安装文档\"\ndate:   2018-09-04 16:02:54\nauthor: owelinux\ncategories: linux \ntags:  CDH  \nexcerpt: CDH 5.15安装文档\nmathjax: true\n---\n\n* content\n{:toc}\n\n# CDH 5.15安装文档\n\n在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理\n\n## 系统环境\n操作系统：centos6.8\n\n数据库：mysql5.7，编码utf-8\n\njava：jdk1.8\n\n\n## 安装包下载\n\n* cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\n* CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\n* CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\n* manifest.json\n\n```\nwget https://archive.cloudera.com/cm5/cm/5/cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/manifest.json\n```\n\nCHD5 相关的 Parcel 包放到主节点的/opt/cloudera/parcel-repo/目录中\nCDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1 重命名为 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha\n\n这点必须注意，否则，系统会重新下载 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel 文件\n\n本文采用离线安装方式，在线安装方式请参照官方文\n\n\n主机名\tip地址\t安装服务\nnode1 (Master)\t172.22.145.177\tjdk、cloudera-manager、MySql\n\nnode2 (Agents)\t172.22.145.178\tjdk、cloudera-manager\n\nnode3 (Agents)\t172.22.145.179\tjdk、cloudera-manager\n\n## 系统环境搭建\n\n### 配置系统环境\n```\necho 0 > /proc/sys/vm/swappiness\n\necho never > /sys/kernel/mm/transparent_hugepage/defrag echo never > /sys/kernel/mm/transparent_hugepage/enabled\n```\n\n\n### 配置hostname\n```\nvim /etc/sysconfig/network\nhostname node1\n```\n\n### 配置hosts\n```\nvim /etc/hosts\n172.22.145.177 node1\n172.22.145.178 node2\n172.22.145.179 node3\n```\n\n### 配置免密码登陆\n```\nvim /etc/ssh/sshd_config\nRSAAuthentication yes      #开启私钥验证PubkeyAuthentication yes   #开启公钥验证\nservice sshd reload\n\n生成公钥，私钥\nssh-keygen -t rsa -P ''\n\n每个节点的公钥放入认证文件\ncat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys\n\n以上步骤每台机器需要配置，配置完成严重免密登陆\n```\n### 关闭防火墙和selinux\n```\nservice iptables stop\nsetenforce 0\nvi /etc/selinux/config\n将 SELINUX=enforcing 改为 SELINUX=disabled\n```\n\n### 安装jdk环境\n```\nwget http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz\ntar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr\nvim /etc/profile\n\nJAVA_HOME=/usr/jdk1.8.0_51\nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport JAVA_HOME\nexport PATH\nexport CLASSPATH\n```\n\n### 配置ntp时间同步\n```\nntpdate -d 182.92.12.11\n```\n\n## mysql安装及配置\n```\n# yum安装mysql5.7\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\nyum install -y mysql-community-server\ngroupadd mysql\nuseradd mysql -g mysql\n\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep \"password\" | grep \"generated\" \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD('your new password');\ngrant all privileges on *.*  to  'root'@'%'  identified by 'your new password'  with grant option;\nflush privileges;\nexit;\n```\n### MySQL新建数据库\n```\n# amon\ncreate database amon DEFAULT CHARACTER SET utf8; \ngrant all on amon.* TO 'amon'@'%' IDENTIFIED BY 'amon';\n\n#hive\ncreate database hive DEFAULT CHARACTER SET utf8; \ngrant all on hive.* TO 'hive'@'%' IDENTIFIED BY 'hive';\n\n#oozie\ncreate database oozie DEFAULT CHARACTER SET utf8; \ngrant all on oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';\n```\n\n## 安装依赖包\n```\nyum -y install chkconfig bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs redhat-lsb\n```\n\n## cloudera manager Server & Agent 安装\n\n### 安装 CM Server & Agent\n\n在所有节点，创建/opt/cloudera-manager\n```\nmkdir /opt/cloudera-manager\ncd /opt/\ntar -zxvf cloudera-manager-el6-cm5.15.1_x86_64.tar.gz -C /opt/cloudera-manager\n```\n\n### 创建用户(所有节点)\n```\nuseradd --system --home=/opt/cloudera-manager/cm-5.15.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment \"Cloudera SCM User\" cloudera-scm\n```\n\n### 配置CM Agent\n修改 node1 节点\n```\nvi /opt/cloudera-manager/cm-5.15.1/etc/cloudera-scm-agent/config.ini\n将server_host改为为主节点的主机名。\n在node1 操作将 node1 节点修改后的 (复制到所有节点)\n```\n### 配置CM Server的数据库\n在主节点 node1 初始化CM5的数据库：\n\n下载 mysql 驱动包\n\n地址：[https://downloads.mysql.com/archives/c-j/](https://downloads.mysql.com/archives/c-j/)\n\n```\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/lib\nwget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.46.tar.gz\ntar -zxvf mysql-connector-java-5.1.46.tar.gz && mv mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar . && rm -rf mysql-connector-java-5.1.46.tar.gz mysql-connector-java-5.1.46\n```\n\n启动MySQL服务\n```\nservice mysql.server start\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/schema/\n./scm_prepare_database.sh mysql cm -h master -uroot -proot --scm-host master scm scm scm  \n\n以下信息为正常：\n[                          main] DbCommandExecutor              INFO  Successfully connected to database.\nAll done, your SCM database is configured correctly!\n```\n### 创建Parcel目录\n\nManager 节点创建目录/opt/cloudera/parcel-repo\n```\nmkdir -p /opt/cloudera/parcel-repo\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcel-repo\ncd /opt/cloudera/parcel-repo\nmv CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha1  CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha\nmv /opt/manifest.json /opt/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel .\n```\n\nAgent 节点创建目录/opt/cloudera/parcels，执行：\n```\nmkdir -p /opt/cloudera/parcels\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcels\n```\n\n### 启动 CM Manager&Agent 服务\n\n在 node1 (master) 执行：\nServer\n```\n/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-server start\n```\n\n在 node2-7 (Agents) 执行：\nAgents\n```\n/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-agent start\n```\n访问 http://Master:7180 若可以访问（用户名、密码：admin），则安装成功。\n\nManager 启动成功需要等待一段时间，过程中会在数据库中创建对应的表需要耗费一些时间。\n\n## CDH5 安装\nCM Manager && Agent 成功启动后，登录前端页面进行 CDH 安装配置。\n\n\n## 参考\n*  [https://yq.aliyun.com/articles/341408](https://yq.aliyun.com/articles/341408)","slug":"2018-09-04-article30-linux-CDH","published":1,"updated":"2021-02-09T02:00:24.573Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0k0021yc974qw78nex","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"CDH-5-15安装文档\"><a href=\"#CDH-5-15安装文档\" class=\"headerlink\" title=\"CDH 5.15安装文档\"></a>CDH 5.15安装文档</h1><p>在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理</p>\n<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><p>操作系统：centos6.8</p>\n<p>数据库：mysql5.7，编码utf-8</p>\n<p>java：jdk1.8</p>\n<h2 id=\"安装包下载\"><a href=\"#安装包下载\" class=\"headerlink\" title=\"安装包下载\"></a>安装包下载</h2><ul>\n<li><p>cloudera-manager-el6-cm5.15.1_x86_64.tar.gz</p>\n</li>\n<li><p>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel</p>\n</li>\n<li><p>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1</p>\n</li>\n<li><p>manifest.json</p>\n</li>\n</ul>\n<pre><code>wget https://archive.cloudera.com/cm5/cm/5/cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/manifest.json\n</code></pre>\n<p>CHD5 相关的 Parcel 包放到主节点的/opt/cloudera/parcel-repo/目录中<br>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1 重命名为 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha</p>\n<p>这点必须注意，否则，系统会重新下载 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel 文件</p>\n<p>本文采用离线安装方式，在线安装方式请参照官方文</p>\n<p>主机名    ip地址    安装服务<br>node1 (Master)    172.22.145.177    jdk、cloudera-manager、MySql</p>\n<p>node2 (Agents)    172.22.145.178    jdk、cloudera-manager</p>\n<p>node3 (Agents)    172.22.145.179    jdk、cloudera-manager</p>\n<h2 id=\"系统环境搭建\"><a href=\"#系统环境搭建\" class=\"headerlink\" title=\"系统环境搭建\"></a>系统环境搭建</h2><h3 id=\"配置系统环境\"><a href=\"#配置系统环境\" class=\"headerlink\" title=\"配置系统环境\"></a>配置系统环境</h3><pre><code>echo 0 &gt; /proc/sys/vm/swappiness\n\necho never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre>\n<h3 id=\"配置hostname\"><a href=\"#配置hostname\" class=\"headerlink\" title=\"配置hostname\"></a>配置hostname</h3><pre><code>vim /etc/sysconfig/network\nhostname node1\n</code></pre>\n<h3 id=\"配置hosts\"><a href=\"#配置hosts\" class=\"headerlink\" title=\"配置hosts\"></a>配置hosts</h3><pre><code>vim /etc/hosts\n172.22.145.177 node1\n172.22.145.178 node2\n172.22.145.179 node3\n</code></pre>\n<h3 id=\"配置免密码登陆\"><a href=\"#配置免密码登陆\" class=\"headerlink\" title=\"配置免密码登陆\"></a>配置免密码登陆</h3><pre><code>vim /etc/ssh/sshd_config\nRSAAuthentication yes      #开启私钥验证PubkeyAuthentication yes   #开启公钥验证\nservice sshd reload\n\n生成公钥，私钥\nssh-keygen -t rsa -P &#39;&#39;\n\n每个节点的公钥放入认证文件\ncat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys\n\n以上步骤每台机器需要配置，配置完成严重免密登陆\n</code></pre>\n<h3 id=\"关闭防火墙和selinux\"><a href=\"#关闭防火墙和selinux\" class=\"headerlink\" title=\"关闭防火墙和selinux\"></a>关闭防火墙和selinux</h3><pre><code>service iptables stop\nsetenforce 0\nvi /etc/selinux/config\n将 SELINUX=enforcing 改为 SELINUX=disabled\n</code></pre>\n<h3 id=\"安装jdk环境\"><a href=\"#安装jdk环境\" class=\"headerlink\" title=\"安装jdk环境\"></a>安装jdk环境</h3><pre><code>wget http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz\ntar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr\nvim /etc/profile\n\nJAVA_HOME=/usr/jdk1.8.0_51\nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport JAVA_HOME\nexport PATH\nexport CLASSPATH\n</code></pre>\n<h3 id=\"配置ntp时间同步\"><a href=\"#配置ntp时间同步\" class=\"headerlink\" title=\"配置ntp时间同步\"></a>配置ntp时间同步</h3><pre><code>ntpdate -d 182.92.12.11\n</code></pre>\n<h2 id=\"mysql安装及配置\"><a href=\"#mysql安装及配置\" class=\"headerlink\" title=\"mysql安装及配置\"></a>mysql安装及配置</h2><pre><code># yum安装mysql5.7\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\nyum install -y mysql-community-server\ngroupadd mysql\nuseradd mysql -g mysql\n\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep &quot;password&quot; | grep &quot;generated&quot; \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD(&#39;your new password&#39;);\ngrant all privileges on *.*  to  &#39;root&#39;@&#39;%&#39;  identified by &#39;your new password&#39;  with grant option;\nflush privileges;\nexit;\n</code></pre>\n<h3 id=\"MySQL新建数据库\"><a href=\"#MySQL新建数据库\" class=\"headerlink\" title=\"MySQL新建数据库\"></a>MySQL新建数据库</h3><pre><code># amon\ncreate database amon DEFAULT CHARACTER SET utf8; \ngrant all on amon.* TO &#39;amon&#39;@&#39;%&#39; IDENTIFIED BY &#39;amon&#39;;\n\n#hive\ncreate database hive DEFAULT CHARACTER SET utf8; \ngrant all on hive.* TO &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive&#39;;\n\n#oozie\ncreate database oozie DEFAULT CHARACTER SET utf8; \ngrant all on oozie.* TO &#39;oozie&#39;@&#39;%&#39; IDENTIFIED BY &#39;oozie&#39;;\n</code></pre>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h2><pre><code>yum -y install chkconfig bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs redhat-lsb\n</code></pre>\n<h2 id=\"cloudera-manager-Server-amp-Agent-安装\"><a href=\"#cloudera-manager-Server-amp-Agent-安装\" class=\"headerlink\" title=\"cloudera manager Server &amp; Agent 安装\"></a>cloudera manager Server &amp; Agent 安装</h2><h3 id=\"安装-CM-Server-amp-Agent\"><a href=\"#安装-CM-Server-amp-Agent\" class=\"headerlink\" title=\"安装 CM Server &amp; Agent\"></a>安装 CM Server &amp; Agent</h3><p>在所有节点，创建/opt/cloudera-manager</p>\n<pre><code>mkdir /opt/cloudera-manager\ncd /opt/\ntar -zxvf cloudera-manager-el6-cm5.15.1_x86_64.tar.gz -C /opt/cloudera-manager\n</code></pre>\n<h3 id=\"创建用户-所有节点\"><a href=\"#创建用户-所有节点\" class=\"headerlink\" title=\"创建用户(所有节点)\"></a>创建用户(所有节点)</h3><pre><code>useradd --system --home=/opt/cloudera-manager/cm-5.15.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm\n</code></pre>\n<h3 id=\"配置CM-Agent\"><a href=\"#配置CM-Agent\" class=\"headerlink\" title=\"配置CM Agent\"></a>配置CM Agent</h3><p>修改 node1 节点</p>\n<pre><code>vi /opt/cloudera-manager/cm-5.15.1/etc/cloudera-scm-agent/config.ini\n将server_host改为为主节点的主机名。\n在node1 操作将 node1 节点修改后的 (复制到所有节点)\n</code></pre>\n<h3 id=\"配置CM-Server的数据库\"><a href=\"#配置CM-Server的数据库\" class=\"headerlink\" title=\"配置CM Server的数据库\"></a>配置CM Server的数据库</h3><p>在主节点 node1 初始化CM5的数据库：</p>\n<p>下载 mysql 驱动包</p>\n<p>地址：<a href=\"https://downloads.mysql.com/archives/c-j/\">https://downloads.mysql.com/archives/c-j/</a></p>\n<pre><code>cd /opt/cloudera-manager/cm-5.15.1/share/cmf/lib\nwget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.46.tar.gz\ntar -zxvf mysql-connector-java-5.1.46.tar.gz &amp;&amp; mv mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar . &amp;&amp; rm -rf mysql-connector-java-5.1.46.tar.gz mysql-connector-java-5.1.46\n</code></pre>\n<p>启动MySQL服务</p>\n<pre><code>service mysql.server start\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/schema/\n./scm_prepare_database.sh mysql cm -h master -uroot -proot --scm-host master scm scm scm  \n\n以下信息为正常：\n[                          main] DbCommandExecutor              INFO  Successfully connected to database.\nAll done, your SCM database is configured correctly!\n</code></pre>\n<h3 id=\"创建Parcel目录\"><a href=\"#创建Parcel目录\" class=\"headerlink\" title=\"创建Parcel目录\"></a>创建Parcel目录</h3><p>Manager 节点创建目录/opt/cloudera/parcel-repo</p>\n<pre><code>mkdir -p /opt/cloudera/parcel-repo\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcel-repo\ncd /opt/cloudera/parcel-repo\nmv CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha1  CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha\nmv /opt/manifest.json /opt/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel .\n</code></pre>\n<p>Agent 节点创建目录/opt/cloudera/parcels，执行：</p>\n<pre><code>mkdir -p /opt/cloudera/parcels\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcels\n</code></pre>\n<h3 id=\"启动-CM-Manager-amp-Agent-服务\"><a href=\"#启动-CM-Manager-amp-Agent-服务\" class=\"headerlink\" title=\"启动 CM Manager&amp;Agent 服务\"></a>启动 CM Manager&amp;Agent 服务</h3><p>在 node1 (master) 执行：<br>Server</p>\n<pre><code>/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-server start\n</code></pre>\n<p>在 node2-7 (Agents) 执行：<br>Agents</p>\n<pre><code>/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-agent start\n</code></pre>\n<p>访问 <a href=\"http://master:7180/\">http://Master:7180</a> 若可以访问（用户名、密码：admin），则安装成功。</p>\n<p>Manager 启动成功需要等待一段时间，过程中会在数据库中创建对应的表需要耗费一些时间。</p>\n<h2 id=\"CDH5-安装\"><a href=\"#CDH5-安装\" class=\"headerlink\" title=\"CDH5 安装\"></a>CDH5 安装</h2><p>CM Manager &amp;&amp; Agent 成功启动后，登录前端页面进行 CDH 安装配置。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li> <a href=\"https://yq.aliyun.com/articles/341408\">https://yq.aliyun.com/articles/341408</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"CDH-5-15安装文档\"><a href=\"#CDH-5-15安装文档\" class=\"headerlink\" title=\"CDH 5.15安装文档\"></a>CDH 5.15安装文档</h1><p>在测试开发环境，初始化一个数据库，通常选择yum来安装，本文将常见的mysqlyum源及安装方式梳理</p>\n<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><p>操作系统：centos6.8</p>\n<p>数据库：mysql5.7，编码utf-8</p>\n<p>java：jdk1.8</p>\n<h2 id=\"安装包下载\"><a href=\"#安装包下载\" class=\"headerlink\" title=\"安装包下载\"></a>安装包下载</h2><ul>\n<li><p>cloudera-manager-el6-cm5.15.1_x86_64.tar.gz</p>\n</li>\n<li><p>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel</p>\n</li>\n<li><p>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1</p>\n</li>\n<li><p>manifest.json</p>\n</li>\n</ul>\n<pre><code>wget https://archive.cloudera.com/cm5/cm/5/cloudera-manager-el6-cm5.15.1_x86_64.tar.gz\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1\n\nwget https://archive.cloudera.com/cdh5/parcels/5.15.1/manifest.json\n</code></pre>\n<p>CHD5 相关的 Parcel 包放到主节点的/opt/cloudera/parcel-repo/目录中<br>CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha1 重命名为 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel.sha</p>\n<p>这点必须注意，否则，系统会重新下载 CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel 文件</p>\n<p>本文采用离线安装方式，在线安装方式请参照官方文</p>\n<p>主机名    ip地址    安装服务<br>node1 (Master)    172.22.145.177    jdk、cloudera-manager、MySql</p>\n<p>node2 (Agents)    172.22.145.178    jdk、cloudera-manager</p>\n<p>node3 (Agents)    172.22.145.179    jdk、cloudera-manager</p>\n<h2 id=\"系统环境搭建\"><a href=\"#系统环境搭建\" class=\"headerlink\" title=\"系统环境搭建\"></a>系统环境搭建</h2><h3 id=\"配置系统环境\"><a href=\"#配置系统环境\" class=\"headerlink\" title=\"配置系统环境\"></a>配置系统环境</h3><pre><code>echo 0 &gt; /proc/sys/vm/swappiness\n\necho never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre>\n<h3 id=\"配置hostname\"><a href=\"#配置hostname\" class=\"headerlink\" title=\"配置hostname\"></a>配置hostname</h3><pre><code>vim /etc/sysconfig/network\nhostname node1\n</code></pre>\n<h3 id=\"配置hosts\"><a href=\"#配置hosts\" class=\"headerlink\" title=\"配置hosts\"></a>配置hosts</h3><pre><code>vim /etc/hosts\n172.22.145.177 node1\n172.22.145.178 node2\n172.22.145.179 node3\n</code></pre>\n<h3 id=\"配置免密码登陆\"><a href=\"#配置免密码登陆\" class=\"headerlink\" title=\"配置免密码登陆\"></a>配置免密码登陆</h3><pre><code>vim /etc/ssh/sshd_config\nRSAAuthentication yes      #开启私钥验证PubkeyAuthentication yes   #开启公钥验证\nservice sshd reload\n\n生成公钥，私钥\nssh-keygen -t rsa -P &#39;&#39;\n\n每个节点的公钥放入认证文件\ncat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys\n\n以上步骤每台机器需要配置，配置完成严重免密登陆\n</code></pre>\n<h3 id=\"关闭防火墙和selinux\"><a href=\"#关闭防火墙和selinux\" class=\"headerlink\" title=\"关闭防火墙和selinux\"></a>关闭防火墙和selinux</h3><pre><code>service iptables stop\nsetenforce 0\nvi /etc/selinux/config\n将 SELINUX=enforcing 改为 SELINUX=disabled\n</code></pre>\n<h3 id=\"安装jdk环境\"><a href=\"#安装jdk环境\" class=\"headerlink\" title=\"安装jdk环境\"></a>安装jdk环境</h3><pre><code>wget http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz\ntar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr\nvim /etc/profile\n\nJAVA_HOME=/usr/jdk1.8.0_51\nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport JAVA_HOME\nexport PATH\nexport CLASSPATH\n</code></pre>\n<h3 id=\"配置ntp时间同步\"><a href=\"#配置ntp时间同步\" class=\"headerlink\" title=\"配置ntp时间同步\"></a>配置ntp时间同步</h3><pre><code>ntpdate -d 182.92.12.11\n</code></pre>\n<h2 id=\"mysql安装及配置\"><a href=\"#mysql安装及配置\" class=\"headerlink\" title=\"mysql安装及配置\"></a>mysql安装及配置</h2><pre><code># yum安装mysql5.7\nyum install -y http://repo.mysql.com//mysql57-community-release-el6-8.noarch.rpm\nyum install -y mysql-community-server\ngroupadd mysql\nuseradd mysql -g mysql\n\n# 启动数据库\nservice mysqld start\n# 查看密码\ncat  /var/log/mysqld.log |  grep &quot;password&quot; | grep &quot;generated&quot; \n# 登陆数据库\nmysql-uroot -p\n# 修改密码\nSET PASSWORD = PASSWORD(&#39;your new password&#39;);\ngrant all privileges on *.*  to  &#39;root&#39;@&#39;%&#39;  identified by &#39;your new password&#39;  with grant option;\nflush privileges;\nexit;\n</code></pre>\n<h3 id=\"MySQL新建数据库\"><a href=\"#MySQL新建数据库\" class=\"headerlink\" title=\"MySQL新建数据库\"></a>MySQL新建数据库</h3><pre><code># amon\ncreate database amon DEFAULT CHARACTER SET utf8; \ngrant all on amon.* TO &#39;amon&#39;@&#39;%&#39; IDENTIFIED BY &#39;amon&#39;;\n\n#hive\ncreate database hive DEFAULT CHARACTER SET utf8; \ngrant all on hive.* TO &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive&#39;;\n\n#oozie\ncreate database oozie DEFAULT CHARACTER SET utf8; \ngrant all on oozie.* TO &#39;oozie&#39;@&#39;%&#39; IDENTIFIED BY &#39;oozie&#39;;\n</code></pre>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h2><pre><code>yum -y install chkconfig bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs redhat-lsb\n</code></pre>\n<h2 id=\"cloudera-manager-Server-amp-Agent-安装\"><a href=\"#cloudera-manager-Server-amp-Agent-安装\" class=\"headerlink\" title=\"cloudera manager Server &amp; Agent 安装\"></a>cloudera manager Server &amp; Agent 安装</h2><h3 id=\"安装-CM-Server-amp-Agent\"><a href=\"#安装-CM-Server-amp-Agent\" class=\"headerlink\" title=\"安装 CM Server &amp; Agent\"></a>安装 CM Server &amp; Agent</h3><p>在所有节点，创建/opt/cloudera-manager</p>\n<pre><code>mkdir /opt/cloudera-manager\ncd /opt/\ntar -zxvf cloudera-manager-el6-cm5.15.1_x86_64.tar.gz -C /opt/cloudera-manager\n</code></pre>\n<h3 id=\"创建用户-所有节点\"><a href=\"#创建用户-所有节点\" class=\"headerlink\" title=\"创建用户(所有节点)\"></a>创建用户(所有节点)</h3><pre><code>useradd --system --home=/opt/cloudera-manager/cm-5.15.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm\n</code></pre>\n<h3 id=\"配置CM-Agent\"><a href=\"#配置CM-Agent\" class=\"headerlink\" title=\"配置CM Agent\"></a>配置CM Agent</h3><p>修改 node1 节点</p>\n<pre><code>vi /opt/cloudera-manager/cm-5.15.1/etc/cloudera-scm-agent/config.ini\n将server_host改为为主节点的主机名。\n在node1 操作将 node1 节点修改后的 (复制到所有节点)\n</code></pre>\n<h3 id=\"配置CM-Server的数据库\"><a href=\"#配置CM-Server的数据库\" class=\"headerlink\" title=\"配置CM Server的数据库\"></a>配置CM Server的数据库</h3><p>在主节点 node1 初始化CM5的数据库：</p>\n<p>下载 mysql 驱动包</p>\n<p>地址：<a href=\"https://downloads.mysql.com/archives/c-j/\">https://downloads.mysql.com/archives/c-j/</a></p>\n<pre><code>cd /opt/cloudera-manager/cm-5.15.1/share/cmf/lib\nwget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.46.tar.gz\ntar -zxvf mysql-connector-java-5.1.46.tar.gz &amp;&amp; mv mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar . &amp;&amp; rm -rf mysql-connector-java-5.1.46.tar.gz mysql-connector-java-5.1.46\n</code></pre>\n<p>启动MySQL服务</p>\n<pre><code>service mysql.server start\ncd /opt/cloudera-manager/cm-5.15.1/share/cmf/schema/\n./scm_prepare_database.sh mysql cm -h master -uroot -proot --scm-host master scm scm scm  \n\n以下信息为正常：\n[                          main] DbCommandExecutor              INFO  Successfully connected to database.\nAll done, your SCM database is configured correctly!\n</code></pre>\n<h3 id=\"创建Parcel目录\"><a href=\"#创建Parcel目录\" class=\"headerlink\" title=\"创建Parcel目录\"></a>创建Parcel目录</h3><p>Manager 节点创建目录/opt/cloudera/parcel-repo</p>\n<pre><code>mkdir -p /opt/cloudera/parcel-repo\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcel-repo\ncd /opt/cloudera/parcel-repo\nmv CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha1  CDH-5.15.0-1.cdh5.15.0.p0.21-el6.parcel.sha\nmv /opt/manifest.json /opt/CDH-5.15.1-1.cdh5.15.1.p0.4-el6.parcel .\n</code></pre>\n<p>Agent 节点创建目录/opt/cloudera/parcels，执行：</p>\n<pre><code>mkdir -p /opt/cloudera/parcels\nchown cloudera-scm:cloudera-scm -R /opt/cloudera/parcels\n</code></pre>\n<h3 id=\"启动-CM-Manager-amp-Agent-服务\"><a href=\"#启动-CM-Manager-amp-Agent-服务\" class=\"headerlink\" title=\"启动 CM Manager&amp;Agent 服务\"></a>启动 CM Manager&amp;Agent 服务</h3><p>在 node1 (master) 执行：<br>Server</p>\n<pre><code>/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-server start\n</code></pre>\n<p>在 node2-7 (Agents) 执行：<br>Agents</p>\n<pre><code>/opt/cloudera-manager/cm-5.15.1/etc/init.d/cloudera-scm-agent start\n</code></pre>\n<p>访问 <a href=\"http://master:7180/\">http://Master:7180</a> 若可以访问（用户名、密码：admin），则安装成功。</p>\n<p>Manager 启动成功需要等待一段时间，过程中会在数据库中创建对应的表需要耗费一些时间。</p>\n<h2 id=\"CDH5-安装\"><a href=\"#CDH5-安装\" class=\"headerlink\" title=\"CDH5 安装\"></a>CDH5 安装</h2><p>CM Manager &amp;&amp; Agent 成功启动后，登录前端页面进行 CDH 安装配置。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li> <a href=\"https://yq.aliyun.com/articles/341408\">https://yq.aliyun.com/articles/341408</a></li>\n</ul>\n"},{"layout":"post","title":"Let's Encrypt通配符HTTPS证书申请","date":"2018-09-06T02:44:54.000Z","author":"owelinux","excerpt":"Let's Encrypt通配符HTTPS证书申请","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Let's Encrypt通配符HTTPS证书申请\n\nLet's Encrypt 发布的 ACME v2 现已正式支持通配符证书，下面介绍三种方法申请证书。\n\n## 使用acme.sh方式\nacme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书.\n\n主要步骤:\n\n* 安装 acme.sh\n* 生成证书\n* copy 证书到 nginx/apache 或者其他服务\n* 更新证书\n* 更新 acme.sh\n* 出错怎么办, 如何调试\n\n下面详细介绍.\n\n### 1. 安装 acme.sh\n```\ncurl  https://get.acme.sh | sh\n```\n\n* 1）安装目录中: ~/.acme.sh/\n* 2) 自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.\n\n### 2. 生成证书\n\nacme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.\n\n#### 1. http 方式\n\n方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了.\n```\nacme.sh  --issue  -d mydomain.com -d www.mydomain.com  --webroot  /home/wwwroot/mydomain.com/\n``` \n\n\n#### 2. dns 方式\n\n在域名上添加一条 txt 解析记录, 验证域名所有权.\n\n这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。\n\n其他api：[https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md](https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md)\n##### 手动添加txt记录\n1.生成txt记录\n```\nacme.sh  --issue  --dns   -d mydomain.com\n```\n\n2.域名管理面板中添加这条 txt 记录即可.\n\n3.等待验证解析完成之后, 重新生成证书:\n```\nacme.sh  --renew   -d mydomain.com\n```\n\n##### 通过api自动添加txt记录\n\n以 dnspod 为例, 登录到 dnspod 账号, 生成 api id 和 api key, 然后:\n```\nexport DP_Id=\"1234\"\n\nexport DP_Key=\"sADDsdasdgdsf\"\n\nacme.sh   --issue   --dns dns_dp   -d aa.com  -d www.aa.com\n```\n\n### 3. copy/安装 证书\n\n正确的使用方法是使用 --installcert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如:\n\n```\nacme.sh  --installcert  -d  <domain>.com   \\\n        --key-file   /etc/nginx/ssl/<domain>.key \\\n        --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n        --reloadcmd  \"service nginx force-reload\"\n```\n\nNginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/<domain>.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。\n\nnginx 配置\n```\nserver {\n    server_name www.fuckbb.tk;\n    listen 443 http2 ssl;\n    root /var/www/html;\n\n    ssl on;\n    ssl_certificate /etc/nginx/ssl/fullchain.cer;\n    ssl_certificate_key /etc/nginx/ssl/fuckbb.tk.key;\n    ssl_session_timeout 5m;\n    ssl_protocols  SSLv2 SSLv3 TLSv1;\n    ssl_ciphers  HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;  \n}\n```\n\n### 4. 更新证书\n\n目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.\n\n### 5. 更新 acme.sh\n\n升级 acme.sh 到最新版 :\n```\nacme.sh --upgrade\n```\n开启自动升级:\n```\nacme.sh  --upgrade  --auto-upgrade\n```\n\n关闭自动更新:\n```\nacme.sh --upgrade  --auto-upgrade  0\n```\n\n### 6. 出错怎么办：\n如果出错, 请添加 debug log：\n```\nacme.sh  --issue  .....  --debug \n或者：\nacme.sh  --issue  .....  --debug  2\n```\n\n## 采用docker方式\n```\n#revoke a cert\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --revoke -d example.com\n\n#use dns mode\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  neilpang/acme.sh  --issue --dns -d example.com\n\n#use api-dns mode\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  -e Ali_Key=\"xxxxxx\" \\\n  -e Ali_Secret=\"xxxx\" \\\n  neilpang/acme.sh  --issue --dns dns_dp -d domain.cn -d *.domain.cn\n\n#run cron job\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --cron\n\n#run cronjob\ndocker run --rm  -itd  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  --name=acme.sh \\\n  neilpang/acme.sh daemon\n\n```\n\n## certbot方式获取证书[不推荐]\n\n### 1.获取certbot-auto\n```\nwget https://dl.eff.org/certbot-auto\nchmod a+x certbot-auto\n```\n### 2.开始申请证书\n```\n./certbot-auto --server https://acme-v02.api.letsencrypt.org/directory -d \"*.xxx.com\" -d \"xxx.com\" --manual --preerred-challenges dns-01 certonly\n```\n执行完这一步之后，会下载一些需要的依赖，稍等片刻之后，会提示输入邮箱，随便输入都行【该邮箱用于安全提醒以及续期提醒】,然后提示添加txt记录，带添加完成使用dig验证后回车，生成证书\n/etc/letsencrypt/live/xxx.com/\n\n### 3.续期\n```\n./certbot-auto renew\n```\n\n## nginx证书配置\n```\nserver {\n    server_name xxx.com;\n    listen 443 http2 ssl;\n    ssl on;\n    ssl_certificate /etc/cert/xxx.cn/fullchain.pem;\n    ssl_certificate_key /etc/cert/xxx.cn/privkey.pem;\n    ssl_trusted_certificate  /etc/cert/xxx.cn/chain.pem;\n\n    location / {\n      proxy_pass http://127.0.0.1:6666;\n    }\n}\n```\n\n## 参考\n*  [https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E](https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E)","source":"_posts/2018-09-06-article31-linux-let-ssl.md","raw":"---\nlayout: post\ntitle:  \"Let's Encrypt通配符HTTPS证书申请\"\ndate:   2018-09-06 10:44:54\nauthor: owelinux\ncategories: linux \ntags:  https  \nexcerpt: Let's Encrypt通配符HTTPS证书申请\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Let's Encrypt通配符HTTPS证书申请\n\nLet's Encrypt 发布的 ACME v2 现已正式支持通配符证书，下面介绍三种方法申请证书。\n\n## 使用acme.sh方式\nacme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书.\n\n主要步骤:\n\n* 安装 acme.sh\n* 生成证书\n* copy 证书到 nginx/apache 或者其他服务\n* 更新证书\n* 更新 acme.sh\n* 出错怎么办, 如何调试\n\n下面详细介绍.\n\n### 1. 安装 acme.sh\n```\ncurl  https://get.acme.sh | sh\n```\n\n* 1）安装目录中: ~/.acme.sh/\n* 2) 自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.\n\n### 2. 生成证书\n\nacme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.\n\n#### 1. http 方式\n\n方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了.\n```\nacme.sh  --issue  -d mydomain.com -d www.mydomain.com  --webroot  /home/wwwroot/mydomain.com/\n``` \n\n\n#### 2. dns 方式\n\n在域名上添加一条 txt 解析记录, 验证域名所有权.\n\n这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。\n\n其他api：[https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md](https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md)\n##### 手动添加txt记录\n1.生成txt记录\n```\nacme.sh  --issue  --dns   -d mydomain.com\n```\n\n2.域名管理面板中添加这条 txt 记录即可.\n\n3.等待验证解析完成之后, 重新生成证书:\n```\nacme.sh  --renew   -d mydomain.com\n```\n\n##### 通过api自动添加txt记录\n\n以 dnspod 为例, 登录到 dnspod 账号, 生成 api id 和 api key, 然后:\n```\nexport DP_Id=\"1234\"\n\nexport DP_Key=\"sADDsdasdgdsf\"\n\nacme.sh   --issue   --dns dns_dp   -d aa.com  -d www.aa.com\n```\n\n### 3. copy/安装 证书\n\n正确的使用方法是使用 --installcert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如:\n\n```\nacme.sh  --installcert  -d  <domain>.com   \\\n        --key-file   /etc/nginx/ssl/<domain>.key \\\n        --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n        --reloadcmd  \"service nginx force-reload\"\n```\n\nNginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/<domain>.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。\n\nnginx 配置\n```\nserver {\n    server_name www.fuckbb.tk;\n    listen 443 http2 ssl;\n    root /var/www/html;\n\n    ssl on;\n    ssl_certificate /etc/nginx/ssl/fullchain.cer;\n    ssl_certificate_key /etc/nginx/ssl/fuckbb.tk.key;\n    ssl_session_timeout 5m;\n    ssl_protocols  SSLv2 SSLv3 TLSv1;\n    ssl_ciphers  HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;  \n}\n```\n\n### 4. 更新证书\n\n目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.\n\n### 5. 更新 acme.sh\n\n升级 acme.sh 到最新版 :\n```\nacme.sh --upgrade\n```\n开启自动升级:\n```\nacme.sh  --upgrade  --auto-upgrade\n```\n\n关闭自动更新:\n```\nacme.sh --upgrade  --auto-upgrade  0\n```\n\n### 6. 出错怎么办：\n如果出错, 请添加 debug log：\n```\nacme.sh  --issue  .....  --debug \n或者：\nacme.sh  --issue  .....  --debug  2\n```\n\n## 采用docker方式\n```\n#revoke a cert\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --revoke -d example.com\n\n#use dns mode\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  neilpang/acme.sh  --issue --dns -d example.com\n\n#use api-dns mode\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  -e Ali_Key=\"xxxxxx\" \\\n  -e Ali_Secret=\"xxxx\" \\\n  neilpang/acme.sh  --issue --dns dns_dp -d domain.cn -d *.domain.cn\n\n#run cron job\ndocker run --rm  -it  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --cron\n\n#run cronjob\ndocker run --rm  -itd  \\\n  -v \"$(pwd)/out\":/acme.sh  \\\n  --net=host \\\n  --name=acme.sh \\\n  neilpang/acme.sh daemon\n\n```\n\n## certbot方式获取证书[不推荐]\n\n### 1.获取certbot-auto\n```\nwget https://dl.eff.org/certbot-auto\nchmod a+x certbot-auto\n```\n### 2.开始申请证书\n```\n./certbot-auto --server https://acme-v02.api.letsencrypt.org/directory -d \"*.xxx.com\" -d \"xxx.com\" --manual --preerred-challenges dns-01 certonly\n```\n执行完这一步之后，会下载一些需要的依赖，稍等片刻之后，会提示输入邮箱，随便输入都行【该邮箱用于安全提醒以及续期提醒】,然后提示添加txt记录，带添加完成使用dig验证后回车，生成证书\n/etc/letsencrypt/live/xxx.com/\n\n### 3.续期\n```\n./certbot-auto renew\n```\n\n## nginx证书配置\n```\nserver {\n    server_name xxx.com;\n    listen 443 http2 ssl;\n    ssl on;\n    ssl_certificate /etc/cert/xxx.cn/fullchain.pem;\n    ssl_certificate_key /etc/cert/xxx.cn/privkey.pem;\n    ssl_trusted_certificate  /etc/cert/xxx.cn/chain.pem;\n\n    location / {\n      proxy_pass http://127.0.0.1:6666;\n    }\n}\n```\n\n## 参考\n*  [https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E](https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E)","slug":"2018-09-06-article31-linux-let-ssl","published":1,"updated":"2021-02-09T02:00:24.574Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0l0023yc970re7b3eb","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Let’s-Encrypt通配符HTTPS证书申请\"><a href=\"#Let’s-Encrypt通配符HTTPS证书申请\" class=\"headerlink\" title=\"Let’s Encrypt通配符HTTPS证书申请\"></a>Let’s Encrypt通配符HTTPS证书申请</h1><p>Let’s Encrypt 发布的 ACME v2 现已正式支持通配符证书，下面介绍三种方法申请证书。</p>\n<h2 id=\"使用acme-sh方式\"><a href=\"#使用acme-sh方式\" class=\"headerlink\" title=\"使用acme.sh方式\"></a>使用acme.sh方式</h2><p>acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书.</p>\n<p>主要步骤:</p>\n<ul>\n<li>安装 acme.sh</li>\n<li>生成证书</li>\n<li>copy 证书到 nginx/apache 或者其他服务</li>\n<li>更新证书</li>\n<li>更新 acme.sh</li>\n<li>出错怎么办, 如何调试</li>\n</ul>\n<p>下面详细介绍.</p>\n<h3 id=\"1-安装-acme-sh\"><a href=\"#1-安装-acme-sh\" class=\"headerlink\" title=\"1. 安装 acme.sh\"></a>1. 安装 acme.sh</h3><pre><code>curl  https://get.acme.sh | sh\n</code></pre>\n<ul>\n<li>1）安装目录中: ~/.acme.sh/</li>\n<li><ol start=\"2\">\n<li>自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"2-生成证书\"><a href=\"#2-生成证书\" class=\"headerlink\" title=\"2. 生成证书\"></a>2. 生成证书</h3><p>acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.</p>\n<h4 id=\"1-http-方式\"><a href=\"#1-http-方式\" class=\"headerlink\" title=\"1. http 方式\"></a>1. http 方式</h4><p>方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了.</p>\n<pre><code>acme.sh  --issue  -d mydomain.com -d www.mydomain.com  --webroot  /home/wwwroot/mydomain.com/\n</code></pre>\n<h4 id=\"2-dns-方式\"><a href=\"#2-dns-方式\" class=\"headerlink\" title=\"2. dns 方式\"></a>2. dns 方式</h4><p>在域名上添加一条 txt 解析记录, 验证域名所有权.</p>\n<p>这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。</p>\n<p>其他api：<a href=\"https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md\">https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md</a></p>\n<h5 id=\"手动添加txt记录\"><a href=\"#手动添加txt记录\" class=\"headerlink\" title=\"手动添加txt记录\"></a>手动添加txt记录</h5><p>1.生成txt记录</p>\n<pre><code>acme.sh  --issue  --dns   -d mydomain.com\n</code></pre>\n<p>2.域名管理面板中添加这条 txt 记录即可.</p>\n<p>3.等待验证解析完成之后, 重新生成证书:</p>\n<pre><code>acme.sh  --renew   -d mydomain.com\n</code></pre>\n<h5 id=\"通过api自动添加txt记录\"><a href=\"#通过api自动添加txt记录\" class=\"headerlink\" title=\"通过api自动添加txt记录\"></a>通过api自动添加txt记录</h5><p>以 dnspod 为例, 登录到 dnspod 账号, 生成 api id 和 api key, 然后:</p>\n<pre><code>export DP_Id=&quot;1234&quot;\n\nexport DP_Key=&quot;sADDsdasdgdsf&quot;\n\nacme.sh   --issue   --dns dns_dp   -d aa.com  -d www.aa.com\n</code></pre>\n<h3 id=\"3-copy-安装-证书\"><a href=\"#3-copy-安装-证书\" class=\"headerlink\" title=\"3. copy/安装 证书\"></a>3. copy/安装 证书</h3><p>正确的使用方法是使用 –installcert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如:</p>\n<pre><code>acme.sh  --installcert  -d  &lt;domain&gt;.com   \\\n        --key-file   /etc/nginx/ssl/&lt;domain&gt;.key \\\n        --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n        --reloadcmd  &quot;service nginx force-reload&quot;\n</code></pre>\n<p>Nginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/<domain>.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。</p>\n<p>nginx 配置</p>\n<pre><code>server &#123;\n    server_name www.fuckbb.tk;\n    listen 443 http2 ssl;\n    root /var/www/html;\n\n    ssl on;\n    ssl_certificate /etc/nginx/ssl/fullchain.cer;\n    ssl_certificate_key /etc/nginx/ssl/fuckbb.tk.key;\n    ssl_session_timeout 5m;\n    ssl_protocols  SSLv2 SSLv3 TLSv1;\n    ssl_ciphers  HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;  \n&#125;\n</code></pre>\n<h3 id=\"4-更新证书\"><a href=\"#4-更新证书\" class=\"headerlink\" title=\"4. 更新证书\"></a>4. 更新证书</h3><p>目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.</p>\n<h3 id=\"5-更新-acme-sh\"><a href=\"#5-更新-acme-sh\" class=\"headerlink\" title=\"5. 更新 acme.sh\"></a>5. 更新 acme.sh</h3><p>升级 acme.sh 到最新版 :</p>\n<pre><code>acme.sh --upgrade\n</code></pre>\n<p>开启自动升级:</p>\n<pre><code>acme.sh  --upgrade  --auto-upgrade\n</code></pre>\n<p>关闭自动更新:</p>\n<pre><code>acme.sh --upgrade  --auto-upgrade  0\n</code></pre>\n<h3 id=\"6-出错怎么办：\"><a href=\"#6-出错怎么办：\" class=\"headerlink\" title=\"6. 出错怎么办：\"></a>6. 出错怎么办：</h3><p>如果出错, 请添加 debug log：</p>\n<pre><code>acme.sh  --issue  .....  --debug \n或者：\nacme.sh  --issue  .....  --debug  2\n</code></pre>\n<h2 id=\"采用docker方式\"><a href=\"#采用docker方式\" class=\"headerlink\" title=\"采用docker方式\"></a>采用docker方式</h2><pre><code>#revoke a cert\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --revoke -d example.com\n\n#use dns mode\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  neilpang/acme.sh  --issue --dns -d example.com\n\n#use api-dns mode\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  -e Ali_Key=&quot;xxxxxx&quot; \\\n  -e Ali_Secret=&quot;xxxx&quot; \\\n  neilpang/acme.sh  --issue --dns dns_dp -d domain.cn -d *.domain.cn\n\n#run cron job\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --cron\n\n#run cronjob\ndocker run --rm  -itd  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  --name=acme.sh \\\n  neilpang/acme.sh daemon\n</code></pre>\n<h2 id=\"certbot方式获取证书-不推荐\"><a href=\"#certbot方式获取证书-不推荐\" class=\"headerlink\" title=\"certbot方式获取证书[不推荐]\"></a>certbot方式获取证书[不推荐]</h2><h3 id=\"1-获取certbot-auto\"><a href=\"#1-获取certbot-auto\" class=\"headerlink\" title=\"1.获取certbot-auto\"></a>1.获取certbot-auto</h3><pre><code>wget https://dl.eff.org/certbot-auto\nchmod a+x certbot-auto\n</code></pre>\n<h3 id=\"2-开始申请证书\"><a href=\"#2-开始申请证书\" class=\"headerlink\" title=\"2.开始申请证书\"></a>2.开始申请证书</h3><pre><code>./certbot-auto --server https://acme-v02.api.letsencrypt.org/directory -d &quot;*.xxx.com&quot; -d &quot;xxx.com&quot; --manual --preerred-challenges dns-01 certonly\n</code></pre>\n<p>执行完这一步之后，会下载一些需要的依赖，稍等片刻之后，会提示输入邮箱，随便输入都行【该邮箱用于安全提醒以及续期提醒】,然后提示添加txt记录，带添加完成使用dig验证后回车，生成证书<br>/etc/letsencrypt/live/xxx.com/</p>\n<h3 id=\"3-续期\"><a href=\"#3-续期\" class=\"headerlink\" title=\"3.续期\"></a>3.续期</h3><pre><code>./certbot-auto renew\n</code></pre>\n<h2 id=\"nginx证书配置\"><a href=\"#nginx证书配置\" class=\"headerlink\" title=\"nginx证书配置\"></a>nginx证书配置</h2><pre><code>server &#123;\n    server_name xxx.com;\n    listen 443 http2 ssl;\n    ssl on;\n    ssl_certificate /etc/cert/xxx.cn/fullchain.pem;\n    ssl_certificate_key /etc/cert/xxx.cn/privkey.pem;\n    ssl_trusted_certificate  /etc/cert/xxx.cn/chain.pem;\n\n    location / &#123;\n      proxy_pass http://127.0.0.1:6666;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li> <a href=\"https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E\">https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Let’s-Encrypt通配符HTTPS证书申请\"><a href=\"#Let’s-Encrypt通配符HTTPS证书申请\" class=\"headerlink\" title=\"Let’s Encrypt通配符HTTPS证书申请\"></a>Let’s Encrypt通配符HTTPS证书申请</h1><p>Let’s Encrypt 发布的 ACME v2 现已正式支持通配符证书，下面介绍三种方法申请证书。</p>\n<h2 id=\"使用acme-sh方式\"><a href=\"#使用acme-sh方式\" class=\"headerlink\" title=\"使用acme.sh方式\"></a>使用acme.sh方式</h2><p>acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书.</p>\n<p>主要步骤:</p>\n<ul>\n<li>安装 acme.sh</li>\n<li>生成证书</li>\n<li>copy 证书到 nginx/apache 或者其他服务</li>\n<li>更新证书</li>\n<li>更新 acme.sh</li>\n<li>出错怎么办, 如何调试</li>\n</ul>\n<p>下面详细介绍.</p>\n<h3 id=\"1-安装-acme-sh\"><a href=\"#1-安装-acme-sh\" class=\"headerlink\" title=\"1. 安装 acme.sh\"></a>1. 安装 acme.sh</h3><pre><code>curl  https://get.acme.sh | sh\n</code></pre>\n<ul>\n<li>1）安装目录中: ~/.acme.sh/</li>\n<li><ol start=\"2\">\n<li>自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"2-生成证书\"><a href=\"#2-生成证书\" class=\"headerlink\" title=\"2. 生成证书\"></a>2. 生成证书</h3><p>acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.</p>\n<h4 id=\"1-http-方式\"><a href=\"#1-http-方式\" class=\"headerlink\" title=\"1. http 方式\"></a>1. http 方式</h4><p>方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了.</p>\n<pre><code>acme.sh  --issue  -d mydomain.com -d www.mydomain.com  --webroot  /home/wwwroot/mydomain.com/\n</code></pre>\n<h4 id=\"2-dns-方式\"><a href=\"#2-dns-方式\" class=\"headerlink\" title=\"2. dns 方式\"></a>2. dns 方式</h4><p>在域名上添加一条 txt 解析记录, 验证域名所有权.</p>\n<p>这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。</p>\n<p>其他api：<a href=\"https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md\">https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md</a></p>\n<h5 id=\"手动添加txt记录\"><a href=\"#手动添加txt记录\" class=\"headerlink\" title=\"手动添加txt记录\"></a>手动添加txt记录</h5><p>1.生成txt记录</p>\n<pre><code>acme.sh  --issue  --dns   -d mydomain.com\n</code></pre>\n<p>2.域名管理面板中添加这条 txt 记录即可.</p>\n<p>3.等待验证解析完成之后, 重新生成证书:</p>\n<pre><code>acme.sh  --renew   -d mydomain.com\n</code></pre>\n<h5 id=\"通过api自动添加txt记录\"><a href=\"#通过api自动添加txt记录\" class=\"headerlink\" title=\"通过api自动添加txt记录\"></a>通过api自动添加txt记录</h5><p>以 dnspod 为例, 登录到 dnspod 账号, 生成 api id 和 api key, 然后:</p>\n<pre><code>export DP_Id=&quot;1234&quot;\n\nexport DP_Key=&quot;sADDsdasdgdsf&quot;\n\nacme.sh   --issue   --dns dns_dp   -d aa.com  -d www.aa.com\n</code></pre>\n<h3 id=\"3-copy-安装-证书\"><a href=\"#3-copy-安装-证书\" class=\"headerlink\" title=\"3. copy/安装 证书\"></a>3. copy/安装 证书</h3><p>正确的使用方法是使用 –installcert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如:</p>\n<pre><code>acme.sh  --installcert  -d  &lt;domain&gt;.com   \\\n        --key-file   /etc/nginx/ssl/&lt;domain&gt;.key \\\n        --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n        --reloadcmd  &quot;service nginx force-reload&quot;\n</code></pre>\n<p>Nginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/<domain>.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。</p>\n<p>nginx 配置</p>\n<pre><code>server &#123;\n    server_name www.fuckbb.tk;\n    listen 443 http2 ssl;\n    root /var/www/html;\n\n    ssl on;\n    ssl_certificate /etc/nginx/ssl/fullchain.cer;\n    ssl_certificate_key /etc/nginx/ssl/fuckbb.tk.key;\n    ssl_session_timeout 5m;\n    ssl_protocols  SSLv2 SSLv3 TLSv1;\n    ssl_ciphers  HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;  \n&#125;\n</code></pre>\n<h3 id=\"4-更新证书\"><a href=\"#4-更新证书\" class=\"headerlink\" title=\"4. 更新证书\"></a>4. 更新证书</h3><p>目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.</p>\n<h3 id=\"5-更新-acme-sh\"><a href=\"#5-更新-acme-sh\" class=\"headerlink\" title=\"5. 更新 acme.sh\"></a>5. 更新 acme.sh</h3><p>升级 acme.sh 到最新版 :</p>\n<pre><code>acme.sh --upgrade\n</code></pre>\n<p>开启自动升级:</p>\n<pre><code>acme.sh  --upgrade  --auto-upgrade\n</code></pre>\n<p>关闭自动更新:</p>\n<pre><code>acme.sh --upgrade  --auto-upgrade  0\n</code></pre>\n<h3 id=\"6-出错怎么办：\"><a href=\"#6-出错怎么办：\" class=\"headerlink\" title=\"6. 出错怎么办：\"></a>6. 出错怎么办：</h3><p>如果出错, 请添加 debug log：</p>\n<pre><code>acme.sh  --issue  .....  --debug \n或者：\nacme.sh  --issue  .....  --debug  2\n</code></pre>\n<h2 id=\"采用docker方式\"><a href=\"#采用docker方式\" class=\"headerlink\" title=\"采用docker方式\"></a>采用docker方式</h2><pre><code>#revoke a cert\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --revoke -d example.com\n\n#use dns mode\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  neilpang/acme.sh  --issue --dns -d example.com\n\n#use api-dns mode\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  -e Ali_Key=&quot;xxxxxx&quot; \\\n  -e Ali_Secret=&quot;xxxx&quot; \\\n  neilpang/acme.sh  --issue --dns dns_dp -d domain.cn -d *.domain.cn\n\n#run cron job\ndocker run --rm  -it  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  neilpang/acme.sh  --cron\n\n#run cronjob\ndocker run --rm  -itd  \\\n  -v &quot;$(pwd)/out&quot;:/acme.sh  \\\n  --net=host \\\n  --name=acme.sh \\\n  neilpang/acme.sh daemon\n</code></pre>\n<h2 id=\"certbot方式获取证书-不推荐\"><a href=\"#certbot方式获取证书-不推荐\" class=\"headerlink\" title=\"certbot方式获取证书[不推荐]\"></a>certbot方式获取证书[不推荐]</h2><h3 id=\"1-获取certbot-auto\"><a href=\"#1-获取certbot-auto\" class=\"headerlink\" title=\"1.获取certbot-auto\"></a>1.获取certbot-auto</h3><pre><code>wget https://dl.eff.org/certbot-auto\nchmod a+x certbot-auto\n</code></pre>\n<h3 id=\"2-开始申请证书\"><a href=\"#2-开始申请证书\" class=\"headerlink\" title=\"2.开始申请证书\"></a>2.开始申请证书</h3><pre><code>./certbot-auto --server https://acme-v02.api.letsencrypt.org/directory -d &quot;*.xxx.com&quot; -d &quot;xxx.com&quot; --manual --preerred-challenges dns-01 certonly\n</code></pre>\n<p>执行完这一步之后，会下载一些需要的依赖，稍等片刻之后，会提示输入邮箱，随便输入都行【该邮箱用于安全提醒以及续期提醒】,然后提示添加txt记录，带添加完成使用dig验证后回车，生成证书<br>/etc/letsencrypt/live/xxx.com/</p>\n<h3 id=\"3-续期\"><a href=\"#3-续期\" class=\"headerlink\" title=\"3.续期\"></a>3.续期</h3><pre><code>./certbot-auto renew\n</code></pre>\n<h2 id=\"nginx证书配置\"><a href=\"#nginx证书配置\" class=\"headerlink\" title=\"nginx证书配置\"></a>nginx证书配置</h2><pre><code>server &#123;\n    server_name xxx.com;\n    listen 443 http2 ssl;\n    ssl on;\n    ssl_certificate /etc/cert/xxx.cn/fullchain.pem;\n    ssl_certificate_key /etc/cert/xxx.cn/privkey.pem;\n    ssl_trusted_certificate  /etc/cert/xxx.cn/chain.pem;\n\n    location / &#123;\n      proxy_pass http://127.0.0.1:6666;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li> <a href=\"https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E\">https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E</a></li>\n</ul>\n"},{"layout":"post","title":"linux shell中&>file,2>&1,1>&2区别","date":"2018-09-10T10:29:54.000Z","author":"owelinux","excerpt":"linux shell中&>file,2>&1,1>&2区别","mathjax":true,"_content":"\n* content\n{:toc}\n\n# linux shell中&>file,2>&1,1>&2区别\n\nshell中几个定义：\n\n* 0：表示标准输入\n\n* 1：表示标准输出\n\n* 2：表示标准错误输出\n* >：默认为标准输出重定向，与1>相同（替换）\n* >>：表示标准输出重定向（追加）\n* 2>&1：表示把标准错误输出 重定向到标准输出\n* &>file：表示把标准输出和标准错误输出 都重定向到文件file中 \n\n举例：\n\n替换：\n```\ngrep \"aaa\" filename > a.log\n```\n\n追加：\n```\ngrep \"bbb\" filename >>b.log\n```\n\n2>&1:\n```\ngrep \"error\" filename >/dev/null 2>&1\n等价于\ngrep \"error\" filename >/dev/null 2>/dev/null\n```\n\n&>file:\n```\ngrep \"error\" filename >/dev/null \n等价于\ngrep \"error\" filename >/dev/null 2>/dev/null\n```","source":"_posts/2018-09-10-article32-linux-1.md","raw":"---\nlayout: post\ntitle:  \"linux shell中&>file,2>&1,1>&2区别\"\ndate:   2018-09-10 18:29:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: linux shell中&>file,2>&1,1>&2区别\nmathjax: true\n---\n\n* content\n{:toc}\n\n# linux shell中&>file,2>&1,1>&2区别\n\nshell中几个定义：\n\n* 0：表示标准输入\n\n* 1：表示标准输出\n\n* 2：表示标准错误输出\n* >：默认为标准输出重定向，与1>相同（替换）\n* >>：表示标准输出重定向（追加）\n* 2>&1：表示把标准错误输出 重定向到标准输出\n* &>file：表示把标准输出和标准错误输出 都重定向到文件file中 \n\n举例：\n\n替换：\n```\ngrep \"aaa\" filename > a.log\n```\n\n追加：\n```\ngrep \"bbb\" filename >>b.log\n```\n\n2>&1:\n```\ngrep \"error\" filename >/dev/null 2>&1\n等价于\ngrep \"error\" filename >/dev/null 2>/dev/null\n```\n\n&>file:\n```\ngrep \"error\" filename >/dev/null \n等价于\ngrep \"error\" filename >/dev/null 2>/dev/null\n```","slug":"2018-09-10-article32-linux-1","published":1,"updated":"2021-02-09T02:00:24.574Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0n0027yc97haes0eod","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-shell中-amp-gt-file-2-gt-amp-1-1-gt-amp-2区别\"><a href=\"#linux-shell中-amp-gt-file-2-gt-amp-1-1-gt-amp-2区别\" class=\"headerlink\" title=\"linux shell中&amp;&gt;file,2&gt;&amp;1,1&gt;&amp;2区别\"></a>linux shell中&amp;&gt;file,2&gt;&amp;1,1&gt;&amp;2区别</h1><p>shell中几个定义：</p>\n<ul>\n<li><p>0：表示标准输入</p>\n</li>\n<li><p>1：表示标准输出</p>\n</li>\n<li><p>2：表示标准错误输出</p>\n</li>\n<li><blockquote>\n<p>：默认为标准输出重定向，与1&gt;相同（替换）</p>\n</blockquote>\n</li>\n<li><blockquote>\n<blockquote>\n<p>：表示标准输出重定向（追加）</p>\n</blockquote>\n</blockquote>\n</li>\n<li><p>2&gt;&amp;1：表示把标准错误输出 重定向到标准输出</p>\n</li>\n<li><p>&amp;&gt;file：表示把标准输出和标准错误输出 都重定向到文件file中 </p>\n</li>\n</ul>\n<p>举例：</p>\n<p>替换：</p>\n<pre><code>grep &quot;aaa&quot; filename &gt; a.log\n</code></pre>\n<p>追加：</p>\n<pre><code>grep &quot;bbb&quot; filename &gt;&gt;b.log\n</code></pre>\n<p>2&gt;&amp;1:</p>\n<pre><code>grep &quot;error&quot; filename &gt;/dev/null 2&gt;&amp;1\n等价于\ngrep &quot;error&quot; filename &gt;/dev/null 2&gt;/dev/null\n</code></pre>\n<p>&amp;&gt;file:</p>\n<pre><code>grep &quot;error&quot; filename &gt;/dev/null \n等价于\ngrep &quot;error&quot; filename &gt;/dev/null 2&gt;/dev/null\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-shell中-amp-gt-file-2-gt-amp-1-1-gt-amp-2区别\"><a href=\"#linux-shell中-amp-gt-file-2-gt-amp-1-1-gt-amp-2区别\" class=\"headerlink\" title=\"linux shell中&amp;&gt;file,2&gt;&amp;1,1&gt;&amp;2区别\"></a>linux shell中&amp;&gt;file,2&gt;&amp;1,1&gt;&amp;2区别</h1><p>shell中几个定义：</p>\n<ul>\n<li><p>0：表示标准输入</p>\n</li>\n<li><p>1：表示标准输出</p>\n</li>\n<li><p>2：表示标准错误输出</p>\n</li>\n<li><blockquote>\n<p>：默认为标准输出重定向，与1&gt;相同（替换）</p>\n</blockquote>\n</li>\n<li><blockquote>\n<blockquote>\n<p>：表示标准输出重定向（追加）</p>\n</blockquote>\n</blockquote>\n</li>\n<li><p>2&gt;&amp;1：表示把标准错误输出 重定向到标准输出</p>\n</li>\n<li><p>&amp;&gt;file：表示把标准输出和标准错误输出 都重定向到文件file中 </p>\n</li>\n</ul>\n<p>举例：</p>\n<p>替换：</p>\n<pre><code>grep &quot;aaa&quot; filename &gt; a.log\n</code></pre>\n<p>追加：</p>\n<pre><code>grep &quot;bbb&quot; filename &gt;&gt;b.log\n</code></pre>\n<p>2&gt;&amp;1:</p>\n<pre><code>grep &quot;error&quot; filename &gt;/dev/null 2&gt;&amp;1\n等价于\ngrep &quot;error&quot; filename &gt;/dev/null 2&gt;/dev/null\n</code></pre>\n<p>&amp;&gt;file:</p>\n<pre><code>grep &quot;error&quot; filename &gt;/dev/null \n等价于\ngrep &quot;error&quot; filename &gt;/dev/null 2&gt;/dev/null\n</code></pre>\n"},{"layout":"post","title":"linux 系统时区更改","date":"2018-09-10T10:29:54.000Z","author":"owelinux","excerpt":"linux 系统时区更改","mathjax":true,"_content":"\n* content\n{:toc}\n\n# linux 系统时区更改\n\n方法一：\n\n``` \ntzselect\n```\n\n方法二: 仅限于RedHat Linux 和 CentOS系统 \n```\ntimeconfig\n```\n\n方法三: 适用于Debian\n``` \ndpkg-reconfigure tzdata\n```\n\n方法四: 复制相应的时区文件，替换CentOS系统时区文件；或者创建链接文件 \n```\ncp /usr/share/zoneinfo/EST5EDT /etc/localtime \n或者 \nln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n时间同步 \nyum instlal ntp -y\n加入crontab \n* * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP\n```\n\n时间服务器地址：\n[https://www.ntppool.org/zone](https://www.ntppool.org/zone)","source":"_posts/2018-09-10-article33-linux-2.md","raw":"---\nlayout: post\ntitle:  \"linux 系统时区更改\"\ndate:   2018-09-10 18:29:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: linux 系统时区更改\nmathjax: true\n---\n\n* content\n{:toc}\n\n# linux 系统时区更改\n\n方法一：\n\n``` \ntzselect\n```\n\n方法二: 仅限于RedHat Linux 和 CentOS系统 \n```\ntimeconfig\n```\n\n方法三: 适用于Debian\n``` \ndpkg-reconfigure tzdata\n```\n\n方法四: 复制相应的时区文件，替换CentOS系统时区文件；或者创建链接文件 \n```\ncp /usr/share/zoneinfo/EST5EDT /etc/localtime \n或者 \nln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n时间同步 \nyum instlal ntp -y\n加入crontab \n* * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP\n```\n\n时间服务器地址：\n[https://www.ntppool.org/zone](https://www.ntppool.org/zone)","slug":"2018-09-10-article33-linux-2","published":1,"updated":"2021-02-09T02:00:24.575Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0o0029yc975bz1fcie","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-系统时区更改\"><a href=\"#linux-系统时区更改\" class=\"headerlink\" title=\"linux 系统时区更改\"></a>linux 系统时区更改</h1><p>方法一：</p>\n<pre><code>tzselect\n</code></pre>\n<p>方法二: 仅限于RedHat Linux 和 CentOS系统 </p>\n<pre><code>timeconfig\n</code></pre>\n<p>方法三: 适用于Debian</p>\n<pre><code>dpkg-reconfigure tzdata\n</code></pre>\n<p>方法四: 复制相应的时区文件，替换CentOS系统时区文件；或者创建链接文件 </p>\n<pre><code>cp /usr/share/zoneinfo/EST5EDT /etc/localtime \n或者 \nln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n时间同步 \nyum instlal ntp -y\n加入crontab \n* * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP\n</code></pre>\n<p>时间服务器地址：<br><a href=\"https://www.ntppool.org/zone\">https://www.ntppool.org/zone</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-系统时区更改\"><a href=\"#linux-系统时区更改\" class=\"headerlink\" title=\"linux 系统时区更改\"></a>linux 系统时区更改</h1><p>方法一：</p>\n<pre><code>tzselect\n</code></pre>\n<p>方法二: 仅限于RedHat Linux 和 CentOS系统 </p>\n<pre><code>timeconfig\n</code></pre>\n<p>方法三: 适用于Debian</p>\n<pre><code>dpkg-reconfigure tzdata\n</code></pre>\n<p>方法四: 复制相应的时区文件，替换CentOS系统时区文件；或者创建链接文件 </p>\n<pre><code>cp /usr/share/zoneinfo/EST5EDT /etc/localtime \n或者 \nln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n时间同步 \nyum instlal ntp -y\n加入crontab \n* * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP\n</code></pre>\n<p>时间服务器地址：<br><a href=\"https://www.ntppool.org/zone\">https://www.ntppool.org/zone</a></p>\n"},{"layout":"post","title":"linux 根据进程/端口排错","date":"2018-09-10T10:29:54.000Z","author":"owelinux","excerpt":"linux 根据进程/端口排错","mathjax":true,"_content":"\n* content\n{:toc}\n\n# linux 根据进程/端口排错\n\n## linux根据进程号PID查找启动程序的全路径\n\n获取进程号\n``` \nps -ef| grep 'pidname'\n```\n\n根据进程查找路径\n```\nls -ail /proc/pid/\n```\n\n## 根据端口号查找到进程占用\na.\n``` \nlsof -i:port\n```\nb.\n```\nnetstat -lntp | grep 'port'\n```\n\n## 根据服务名查找端口占用\n```\npgrep -f nginx\n```","source":"_posts/2018-09-10-article34-linux-3.md","raw":"---\nlayout: post\ntitle:  \"linux 根据进程/端口排错\"\ndate:   2018-09-10 18:29:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: linux 根据进程/端口排错\nmathjax: true\n---\n\n* content\n{:toc}\n\n# linux 根据进程/端口排错\n\n## linux根据进程号PID查找启动程序的全路径\n\n获取进程号\n``` \nps -ef| grep 'pidname'\n```\n\n根据进程查找路径\n```\nls -ail /proc/pid/\n```\n\n## 根据端口号查找到进程占用\na.\n``` \nlsof -i:port\n```\nb.\n```\nnetstat -lntp | grep 'port'\n```\n\n## 根据服务名查找端口占用\n```\npgrep -f nginx\n```","slug":"2018-09-10-article34-linux-3","published":1,"updated":"2021-02-09T02:00:24.575Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0p002dyc9749r9fw5y","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-根据进程-端口排错\"><a href=\"#linux-根据进程-端口排错\" class=\"headerlink\" title=\"linux 根据进程/端口排错\"></a>linux 根据进程/端口排错</h1><h2 id=\"linux根据进程号PID查找启动程序的全路径\"><a href=\"#linux根据进程号PID查找启动程序的全路径\" class=\"headerlink\" title=\"linux根据进程号PID查找启动程序的全路径\"></a>linux根据进程号PID查找启动程序的全路径</h2><p>获取进程号</p>\n<pre><code>ps -ef| grep &#39;pidname&#39;\n</code></pre>\n<p>根据进程查找路径</p>\n<pre><code>ls -ail /proc/pid/\n</code></pre>\n<h2 id=\"根据端口号查找到进程占用\"><a href=\"#根据端口号查找到进程占用\" class=\"headerlink\" title=\"根据端口号查找到进程占用\"></a>根据端口号查找到进程占用</h2><p>a.</p>\n<pre><code>lsof -i:port\n</code></pre>\n<p>b.</p>\n<pre><code>netstat -lntp | grep &#39;port&#39;\n</code></pre>\n<h2 id=\"根据服务名查找端口占用\"><a href=\"#根据服务名查找端口占用\" class=\"headerlink\" title=\"根据服务名查找端口占用\"></a>根据服务名查找端口占用</h2><pre><code>pgrep -f nginx\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"linux-根据进程-端口排错\"><a href=\"#linux-根据进程-端口排错\" class=\"headerlink\" title=\"linux 根据进程/端口排错\"></a>linux 根据进程/端口排错</h1><h2 id=\"linux根据进程号PID查找启动程序的全路径\"><a href=\"#linux根据进程号PID查找启动程序的全路径\" class=\"headerlink\" title=\"linux根据进程号PID查找启动程序的全路径\"></a>linux根据进程号PID查找启动程序的全路径</h2><p>获取进程号</p>\n<pre><code>ps -ef| grep &#39;pidname&#39;\n</code></pre>\n<p>根据进程查找路径</p>\n<pre><code>ls -ail /proc/pid/\n</code></pre>\n<h2 id=\"根据端口号查找到进程占用\"><a href=\"#根据端口号查找到进程占用\" class=\"headerlink\" title=\"根据端口号查找到进程占用\"></a>根据端口号查找到进程占用</h2><p>a.</p>\n<pre><code>lsof -i:port\n</code></pre>\n<p>b.</p>\n<pre><code>netstat -lntp | grep &#39;port&#39;\n</code></pre>\n<h2 id=\"根据服务名查找端口占用\"><a href=\"#根据服务名查找端口占用\" class=\"headerlink\" title=\"根据服务名查找端口占用\"></a>根据服务名查找端口占用</h2><pre><code>pgrep -f nginx\n</code></pre>\n"},{"layout":"post","title":"Docker 系列01-docker安装","date":"2018-09-12T10:29:54.000Z","author":"owelinux","excerpt":"Docker 系列01-docker安装","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Docker 系列01-docker安装\n\nDocker 提供了两个版本：社区版 (CE) 和企业版 (EE)。\n\nDocker 社区版 (CE) 是开发人员和小型团队开始使用 Docker 并尝试使用基于容器的应用的理想之选。Docker CE 有两个更新渠道，即 stable 和 edge：\n\n* Stable 每个季度为您提供可靠更新\n* Edge 每个月为您提供新功能\n\n## 支持平台\n\nDocker CE 和 EE 可用于多种平台、云和内部部署。使用下表选择适用于您的最佳安装路径。\n\n### 桌面\n* Mac\t \n* Windows\t\n \t \n### 云\n\n* Amazon\n* Microsoft\n* Digital Ocean\n* Packet\n* SoftLink\n* 使用docker云代理创建自己的主机\n\n### 服务器\n\n* CentOS\n* Debian\t\n* Fedora\t\t \n* Microsoft Windows\n* Oracle Linux\n* Red Hat\n* SUSE\n\n## centos安装docker ce\n\n### 操作系统要求\n\n如需安装 Docker CE，您需要 64 位版本的 CentOS 7。\n\n### 卸载旧版本\nDocker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。\n```\n$ sudo yum remove docker \\\n                  docker-common \\\n                  docker-selinux \\\n                  docker-engine\n```\n\n将保留 /var/lib/docker/ 的内容，包括镜像、容器、存储卷和网络。Docker CE 软件包现在称为 docker-ce。\n\n### 安装 Docker CE\n您可以通过不同方式安装 Docker CE，具体取决于您的需求：\n\n* Docker 的镜像仓库安装(推荐方法。)\n\n* RPM 软件包并手动进行安装\n\n#### 使用yum进行安装\n```\n $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n $ sudo yum-config-manager \\\n     --add-repo \\\n     https://download.docker.com/linux/centos/docker-ce.repo\n $ sudo yum makecache fast\n $ sudo yum install docker-ce\n $ sudo systemctl start docker\n```\n\n如需要edge版本，使用以下开启\n```\n $ sudo yum-config-manager --enable docker-ce-edge (默认关闭)\n $ sudo yum-config-manager --enable docker-ce-testing (默认关闭)\n```\n\n安装特定版本：\n```\n $ yum list docker-ce.x86_64  --showduplicates | sort -r\n\n $ sudo yum install docker-ce-<VERSION>\n启动 Docker。\n```\n\n#### rpm方式进行安装\n```\n $ wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-<VERSION>.rpm\n $ sudo yum install /path/to/package.rpm\n $ sudo systemctl start docker\n```\n\n#### 二进制方式安装\n```\n $ wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.1-ce.tgz\n $ tar -zxvf docker-18.06.1-ce.tgz\n $ cp docker/docker /usr/bin/docker\n $ service docker restart\n $ service docker status \n $ systemctl enable docker\n $ docker version\n```\n### 升级 DOCKER CE\n```\n $ yum -y upgrade \n```\n\n### 卸载 Docker CE\n```\n $ sudo yum remove docker-ce\n $ sudo rm -rf /var/lib/docker\n```\n\n## linux安装后步骤\n\n### 以非root用户管理docker\n```\n $ groupadd docker\n $ usermod -aG dockere $USER\n```\n\n### docker开启自启动\n```\ncentos7:\n $ systemctl enable docker\n\ncentos6:\n $ chkconfig docker on\n```\n### 开启ip转发\n```\n $ sysctl -w net.ipv4.ip_forward=1\n $ vim /etc/sysctl.conf\n   net.ipv4.ip_forward = 1\n```\n### 指定dns服务器\n```\n $ vim /etc/docker/daemon.json\n   {\n    \t\"dns\":[\"8.8.8.8\", \"8.8.4.4\"]\n   }\n $ sudo service docker restart\n```\n\n# 参考\n* [https://docs.docker-cn.com](https://docs.docker-cn.com)\n* [http://www.dockerinfo.net/document](http://www.dockerinfo.net/document)","source":"_posts/2018-09-12-article35-linux-docker-01.md","raw":"---\nlayout: post\ntitle:  \"Docker 系列01-docker安装\"\ndate:   2018-09-12 18:29:54\nauthor: owelinux\ncategories: linux 容器与虚拟化\ntags:  linux  docker\nexcerpt: Docker 系列01-docker安装\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Docker 系列01-docker安装\n\nDocker 提供了两个版本：社区版 (CE) 和企业版 (EE)。\n\nDocker 社区版 (CE) 是开发人员和小型团队开始使用 Docker 并尝试使用基于容器的应用的理想之选。Docker CE 有两个更新渠道，即 stable 和 edge：\n\n* Stable 每个季度为您提供可靠更新\n* Edge 每个月为您提供新功能\n\n## 支持平台\n\nDocker CE 和 EE 可用于多种平台、云和内部部署。使用下表选择适用于您的最佳安装路径。\n\n### 桌面\n* Mac\t \n* Windows\t\n \t \n### 云\n\n* Amazon\n* Microsoft\n* Digital Ocean\n* Packet\n* SoftLink\n* 使用docker云代理创建自己的主机\n\n### 服务器\n\n* CentOS\n* Debian\t\n* Fedora\t\t \n* Microsoft Windows\n* Oracle Linux\n* Red Hat\n* SUSE\n\n## centos安装docker ce\n\n### 操作系统要求\n\n如需安装 Docker CE，您需要 64 位版本的 CentOS 7。\n\n### 卸载旧版本\nDocker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。\n```\n$ sudo yum remove docker \\\n                  docker-common \\\n                  docker-selinux \\\n                  docker-engine\n```\n\n将保留 /var/lib/docker/ 的内容，包括镜像、容器、存储卷和网络。Docker CE 软件包现在称为 docker-ce。\n\n### 安装 Docker CE\n您可以通过不同方式安装 Docker CE，具体取决于您的需求：\n\n* Docker 的镜像仓库安装(推荐方法。)\n\n* RPM 软件包并手动进行安装\n\n#### 使用yum进行安装\n```\n $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n $ sudo yum-config-manager \\\n     --add-repo \\\n     https://download.docker.com/linux/centos/docker-ce.repo\n $ sudo yum makecache fast\n $ sudo yum install docker-ce\n $ sudo systemctl start docker\n```\n\n如需要edge版本，使用以下开启\n```\n $ sudo yum-config-manager --enable docker-ce-edge (默认关闭)\n $ sudo yum-config-manager --enable docker-ce-testing (默认关闭)\n```\n\n安装特定版本：\n```\n $ yum list docker-ce.x86_64  --showduplicates | sort -r\n\n $ sudo yum install docker-ce-<VERSION>\n启动 Docker。\n```\n\n#### rpm方式进行安装\n```\n $ wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-<VERSION>.rpm\n $ sudo yum install /path/to/package.rpm\n $ sudo systemctl start docker\n```\n\n#### 二进制方式安装\n```\n $ wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.1-ce.tgz\n $ tar -zxvf docker-18.06.1-ce.tgz\n $ cp docker/docker /usr/bin/docker\n $ service docker restart\n $ service docker status \n $ systemctl enable docker\n $ docker version\n```\n### 升级 DOCKER CE\n```\n $ yum -y upgrade \n```\n\n### 卸载 Docker CE\n```\n $ sudo yum remove docker-ce\n $ sudo rm -rf /var/lib/docker\n```\n\n## linux安装后步骤\n\n### 以非root用户管理docker\n```\n $ groupadd docker\n $ usermod -aG dockere $USER\n```\n\n### docker开启自启动\n```\ncentos7:\n $ systemctl enable docker\n\ncentos6:\n $ chkconfig docker on\n```\n### 开启ip转发\n```\n $ sysctl -w net.ipv4.ip_forward=1\n $ vim /etc/sysctl.conf\n   net.ipv4.ip_forward = 1\n```\n### 指定dns服务器\n```\n $ vim /etc/docker/daemon.json\n   {\n    \t\"dns\":[\"8.8.8.8\", \"8.8.4.4\"]\n   }\n $ sudo service docker restart\n```\n\n# 参考\n* [https://docs.docker-cn.com](https://docs.docker-cn.com)\n* [http://www.dockerinfo.net/document](http://www.dockerinfo.net/document)","slug":"2018-09-12-article35-linux-docker-01","published":1,"updated":"2021-02-09T02:00:24.576Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0q002gyc9740jz5vst","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-系列01-docker安装\"><a href=\"#Docker-系列01-docker安装\" class=\"headerlink\" title=\"Docker 系列01-docker安装\"></a>Docker 系列01-docker安装</h1><p>Docker 提供了两个版本：社区版 (CE) 和企业版 (EE)。</p>\n<p>Docker 社区版 (CE) 是开发人员和小型团队开始使用 Docker 并尝试使用基于容器的应用的理想之选。Docker CE 有两个更新渠道，即 stable 和 edge：</p>\n<ul>\n<li>Stable 每个季度为您提供可靠更新</li>\n<li>Edge 每个月为您提供新功能</li>\n</ul>\n<h2 id=\"支持平台\"><a href=\"#支持平台\" class=\"headerlink\" title=\"支持平台\"></a>支持平台</h2><p>Docker CE 和 EE 可用于多种平台、云和内部部署。使用下表选择适用于您的最佳安装路径。</p>\n<h3 id=\"桌面\"><a href=\"#桌面\" class=\"headerlink\" title=\"桌面\"></a>桌面</h3><ul>\n<li><p>Mac     </p>\n</li>\n<li><p>Windows    </p>\n<h3 id=\"云\"><a href=\"#云\" class=\"headerlink\" title=\"云\"></a>云</h3></li>\n<li><p>Amazon</p>\n</li>\n<li><p>Microsoft</p>\n</li>\n<li><p>Digital Ocean</p>\n</li>\n<li><p>Packet</p>\n</li>\n<li><p>SoftLink</p>\n</li>\n<li><p>使用docker云代理创建自己的主机</p>\n</li>\n</ul>\n<h3 id=\"服务器\"><a href=\"#服务器\" class=\"headerlink\" title=\"服务器\"></a>服务器</h3><ul>\n<li>CentOS</li>\n<li>Debian    </li>\n<li>Fedora         </li>\n<li>Microsoft Windows</li>\n<li>Oracle Linux</li>\n<li>Red Hat</li>\n<li>SUSE</li>\n</ul>\n<h2 id=\"centos安装docker-ce\"><a href=\"#centos安装docker-ce\" class=\"headerlink\" title=\"centos安装docker ce\"></a>centos安装docker ce</h2><h3 id=\"操作系统要求\"><a href=\"#操作系统要求\" class=\"headerlink\" title=\"操作系统要求\"></a>操作系统要求</h3><p>如需安装 Docker CE，您需要 64 位版本的 CentOS 7。</p>\n<h3 id=\"卸载旧版本\"><a href=\"#卸载旧版本\" class=\"headerlink\" title=\"卸载旧版本\"></a>卸载旧版本</h3><p>Docker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。</p>\n<pre><code>$ sudo yum remove docker \\\n                  docker-common \\\n                  docker-selinux \\\n                  docker-engine\n</code></pre>\n<p>将保留 /var/lib/docker/ 的内容，包括镜像、容器、存储卷和网络。Docker CE 软件包现在称为 docker-ce。</p>\n<h3 id=\"安装-Docker-CE\"><a href=\"#安装-Docker-CE\" class=\"headerlink\" title=\"安装 Docker CE\"></a>安装 Docker CE</h3><p>您可以通过不同方式安装 Docker CE，具体取决于您的需求：</p>\n<ul>\n<li><p>Docker 的镜像仓库安装(推荐方法。)</p>\n</li>\n<li><p>RPM 软件包并手动进行安装</p>\n</li>\n</ul>\n<h4 id=\"使用yum进行安装\"><a href=\"#使用yum进行安装\" class=\"headerlink\" title=\"使用yum进行安装\"></a>使用yum进行安装</h4><pre><code> $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n $ sudo yum-config-manager \\\n     --add-repo \\\n     https://download.docker.com/linux/centos/docker-ce.repo\n $ sudo yum makecache fast\n $ sudo yum install docker-ce\n $ sudo systemctl start docker\n</code></pre>\n<p>如需要edge版本，使用以下开启</p>\n<pre><code> $ sudo yum-config-manager --enable docker-ce-edge (默认关闭)\n $ sudo yum-config-manager --enable docker-ce-testing (默认关闭)\n</code></pre>\n<p>安装特定版本：</p>\n<pre><code> $ yum list docker-ce.x86_64  --showduplicates | sort -r\n\n $ sudo yum install docker-ce-&lt;VERSION&gt;\n启动 Docker。\n</code></pre>\n<h4 id=\"rpm方式进行安装\"><a href=\"#rpm方式进行安装\" class=\"headerlink\" title=\"rpm方式进行安装\"></a>rpm方式进行安装</h4><pre><code> $ wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-&lt;VERSION&gt;.rpm\n $ sudo yum install /path/to/package.rpm\n $ sudo systemctl start docker\n</code></pre>\n<h4 id=\"二进制方式安装\"><a href=\"#二进制方式安装\" class=\"headerlink\" title=\"二进制方式安装\"></a>二进制方式安装</h4><pre><code> $ wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.1-ce.tgz\n $ tar -zxvf docker-18.06.1-ce.tgz\n $ cp docker/docker /usr/bin/docker\n $ service docker restart\n $ service docker status \n $ systemctl enable docker\n $ docker version\n</code></pre>\n<h3 id=\"升级-DOCKER-CE\"><a href=\"#升级-DOCKER-CE\" class=\"headerlink\" title=\"升级 DOCKER CE\"></a>升级 DOCKER CE</h3><pre><code> $ yum -y upgrade \n</code></pre>\n<h3 id=\"卸载-Docker-CE\"><a href=\"#卸载-Docker-CE\" class=\"headerlink\" title=\"卸载 Docker CE\"></a>卸载 Docker CE</h3><pre><code> $ sudo yum remove docker-ce\n $ sudo rm -rf /var/lib/docker\n</code></pre>\n<h2 id=\"linux安装后步骤\"><a href=\"#linux安装后步骤\" class=\"headerlink\" title=\"linux安装后步骤\"></a>linux安装后步骤</h2><h3 id=\"以非root用户管理docker\"><a href=\"#以非root用户管理docker\" class=\"headerlink\" title=\"以非root用户管理docker\"></a>以非root用户管理docker</h3><pre><code> $ groupadd docker\n $ usermod -aG dockere $USER\n</code></pre>\n<h3 id=\"docker开启自启动\"><a href=\"#docker开启自启动\" class=\"headerlink\" title=\"docker开启自启动\"></a>docker开启自启动</h3><pre><code>centos7:\n $ systemctl enable docker\n\ncentos6:\n $ chkconfig docker on\n</code></pre>\n<h3 id=\"开启ip转发\"><a href=\"#开启ip转发\" class=\"headerlink\" title=\"开启ip转发\"></a>开启ip转发</h3><pre><code> $ sysctl -w net.ipv4.ip_forward=1\n $ vim /etc/sysctl.conf\n   net.ipv4.ip_forward = 1\n</code></pre>\n<h3 id=\"指定dns服务器\"><a href=\"#指定dns服务器\" class=\"headerlink\" title=\"指定dns服务器\"></a>指定dns服务器</h3><pre><code> $ vim /etc/docker/daemon.json\n   &#123;\n        &quot;dns&quot;:[&quot;8.8.8.8&quot;, &quot;8.8.4.4&quot;]\n   &#125;\n $ sudo service docker restart\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://docs.docker-cn.com/\">https://docs.docker-cn.com</a></li>\n<li><a href=\"http://www.dockerinfo.net/document\">http://www.dockerinfo.net/document</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-系列01-docker安装\"><a href=\"#Docker-系列01-docker安装\" class=\"headerlink\" title=\"Docker 系列01-docker安装\"></a>Docker 系列01-docker安装</h1><p>Docker 提供了两个版本：社区版 (CE) 和企业版 (EE)。</p>\n<p>Docker 社区版 (CE) 是开发人员和小型团队开始使用 Docker 并尝试使用基于容器的应用的理想之选。Docker CE 有两个更新渠道，即 stable 和 edge：</p>\n<ul>\n<li>Stable 每个季度为您提供可靠更新</li>\n<li>Edge 每个月为您提供新功能</li>\n</ul>\n<h2 id=\"支持平台\"><a href=\"#支持平台\" class=\"headerlink\" title=\"支持平台\"></a>支持平台</h2><p>Docker CE 和 EE 可用于多种平台、云和内部部署。使用下表选择适用于您的最佳安装路径。</p>\n<h3 id=\"桌面\"><a href=\"#桌面\" class=\"headerlink\" title=\"桌面\"></a>桌面</h3><ul>\n<li><p>Mac     </p>\n</li>\n<li><p>Windows    </p>\n<h3 id=\"云\"><a href=\"#云\" class=\"headerlink\" title=\"云\"></a>云</h3></li>\n<li><p>Amazon</p>\n</li>\n<li><p>Microsoft</p>\n</li>\n<li><p>Digital Ocean</p>\n</li>\n<li><p>Packet</p>\n</li>\n<li><p>SoftLink</p>\n</li>\n<li><p>使用docker云代理创建自己的主机</p>\n</li>\n</ul>\n<h3 id=\"服务器\"><a href=\"#服务器\" class=\"headerlink\" title=\"服务器\"></a>服务器</h3><ul>\n<li>CentOS</li>\n<li>Debian    </li>\n<li>Fedora         </li>\n<li>Microsoft Windows</li>\n<li>Oracle Linux</li>\n<li>Red Hat</li>\n<li>SUSE</li>\n</ul>\n<h2 id=\"centos安装docker-ce\"><a href=\"#centos安装docker-ce\" class=\"headerlink\" title=\"centos安装docker ce\"></a>centos安装docker ce</h2><h3 id=\"操作系统要求\"><a href=\"#操作系统要求\" class=\"headerlink\" title=\"操作系统要求\"></a>操作系统要求</h3><p>如需安装 Docker CE，您需要 64 位版本的 CentOS 7。</p>\n<h3 id=\"卸载旧版本\"><a href=\"#卸载旧版本\" class=\"headerlink\" title=\"卸载旧版本\"></a>卸载旧版本</h3><p>Docker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。</p>\n<pre><code>$ sudo yum remove docker \\\n                  docker-common \\\n                  docker-selinux \\\n                  docker-engine\n</code></pre>\n<p>将保留 /var/lib/docker/ 的内容，包括镜像、容器、存储卷和网络。Docker CE 软件包现在称为 docker-ce。</p>\n<h3 id=\"安装-Docker-CE\"><a href=\"#安装-Docker-CE\" class=\"headerlink\" title=\"安装 Docker CE\"></a>安装 Docker CE</h3><p>您可以通过不同方式安装 Docker CE，具体取决于您的需求：</p>\n<ul>\n<li><p>Docker 的镜像仓库安装(推荐方法。)</p>\n</li>\n<li><p>RPM 软件包并手动进行安装</p>\n</li>\n</ul>\n<h4 id=\"使用yum进行安装\"><a href=\"#使用yum进行安装\" class=\"headerlink\" title=\"使用yum进行安装\"></a>使用yum进行安装</h4><pre><code> $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n $ sudo yum-config-manager \\\n     --add-repo \\\n     https://download.docker.com/linux/centos/docker-ce.repo\n $ sudo yum makecache fast\n $ sudo yum install docker-ce\n $ sudo systemctl start docker\n</code></pre>\n<p>如需要edge版本，使用以下开启</p>\n<pre><code> $ sudo yum-config-manager --enable docker-ce-edge (默认关闭)\n $ sudo yum-config-manager --enable docker-ce-testing (默认关闭)\n</code></pre>\n<p>安装特定版本：</p>\n<pre><code> $ yum list docker-ce.x86_64  --showduplicates | sort -r\n\n $ sudo yum install docker-ce-&lt;VERSION&gt;\n启动 Docker。\n</code></pre>\n<h4 id=\"rpm方式进行安装\"><a href=\"#rpm方式进行安装\" class=\"headerlink\" title=\"rpm方式进行安装\"></a>rpm方式进行安装</h4><pre><code> $ wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-&lt;VERSION&gt;.rpm\n $ sudo yum install /path/to/package.rpm\n $ sudo systemctl start docker\n</code></pre>\n<h4 id=\"二进制方式安装\"><a href=\"#二进制方式安装\" class=\"headerlink\" title=\"二进制方式安装\"></a>二进制方式安装</h4><pre><code> $ wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.1-ce.tgz\n $ tar -zxvf docker-18.06.1-ce.tgz\n $ cp docker/docker /usr/bin/docker\n $ service docker restart\n $ service docker status \n $ systemctl enable docker\n $ docker version\n</code></pre>\n<h3 id=\"升级-DOCKER-CE\"><a href=\"#升级-DOCKER-CE\" class=\"headerlink\" title=\"升级 DOCKER CE\"></a>升级 DOCKER CE</h3><pre><code> $ yum -y upgrade \n</code></pre>\n<h3 id=\"卸载-Docker-CE\"><a href=\"#卸载-Docker-CE\" class=\"headerlink\" title=\"卸载 Docker CE\"></a>卸载 Docker CE</h3><pre><code> $ sudo yum remove docker-ce\n $ sudo rm -rf /var/lib/docker\n</code></pre>\n<h2 id=\"linux安装后步骤\"><a href=\"#linux安装后步骤\" class=\"headerlink\" title=\"linux安装后步骤\"></a>linux安装后步骤</h2><h3 id=\"以非root用户管理docker\"><a href=\"#以非root用户管理docker\" class=\"headerlink\" title=\"以非root用户管理docker\"></a>以非root用户管理docker</h3><pre><code> $ groupadd docker\n $ usermod -aG dockere $USER\n</code></pre>\n<h3 id=\"docker开启自启动\"><a href=\"#docker开启自启动\" class=\"headerlink\" title=\"docker开启自启动\"></a>docker开启自启动</h3><pre><code>centos7:\n $ systemctl enable docker\n\ncentos6:\n $ chkconfig docker on\n</code></pre>\n<h3 id=\"开启ip转发\"><a href=\"#开启ip转发\" class=\"headerlink\" title=\"开启ip转发\"></a>开启ip转发</h3><pre><code> $ sysctl -w net.ipv4.ip_forward=1\n $ vim /etc/sysctl.conf\n   net.ipv4.ip_forward = 1\n</code></pre>\n<h3 id=\"指定dns服务器\"><a href=\"#指定dns服务器\" class=\"headerlink\" title=\"指定dns服务器\"></a>指定dns服务器</h3><pre><code> $ vim /etc/docker/daemon.json\n   &#123;\n        &quot;dns&quot;:[&quot;8.8.8.8&quot;, &quot;8.8.4.4&quot;]\n   &#125;\n $ sudo service docker restart\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://docs.docker-cn.com/\">https://docs.docker-cn.com</a></li>\n<li><a href=\"http://www.dockerinfo.net/document\">http://www.dockerinfo.net/document</a></li>\n</ul>\n"},{"layout":"post","title":"Docker 系列02-docker常用命令","date":"2018-09-19T02:29:54.000Z","author":"owelinux","excerpt":"Docker 系列02-docker常用命令","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Docker 系列02-docker常用命令\n\n## Dockerfile\n\n定义一个Dockerfile文件\n```\n# 将官方 Python 运行时用作父镜像\nFROM python:2.7-slim\n\n# 将工作目录设置为 /app\nWORKDIR /app\n\n# 将当前目录内容复制到位于 /app 中的容器中\nADD . /app\n\n# 安装 requirements.txt 中指定的任何所需软件包\nRUN pip install -r requirements.txt\n\n# 使端口 80 可供此容器外的环境使用\nEXPOSE 80\n\n# 定义环境变量\nENV NAME World\n\n# 在容器启动时运行 app.py\nCMD [\"python\", \"app.py\"]\n```\n\n\n\n构建镜像\n```\ndocker build -t friendlyname .\n```\n\n启动镜像，并且映射本地4000到容器端口80\n```\ndocker run -p 4000:80 friendlyname  \n```\n后台方式启动镜像\n```\ndocker run -d -p 4000:80 friendlyname\n```\n\n查看所有正在运行的容器的列表\n```         \ndocker ps\n```\n\n停止指定的容器\n```\ndocker stop <hash>\n```\n\n查看所有容器的列表\n```\ndocker ps -a\n```\n\n强制关闭指定的容器\n```\ndocker kill <hash>\n```\n\n删除指定的容器\n```\ndocker rm <hash>\n```\n\n删除所有容器\n```\ndocker rm $(docker ps -a -q)\n```\n\n显示所有镜像\n```\ndocker images -a\n```\n\n删除指定的镜像\n```\ndocker rmi <imagename>\n```\n\n删除所有镜像\n```\ndocker rmi $(docker images -q)\n```\n\n登录docker\n```\ndocker login             \n```\n\n镜像打标签\n```\ndocker tag <image> username/repository:tag\n```\n\n将打完标签的镜像上传\n```\ndocker push username/repository:tag\n```\n\n## swarm\n\n定义一个docker-compose.yml\n```\nversion: \"3.1\"\nservices:\n  web:\n    image: username/rep:tag\n    deploy:\n      replicas: 4\n      resources:\n        limits:\n          cpus: \"0.1\"\n          memory: 50M\n      restart_policy:\n        condition: on-failure\n    ports:\n      - \"80:80\"\n    networks:\n      - webnet\nnetworks:\n  webnet:\n```\n\n初始话swarm管理节点\n```\ndocker swarm init\n```\n\n列出此 Docker 主机上所有正在运行的应用\n```\ndocker stack ls \n```\n\n运行指定的 Compose 文件\n```             \ndocker stack deploy -c <composefile> <appname>\n```\n\n列出与应用关联的服务\n```\ndocker stack services <appname>\n```\n\n列出与应用关联的正在运行的容器\n```\ndocker stack ps <appname>\n```\n\n清除应用\n```\ndocker stack rm <appname>                             #\n```\n\n## swarm集群\n\nswarm 是一组运行 Docker 并且已加入集群中的机器。执行此操作后，您可以继续运行已使用的 Docker 命令，但现在它们在集群上由 swarm 管理节点执行。 swarm 中的机器可以为物理或虚拟机。加入 swarm 后，可以将它们称为节点。\n\nswarm 管理节点可以使用多项策略来运行容器，例如“最空的节点”– 这将使用容器填充使用最少的机器。或“全局”，这将确保每台机器恰好获得指定容器的一个实例。您可以指示 swarm 管理节点使用 Compose 文件中的这些策略，就像您已使用的策略一样。\n\nswarm 管理节点是 swarm 中可以执行命令或授权其他机器加入 swarm 作为工作节点的唯一机器。工作节点仅用于提供功能，并且无权告知任何其他机器它可以做什么和不能做什么。\n\n到目前为止，您已在本地机器上以单主机模式使用 Docker。但是，也可以将 Docker 切换到 swarm mode，并且这可以实现 swarm 的使用。即时启用 swarm mode 可以使当前机器成为 swarm 管理节点。从那时起，Docker 将在您要管理的 swarm 上运行您执行的命令，而不是仅在当前机器上执行命令。\n\n\n创建 VM（Mac、Win7、Linux）\n```\ndocker-machine create --driver virtualbox myvm1\n```\n\n创建 VM (Win10)\n```\ndocker-machine create -d hyperv --hyperv-virtual-switch \"myswitch\" myvm1\n```\n\n查看有关节点的基本信息\n```\ndocker-machine env myvm1\n```\n\n列出 swarm 中的节点\n```\ndocker-machine ssh myvm1 \"docker node ls\"\n```\n\n检查节点\n```\ndocker-machine ssh myvm1 \"docker node inspect <node ID>\"\n```\n\n查看加入令牌\n```\ndocker-machine ssh myvm1 \"docker swarm join-token -q worker\"\n```\n\n打开与 VM 的 SSH 会话；输入“exit”以结束会话\n```\ndocker-machine ssh myvm1\n```\n\n使工作节点退出 swarm\n```\ndocker-machine ssh myvm2 \"docker swarm leave\"\n```\n\n使主节点退出，终止 swarm\n```\ndocker-machine ssh myvm1 \"docker swarm leave -f\"\n```\n\n启动当前未运行的 VM\n```\ndocker-machine start myvm1\n```\n\n停止所有正在运行的 VM\n```\ndocker-machine stop $(docker-machine ls -q)   \n```\n\n删除所有 VM 及其磁盘镜像\n```            \ndocker-machine rm $(docker-machine ls -q)\n```\n\n将文件复制到节点的主目录\n```\ndocker-machine scp docker-compose.yml myvm1:~\n```\n\n部署应用\n```\ndocker-machine ssh myvm1 \"docker stack deploy -c <file> <app>\"\n```\n\n## docker 网络配置\n\n列出所有网络\n```\ndocker network ls\n```\n\n通过网络查找容器ip地址\n```\ndocker network inspect bridge\n```\n\n通过断开容器来从网络中删除容器\n```\ndocker network disconnect bridge <dockername>\n```\n\n创建自定义桥接网络\n```\ndocker network create -d bridge my_bridge\n```\n\n指定容器使用的网络\n```\ndocker  run -d --net=my_bridge --name db training/postgres\n```\n\n查看容器连接位置\n```\ndocker inspect --format='{{json .NetworkSettings.Networks}}'  db\n```\n\n获取容器ip地址\n```\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' db\n```\n\n连接容器网络\n```\ndocker network connect my_bridge db\n```\n\n## docker 数据卷\n\n添加数据卷\n```\ndocker run -d -P --name web -v /webapp training/webapp python app.py\n\n在容器内创建一个新卷/webapp\n```\n\n查看数据卷\n```\ndocker inspect web\n\nSource指定主机上的位置并 Destination指定容器内的卷位置。RW显示卷是否为读/写。\n```\n\n将主机目录挂在为数据卷\n```\ndocer run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py\n\n主机目录/src/webapp,容器目录/webapp;container-dir必须始终是绝对路径\n```\n\n查找空闲卷\n```\ndocker volume ls -f dangling=true\n```\n\n删除卷\n```\ndocker volume rm <volume name>\n```\n\n备份，还原或迁移数据卷\n```\ndocker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata\n\ndocker run -v /dbdata --name dbstore2 ubuntu /bin/bash\n\ndocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c \"cd /dbdata && tar xvf /backup/backup.tar --strip 1\"\n```\n\n删除所有未使用的卷\n```\ndocker volume prune\n```\n\n\n# 参考\n\n* [https://docs.docker-cn.com](https://docs.docker-cn.com)","source":"_posts/2018-09-19-article36-linux-docker-02.md","raw":"---\nlayout: post\ntitle:  \"Docker 系列02-docker常用命令\"\ndate:   2018-09-19 10:29:54\nauthor: owelinux\ncategories: linux 容器与虚拟化\ntags:  linux  docker\nexcerpt: Docker 系列02-docker常用命令\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Docker 系列02-docker常用命令\n\n## Dockerfile\n\n定义一个Dockerfile文件\n```\n# 将官方 Python 运行时用作父镜像\nFROM python:2.7-slim\n\n# 将工作目录设置为 /app\nWORKDIR /app\n\n# 将当前目录内容复制到位于 /app 中的容器中\nADD . /app\n\n# 安装 requirements.txt 中指定的任何所需软件包\nRUN pip install -r requirements.txt\n\n# 使端口 80 可供此容器外的环境使用\nEXPOSE 80\n\n# 定义环境变量\nENV NAME World\n\n# 在容器启动时运行 app.py\nCMD [\"python\", \"app.py\"]\n```\n\n\n\n构建镜像\n```\ndocker build -t friendlyname .\n```\n\n启动镜像，并且映射本地4000到容器端口80\n```\ndocker run -p 4000:80 friendlyname  \n```\n后台方式启动镜像\n```\ndocker run -d -p 4000:80 friendlyname\n```\n\n查看所有正在运行的容器的列表\n```         \ndocker ps\n```\n\n停止指定的容器\n```\ndocker stop <hash>\n```\n\n查看所有容器的列表\n```\ndocker ps -a\n```\n\n强制关闭指定的容器\n```\ndocker kill <hash>\n```\n\n删除指定的容器\n```\ndocker rm <hash>\n```\n\n删除所有容器\n```\ndocker rm $(docker ps -a -q)\n```\n\n显示所有镜像\n```\ndocker images -a\n```\n\n删除指定的镜像\n```\ndocker rmi <imagename>\n```\n\n删除所有镜像\n```\ndocker rmi $(docker images -q)\n```\n\n登录docker\n```\ndocker login             \n```\n\n镜像打标签\n```\ndocker tag <image> username/repository:tag\n```\n\n将打完标签的镜像上传\n```\ndocker push username/repository:tag\n```\n\n## swarm\n\n定义一个docker-compose.yml\n```\nversion: \"3.1\"\nservices:\n  web:\n    image: username/rep:tag\n    deploy:\n      replicas: 4\n      resources:\n        limits:\n          cpus: \"0.1\"\n          memory: 50M\n      restart_policy:\n        condition: on-failure\n    ports:\n      - \"80:80\"\n    networks:\n      - webnet\nnetworks:\n  webnet:\n```\n\n初始话swarm管理节点\n```\ndocker swarm init\n```\n\n列出此 Docker 主机上所有正在运行的应用\n```\ndocker stack ls \n```\n\n运行指定的 Compose 文件\n```             \ndocker stack deploy -c <composefile> <appname>\n```\n\n列出与应用关联的服务\n```\ndocker stack services <appname>\n```\n\n列出与应用关联的正在运行的容器\n```\ndocker stack ps <appname>\n```\n\n清除应用\n```\ndocker stack rm <appname>                             #\n```\n\n## swarm集群\n\nswarm 是一组运行 Docker 并且已加入集群中的机器。执行此操作后，您可以继续运行已使用的 Docker 命令，但现在它们在集群上由 swarm 管理节点执行。 swarm 中的机器可以为物理或虚拟机。加入 swarm 后，可以将它们称为节点。\n\nswarm 管理节点可以使用多项策略来运行容器，例如“最空的节点”– 这将使用容器填充使用最少的机器。或“全局”，这将确保每台机器恰好获得指定容器的一个实例。您可以指示 swarm 管理节点使用 Compose 文件中的这些策略，就像您已使用的策略一样。\n\nswarm 管理节点是 swarm 中可以执行命令或授权其他机器加入 swarm 作为工作节点的唯一机器。工作节点仅用于提供功能，并且无权告知任何其他机器它可以做什么和不能做什么。\n\n到目前为止，您已在本地机器上以单主机模式使用 Docker。但是，也可以将 Docker 切换到 swarm mode，并且这可以实现 swarm 的使用。即时启用 swarm mode 可以使当前机器成为 swarm 管理节点。从那时起，Docker 将在您要管理的 swarm 上运行您执行的命令，而不是仅在当前机器上执行命令。\n\n\n创建 VM（Mac、Win7、Linux）\n```\ndocker-machine create --driver virtualbox myvm1\n```\n\n创建 VM (Win10)\n```\ndocker-machine create -d hyperv --hyperv-virtual-switch \"myswitch\" myvm1\n```\n\n查看有关节点的基本信息\n```\ndocker-machine env myvm1\n```\n\n列出 swarm 中的节点\n```\ndocker-machine ssh myvm1 \"docker node ls\"\n```\n\n检查节点\n```\ndocker-machine ssh myvm1 \"docker node inspect <node ID>\"\n```\n\n查看加入令牌\n```\ndocker-machine ssh myvm1 \"docker swarm join-token -q worker\"\n```\n\n打开与 VM 的 SSH 会话；输入“exit”以结束会话\n```\ndocker-machine ssh myvm1\n```\n\n使工作节点退出 swarm\n```\ndocker-machine ssh myvm2 \"docker swarm leave\"\n```\n\n使主节点退出，终止 swarm\n```\ndocker-machine ssh myvm1 \"docker swarm leave -f\"\n```\n\n启动当前未运行的 VM\n```\ndocker-machine start myvm1\n```\n\n停止所有正在运行的 VM\n```\ndocker-machine stop $(docker-machine ls -q)   \n```\n\n删除所有 VM 及其磁盘镜像\n```            \ndocker-machine rm $(docker-machine ls -q)\n```\n\n将文件复制到节点的主目录\n```\ndocker-machine scp docker-compose.yml myvm1:~\n```\n\n部署应用\n```\ndocker-machine ssh myvm1 \"docker stack deploy -c <file> <app>\"\n```\n\n## docker 网络配置\n\n列出所有网络\n```\ndocker network ls\n```\n\n通过网络查找容器ip地址\n```\ndocker network inspect bridge\n```\n\n通过断开容器来从网络中删除容器\n```\ndocker network disconnect bridge <dockername>\n```\n\n创建自定义桥接网络\n```\ndocker network create -d bridge my_bridge\n```\n\n指定容器使用的网络\n```\ndocker  run -d --net=my_bridge --name db training/postgres\n```\n\n查看容器连接位置\n```\ndocker inspect --format='{{json .NetworkSettings.Networks}}'  db\n```\n\n获取容器ip地址\n```\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' db\n```\n\n连接容器网络\n```\ndocker network connect my_bridge db\n```\n\n## docker 数据卷\n\n添加数据卷\n```\ndocker run -d -P --name web -v /webapp training/webapp python app.py\n\n在容器内创建一个新卷/webapp\n```\n\n查看数据卷\n```\ndocker inspect web\n\nSource指定主机上的位置并 Destination指定容器内的卷位置。RW显示卷是否为读/写。\n```\n\n将主机目录挂在为数据卷\n```\ndocer run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py\n\n主机目录/src/webapp,容器目录/webapp;container-dir必须始终是绝对路径\n```\n\n查找空闲卷\n```\ndocker volume ls -f dangling=true\n```\n\n删除卷\n```\ndocker volume rm <volume name>\n```\n\n备份，还原或迁移数据卷\n```\ndocker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata\n\ndocker run -v /dbdata --name dbstore2 ubuntu /bin/bash\n\ndocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c \"cd /dbdata && tar xvf /backup/backup.tar --strip 1\"\n```\n\n删除所有未使用的卷\n```\ndocker volume prune\n```\n\n\n# 参考\n\n* [https://docs.docker-cn.com](https://docs.docker-cn.com)","slug":"2018-09-19-article36-linux-docker-02","published":1,"updated":"2021-02-09T02:00:24.576Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0r002kyc972jnmgvdb","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-系列02-docker常用命令\"><a href=\"#Docker-系列02-docker常用命令\" class=\"headerlink\" title=\"Docker 系列02-docker常用命令\"></a>Docker 系列02-docker常用命令</h1><h2 id=\"Dockerfile\"><a href=\"#Dockerfile\" class=\"headerlink\" title=\"Dockerfile\"></a>Dockerfile</h2><p>定义一个Dockerfile文件</p>\n<pre><code># 将官方 Python 运行时用作父镜像\nFROM python:2.7-slim\n\n# 将工作目录设置为 /app\nWORKDIR /app\n\n# 将当前目录内容复制到位于 /app 中的容器中\nADD . /app\n\n# 安装 requirements.txt 中指定的任何所需软件包\nRUN pip install -r requirements.txt\n\n# 使端口 80 可供此容器外的环境使用\nEXPOSE 80\n\n# 定义环境变量\nENV NAME World\n\n# 在容器启动时运行 app.py\nCMD [&quot;python&quot;, &quot;app.py&quot;]\n</code></pre>\n<p>构建镜像</p>\n<pre><code>docker build -t friendlyname .\n</code></pre>\n<p>启动镜像，并且映射本地4000到容器端口80</p>\n<pre><code>docker run -p 4000:80 friendlyname  \n</code></pre>\n<p>后台方式启动镜像</p>\n<pre><code>docker run -d -p 4000:80 friendlyname\n</code></pre>\n<p>查看所有正在运行的容器的列表</p>\n<pre><code>docker ps\n</code></pre>\n<p>停止指定的容器</p>\n<pre><code>docker stop &lt;hash&gt;\n</code></pre>\n<p>查看所有容器的列表</p>\n<pre><code>docker ps -a\n</code></pre>\n<p>强制关闭指定的容器</p>\n<pre><code>docker kill &lt;hash&gt;\n</code></pre>\n<p>删除指定的容器</p>\n<pre><code>docker rm &lt;hash&gt;\n</code></pre>\n<p>删除所有容器</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre>\n<p>显示所有镜像</p>\n<pre><code>docker images -a\n</code></pre>\n<p>删除指定的镜像</p>\n<pre><code>docker rmi &lt;imagename&gt;\n</code></pre>\n<p>删除所有镜像</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre>\n<p>登录docker</p>\n<pre><code>docker login             \n</code></pre>\n<p>镜像打标签</p>\n<pre><code>docker tag &lt;image&gt; username/repository:tag\n</code></pre>\n<p>将打完标签的镜像上传</p>\n<pre><code>docker push username/repository:tag\n</code></pre>\n<h2 id=\"swarm\"><a href=\"#swarm\" class=\"headerlink\" title=\"swarm\"></a>swarm</h2><p>定义一个docker-compose.yml</p>\n<pre><code>version: &quot;3.1&quot;\nservices:\n  web:\n    image: username/rep:tag\n    deploy:\n      replicas: 4\n      resources:\n        limits:\n          cpus: &quot;0.1&quot;\n          memory: 50M\n      restart_policy:\n        condition: on-failure\n    ports:\n      - &quot;80:80&quot;\n    networks:\n      - webnet\nnetworks:\n  webnet:\n</code></pre>\n<p>初始话swarm管理节点</p>\n<pre><code>docker swarm init\n</code></pre>\n<p>列出此 Docker 主机上所有正在运行的应用</p>\n<pre><code>docker stack ls \n</code></pre>\n<p>运行指定的 Compose 文件</p>\n<pre><code>docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;\n</code></pre>\n<p>列出与应用关联的服务</p>\n<pre><code>docker stack services &lt;appname&gt;\n</code></pre>\n<p>列出与应用关联的正在运行的容器</p>\n<pre><code>docker stack ps &lt;appname&gt;\n</code></pre>\n<p>清除应用</p>\n<pre><code>docker stack rm &lt;appname&gt;                             #\n</code></pre>\n<h2 id=\"swarm集群\"><a href=\"#swarm集群\" class=\"headerlink\" title=\"swarm集群\"></a>swarm集群</h2><p>swarm 是一组运行 Docker 并且已加入集群中的机器。执行此操作后，您可以继续运行已使用的 Docker 命令，但现在它们在集群上由 swarm 管理节点执行。 swarm 中的机器可以为物理或虚拟机。加入 swarm 后，可以将它们称为节点。</p>\n<p>swarm 管理节点可以使用多项策略来运行容器，例如“最空的节点”– 这将使用容器填充使用最少的机器。或“全局”，这将确保每台机器恰好获得指定容器的一个实例。您可以指示 swarm 管理节点使用 Compose 文件中的这些策略，就像您已使用的策略一样。</p>\n<p>swarm 管理节点是 swarm 中可以执行命令或授权其他机器加入 swarm 作为工作节点的唯一机器。工作节点仅用于提供功能，并且无权告知任何其他机器它可以做什么和不能做什么。</p>\n<p>到目前为止，您已在本地机器上以单主机模式使用 Docker。但是，也可以将 Docker 切换到 swarm mode，并且这可以实现 swarm 的使用。即时启用 swarm mode 可以使当前机器成为 swarm 管理节点。从那时起，Docker 将在您要管理的 swarm 上运行您执行的命令，而不是仅在当前机器上执行命令。</p>\n<p>创建 VM（Mac、Win7、Linux）</p>\n<pre><code>docker-machine create --driver virtualbox myvm1\n</code></pre>\n<p>创建 VM (Win10)</p>\n<pre><code>docker-machine create -d hyperv --hyperv-virtual-switch &quot;myswitch&quot; myvm1\n</code></pre>\n<p>查看有关节点的基本信息</p>\n<pre><code>docker-machine env myvm1\n</code></pre>\n<p>列出 swarm 中的节点</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker node ls&quot;\n</code></pre>\n<p>检查节点</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker node inspect &lt;node ID&gt;&quot;\n</code></pre>\n<p>查看加入令牌</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker swarm join-token -q worker&quot;\n</code></pre>\n<p>打开与 VM 的 SSH 会话；输入“exit”以结束会话</p>\n<pre><code>docker-machine ssh myvm1\n</code></pre>\n<p>使工作节点退出 swarm</p>\n<pre><code>docker-machine ssh myvm2 &quot;docker swarm leave&quot;\n</code></pre>\n<p>使主节点退出，终止 swarm</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker swarm leave -f&quot;\n</code></pre>\n<p>启动当前未运行的 VM</p>\n<pre><code>docker-machine start myvm1\n</code></pre>\n<p>停止所有正在运行的 VM</p>\n<pre><code>docker-machine stop $(docker-machine ls -q)   \n</code></pre>\n<p>删除所有 VM 及其磁盘镜像</p>\n<pre><code>docker-machine rm $(docker-machine ls -q)\n</code></pre>\n<p>将文件复制到节点的主目录</p>\n<pre><code>docker-machine scp docker-compose.yml myvm1:~\n</code></pre>\n<p>部署应用</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker stack deploy -c &lt;file&gt; &lt;app&gt;&quot;\n</code></pre>\n<h2 id=\"docker-网络配置\"><a href=\"#docker-网络配置\" class=\"headerlink\" title=\"docker 网络配置\"></a>docker 网络配置</h2><p>列出所有网络</p>\n<pre><code>docker network ls\n</code></pre>\n<p>通过网络查找容器ip地址</p>\n<pre><code>docker network inspect bridge\n</code></pre>\n<p>通过断开容器来从网络中删除容器</p>\n<pre><code>docker network disconnect bridge &lt;dockername&gt;\n</code></pre>\n<p>创建自定义桥接网络</p>\n<pre><code>docker network create -d bridge my_bridge\n</code></pre>\n<p>指定容器使用的网络</p>\n<pre><code>docker  run -d --net=my_bridge --name db training/postgres\n</code></pre>\n<p>查看容器连接位置</p>\n<pre><code>docker inspect --format=&#39;&#123;&#123;json .NetworkSettings.Networks&#125;&#125;&#39;  db\n</code></pre>\n<p>获取容器ip地址</p>\n<pre><code>docker inspect --format=&#39;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; db\n</code></pre>\n<p>连接容器网络</p>\n<pre><code>docker network connect my_bridge db\n</code></pre>\n<h2 id=\"docker-数据卷\"><a href=\"#docker-数据卷\" class=\"headerlink\" title=\"docker 数据卷\"></a>docker 数据卷</h2><p>添加数据卷</p>\n<pre><code>docker run -d -P --name web -v /webapp training/webapp python app.py\n\n在容器内创建一个新卷/webapp\n</code></pre>\n<p>查看数据卷</p>\n<pre><code>docker inspect web\n\nSource指定主机上的位置并 Destination指定容器内的卷位置。RW显示卷是否为读/写。\n</code></pre>\n<p>将主机目录挂在为数据卷</p>\n<pre><code>docer run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py\n\n主机目录/src/webapp,容器目录/webapp;container-dir必须始终是绝对路径\n</code></pre>\n<p>查找空闲卷</p>\n<pre><code>docker volume ls -f dangling=true\n</code></pre>\n<p>删除卷</p>\n<pre><code>docker volume rm &lt;volume name&gt;\n</code></pre>\n<p>备份，还原或迁移数据卷</p>\n<pre><code>docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata\n\ndocker run -v /dbdata --name dbstore2 ubuntu /bin/bash\n\ndocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot;\n</code></pre>\n<p>删除所有未使用的卷</p>\n<pre><code>docker volume prune\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://docs.docker-cn.com/\">https://docs.docker-cn.com</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-系列02-docker常用命令\"><a href=\"#Docker-系列02-docker常用命令\" class=\"headerlink\" title=\"Docker 系列02-docker常用命令\"></a>Docker 系列02-docker常用命令</h1><h2 id=\"Dockerfile\"><a href=\"#Dockerfile\" class=\"headerlink\" title=\"Dockerfile\"></a>Dockerfile</h2><p>定义一个Dockerfile文件</p>\n<pre><code># 将官方 Python 运行时用作父镜像\nFROM python:2.7-slim\n\n# 将工作目录设置为 /app\nWORKDIR /app\n\n# 将当前目录内容复制到位于 /app 中的容器中\nADD . /app\n\n# 安装 requirements.txt 中指定的任何所需软件包\nRUN pip install -r requirements.txt\n\n# 使端口 80 可供此容器外的环境使用\nEXPOSE 80\n\n# 定义环境变量\nENV NAME World\n\n# 在容器启动时运行 app.py\nCMD [&quot;python&quot;, &quot;app.py&quot;]\n</code></pre>\n<p>构建镜像</p>\n<pre><code>docker build -t friendlyname .\n</code></pre>\n<p>启动镜像，并且映射本地4000到容器端口80</p>\n<pre><code>docker run -p 4000:80 friendlyname  \n</code></pre>\n<p>后台方式启动镜像</p>\n<pre><code>docker run -d -p 4000:80 friendlyname\n</code></pre>\n<p>查看所有正在运行的容器的列表</p>\n<pre><code>docker ps\n</code></pre>\n<p>停止指定的容器</p>\n<pre><code>docker stop &lt;hash&gt;\n</code></pre>\n<p>查看所有容器的列表</p>\n<pre><code>docker ps -a\n</code></pre>\n<p>强制关闭指定的容器</p>\n<pre><code>docker kill &lt;hash&gt;\n</code></pre>\n<p>删除指定的容器</p>\n<pre><code>docker rm &lt;hash&gt;\n</code></pre>\n<p>删除所有容器</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre>\n<p>显示所有镜像</p>\n<pre><code>docker images -a\n</code></pre>\n<p>删除指定的镜像</p>\n<pre><code>docker rmi &lt;imagename&gt;\n</code></pre>\n<p>删除所有镜像</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre>\n<p>登录docker</p>\n<pre><code>docker login             \n</code></pre>\n<p>镜像打标签</p>\n<pre><code>docker tag &lt;image&gt; username/repository:tag\n</code></pre>\n<p>将打完标签的镜像上传</p>\n<pre><code>docker push username/repository:tag\n</code></pre>\n<h2 id=\"swarm\"><a href=\"#swarm\" class=\"headerlink\" title=\"swarm\"></a>swarm</h2><p>定义一个docker-compose.yml</p>\n<pre><code>version: &quot;3.1&quot;\nservices:\n  web:\n    image: username/rep:tag\n    deploy:\n      replicas: 4\n      resources:\n        limits:\n          cpus: &quot;0.1&quot;\n          memory: 50M\n      restart_policy:\n        condition: on-failure\n    ports:\n      - &quot;80:80&quot;\n    networks:\n      - webnet\nnetworks:\n  webnet:\n</code></pre>\n<p>初始话swarm管理节点</p>\n<pre><code>docker swarm init\n</code></pre>\n<p>列出此 Docker 主机上所有正在运行的应用</p>\n<pre><code>docker stack ls \n</code></pre>\n<p>运行指定的 Compose 文件</p>\n<pre><code>docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;\n</code></pre>\n<p>列出与应用关联的服务</p>\n<pre><code>docker stack services &lt;appname&gt;\n</code></pre>\n<p>列出与应用关联的正在运行的容器</p>\n<pre><code>docker stack ps &lt;appname&gt;\n</code></pre>\n<p>清除应用</p>\n<pre><code>docker stack rm &lt;appname&gt;                             #\n</code></pre>\n<h2 id=\"swarm集群\"><a href=\"#swarm集群\" class=\"headerlink\" title=\"swarm集群\"></a>swarm集群</h2><p>swarm 是一组运行 Docker 并且已加入集群中的机器。执行此操作后，您可以继续运行已使用的 Docker 命令，但现在它们在集群上由 swarm 管理节点执行。 swarm 中的机器可以为物理或虚拟机。加入 swarm 后，可以将它们称为节点。</p>\n<p>swarm 管理节点可以使用多项策略来运行容器，例如“最空的节点”– 这将使用容器填充使用最少的机器。或“全局”，这将确保每台机器恰好获得指定容器的一个实例。您可以指示 swarm 管理节点使用 Compose 文件中的这些策略，就像您已使用的策略一样。</p>\n<p>swarm 管理节点是 swarm 中可以执行命令或授权其他机器加入 swarm 作为工作节点的唯一机器。工作节点仅用于提供功能，并且无权告知任何其他机器它可以做什么和不能做什么。</p>\n<p>到目前为止，您已在本地机器上以单主机模式使用 Docker。但是，也可以将 Docker 切换到 swarm mode，并且这可以实现 swarm 的使用。即时启用 swarm mode 可以使当前机器成为 swarm 管理节点。从那时起，Docker 将在您要管理的 swarm 上运行您执行的命令，而不是仅在当前机器上执行命令。</p>\n<p>创建 VM（Mac、Win7、Linux）</p>\n<pre><code>docker-machine create --driver virtualbox myvm1\n</code></pre>\n<p>创建 VM (Win10)</p>\n<pre><code>docker-machine create -d hyperv --hyperv-virtual-switch &quot;myswitch&quot; myvm1\n</code></pre>\n<p>查看有关节点的基本信息</p>\n<pre><code>docker-machine env myvm1\n</code></pre>\n<p>列出 swarm 中的节点</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker node ls&quot;\n</code></pre>\n<p>检查节点</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker node inspect &lt;node ID&gt;&quot;\n</code></pre>\n<p>查看加入令牌</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker swarm join-token -q worker&quot;\n</code></pre>\n<p>打开与 VM 的 SSH 会话；输入“exit”以结束会话</p>\n<pre><code>docker-machine ssh myvm1\n</code></pre>\n<p>使工作节点退出 swarm</p>\n<pre><code>docker-machine ssh myvm2 &quot;docker swarm leave&quot;\n</code></pre>\n<p>使主节点退出，终止 swarm</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker swarm leave -f&quot;\n</code></pre>\n<p>启动当前未运行的 VM</p>\n<pre><code>docker-machine start myvm1\n</code></pre>\n<p>停止所有正在运行的 VM</p>\n<pre><code>docker-machine stop $(docker-machine ls -q)   \n</code></pre>\n<p>删除所有 VM 及其磁盘镜像</p>\n<pre><code>docker-machine rm $(docker-machine ls -q)\n</code></pre>\n<p>将文件复制到节点的主目录</p>\n<pre><code>docker-machine scp docker-compose.yml myvm1:~\n</code></pre>\n<p>部署应用</p>\n<pre><code>docker-machine ssh myvm1 &quot;docker stack deploy -c &lt;file&gt; &lt;app&gt;&quot;\n</code></pre>\n<h2 id=\"docker-网络配置\"><a href=\"#docker-网络配置\" class=\"headerlink\" title=\"docker 网络配置\"></a>docker 网络配置</h2><p>列出所有网络</p>\n<pre><code>docker network ls\n</code></pre>\n<p>通过网络查找容器ip地址</p>\n<pre><code>docker network inspect bridge\n</code></pre>\n<p>通过断开容器来从网络中删除容器</p>\n<pre><code>docker network disconnect bridge &lt;dockername&gt;\n</code></pre>\n<p>创建自定义桥接网络</p>\n<pre><code>docker network create -d bridge my_bridge\n</code></pre>\n<p>指定容器使用的网络</p>\n<pre><code>docker  run -d --net=my_bridge --name db training/postgres\n</code></pre>\n<p>查看容器连接位置</p>\n<pre><code>docker inspect --format=&#39;&#123;&#123;json .NetworkSettings.Networks&#125;&#125;&#39;  db\n</code></pre>\n<p>获取容器ip地址</p>\n<pre><code>docker inspect --format=&#39;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; db\n</code></pre>\n<p>连接容器网络</p>\n<pre><code>docker network connect my_bridge db\n</code></pre>\n<h2 id=\"docker-数据卷\"><a href=\"#docker-数据卷\" class=\"headerlink\" title=\"docker 数据卷\"></a>docker 数据卷</h2><p>添加数据卷</p>\n<pre><code>docker run -d -P --name web -v /webapp training/webapp python app.py\n\n在容器内创建一个新卷/webapp\n</code></pre>\n<p>查看数据卷</p>\n<pre><code>docker inspect web\n\nSource指定主机上的位置并 Destination指定容器内的卷位置。RW显示卷是否为读/写。\n</code></pre>\n<p>将主机目录挂在为数据卷</p>\n<pre><code>docer run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py\n\n主机目录/src/webapp,容器目录/webapp;container-dir必须始终是绝对路径\n</code></pre>\n<p>查找空闲卷</p>\n<pre><code>docker volume ls -f dangling=true\n</code></pre>\n<p>删除卷</p>\n<pre><code>docker volume rm &lt;volume name&gt;\n</code></pre>\n<p>备份，还原或迁移数据卷</p>\n<pre><code>docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata\n\ndocker run -v /dbdata --name dbstore2 ubuntu /bin/bash\n\ndocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot;\n</code></pre>\n<p>删除所有未使用的卷</p>\n<pre><code>docker volume prune\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://docs.docker-cn.com/\">https://docs.docker-cn.com</a></li>\n</ul>\n"},{"layout":"post","title":"使用rpmbuild自定义构建rpm包","date":"2018-09-20T09:29:54.000Z","author":"owelinux","excerpt":"使用rpmbuild自定义构建rpm包","mathjax":true,"_content":"\n* content\n{:toc}\n\n# 使用rpmbuild自定义构建rpm包\n\n目前我所知道的 build nginx RPM 的方式(测试过)总共 3 种,大致分为 2 类\n\n* 基于源码 build\n* 基于已有 rpm 替换\n\n第一种方案的好处就是配置文件等能始终保持最新的,编译版本等不受限制;但是从源码 build 非常耗时,尤其是网络环境复杂的情况下,没有高配置国外服务器很难完成 build,而且要维护 build 所需 spec 文件等,自己维护这些未必能够尽善尽美;\n\n第二种方式是创建速度快,build 方式简单可靠,但是由于是替换方式,所以 rpm 中的配置不一定能够即使更新,而且只能基于官方build 好以后的二进制文件进行替换,如果想要尝试 master 最新代码则无法实现\n\n## 二、基于源码 Build\n对于 Centos RPM build 原理方式这里不再细说，基于源码 build 的关键就在于 spec 文件，我尝试过自己去写，后来对比一些开源项目的感觉 low 得很，所以以前一直采用一个国外哥们写的脚本 build[参见这里](https://github.com/JohnTheodore/kubernetes-rpm-builder)；这个脚本不太好的地方是作者已经停止了维护；经过不懈努力，找到了 Fedora 系统的 rpm 仓库，鼓捣了一阵摸清了套路；以下主要以 Fedora 仓库为例进行 build\n\n以下 Build 在一台 Do 8核心 16G VPS 上进行，由于众所周知的原因，国内 Build 很费劲，一般国外 VPS 都是按小时收费，有个 2 块钱就够了\n\n### 2.1、安装 build 所需依赖\n由于 spec 文件中定义了依赖于 golang 这个包，所以如果不装的话会报错；事实上如果使用刚刚安装的这个 golang 去 build 还是会挂掉，因为实际编译要求 golang > 1.7，直接 yum 装的是 1.6，故下面又使用 gvm 装了一个 1.8 的 golang，上面的 golang 安装只是为了通过 spec 检查\n```\n# EPEL\nyum install epel-release -y\n# update 系统组件\nyum update -y && yum upgrade -y\n# 安装基本的编译依赖\nyum install golang go-md2man go-bindata gcc bison git rpm-build vim -y\n# 安装 gvm(用于 golang 版本管理)\nbash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource /root/.gvm/scripts/gvm\n# 安装 1.8 之前需要先安装 1.4\ngvm install go1.4 -B\ngvm use go1.4\n# 使用 golang 1.8 版本 build\ngvm install go1.9\ngvm use go1.9\n```\n### 2.2、克隆 build 仓库\nFedora 官方 Kubernetes 仓库地址在 这里，如果有版本选择请自行区分\n\n```\ngit clone https://src.fedoraproject.org/git/rpms/nginx.git\n```\n\n### 2.3、从 spec 获取所需文件\n克隆好 build 仓库后首先查看 kubernetes.spec 文件，确定 build 所需文件，spec 文件如下\n```\n%global  _hardened_build     1\n%global  nginx_user          nginx\n\n# Disable strict symbol checks in the link editor.\n# See: https://src.fedoraproject.org/rpms/redhat-rpm-config/c/078af19\n%undefine _strict_symbol_defs_build\n\n%bcond_with geoip\n\n# gperftools exist only on selected arches\n# gperftools *detection* is failing on ppc64*, possibly only configure\n# bug, but disable anyway.\n%ifnarch s390 s390x ppc64 ppc64le\n%global with_gperftools 1\n%endif\n\n%global with_aio 1\n\n%if 0%{?fedora} > 22\n%global with_mailcap_mimetypes 1\n%endif\n```\n\n从 spec 文件中可以看到 build 主要需要两个仓库的源码，一个是 kubernetes 主仓库，存放着主要的 build 源码；另一个是 contrib 仓库，存放着一些配置文件，如 systemd 配置等\n\n接下来从 spec 文件的 source 段中可以解读到(source0、source1)最终所需的两个仓库压缩文件名为 kubernetes-SHORTCOMMIT、contrib-SHORTCOMIT，source 段如下\n\n```\nName:              nginx\nEpoch:             1\nVersion:           1.11.1\nRelease:           14%{?dist}\n\nSummary:           A high performance web server and reverse proxy server\nGroup:             System Environment/Daemons\n# BSD License (two clause)\n# http://www.freebsd.org/copyright/freebsd-license.html\nLicense:           BSD\nURL:               http://nginx.org/\n\nSource0:           https://nginx.org/download/nginx-%{version}.tar.gz\nSource10:          nginx.service\nSource11:          nginx.logrotate\nSource12:          nginx.conf\nSource13:          nginx-upgrade\nSource14:          nginx-upgrade.8\nSource100:         index.html\nSource101:         poweredby.png\nSource102:         nginx-logo.png\nSource103:         404.html\nSource104:         50x.html\nSource200:         README.dynamic\nSource210:         UPGRADE-NOTES-1.6-to-1.10\n```\n我们准备 build 一个最新的 1.12.1 的 rpm,修改\n```\nName:              nginx\nEpoch:             1\nVersion:           1.12.1\nRelease:           14%{?dist}\n```\n\n### 2.4、准备源码\n修改好文件以后，就可以下载源码文件了，源码下载不必去克隆 github 项目，直接从 spec 中给出的地址下载即可\n```\ncd nginx\nwget https://nginx.org/download/nginx-1.12.1.tar.gz\n```\n### 2.5、build rpm\n在正式开始 build 之前，还有一点需要注意的是 默认的 kubernetes.spec 文件中指定了该 rpm 依赖于 docker 这个包，在 CentOS 上可能我们会安装 docker-engine 或者 docker-ce，此时安装 kubernetes rpm 是无法安装的，因为他以来的包不存在，解决的办法就是编译之前删除 spec 文件中的 Requires: docker 即可，最后创建好 build 目录，并放置好源码文件开始 build 即可，当然 build 可以有不同选择\n\n# 由于我是 root 用户，所以目录位置在这\n# 实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)\n# 我的是一台临时 vps，所以无所谓了\n```\nmkdir -p /root/rpmbuild/SOURCES/\nmv ~/nginx/* /root/rpmbuild/SOURCES/\ncd /root/rpmbuild/SOURCES/\n# 执行 build\nrpmbuild -ba nginx.spec\n```\n\n注意，由于我们选择的版本已经超出了仓库所支持的最大版本，所以有些 Patch 已经不再适用，如 spec 中的 Patch12、Patch19 会出错，所需要注释掉(%prep 段中也有一个)\n\nrpmbuild 可选项有很多，常用的 3 个，可以根据自己实际需要进行 build:\n\n* -ba : build 源码包+二进制包\n* -bb : 只 build 二进制包\n* -bs : 只 build 源码包\n\n最后 build 完成后如下\n```\n[root@test x86_64]# ll\ntotal 2480\n-rw-r--r-- 1 root root  543948 Sep 20 17:21 nginx-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root 1754960 Sep 20 17:21 nginx-debuginfo-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   27544 Sep 20 17:21 nginx-mod-http-image-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   36992 Sep 20 17:21 nginx-mod-http-perl-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   26628 Sep 20 17:21 nginx-mod-http-xslt-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   55316 Sep 20 17:21 nginx-mod-mail-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   78512 Sep 20 17:21 nginx-mod-stream-1.12.1-14.el7.x86_64.rpm\n``` \n\n# 参考\n\n* [https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/](https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/)","source":"_posts/2018-09-20-article37-linux-rpmbuild.md","raw":"---\nlayout: post\ntitle:  \"使用rpmbuild自定义构建rpm包\"\ndate:   2018-09-20 17:29:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: 使用rpmbuild自定义构建rpm包\nmathjax: true\n---\n\n* content\n{:toc}\n\n# 使用rpmbuild自定义构建rpm包\n\n目前我所知道的 build nginx RPM 的方式(测试过)总共 3 种,大致分为 2 类\n\n* 基于源码 build\n* 基于已有 rpm 替换\n\n第一种方案的好处就是配置文件等能始终保持最新的,编译版本等不受限制;但是从源码 build 非常耗时,尤其是网络环境复杂的情况下,没有高配置国外服务器很难完成 build,而且要维护 build 所需 spec 文件等,自己维护这些未必能够尽善尽美;\n\n第二种方式是创建速度快,build 方式简单可靠,但是由于是替换方式,所以 rpm 中的配置不一定能够即使更新,而且只能基于官方build 好以后的二进制文件进行替换,如果想要尝试 master 最新代码则无法实现\n\n## 二、基于源码 Build\n对于 Centos RPM build 原理方式这里不再细说，基于源码 build 的关键就在于 spec 文件，我尝试过自己去写，后来对比一些开源项目的感觉 low 得很，所以以前一直采用一个国外哥们写的脚本 build[参见这里](https://github.com/JohnTheodore/kubernetes-rpm-builder)；这个脚本不太好的地方是作者已经停止了维护；经过不懈努力，找到了 Fedora 系统的 rpm 仓库，鼓捣了一阵摸清了套路；以下主要以 Fedora 仓库为例进行 build\n\n以下 Build 在一台 Do 8核心 16G VPS 上进行，由于众所周知的原因，国内 Build 很费劲，一般国外 VPS 都是按小时收费，有个 2 块钱就够了\n\n### 2.1、安装 build 所需依赖\n由于 spec 文件中定义了依赖于 golang 这个包，所以如果不装的话会报错；事实上如果使用刚刚安装的这个 golang 去 build 还是会挂掉，因为实际编译要求 golang > 1.7，直接 yum 装的是 1.6，故下面又使用 gvm 装了一个 1.8 的 golang，上面的 golang 安装只是为了通过 spec 检查\n```\n# EPEL\nyum install epel-release -y\n# update 系统组件\nyum update -y && yum upgrade -y\n# 安装基本的编译依赖\nyum install golang go-md2man go-bindata gcc bison git rpm-build vim -y\n# 安装 gvm(用于 golang 版本管理)\nbash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource /root/.gvm/scripts/gvm\n# 安装 1.8 之前需要先安装 1.4\ngvm install go1.4 -B\ngvm use go1.4\n# 使用 golang 1.8 版本 build\ngvm install go1.9\ngvm use go1.9\n```\n### 2.2、克隆 build 仓库\nFedora 官方 Kubernetes 仓库地址在 这里，如果有版本选择请自行区分\n\n```\ngit clone https://src.fedoraproject.org/git/rpms/nginx.git\n```\n\n### 2.3、从 spec 获取所需文件\n克隆好 build 仓库后首先查看 kubernetes.spec 文件，确定 build 所需文件，spec 文件如下\n```\n%global  _hardened_build     1\n%global  nginx_user          nginx\n\n# Disable strict symbol checks in the link editor.\n# See: https://src.fedoraproject.org/rpms/redhat-rpm-config/c/078af19\n%undefine _strict_symbol_defs_build\n\n%bcond_with geoip\n\n# gperftools exist only on selected arches\n# gperftools *detection* is failing on ppc64*, possibly only configure\n# bug, but disable anyway.\n%ifnarch s390 s390x ppc64 ppc64le\n%global with_gperftools 1\n%endif\n\n%global with_aio 1\n\n%if 0%{?fedora} > 22\n%global with_mailcap_mimetypes 1\n%endif\n```\n\n从 spec 文件中可以看到 build 主要需要两个仓库的源码，一个是 kubernetes 主仓库，存放着主要的 build 源码；另一个是 contrib 仓库，存放着一些配置文件，如 systemd 配置等\n\n接下来从 spec 文件的 source 段中可以解读到(source0、source1)最终所需的两个仓库压缩文件名为 kubernetes-SHORTCOMMIT、contrib-SHORTCOMIT，source 段如下\n\n```\nName:              nginx\nEpoch:             1\nVersion:           1.11.1\nRelease:           14%{?dist}\n\nSummary:           A high performance web server and reverse proxy server\nGroup:             System Environment/Daemons\n# BSD License (two clause)\n# http://www.freebsd.org/copyright/freebsd-license.html\nLicense:           BSD\nURL:               http://nginx.org/\n\nSource0:           https://nginx.org/download/nginx-%{version}.tar.gz\nSource10:          nginx.service\nSource11:          nginx.logrotate\nSource12:          nginx.conf\nSource13:          nginx-upgrade\nSource14:          nginx-upgrade.8\nSource100:         index.html\nSource101:         poweredby.png\nSource102:         nginx-logo.png\nSource103:         404.html\nSource104:         50x.html\nSource200:         README.dynamic\nSource210:         UPGRADE-NOTES-1.6-to-1.10\n```\n我们准备 build 一个最新的 1.12.1 的 rpm,修改\n```\nName:              nginx\nEpoch:             1\nVersion:           1.12.1\nRelease:           14%{?dist}\n```\n\n### 2.4、准备源码\n修改好文件以后，就可以下载源码文件了，源码下载不必去克隆 github 项目，直接从 spec 中给出的地址下载即可\n```\ncd nginx\nwget https://nginx.org/download/nginx-1.12.1.tar.gz\n```\n### 2.5、build rpm\n在正式开始 build 之前，还有一点需要注意的是 默认的 kubernetes.spec 文件中指定了该 rpm 依赖于 docker 这个包，在 CentOS 上可能我们会安装 docker-engine 或者 docker-ce，此时安装 kubernetes rpm 是无法安装的，因为他以来的包不存在，解决的办法就是编译之前删除 spec 文件中的 Requires: docker 即可，最后创建好 build 目录，并放置好源码文件开始 build 即可，当然 build 可以有不同选择\n\n# 由于我是 root 用户，所以目录位置在这\n# 实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)\n# 我的是一台临时 vps，所以无所谓了\n```\nmkdir -p /root/rpmbuild/SOURCES/\nmv ~/nginx/* /root/rpmbuild/SOURCES/\ncd /root/rpmbuild/SOURCES/\n# 执行 build\nrpmbuild -ba nginx.spec\n```\n\n注意，由于我们选择的版本已经超出了仓库所支持的最大版本，所以有些 Patch 已经不再适用，如 spec 中的 Patch12、Patch19 会出错，所需要注释掉(%prep 段中也有一个)\n\nrpmbuild 可选项有很多，常用的 3 个，可以根据自己实际需要进行 build:\n\n* -ba : build 源码包+二进制包\n* -bb : 只 build 二进制包\n* -bs : 只 build 源码包\n\n最后 build 完成后如下\n```\n[root@test x86_64]# ll\ntotal 2480\n-rw-r--r-- 1 root root  543948 Sep 20 17:21 nginx-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root 1754960 Sep 20 17:21 nginx-debuginfo-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   27544 Sep 20 17:21 nginx-mod-http-image-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   36992 Sep 20 17:21 nginx-mod-http-perl-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   26628 Sep 20 17:21 nginx-mod-http-xslt-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   55316 Sep 20 17:21 nginx-mod-mail-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   78512 Sep 20 17:21 nginx-mod-stream-1.12.1-14.el7.x86_64.rpm\n``` \n\n# 参考\n\n* [https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/](https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/)","slug":"2018-09-20-article37-linux-rpmbuild","published":1,"updated":"2021-02-09T02:00:24.577Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0t002oyc97hk1de1m7","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"使用rpmbuild自定义构建rpm包\"><a href=\"#使用rpmbuild自定义构建rpm包\" class=\"headerlink\" title=\"使用rpmbuild自定义构建rpm包\"></a>使用rpmbuild自定义构建rpm包</h1><p>目前我所知道的 build nginx RPM 的方式(测试过)总共 3 种,大致分为 2 类</p>\n<ul>\n<li>基于源码 build</li>\n<li>基于已有 rpm 替换</li>\n</ul>\n<p>第一种方案的好处就是配置文件等能始终保持最新的,编译版本等不受限制;但是从源码 build 非常耗时,尤其是网络环境复杂的情况下,没有高配置国外服务器很难完成 build,而且要维护 build 所需 spec 文件等,自己维护这些未必能够尽善尽美;</p>\n<p>第二种方式是创建速度快,build 方式简单可靠,但是由于是替换方式,所以 rpm 中的配置不一定能够即使更新,而且只能基于官方build 好以后的二进制文件进行替换,如果想要尝试 master 最新代码则无法实现</p>\n<h2 id=\"二、基于源码-Build\"><a href=\"#二、基于源码-Build\" class=\"headerlink\" title=\"二、基于源码 Build\"></a>二、基于源码 Build</h2><p>对于 Centos RPM build 原理方式这里不再细说，基于源码 build 的关键就在于 spec 文件，我尝试过自己去写，后来对比一些开源项目的感觉 low 得很，所以以前一直采用一个国外哥们写的脚本 build<a href=\"https://github.com/JohnTheodore/kubernetes-rpm-builder\">参见这里</a>；这个脚本不太好的地方是作者已经停止了维护；经过不懈努力，找到了 Fedora 系统的 rpm 仓库，鼓捣了一阵摸清了套路；以下主要以 Fedora 仓库为例进行 build</p>\n<p>以下 Build 在一台 Do 8核心 16G VPS 上进行，由于众所周知的原因，国内 Build 很费劲，一般国外 VPS 都是按小时收费，有个 2 块钱就够了</p>\n<h3 id=\"2-1、安装-build-所需依赖\"><a href=\"#2-1、安装-build-所需依赖\" class=\"headerlink\" title=\"2.1、安装 build 所需依赖\"></a>2.1、安装 build 所需依赖</h3><p>由于 spec 文件中定义了依赖于 golang 这个包，所以如果不装的话会报错；事实上如果使用刚刚安装的这个 golang 去 build 还是会挂掉，因为实际编译要求 golang &gt; 1.7，直接 yum 装的是 1.6，故下面又使用 gvm 装了一个 1.8 的 golang，上面的 golang 安装只是为了通过 spec 检查</p>\n<pre><code># EPEL\nyum install epel-release -y\n# update 系统组件\nyum update -y &amp;&amp; yum upgrade -y\n# 安装基本的编译依赖\nyum install golang go-md2man go-bindata gcc bison git rpm-build vim -y\n# 安装 gvm(用于 golang 版本管理)\nbash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource /root/.gvm/scripts/gvm\n# 安装 1.8 之前需要先安装 1.4\ngvm install go1.4 -B\ngvm use go1.4\n# 使用 golang 1.8 版本 build\ngvm install go1.9\ngvm use go1.9\n</code></pre>\n<h3 id=\"2-2、克隆-build-仓库\"><a href=\"#2-2、克隆-build-仓库\" class=\"headerlink\" title=\"2.2、克隆 build 仓库\"></a>2.2、克隆 build 仓库</h3><p>Fedora 官方 Kubernetes 仓库地址在 这里，如果有版本选择请自行区分</p>\n<pre><code>git clone https://src.fedoraproject.org/git/rpms/nginx.git\n</code></pre>\n<h3 id=\"2-3、从-spec-获取所需文件\"><a href=\"#2-3、从-spec-获取所需文件\" class=\"headerlink\" title=\"2.3、从 spec 获取所需文件\"></a>2.3、从 spec 获取所需文件</h3><p>克隆好 build 仓库后首先查看 kubernetes.spec 文件，确定 build 所需文件，spec 文件如下</p>\n<pre><code>%global  _hardened_build     1\n%global  nginx_user          nginx\n\n# Disable strict symbol checks in the link editor.\n# See: https://src.fedoraproject.org/rpms/redhat-rpm-config/c/078af19\n%undefine _strict_symbol_defs_build\n\n%bcond_with geoip\n\n# gperftools exist only on selected arches\n# gperftools *detection* is failing on ppc64*, possibly only configure\n# bug, but disable anyway.\n%ifnarch s390 s390x ppc64 ppc64le\n%global with_gperftools 1\n%endif\n\n%global with_aio 1\n\n%if 0%&#123;?fedora&#125; &gt; 22\n%global with_mailcap_mimetypes 1\n%endif\n</code></pre>\n<p>从 spec 文件中可以看到 build 主要需要两个仓库的源码，一个是 kubernetes 主仓库，存放着主要的 build 源码；另一个是 contrib 仓库，存放着一些配置文件，如 systemd 配置等</p>\n<p>接下来从 spec 文件的 source 段中可以解读到(source0、source1)最终所需的两个仓库压缩文件名为 kubernetes-SHORTCOMMIT、contrib-SHORTCOMIT，source 段如下</p>\n<pre><code>Name:              nginx\nEpoch:             1\nVersion:           1.11.1\nRelease:           14%&#123;?dist&#125;\n\nSummary:           A high performance web server and reverse proxy server\nGroup:             System Environment/Daemons\n# BSD License (two clause)\n# http://www.freebsd.org/copyright/freebsd-license.html\nLicense:           BSD\nURL:               http://nginx.org/\n\nSource0:           https://nginx.org/download/nginx-%&#123;version&#125;.tar.gz\nSource10:          nginx.service\nSource11:          nginx.logrotate\nSource12:          nginx.conf\nSource13:          nginx-upgrade\nSource14:          nginx-upgrade.8\nSource100:         index.html\nSource101:         poweredby.png\nSource102:         nginx-logo.png\nSource103:         404.html\nSource104:         50x.html\nSource200:         README.dynamic\nSource210:         UPGRADE-NOTES-1.6-to-1.10\n</code></pre>\n<p>我们准备 build 一个最新的 1.12.1 的 rpm,修改</p>\n<pre><code>Name:              nginx\nEpoch:             1\nVersion:           1.12.1\nRelease:           14%&#123;?dist&#125;\n</code></pre>\n<h3 id=\"2-4、准备源码\"><a href=\"#2-4、准备源码\" class=\"headerlink\" title=\"2.4、准备源码\"></a>2.4、准备源码</h3><p>修改好文件以后，就可以下载源码文件了，源码下载不必去克隆 github 项目，直接从 spec 中给出的地址下载即可</p>\n<pre><code>cd nginx\nwget https://nginx.org/download/nginx-1.12.1.tar.gz\n</code></pre>\n<h3 id=\"2-5、build-rpm\"><a href=\"#2-5、build-rpm\" class=\"headerlink\" title=\"2.5、build rpm\"></a>2.5、build rpm</h3><p>在正式开始 build 之前，还有一点需要注意的是 默认的 kubernetes.spec 文件中指定了该 rpm 依赖于 docker 这个包，在 CentOS 上可能我们会安装 docker-engine 或者 docker-ce，此时安装 kubernetes rpm 是无法安装的，因为他以来的包不存在，解决的办法就是编译之前删除 spec 文件中的 Requires: docker 即可，最后创建好 build 目录，并放置好源码文件开始 build 即可，当然 build 可以有不同选择</p>\n<h1 id=\"由于我是-root-用户，所以目录位置在这\"><a href=\"#由于我是-root-用户，所以目录位置在这\" class=\"headerlink\" title=\"由于我是 root 用户，所以目录位置在这\"></a>由于我是 root 用户，所以目录位置在这</h1><h1 id=\"实际生产-强烈不推荐使用-root-build-操作失误会损毁宿主机\"><a href=\"#实际生产-强烈不推荐使用-root-build-操作失误会损毁宿主机\" class=\"headerlink\" title=\"实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)\"></a>实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)</h1><h1 id=\"我的是一台临时-vps，所以无所谓了\"><a href=\"#我的是一台临时-vps，所以无所谓了\" class=\"headerlink\" title=\"我的是一台临时 vps，所以无所谓了\"></a>我的是一台临时 vps，所以无所谓了</h1><pre><code>mkdir -p /root/rpmbuild/SOURCES/\nmv ~/nginx/* /root/rpmbuild/SOURCES/\ncd /root/rpmbuild/SOURCES/\n# 执行 build\nrpmbuild -ba nginx.spec\n</code></pre>\n<p>注意，由于我们选择的版本已经超出了仓库所支持的最大版本，所以有些 Patch 已经不再适用，如 spec 中的 Patch12、Patch19 会出错，所需要注释掉(%prep 段中也有一个)</p>\n<p>rpmbuild 可选项有很多，常用的 3 个，可以根据自己实际需要进行 build:</p>\n<ul>\n<li>-ba : build 源码包+二进制包</li>\n<li>-bb : 只 build 二进制包</li>\n<li>-bs : 只 build 源码包</li>\n</ul>\n<p>最后 build 完成后如下</p>\n<pre><code>[root@test x86_64]# ll\ntotal 2480\n-rw-r--r-- 1 root root  543948 Sep 20 17:21 nginx-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root 1754960 Sep 20 17:21 nginx-debuginfo-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   27544 Sep 20 17:21 nginx-mod-http-image-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   36992 Sep 20 17:21 nginx-mod-http-perl-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   26628 Sep 20 17:21 nginx-mod-http-xslt-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   55316 Sep 20 17:21 nginx-mod-mail-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   78512 Sep 20 17:21 nginx-mod-stream-1.12.1-14.el7.x86_64.rpm\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/\">https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"使用rpmbuild自定义构建rpm包\"><a href=\"#使用rpmbuild自定义构建rpm包\" class=\"headerlink\" title=\"使用rpmbuild自定义构建rpm包\"></a>使用rpmbuild自定义构建rpm包</h1><p>目前我所知道的 build nginx RPM 的方式(测试过)总共 3 种,大致分为 2 类</p>\n<ul>\n<li>基于源码 build</li>\n<li>基于已有 rpm 替换</li>\n</ul>\n<p>第一种方案的好处就是配置文件等能始终保持最新的,编译版本等不受限制;但是从源码 build 非常耗时,尤其是网络环境复杂的情况下,没有高配置国外服务器很难完成 build,而且要维护 build 所需 spec 文件等,自己维护这些未必能够尽善尽美;</p>\n<p>第二种方式是创建速度快,build 方式简单可靠,但是由于是替换方式,所以 rpm 中的配置不一定能够即使更新,而且只能基于官方build 好以后的二进制文件进行替换,如果想要尝试 master 最新代码则无法实现</p>\n<h2 id=\"二、基于源码-Build\"><a href=\"#二、基于源码-Build\" class=\"headerlink\" title=\"二、基于源码 Build\"></a>二、基于源码 Build</h2><p>对于 Centos RPM build 原理方式这里不再细说，基于源码 build 的关键就在于 spec 文件，我尝试过自己去写，后来对比一些开源项目的感觉 low 得很，所以以前一直采用一个国外哥们写的脚本 build<a href=\"https://github.com/JohnTheodore/kubernetes-rpm-builder\">参见这里</a>；这个脚本不太好的地方是作者已经停止了维护；经过不懈努力，找到了 Fedora 系统的 rpm 仓库，鼓捣了一阵摸清了套路；以下主要以 Fedora 仓库为例进行 build</p>\n<p>以下 Build 在一台 Do 8核心 16G VPS 上进行，由于众所周知的原因，国内 Build 很费劲，一般国外 VPS 都是按小时收费，有个 2 块钱就够了</p>\n<h3 id=\"2-1、安装-build-所需依赖\"><a href=\"#2-1、安装-build-所需依赖\" class=\"headerlink\" title=\"2.1、安装 build 所需依赖\"></a>2.1、安装 build 所需依赖</h3><p>由于 spec 文件中定义了依赖于 golang 这个包，所以如果不装的话会报错；事实上如果使用刚刚安装的这个 golang 去 build 还是会挂掉，因为实际编译要求 golang &gt; 1.7，直接 yum 装的是 1.6，故下面又使用 gvm 装了一个 1.8 的 golang，上面的 golang 安装只是为了通过 spec 检查</p>\n<pre><code># EPEL\nyum install epel-release -y\n# update 系统组件\nyum update -y &amp;&amp; yum upgrade -y\n# 安装基本的编译依赖\nyum install golang go-md2man go-bindata gcc bison git rpm-build vim -y\n# 安装 gvm(用于 golang 版本管理)\nbash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource /root/.gvm/scripts/gvm\n# 安装 1.8 之前需要先安装 1.4\ngvm install go1.4 -B\ngvm use go1.4\n# 使用 golang 1.8 版本 build\ngvm install go1.9\ngvm use go1.9\n</code></pre>\n<h3 id=\"2-2、克隆-build-仓库\"><a href=\"#2-2、克隆-build-仓库\" class=\"headerlink\" title=\"2.2、克隆 build 仓库\"></a>2.2、克隆 build 仓库</h3><p>Fedora 官方 Kubernetes 仓库地址在 这里，如果有版本选择请自行区分</p>\n<pre><code>git clone https://src.fedoraproject.org/git/rpms/nginx.git\n</code></pre>\n<h3 id=\"2-3、从-spec-获取所需文件\"><a href=\"#2-3、从-spec-获取所需文件\" class=\"headerlink\" title=\"2.3、从 spec 获取所需文件\"></a>2.3、从 spec 获取所需文件</h3><p>克隆好 build 仓库后首先查看 kubernetes.spec 文件，确定 build 所需文件，spec 文件如下</p>\n<pre><code>%global  _hardened_build     1\n%global  nginx_user          nginx\n\n# Disable strict symbol checks in the link editor.\n# See: https://src.fedoraproject.org/rpms/redhat-rpm-config/c/078af19\n%undefine _strict_symbol_defs_build\n\n%bcond_with geoip\n\n# gperftools exist only on selected arches\n# gperftools *detection* is failing on ppc64*, possibly only configure\n# bug, but disable anyway.\n%ifnarch s390 s390x ppc64 ppc64le\n%global with_gperftools 1\n%endif\n\n%global with_aio 1\n\n%if 0%&#123;?fedora&#125; &gt; 22\n%global with_mailcap_mimetypes 1\n%endif\n</code></pre>\n<p>从 spec 文件中可以看到 build 主要需要两个仓库的源码，一个是 kubernetes 主仓库，存放着主要的 build 源码；另一个是 contrib 仓库，存放着一些配置文件，如 systemd 配置等</p>\n<p>接下来从 spec 文件的 source 段中可以解读到(source0、source1)最终所需的两个仓库压缩文件名为 kubernetes-SHORTCOMMIT、contrib-SHORTCOMIT，source 段如下</p>\n<pre><code>Name:              nginx\nEpoch:             1\nVersion:           1.11.1\nRelease:           14%&#123;?dist&#125;\n\nSummary:           A high performance web server and reverse proxy server\nGroup:             System Environment/Daemons\n# BSD License (two clause)\n# http://www.freebsd.org/copyright/freebsd-license.html\nLicense:           BSD\nURL:               http://nginx.org/\n\nSource0:           https://nginx.org/download/nginx-%&#123;version&#125;.tar.gz\nSource10:          nginx.service\nSource11:          nginx.logrotate\nSource12:          nginx.conf\nSource13:          nginx-upgrade\nSource14:          nginx-upgrade.8\nSource100:         index.html\nSource101:         poweredby.png\nSource102:         nginx-logo.png\nSource103:         404.html\nSource104:         50x.html\nSource200:         README.dynamic\nSource210:         UPGRADE-NOTES-1.6-to-1.10\n</code></pre>\n<p>我们准备 build 一个最新的 1.12.1 的 rpm,修改</p>\n<pre><code>Name:              nginx\nEpoch:             1\nVersion:           1.12.1\nRelease:           14%&#123;?dist&#125;\n</code></pre>\n<h3 id=\"2-4、准备源码\"><a href=\"#2-4、准备源码\" class=\"headerlink\" title=\"2.4、准备源码\"></a>2.4、准备源码</h3><p>修改好文件以后，就可以下载源码文件了，源码下载不必去克隆 github 项目，直接从 spec 中给出的地址下载即可</p>\n<pre><code>cd nginx\nwget https://nginx.org/download/nginx-1.12.1.tar.gz\n</code></pre>\n<h3 id=\"2-5、build-rpm\"><a href=\"#2-5、build-rpm\" class=\"headerlink\" title=\"2.5、build rpm\"></a>2.5、build rpm</h3><p>在正式开始 build 之前，还有一点需要注意的是 默认的 kubernetes.spec 文件中指定了该 rpm 依赖于 docker 这个包，在 CentOS 上可能我们会安装 docker-engine 或者 docker-ce，此时安装 kubernetes rpm 是无法安装的，因为他以来的包不存在，解决的办法就是编译之前删除 spec 文件中的 Requires: docker 即可，最后创建好 build 目录，并放置好源码文件开始 build 即可，当然 build 可以有不同选择</p>\n<h1 id=\"由于我是-root-用户，所以目录位置在这\"><a href=\"#由于我是-root-用户，所以目录位置在这\" class=\"headerlink\" title=\"由于我是 root 用户，所以目录位置在这\"></a>由于我是 root 用户，所以目录位置在这</h1><h1 id=\"实际生产-强烈不推荐使用-root-build-操作失误会损毁宿主机\"><a href=\"#实际生产-强烈不推荐使用-root-build-操作失误会损毁宿主机\" class=\"headerlink\" title=\"实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)\"></a>实际生产 强烈不推荐使用 root build(操作失误会损毁宿主机)</h1><h1 id=\"我的是一台临时-vps，所以无所谓了\"><a href=\"#我的是一台临时-vps，所以无所谓了\" class=\"headerlink\" title=\"我的是一台临时 vps，所以无所谓了\"></a>我的是一台临时 vps，所以无所谓了</h1><pre><code>mkdir -p /root/rpmbuild/SOURCES/\nmv ~/nginx/* /root/rpmbuild/SOURCES/\ncd /root/rpmbuild/SOURCES/\n# 执行 build\nrpmbuild -ba nginx.spec\n</code></pre>\n<p>注意，由于我们选择的版本已经超出了仓库所支持的最大版本，所以有些 Patch 已经不再适用，如 spec 中的 Patch12、Patch19 会出错，所需要注释掉(%prep 段中也有一个)</p>\n<p>rpmbuild 可选项有很多，常用的 3 个，可以根据自己实际需要进行 build:</p>\n<ul>\n<li>-ba : build 源码包+二进制包</li>\n<li>-bb : 只 build 二进制包</li>\n<li>-bs : 只 build 源码包</li>\n</ul>\n<p>最后 build 完成后如下</p>\n<pre><code>[root@test x86_64]# ll\ntotal 2480\n-rw-r--r-- 1 root root  543948 Sep 20 17:21 nginx-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root 1754960 Sep 20 17:21 nginx-debuginfo-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   27544 Sep 20 17:21 nginx-mod-http-image-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   36992 Sep 20 17:21 nginx-mod-http-perl-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   26628 Sep 20 17:21 nginx-mod-http-xslt-filter-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   55316 Sep 20 17:21 nginx-mod-mail-1.12.1-14.el7.x86_64.rpm\n-rw-r--r-- 1 root root   78512 Sep 20 17:21 nginx-mod-stream-1.12.1-14.el7.x86_64.rpm\n</code></pre>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/\">https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/</a></li>\n</ul>\n"},{"layout":"post","title":"Docker Swarm 学习笔记总结","date":"2018-11-28T10:23:54.000Z","author":"owelinux","excerpt":"Docker Swarm 学习笔记总结","mathjax":true,"_content":"\n* content\n{:toc}\n\n# Docker Swarm 学习笔记总结 \n\n## Swarm 介绍\nDocker Swarm是Docker官方提供的集群工具。它可以将一些关联的Docker主机转变成一个虚拟Docker主机。因为Docker Swarm符合Docker API的标准,任何已经可以与Docker守护进程通信的工具都可以使用Swarm来透明地扩展到多个主机。支持工具包括:\n\n*    Dokku\n*    Docker Compose\n*    Docker Machine\n*    Jenkins\n\n\n## Swarm 架构\nSwarm 是用来被用来管理 Docker 集群的，所以单个 Docker host 是整个集群的基础。Swarm 自身可以有两种安装方式，一种是当成普通的 Docker 容器来安装，一种是当成一个简单的应用被安装在一台虚拟机或者物理机上。它的架构图如下：\n\n![Swarm 架构图](https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index1869.png)\n\n\n所有的 Docker node 都会被当成一个调度候选对象。类似于 OpenStack 中的 compute node.\n\n## Swarm 集群功能\n\n### Swarm 调度器\n\n调度是集群中十分重要的功能，Swarm目前支持三种调度策略：Spread、Binpack和random。\n在执行swarm manage启动管理服务时，可通过--strategy参数指定调度策略，默认是：spread。\n\n三种调度策略的优缺点：\n\n* spread： 配置相同情况下，选择一个正在运行的容器数量最少的那个节点，平摊容器到各个节点。\n\n* binpack：尽可能将所有容器放在一台节点上运行，尽量少用节点，避免容器碎片化。\n\n* random： 直接随机分配，不考虑集群节点状态，方便进行测试使用。\n\n### Swarm 过滤器\nSwarm 过滤器（filter）可以实现特定的容器分配到特点的节点上。目前支持物种过滤器：Constraint、Affinity、Port、Dependency、Health。\n\n* Constraint 过滤器： 绑定到节点的键值对，相当于给节点打标签。比如在启动Docker服务时，指定某个节点颜色为 red。\n\n* Affinity 过滤器：允许用户在启动一个容器的时候，让它分配到某个已有容器的节点上。\n\n* 其他过滤器也类似，通过-e affinity:image==<name or id>选择拥有指定镜像的节点，通过-e affinity:lael_name==value来选择拥有指定标签的容器所允许的节点。 \n\n### Swarm 服务发现\n\n通过不同的路径来选择特定的服务发现后端机制：\n\n* token://<token>: 使用Docker Hub提供的服务，适用于公网；\n* file://pah/to/file：使用本地文件，需手动管理；\n* consul://<ip>/<path>：使用consul服务，私有环境；\n* etcd://<ip1>,<ip2>,<ip3>/<path>：使用etcd服务，私有环境；\n* zk://<ip1>,<ip2>,<ip3>/<path>：使用zk服务，私有环境；\n* [nodes://]<ip1>,<ip2>,<ip3>：手动指定集群中节点地址，方便进行服务测试。\n\n## Swarm 集群实战\n\n### 安装Dcoker Swarm的方式\n安装Docker Swarm有两种方式：\n\n* 直接以swarm为镜像模板启动容器；\n* 在系统中安装swarm的二进制可执行文件。\n\n官网也列举出了这两种方法的优缺点：\n\n以swarm镜像启动容器：\n\n* 无需在系统中安装可执行的二进制文件；\n* 用docker run命令每次都可以获取并运行最近版本的镜像；\n* 容器是Swarm与主机环境相隔离，无需维护shell的路径和环境。\n\n在系统中安装swarm：\n\n* Swarm项目的开发者在测试代码变更的过程中，无需在运行该二进制文件前进行容器化(“containerizing”)操作。\n\n### 集群创建步骤\n创建一个Swarm集群的第一步是从网上拉取Docker Swarm镜像。然后,你可以使用Docker配置Swarm manager和所有节点运行Docker Swarm。步骤:\n\n* 在每个节点上打开一个TCP端口用于跟Swarm manager通信\n* 在每个节点上安装Docker\n* 创建和管理TLS证书以保护集群\n\n### 集群部署环境\n\n    Docker01 和 Docker02 分别对应 manager0 和 manager1；\n    Docker04 和 Docker05 分别对应 node0 和 node1；\n    Docker03 对应 consul0；\n\n配置ssl证书及安装docker服务\n```\nmkdir -p /etc/docker/certs.d/DomainName:Port\ncp ca.crt /etc/docker/certs.d/DomainName:Port/\nservice docker restart\n```\n\n创建Swarm集群：\n```\n # 在高可用的Swarm集群中创建主管理者\n # 操作对象 manager0 和 consul0\n # <manager0_ip> 和 <consul_ip>相同\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager0_ip>:4000 consul://<consul_ip>:8500\n\n # 操作对象 manager1\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager1_ip>:4000 consul://172.30.0.161:8500\n\n # 操作对象 node0 和 node1\n docker run -d swarm join --advertise=<node_ip>:2375 consul://<consul_ip>:8500\n```\n\n集群使用：\n```\n # 操作对象 manager0 和 consul0\n docker -H :4000 info\n\n # 在Swarm集群中运行应用\n docker -H :4000 run hello-world\n\n # 查询Swarm集群的哪个节点在运行该应用\n docker -H :4000 ps\n- 测试Swarm集群的故障；\n # 获取swarm容器的id或名称\n # 操作对象 manager0\n docker ps\n\n # 删除或关闭当前的主管理者 manager0\n docker rm -f <id_name>\n\n # 创建或启动Swarm集群管理者 manager0\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager0_ip>:4000 consul://<consul_ip>:8500\n\n # 查看该容器的日志\n sudo docker logs <id_name>\n\n # 获取集群管理者和节点的信息\n docker -H :4000 info\n```\n## 个人总结\n\n### Swarm 上的容器选择\n\n* 适合无状态服务：web服务、反向代理、采集器等\n* 不适合有状态服务：数据库、redis、zk等\n### 设置Docker仓库\n* 指明Docker仓库地址\n* 私有仓库增加参数：--with-registry-auth\n* 使用tag进行版本上线及回滚\n\n### 改造无状态化应用容器\n* 采用共享存储挂载方式\n\n### 日志采集服务\n集中式的日志和指标是使用分布式文件系统的必须项，如ELK，Graphana，Graylog 等等。\n\n这里有许多可选项，有开源项目，也有SaaS类服务。这些打造和整合成可靠的服务是复杂且艰难的。建议先使用云端服务（如Loggly, Logentries）, 当成本上涨的时候，再开始架设自己的日志收集服务。\n例：ELK 栈日志处理配置:\n```\ndocker service update \\ --log-driver gelf \\\n--log-opt gelf-address=udp://monitoring.example.com:12201 \\\n--log-opt tag=example-tag \\\nexample-service\n```\n\n### 创建可附加的网络\n记得使用它，否则无法在Docker Swarm下一条命令跑起一个容器。这是Docker1.13+新功能。如果使用旧版本的Docker, 最好升级下。\n\n代码：\n```\ndocker network create --driver=overlay --attachable core\n```\n\n### 增加环境变量\n如果创建Docker镜像的时候，遵循了最佳实践原则（https://rock-it.pl/how-to-writ ... iles/），允许在运行的时候通过环境变量设置一切配置项，那么把应用迁到Swarm的过程完全没有问题。\n\n例，有用的命令：\n\n```\ndocker service create \\\n\n--env VAR=VALUE \\\n--env-file FILENAME \\\n...\n\ndocker service update \\\n\n--env-add VAR=NEW_VALUE \\\n--env-rm VAR \\\n..\n```\n\n下一个级别就是使用非公开的API挂载文件像挂载秘钥那样（Authorized keys, SSL certs 等）。作者暂时还未使用此功能，不能详述，但这个功能特性绝对值得思考和使用。\n\n### 设置适当实例和批量更新\n保持适当数量的实例，以应对高流量和实例或者节点不可用的情况。同时太多的实例数也会占用CPU和内存，并且导致争抢CUP资源。\n\nupdate-parallelism的默认值是1，默认只有一个实例在运行。但这个更新速度太慢了，建议是 replicas / 2。\n\n相关命令：\n\n```\ndocker service update \\\n\n--update-parallelism 10 \\\nwebapp\n\nYou can scale multiple services at once\ndocker service scale redis=1 nginx=4 webapp=20\n\nCheck scaling status\ndocker service ls\n\nCheck details of a service (without stopped containers)\ndocker service ps webapp | grep -v \"Shutdown\"\n```\n\n### 把Swarm配置保存为代码\n最好使用Docker Compose v3版本的语法（https://docs.docker.com/compos ... eploy）。\n\n他允许使用代码指定几乎所有的服务选项。作者在开发的时候使用 Docker-compose.yml，在生产环境（swarm）配置使用 Docker-compose.prod.yml . 部署Docker-compose文件中所描述的服务，需要Docker stack deploy 命令（属于新版本 Stack命令集合中的一部分[https://docs.docker.com/engine ... tack/]）\n\nDocker compose v3例子：\n\n```\ndocker-compose.prod.yml\nversion: '3'\n\nservices:\n\nwebapp:\nimage: registry.example.com/webapp\nnetworks:\n- ingress\ndeploy:\nreplicas: ${WEBAPP_REPLICAS}\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nproxy:\nimage: registry.example.com/webapp-nginx-proxy\nnetworks:\n- ingress\nports:\n- 80:80\n- 443:443\ndeploy:\nreplicas: ${NGINX_REPLICAS}\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nnetworks:\n\ningress:\nexternal: true\n```\n\n部署的例子（创建或者更新服务）：\n\n```\nexport NGINX_REPLICAS=2 WEBAPP_REPLICAS=5\n\ndocker login registry.example.com\n\ndocker stack deploy \\\n\n-c docker-compose.prod.yml\\\n--with-registry-auth \\\nfrontend\n```\n\n提示：Docker-compose文件支持环境变量 (${VARIABLE}), 所以，可以动态调整配置作为测试等。\n\n### 设置限制\n就经验而言，可以为所有服务设置CPU使用限制。当某一个容器应用占用掉所有主机资源时，此限制可以避免这种情况发生。\n\n当想把所有容器均匀地发布在所有主机上或是想确保有足够的资源来响应操作时，需使用Reserve-cpu这个参数。\n\n例如：\n```\ndocker service update --limit-cpu 0.25\n--reserve-cpu 0.1\nwebapp\n```\n\n### 监控连接\n曾经在Swarm网络上遇到过一些问题。很多次所有的流量都被路由到同一个容器实例上，而同时有9个容器实例正常且健康的。这种情况下——即流量持续导到一个实例上，做扩容或者缩容操作的时候，加上这个参数--endpoint-mode 。\n\n## 参考文档\n[https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html](https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html)\n\n[http://dockone.io/article/1486](http://dockone.io/article/1486)\n\n[http://dockone.io/article/2318](http://dockone.io/article/2318)\n\n[https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/](https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/)\n\n[Docker技术入门于实战~Swarm章节]()","source":"_posts/2018-11-28-article38-docker-swarm.md","raw":"---\nlayout: post\ntitle:  \"Docker Swarm 学习笔记总结\"\ndate:   2018-11-28 18:23:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: Docker Swarm 学习笔记总结\nmathjax: true\n---\n\n* content\n{:toc}\n\n# Docker Swarm 学习笔记总结 \n\n## Swarm 介绍\nDocker Swarm是Docker官方提供的集群工具。它可以将一些关联的Docker主机转变成一个虚拟Docker主机。因为Docker Swarm符合Docker API的标准,任何已经可以与Docker守护进程通信的工具都可以使用Swarm来透明地扩展到多个主机。支持工具包括:\n\n*    Dokku\n*    Docker Compose\n*    Docker Machine\n*    Jenkins\n\n\n## Swarm 架构\nSwarm 是用来被用来管理 Docker 集群的，所以单个 Docker host 是整个集群的基础。Swarm 自身可以有两种安装方式，一种是当成普通的 Docker 容器来安装，一种是当成一个简单的应用被安装在一台虚拟机或者物理机上。它的架构图如下：\n\n![Swarm 架构图](https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index1869.png)\n\n\n所有的 Docker node 都会被当成一个调度候选对象。类似于 OpenStack 中的 compute node.\n\n## Swarm 集群功能\n\n### Swarm 调度器\n\n调度是集群中十分重要的功能，Swarm目前支持三种调度策略：Spread、Binpack和random。\n在执行swarm manage启动管理服务时，可通过--strategy参数指定调度策略，默认是：spread。\n\n三种调度策略的优缺点：\n\n* spread： 配置相同情况下，选择一个正在运行的容器数量最少的那个节点，平摊容器到各个节点。\n\n* binpack：尽可能将所有容器放在一台节点上运行，尽量少用节点，避免容器碎片化。\n\n* random： 直接随机分配，不考虑集群节点状态，方便进行测试使用。\n\n### Swarm 过滤器\nSwarm 过滤器（filter）可以实现特定的容器分配到特点的节点上。目前支持物种过滤器：Constraint、Affinity、Port、Dependency、Health。\n\n* Constraint 过滤器： 绑定到节点的键值对，相当于给节点打标签。比如在启动Docker服务时，指定某个节点颜色为 red。\n\n* Affinity 过滤器：允许用户在启动一个容器的时候，让它分配到某个已有容器的节点上。\n\n* 其他过滤器也类似，通过-e affinity:image==<name or id>选择拥有指定镜像的节点，通过-e affinity:lael_name==value来选择拥有指定标签的容器所允许的节点。 \n\n### Swarm 服务发现\n\n通过不同的路径来选择特定的服务发现后端机制：\n\n* token://<token>: 使用Docker Hub提供的服务，适用于公网；\n* file://pah/to/file：使用本地文件，需手动管理；\n* consul://<ip>/<path>：使用consul服务，私有环境；\n* etcd://<ip1>,<ip2>,<ip3>/<path>：使用etcd服务，私有环境；\n* zk://<ip1>,<ip2>,<ip3>/<path>：使用zk服务，私有环境；\n* [nodes://]<ip1>,<ip2>,<ip3>：手动指定集群中节点地址，方便进行服务测试。\n\n## Swarm 集群实战\n\n### 安装Dcoker Swarm的方式\n安装Docker Swarm有两种方式：\n\n* 直接以swarm为镜像模板启动容器；\n* 在系统中安装swarm的二进制可执行文件。\n\n官网也列举出了这两种方法的优缺点：\n\n以swarm镜像启动容器：\n\n* 无需在系统中安装可执行的二进制文件；\n* 用docker run命令每次都可以获取并运行最近版本的镜像；\n* 容器是Swarm与主机环境相隔离，无需维护shell的路径和环境。\n\n在系统中安装swarm：\n\n* Swarm项目的开发者在测试代码变更的过程中，无需在运行该二进制文件前进行容器化(“containerizing”)操作。\n\n### 集群创建步骤\n创建一个Swarm集群的第一步是从网上拉取Docker Swarm镜像。然后,你可以使用Docker配置Swarm manager和所有节点运行Docker Swarm。步骤:\n\n* 在每个节点上打开一个TCP端口用于跟Swarm manager通信\n* 在每个节点上安装Docker\n* 创建和管理TLS证书以保护集群\n\n### 集群部署环境\n\n    Docker01 和 Docker02 分别对应 manager0 和 manager1；\n    Docker04 和 Docker05 分别对应 node0 和 node1；\n    Docker03 对应 consul0；\n\n配置ssl证书及安装docker服务\n```\nmkdir -p /etc/docker/certs.d/DomainName:Port\ncp ca.crt /etc/docker/certs.d/DomainName:Port/\nservice docker restart\n```\n\n创建Swarm集群：\n```\n # 在高可用的Swarm集群中创建主管理者\n # 操作对象 manager0 和 consul0\n # <manager0_ip> 和 <consul_ip>相同\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager0_ip>:4000 consul://<consul_ip>:8500\n\n # 操作对象 manager1\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager1_ip>:4000 consul://172.30.0.161:8500\n\n # 操作对象 node0 和 node1\n docker run -d swarm join --advertise=<node_ip>:2375 consul://<consul_ip>:8500\n```\n\n集群使用：\n```\n # 操作对象 manager0 和 consul0\n docker -H :4000 info\n\n # 在Swarm集群中运行应用\n docker -H :4000 run hello-world\n\n # 查询Swarm集群的哪个节点在运行该应用\n docker -H :4000 ps\n- 测试Swarm集群的故障；\n # 获取swarm容器的id或名称\n # 操作对象 manager0\n docker ps\n\n # 删除或关闭当前的主管理者 manager0\n docker rm -f <id_name>\n\n # 创建或启动Swarm集群管理者 manager0\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise <manager0_ip>:4000 consul://<consul_ip>:8500\n\n # 查看该容器的日志\n sudo docker logs <id_name>\n\n # 获取集群管理者和节点的信息\n docker -H :4000 info\n```\n## 个人总结\n\n### Swarm 上的容器选择\n\n* 适合无状态服务：web服务、反向代理、采集器等\n* 不适合有状态服务：数据库、redis、zk等\n### 设置Docker仓库\n* 指明Docker仓库地址\n* 私有仓库增加参数：--with-registry-auth\n* 使用tag进行版本上线及回滚\n\n### 改造无状态化应用容器\n* 采用共享存储挂载方式\n\n### 日志采集服务\n集中式的日志和指标是使用分布式文件系统的必须项，如ELK，Graphana，Graylog 等等。\n\n这里有许多可选项，有开源项目，也有SaaS类服务。这些打造和整合成可靠的服务是复杂且艰难的。建议先使用云端服务（如Loggly, Logentries）, 当成本上涨的时候，再开始架设自己的日志收集服务。\n例：ELK 栈日志处理配置:\n```\ndocker service update \\ --log-driver gelf \\\n--log-opt gelf-address=udp://monitoring.example.com:12201 \\\n--log-opt tag=example-tag \\\nexample-service\n```\n\n### 创建可附加的网络\n记得使用它，否则无法在Docker Swarm下一条命令跑起一个容器。这是Docker1.13+新功能。如果使用旧版本的Docker, 最好升级下。\n\n代码：\n```\ndocker network create --driver=overlay --attachable core\n```\n\n### 增加环境变量\n如果创建Docker镜像的时候，遵循了最佳实践原则（https://rock-it.pl/how-to-writ ... iles/），允许在运行的时候通过环境变量设置一切配置项，那么把应用迁到Swarm的过程完全没有问题。\n\n例，有用的命令：\n\n```\ndocker service create \\\n\n--env VAR=VALUE \\\n--env-file FILENAME \\\n...\n\ndocker service update \\\n\n--env-add VAR=NEW_VALUE \\\n--env-rm VAR \\\n..\n```\n\n下一个级别就是使用非公开的API挂载文件像挂载秘钥那样（Authorized keys, SSL certs 等）。作者暂时还未使用此功能，不能详述，但这个功能特性绝对值得思考和使用。\n\n### 设置适当实例和批量更新\n保持适当数量的实例，以应对高流量和实例或者节点不可用的情况。同时太多的实例数也会占用CPU和内存，并且导致争抢CUP资源。\n\nupdate-parallelism的默认值是1，默认只有一个实例在运行。但这个更新速度太慢了，建议是 replicas / 2。\n\n相关命令：\n\n```\ndocker service update \\\n\n--update-parallelism 10 \\\nwebapp\n\nYou can scale multiple services at once\ndocker service scale redis=1 nginx=4 webapp=20\n\nCheck scaling status\ndocker service ls\n\nCheck details of a service (without stopped containers)\ndocker service ps webapp | grep -v \"Shutdown\"\n```\n\n### 把Swarm配置保存为代码\n最好使用Docker Compose v3版本的语法（https://docs.docker.com/compos ... eploy）。\n\n他允许使用代码指定几乎所有的服务选项。作者在开发的时候使用 Docker-compose.yml，在生产环境（swarm）配置使用 Docker-compose.prod.yml . 部署Docker-compose文件中所描述的服务，需要Docker stack deploy 命令（属于新版本 Stack命令集合中的一部分[https://docs.docker.com/engine ... tack/]）\n\nDocker compose v3例子：\n\n```\ndocker-compose.prod.yml\nversion: '3'\n\nservices:\n\nwebapp:\nimage: registry.example.com/webapp\nnetworks:\n- ingress\ndeploy:\nreplicas: ${WEBAPP_REPLICAS}\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nproxy:\nimage: registry.example.com/webapp-nginx-proxy\nnetworks:\n- ingress\nports:\n- 80:80\n- 443:443\ndeploy:\nreplicas: ${NGINX_REPLICAS}\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nnetworks:\n\ningress:\nexternal: true\n```\n\n部署的例子（创建或者更新服务）：\n\n```\nexport NGINX_REPLICAS=2 WEBAPP_REPLICAS=5\n\ndocker login registry.example.com\n\ndocker stack deploy \\\n\n-c docker-compose.prod.yml\\\n--with-registry-auth \\\nfrontend\n```\n\n提示：Docker-compose文件支持环境变量 (${VARIABLE}), 所以，可以动态调整配置作为测试等。\n\n### 设置限制\n就经验而言，可以为所有服务设置CPU使用限制。当某一个容器应用占用掉所有主机资源时，此限制可以避免这种情况发生。\n\n当想把所有容器均匀地发布在所有主机上或是想确保有足够的资源来响应操作时，需使用Reserve-cpu这个参数。\n\n例如：\n```\ndocker service update --limit-cpu 0.25\n--reserve-cpu 0.1\nwebapp\n```\n\n### 监控连接\n曾经在Swarm网络上遇到过一些问题。很多次所有的流量都被路由到同一个容器实例上，而同时有9个容器实例正常且健康的。这种情况下——即流量持续导到一个实例上，做扩容或者缩容操作的时候，加上这个参数--endpoint-mode 。\n\n## 参考文档\n[https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html](https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html)\n\n[http://dockone.io/article/1486](http://dockone.io/article/1486)\n\n[http://dockone.io/article/2318](http://dockone.io/article/2318)\n\n[https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/](https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/)\n\n[Docker技术入门于实战~Swarm章节]()","slug":"2018-11-28-article38-docker-swarm","published":1,"updated":"2021-02-09T02:00:24.577Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0u002syc97d9n5g4e5","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-Swarm-学习笔记总结\"><a href=\"#Docker-Swarm-学习笔记总结\" class=\"headerlink\" title=\"Docker Swarm 学习笔记总结\"></a>Docker Swarm 学习笔记总结</h1><h2 id=\"Swarm-介绍\"><a href=\"#Swarm-介绍\" class=\"headerlink\" title=\"Swarm 介绍\"></a>Swarm 介绍</h2><p>Docker Swarm是Docker官方提供的集群工具。它可以将一些关联的Docker主机转变成一个虚拟Docker主机。因为Docker Swarm符合Docker API的标准,任何已经可以与Docker守护进程通信的工具都可以使用Swarm来透明地扩展到多个主机。支持工具包括:</p>\n<ul>\n<li>   Dokku</li>\n<li>   Docker Compose</li>\n<li>   Docker Machine</li>\n<li>   Jenkins</li>\n</ul>\n<h2 id=\"Swarm-架构\"><a href=\"#Swarm-架构\" class=\"headerlink\" title=\"Swarm 架构\"></a>Swarm 架构</h2><p>Swarm 是用来被用来管理 Docker 集群的，所以单个 Docker host 是整个集群的基础。Swarm 自身可以有两种安装方式，一种是当成普通的 Docker 容器来安装，一种是当成一个简单的应用被安装在一台虚拟机或者物理机上。它的架构图如下：</p>\n<p><img src=\"https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index1869.png\" alt=\"Swarm 架构图\"></p>\n<p>所有的 Docker node 都会被当成一个调度候选对象。类似于 OpenStack 中的 compute node.</p>\n<h2 id=\"Swarm-集群功能\"><a href=\"#Swarm-集群功能\" class=\"headerlink\" title=\"Swarm 集群功能\"></a>Swarm 集群功能</h2><h3 id=\"Swarm-调度器\"><a href=\"#Swarm-调度器\" class=\"headerlink\" title=\"Swarm 调度器\"></a>Swarm 调度器</h3><p>调度是集群中十分重要的功能，Swarm目前支持三种调度策略：Spread、Binpack和random。<br>在执行swarm manage启动管理服务时，可通过–strategy参数指定调度策略，默认是：spread。</p>\n<p>三种调度策略的优缺点：</p>\n<ul>\n<li><p>spread： 配置相同情况下，选择一个正在运行的容器数量最少的那个节点，平摊容器到各个节点。</p>\n</li>\n<li><p>binpack：尽可能将所有容器放在一台节点上运行，尽量少用节点，避免容器碎片化。</p>\n</li>\n<li><p>random： 直接随机分配，不考虑集群节点状态，方便进行测试使用。</p>\n</li>\n</ul>\n<h3 id=\"Swarm-过滤器\"><a href=\"#Swarm-过滤器\" class=\"headerlink\" title=\"Swarm 过滤器\"></a>Swarm 过滤器</h3><p>Swarm 过滤器（filter）可以实现特定的容器分配到特点的节点上。目前支持物种过滤器：Constraint、Affinity、Port、Dependency、Health。</p>\n<ul>\n<li><p>Constraint 过滤器： 绑定到节点的键值对，相当于给节点打标签。比如在启动Docker服务时，指定某个节点颜色为 red。</p>\n</li>\n<li><p>Affinity 过滤器：允许用户在启动一个容器的时候，让它分配到某个已有容器的节点上。</p>\n</li>\n<li><p>其他过滤器也类似，通过-e affinity:image==<name or id>选择拥有指定镜像的节点，通过-e affinity:lael_name==value来选择拥有指定标签的容器所允许的节点。 </p>\n</li>\n</ul>\n<h3 id=\"Swarm-服务发现\"><a href=\"#Swarm-服务发现\" class=\"headerlink\" title=\"Swarm 服务发现\"></a>Swarm 服务发现</h3><p>通过不同的路径来选择特定的服务发现后端机制：</p>\n<ul>\n<li>token://<token>: 使用Docker Hub提供的服务，适用于公网；</li>\n<li>file://pah/to/file：使用本地文件，需手动管理；</li>\n<li>consul://<ip>/<path>：使用consul服务，私有环境；</li>\n<li>etcd://<ip1>,<ip2>,<ip3>/<path>：使用etcd服务，私有环境；</li>\n<li>zk://<ip1>,<ip2>,<ip3>/<path>：使用zk服务，私有环境；</li>\n<li>[nodes://]<ip1>,<ip2>,<ip3>：手动指定集群中节点地址，方便进行服务测试。</li>\n</ul>\n<h2 id=\"Swarm-集群实战\"><a href=\"#Swarm-集群实战\" class=\"headerlink\" title=\"Swarm 集群实战\"></a>Swarm 集群实战</h2><h3 id=\"安装Dcoker-Swarm的方式\"><a href=\"#安装Dcoker-Swarm的方式\" class=\"headerlink\" title=\"安装Dcoker Swarm的方式\"></a>安装Dcoker Swarm的方式</h3><p>安装Docker Swarm有两种方式：</p>\n<ul>\n<li>直接以swarm为镜像模板启动容器；</li>\n<li>在系统中安装swarm的二进制可执行文件。</li>\n</ul>\n<p>官网也列举出了这两种方法的优缺点：</p>\n<p>以swarm镜像启动容器：</p>\n<ul>\n<li>无需在系统中安装可执行的二进制文件；</li>\n<li>用docker run命令每次都可以获取并运行最近版本的镜像；</li>\n<li>容器是Swarm与主机环境相隔离，无需维护shell的路径和环境。</li>\n</ul>\n<p>在系统中安装swarm：</p>\n<ul>\n<li>Swarm项目的开发者在测试代码变更的过程中，无需在运行该二进制文件前进行容器化(“containerizing”)操作。</li>\n</ul>\n<h3 id=\"集群创建步骤\"><a href=\"#集群创建步骤\" class=\"headerlink\" title=\"集群创建步骤\"></a>集群创建步骤</h3><p>创建一个Swarm集群的第一步是从网上拉取Docker Swarm镜像。然后,你可以使用Docker配置Swarm manager和所有节点运行Docker Swarm。步骤:</p>\n<ul>\n<li>在每个节点上打开一个TCP端口用于跟Swarm manager通信</li>\n<li>在每个节点上安装Docker</li>\n<li>创建和管理TLS证书以保护集群</li>\n</ul>\n<h3 id=\"集群部署环境\"><a href=\"#集群部署环境\" class=\"headerlink\" title=\"集群部署环境\"></a>集群部署环境</h3><pre><code>Docker01 和 Docker02 分别对应 manager0 和 manager1；\nDocker04 和 Docker05 分别对应 node0 和 node1；\nDocker03 对应 consul0；\n</code></pre>\n<p>配置ssl证书及安装docker服务</p>\n<pre><code>mkdir -p /etc/docker/certs.d/DomainName:Port\ncp ca.crt /etc/docker/certs.d/DomainName:Port/\nservice docker restart\n</code></pre>\n<p>创建Swarm集群：</p>\n<pre><code> # 在高可用的Swarm集群中创建主管理者\n # 操作对象 manager0 和 consul0\n # &lt;manager0_ip&gt; 和 &lt;consul_ip&gt;相同\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager0_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500\n\n # 操作对象 manager1\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager1_ip&gt;:4000 consul://172.30.0.161:8500\n\n # 操作对象 node0 和 node1\n docker run -d swarm join --advertise=&lt;node_ip&gt;:2375 consul://&lt;consul_ip&gt;:8500\n</code></pre>\n<p>集群使用：</p>\n<pre><code> # 操作对象 manager0 和 consul0\n docker -H :4000 info\n\n # 在Swarm集群中运行应用\n docker -H :4000 run hello-world\n\n # 查询Swarm集群的哪个节点在运行该应用\n docker -H :4000 ps\n- 测试Swarm集群的故障；\n # 获取swarm容器的id或名称\n # 操作对象 manager0\n docker ps\n\n # 删除或关闭当前的主管理者 manager0\n docker rm -f &lt;id_name&gt;\n\n # 创建或启动Swarm集群管理者 manager0\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager0_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500\n\n # 查看该容器的日志\n sudo docker logs &lt;id_name&gt;\n\n # 获取集群管理者和节点的信息\n docker -H :4000 info\n</code></pre>\n<h2 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h2><h3 id=\"Swarm-上的容器选择\"><a href=\"#Swarm-上的容器选择\" class=\"headerlink\" title=\"Swarm 上的容器选择\"></a>Swarm 上的容器选择</h3><ul>\n<li>适合无状态服务：web服务、反向代理、采集器等</li>\n<li>不适合有状态服务：数据库、redis、zk等<h3 id=\"设置Docker仓库\"><a href=\"#设置Docker仓库\" class=\"headerlink\" title=\"设置Docker仓库\"></a>设置Docker仓库</h3></li>\n<li>指明Docker仓库地址</li>\n<li>私有仓库增加参数：–with-registry-auth</li>\n<li>使用tag进行版本上线及回滚</li>\n</ul>\n<h3 id=\"改造无状态化应用容器\"><a href=\"#改造无状态化应用容器\" class=\"headerlink\" title=\"改造无状态化应用容器\"></a>改造无状态化应用容器</h3><ul>\n<li>采用共享存储挂载方式</li>\n</ul>\n<h3 id=\"日志采集服务\"><a href=\"#日志采集服务\" class=\"headerlink\" title=\"日志采集服务\"></a>日志采集服务</h3><p>集中式的日志和指标是使用分布式文件系统的必须项，如ELK，Graphana，Graylog 等等。</p>\n<p>这里有许多可选项，有开源项目，也有SaaS类服务。这些打造和整合成可靠的服务是复杂且艰难的。建议先使用云端服务（如Loggly, Logentries）, 当成本上涨的时候，再开始架设自己的日志收集服务。<br>例：ELK 栈日志处理配置:</p>\n<pre><code>docker service update \\ --log-driver gelf \\\n--log-opt gelf-address=udp://monitoring.example.com:12201 \\\n--log-opt tag=example-tag \\\nexample-service\n</code></pre>\n<h3 id=\"创建可附加的网络\"><a href=\"#创建可附加的网络\" class=\"headerlink\" title=\"创建可附加的网络\"></a>创建可附加的网络</h3><p>记得使用它，否则无法在Docker Swarm下一条命令跑起一个容器。这是Docker1.13+新功能。如果使用旧版本的Docker, 最好升级下。</p>\n<p>代码：</p>\n<pre><code>docker network create --driver=overlay --attachable core\n</code></pre>\n<h3 id=\"增加环境变量\"><a href=\"#增加环境变量\" class=\"headerlink\" title=\"增加环境变量\"></a>增加环境变量</h3><p>如果创建Docker镜像的时候，遵循了最佳实践原则（<a href=\"https://rock-it.pl/how-to-writ\">https://rock-it.pl/how-to-writ</a> … iles/），允许在运行的时候通过环境变量设置一切配置项，那么把应用迁到Swarm的过程完全没有问题。</p>\n<p>例，有用的命令：</p>\n<pre><code>docker service create \\\n\n--env VAR=VALUE \\\n--env-file FILENAME \\\n...\n\ndocker service update \\\n\n--env-add VAR=NEW_VALUE \\\n--env-rm VAR \\\n..\n</code></pre>\n<p>下一个级别就是使用非公开的API挂载文件像挂载秘钥那样（Authorized keys, SSL certs 等）。作者暂时还未使用此功能，不能详述，但这个功能特性绝对值得思考和使用。</p>\n<h3 id=\"设置适当实例和批量更新\"><a href=\"#设置适当实例和批量更新\" class=\"headerlink\" title=\"设置适当实例和批量更新\"></a>设置适当实例和批量更新</h3><p>保持适当数量的实例，以应对高流量和实例或者节点不可用的情况。同时太多的实例数也会占用CPU和内存，并且导致争抢CUP资源。</p>\n<p>update-parallelism的默认值是1，默认只有一个实例在运行。但这个更新速度太慢了，建议是 replicas / 2。</p>\n<p>相关命令：</p>\n<pre><code>docker service update \\\n\n--update-parallelism 10 \\\nwebapp\n\nYou can scale multiple services at once\ndocker service scale redis=1 nginx=4 webapp=20\n\nCheck scaling status\ndocker service ls\n\nCheck details of a service (without stopped containers)\ndocker service ps webapp | grep -v &quot;Shutdown&quot;\n</code></pre>\n<h3 id=\"把Swarm配置保存为代码\"><a href=\"#把Swarm配置保存为代码\" class=\"headerlink\" title=\"把Swarm配置保存为代码\"></a>把Swarm配置保存为代码</h3><p>最好使用Docker Compose v3版本的语法（<a href=\"https://docs.docker.com/compos\">https://docs.docker.com/compos</a> … eploy）。</p>\n<p>他允许使用代码指定几乎所有的服务选项。作者在开发的时候使用 Docker-compose.yml，在生产环境（swarm）配置使用 Docker-compose.prod.yml . 部署Docker-compose文件中所描述的服务，需要Docker stack deploy 命令（属于新版本 Stack命令集合中的一部分[<a href=\"https://docs.docker.com/engine\">https://docs.docker.com/engine</a> … tack/]）</p>\n<p>Docker compose v3例子：</p>\n<pre><code>docker-compose.prod.yml\nversion: &#39;3&#39;\n\nservices:\n\nwebapp:\nimage: registry.example.com/webapp\nnetworks:\n- ingress\ndeploy:\nreplicas: $&#123;WEBAPP_REPLICAS&#125;\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nproxy:\nimage: registry.example.com/webapp-nginx-proxy\nnetworks:\n- ingress\nports:\n- 80:80\n- 443:443\ndeploy:\nreplicas: $&#123;NGINX_REPLICAS&#125;\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nnetworks:\n\ningress:\nexternal: true\n</code></pre>\n<p>部署的例子（创建或者更新服务）：</p>\n<pre><code>export NGINX_REPLICAS=2 WEBAPP_REPLICAS=5\n\ndocker login registry.example.com\n\ndocker stack deploy \\\n\n-c docker-compose.prod.yml\\\n--with-registry-auth \\\nfrontend\n</code></pre>\n<p>提示：Docker-compose文件支持环境变量 (${VARIABLE}), 所以，可以动态调整配置作为测试等。</p>\n<h3 id=\"设置限制\"><a href=\"#设置限制\" class=\"headerlink\" title=\"设置限制\"></a>设置限制</h3><p>就经验而言，可以为所有服务设置CPU使用限制。当某一个容器应用占用掉所有主机资源时，此限制可以避免这种情况发生。</p>\n<p>当想把所有容器均匀地发布在所有主机上或是想确保有足够的资源来响应操作时，需使用Reserve-cpu这个参数。</p>\n<p>例如：</p>\n<pre><code>docker service update --limit-cpu 0.25\n--reserve-cpu 0.1\nwebapp\n</code></pre>\n<h3 id=\"监控连接\"><a href=\"#监控连接\" class=\"headerlink\" title=\"监控连接\"></a>监控连接</h3><p>曾经在Swarm网络上遇到过一些问题。很多次所有的流量都被路由到同一个容器实例上，而同时有9个容器实例正常且健康的。这种情况下——即流量持续导到一个实例上，做扩容或者缩容操作的时候，加上这个参数–endpoint-mode 。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html\">https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html</a></p>\n<p><a href=\"http://dockone.io/article/1486\">http://dockone.io/article/1486</a></p>\n<p><a href=\"http://dockone.io/article/2318\">http://dockone.io/article/2318</a></p>\n<p><a href=\"https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/\">https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/</a></p>\n<p><a href=\"\">Docker技术入门于实战~Swarm章节</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"Docker-Swarm-学习笔记总结\"><a href=\"#Docker-Swarm-学习笔记总结\" class=\"headerlink\" title=\"Docker Swarm 学习笔记总结\"></a>Docker Swarm 学习笔记总结</h1><h2 id=\"Swarm-介绍\"><a href=\"#Swarm-介绍\" class=\"headerlink\" title=\"Swarm 介绍\"></a>Swarm 介绍</h2><p>Docker Swarm是Docker官方提供的集群工具。它可以将一些关联的Docker主机转变成一个虚拟Docker主机。因为Docker Swarm符合Docker API的标准,任何已经可以与Docker守护进程通信的工具都可以使用Swarm来透明地扩展到多个主机。支持工具包括:</p>\n<ul>\n<li>   Dokku</li>\n<li>   Docker Compose</li>\n<li>   Docker Machine</li>\n<li>   Jenkins</li>\n</ul>\n<h2 id=\"Swarm-架构\"><a href=\"#Swarm-架构\" class=\"headerlink\" title=\"Swarm 架构\"></a>Swarm 架构</h2><p>Swarm 是用来被用来管理 Docker 集群的，所以单个 Docker host 是整个集群的基础。Swarm 自身可以有两种安装方式，一种是当成普通的 Docker 容器来安装，一种是当成一个简单的应用被安装在一台虚拟机或者物理机上。它的架构图如下：</p>\n<p><img src=\"https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index1869.png\" alt=\"Swarm 架构图\"></p>\n<p>所有的 Docker node 都会被当成一个调度候选对象。类似于 OpenStack 中的 compute node.</p>\n<h2 id=\"Swarm-集群功能\"><a href=\"#Swarm-集群功能\" class=\"headerlink\" title=\"Swarm 集群功能\"></a>Swarm 集群功能</h2><h3 id=\"Swarm-调度器\"><a href=\"#Swarm-调度器\" class=\"headerlink\" title=\"Swarm 调度器\"></a>Swarm 调度器</h3><p>调度是集群中十分重要的功能，Swarm目前支持三种调度策略：Spread、Binpack和random。<br>在执行swarm manage启动管理服务时，可通过–strategy参数指定调度策略，默认是：spread。</p>\n<p>三种调度策略的优缺点：</p>\n<ul>\n<li><p>spread： 配置相同情况下，选择一个正在运行的容器数量最少的那个节点，平摊容器到各个节点。</p>\n</li>\n<li><p>binpack：尽可能将所有容器放在一台节点上运行，尽量少用节点，避免容器碎片化。</p>\n</li>\n<li><p>random： 直接随机分配，不考虑集群节点状态，方便进行测试使用。</p>\n</li>\n</ul>\n<h3 id=\"Swarm-过滤器\"><a href=\"#Swarm-过滤器\" class=\"headerlink\" title=\"Swarm 过滤器\"></a>Swarm 过滤器</h3><p>Swarm 过滤器（filter）可以实现特定的容器分配到特点的节点上。目前支持物种过滤器：Constraint、Affinity、Port、Dependency、Health。</p>\n<ul>\n<li><p>Constraint 过滤器： 绑定到节点的键值对，相当于给节点打标签。比如在启动Docker服务时，指定某个节点颜色为 red。</p>\n</li>\n<li><p>Affinity 过滤器：允许用户在启动一个容器的时候，让它分配到某个已有容器的节点上。</p>\n</li>\n<li><p>其他过滤器也类似，通过-e affinity:image==<name or id>选择拥有指定镜像的节点，通过-e affinity:lael_name==value来选择拥有指定标签的容器所允许的节点。 </p>\n</li>\n</ul>\n<h3 id=\"Swarm-服务发现\"><a href=\"#Swarm-服务发现\" class=\"headerlink\" title=\"Swarm 服务发现\"></a>Swarm 服务发现</h3><p>通过不同的路径来选择特定的服务发现后端机制：</p>\n<ul>\n<li>token://<token>: 使用Docker Hub提供的服务，适用于公网；</li>\n<li>file://pah/to/file：使用本地文件，需手动管理；</li>\n<li>consul://<ip>/<path>：使用consul服务，私有环境；</li>\n<li>etcd://<ip1>,<ip2>,<ip3>/<path>：使用etcd服务，私有环境；</li>\n<li>zk://<ip1>,<ip2>,<ip3>/<path>：使用zk服务，私有环境；</li>\n<li>[nodes://]<ip1>,<ip2>,<ip3>：手动指定集群中节点地址，方便进行服务测试。</li>\n</ul>\n<h2 id=\"Swarm-集群实战\"><a href=\"#Swarm-集群实战\" class=\"headerlink\" title=\"Swarm 集群实战\"></a>Swarm 集群实战</h2><h3 id=\"安装Dcoker-Swarm的方式\"><a href=\"#安装Dcoker-Swarm的方式\" class=\"headerlink\" title=\"安装Dcoker Swarm的方式\"></a>安装Dcoker Swarm的方式</h3><p>安装Docker Swarm有两种方式：</p>\n<ul>\n<li>直接以swarm为镜像模板启动容器；</li>\n<li>在系统中安装swarm的二进制可执行文件。</li>\n</ul>\n<p>官网也列举出了这两种方法的优缺点：</p>\n<p>以swarm镜像启动容器：</p>\n<ul>\n<li>无需在系统中安装可执行的二进制文件；</li>\n<li>用docker run命令每次都可以获取并运行最近版本的镜像；</li>\n<li>容器是Swarm与主机环境相隔离，无需维护shell的路径和环境。</li>\n</ul>\n<p>在系统中安装swarm：</p>\n<ul>\n<li>Swarm项目的开发者在测试代码变更的过程中，无需在运行该二进制文件前进行容器化(“containerizing”)操作。</li>\n</ul>\n<h3 id=\"集群创建步骤\"><a href=\"#集群创建步骤\" class=\"headerlink\" title=\"集群创建步骤\"></a>集群创建步骤</h3><p>创建一个Swarm集群的第一步是从网上拉取Docker Swarm镜像。然后,你可以使用Docker配置Swarm manager和所有节点运行Docker Swarm。步骤:</p>\n<ul>\n<li>在每个节点上打开一个TCP端口用于跟Swarm manager通信</li>\n<li>在每个节点上安装Docker</li>\n<li>创建和管理TLS证书以保护集群</li>\n</ul>\n<h3 id=\"集群部署环境\"><a href=\"#集群部署环境\" class=\"headerlink\" title=\"集群部署环境\"></a>集群部署环境</h3><pre><code>Docker01 和 Docker02 分别对应 manager0 和 manager1；\nDocker04 和 Docker05 分别对应 node0 和 node1；\nDocker03 对应 consul0；\n</code></pre>\n<p>配置ssl证书及安装docker服务</p>\n<pre><code>mkdir -p /etc/docker/certs.d/DomainName:Port\ncp ca.crt /etc/docker/certs.d/DomainName:Port/\nservice docker restart\n</code></pre>\n<p>创建Swarm集群：</p>\n<pre><code> # 在高可用的Swarm集群中创建主管理者\n # 操作对象 manager0 和 consul0\n # &lt;manager0_ip&gt; 和 &lt;consul_ip&gt;相同\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager0_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500\n\n # 操作对象 manager1\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager1_ip&gt;:4000 consul://172.30.0.161:8500\n\n # 操作对象 node0 和 node1\n docker run -d swarm join --advertise=&lt;node_ip&gt;:2375 consul://&lt;consul_ip&gt;:8500\n</code></pre>\n<p>集群使用：</p>\n<pre><code> # 操作对象 manager0 和 consul0\n docker -H :4000 info\n\n # 在Swarm集群中运行应用\n docker -H :4000 run hello-world\n\n # 查询Swarm集群的哪个节点在运行该应用\n docker -H :4000 ps\n- 测试Swarm集群的故障；\n # 获取swarm容器的id或名称\n # 操作对象 manager0\n docker ps\n\n # 删除或关闭当前的主管理者 manager0\n docker rm -f &lt;id_name&gt;\n\n # 创建或启动Swarm集群管理者 manager0\n docker run -d -p 4000:4000 swarm manage -H :4000 --replication --advertise &lt;manager0_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500\n\n # 查看该容器的日志\n sudo docker logs &lt;id_name&gt;\n\n # 获取集群管理者和节点的信息\n docker -H :4000 info\n</code></pre>\n<h2 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h2><h3 id=\"Swarm-上的容器选择\"><a href=\"#Swarm-上的容器选择\" class=\"headerlink\" title=\"Swarm 上的容器选择\"></a>Swarm 上的容器选择</h3><ul>\n<li>适合无状态服务：web服务、反向代理、采集器等</li>\n<li>不适合有状态服务：数据库、redis、zk等<h3 id=\"设置Docker仓库\"><a href=\"#设置Docker仓库\" class=\"headerlink\" title=\"设置Docker仓库\"></a>设置Docker仓库</h3></li>\n<li>指明Docker仓库地址</li>\n<li>私有仓库增加参数：–with-registry-auth</li>\n<li>使用tag进行版本上线及回滚</li>\n</ul>\n<h3 id=\"改造无状态化应用容器\"><a href=\"#改造无状态化应用容器\" class=\"headerlink\" title=\"改造无状态化应用容器\"></a>改造无状态化应用容器</h3><ul>\n<li>采用共享存储挂载方式</li>\n</ul>\n<h3 id=\"日志采集服务\"><a href=\"#日志采集服务\" class=\"headerlink\" title=\"日志采集服务\"></a>日志采集服务</h3><p>集中式的日志和指标是使用分布式文件系统的必须项，如ELK，Graphana，Graylog 等等。</p>\n<p>这里有许多可选项，有开源项目，也有SaaS类服务。这些打造和整合成可靠的服务是复杂且艰难的。建议先使用云端服务（如Loggly, Logentries）, 当成本上涨的时候，再开始架设自己的日志收集服务。<br>例：ELK 栈日志处理配置:</p>\n<pre><code>docker service update \\ --log-driver gelf \\\n--log-opt gelf-address=udp://monitoring.example.com:12201 \\\n--log-opt tag=example-tag \\\nexample-service\n</code></pre>\n<h3 id=\"创建可附加的网络\"><a href=\"#创建可附加的网络\" class=\"headerlink\" title=\"创建可附加的网络\"></a>创建可附加的网络</h3><p>记得使用它，否则无法在Docker Swarm下一条命令跑起一个容器。这是Docker1.13+新功能。如果使用旧版本的Docker, 最好升级下。</p>\n<p>代码：</p>\n<pre><code>docker network create --driver=overlay --attachable core\n</code></pre>\n<h3 id=\"增加环境变量\"><a href=\"#增加环境变量\" class=\"headerlink\" title=\"增加环境变量\"></a>增加环境变量</h3><p>如果创建Docker镜像的时候，遵循了最佳实践原则（<a href=\"https://rock-it.pl/how-to-writ\">https://rock-it.pl/how-to-writ</a> … iles/），允许在运行的时候通过环境变量设置一切配置项，那么把应用迁到Swarm的过程完全没有问题。</p>\n<p>例，有用的命令：</p>\n<pre><code>docker service create \\\n\n--env VAR=VALUE \\\n--env-file FILENAME \\\n...\n\ndocker service update \\\n\n--env-add VAR=NEW_VALUE \\\n--env-rm VAR \\\n..\n</code></pre>\n<p>下一个级别就是使用非公开的API挂载文件像挂载秘钥那样（Authorized keys, SSL certs 等）。作者暂时还未使用此功能，不能详述，但这个功能特性绝对值得思考和使用。</p>\n<h3 id=\"设置适当实例和批量更新\"><a href=\"#设置适当实例和批量更新\" class=\"headerlink\" title=\"设置适当实例和批量更新\"></a>设置适当实例和批量更新</h3><p>保持适当数量的实例，以应对高流量和实例或者节点不可用的情况。同时太多的实例数也会占用CPU和内存，并且导致争抢CUP资源。</p>\n<p>update-parallelism的默认值是1，默认只有一个实例在运行。但这个更新速度太慢了，建议是 replicas / 2。</p>\n<p>相关命令：</p>\n<pre><code>docker service update \\\n\n--update-parallelism 10 \\\nwebapp\n\nYou can scale multiple services at once\ndocker service scale redis=1 nginx=4 webapp=20\n\nCheck scaling status\ndocker service ls\n\nCheck details of a service (without stopped containers)\ndocker service ps webapp | grep -v &quot;Shutdown&quot;\n</code></pre>\n<h3 id=\"把Swarm配置保存为代码\"><a href=\"#把Swarm配置保存为代码\" class=\"headerlink\" title=\"把Swarm配置保存为代码\"></a>把Swarm配置保存为代码</h3><p>最好使用Docker Compose v3版本的语法（<a href=\"https://docs.docker.com/compos\">https://docs.docker.com/compos</a> … eploy）。</p>\n<p>他允许使用代码指定几乎所有的服务选项。作者在开发的时候使用 Docker-compose.yml，在生产环境（swarm）配置使用 Docker-compose.prod.yml . 部署Docker-compose文件中所描述的服务，需要Docker stack deploy 命令（属于新版本 Stack命令集合中的一部分[<a href=\"https://docs.docker.com/engine\">https://docs.docker.com/engine</a> … tack/]）</p>\n<p>Docker compose v3例子：</p>\n<pre><code>docker-compose.prod.yml\nversion: &#39;3&#39;\n\nservices:\n\nwebapp:\nimage: registry.example.com/webapp\nnetworks:\n- ingress\ndeploy:\nreplicas: $&#123;WEBAPP_REPLICAS&#125;\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nproxy:\nimage: registry.example.com/webapp-nginx-proxy\nnetworks:\n- ingress\nports:\n- 80:80\n- 443:443\ndeploy:\nreplicas: $&#123;NGINX_REPLICAS&#125;\nmode: replicated\nrestart_policy:\ncondition: on-failure\n\nnetworks:\n\ningress:\nexternal: true\n</code></pre>\n<p>部署的例子（创建或者更新服务）：</p>\n<pre><code>export NGINX_REPLICAS=2 WEBAPP_REPLICAS=5\n\ndocker login registry.example.com\n\ndocker stack deploy \\\n\n-c docker-compose.prod.yml\\\n--with-registry-auth \\\nfrontend\n</code></pre>\n<p>提示：Docker-compose文件支持环境变量 (${VARIABLE}), 所以，可以动态调整配置作为测试等。</p>\n<h3 id=\"设置限制\"><a href=\"#设置限制\" class=\"headerlink\" title=\"设置限制\"></a>设置限制</h3><p>就经验而言，可以为所有服务设置CPU使用限制。当某一个容器应用占用掉所有主机资源时，此限制可以避免这种情况发生。</p>\n<p>当想把所有容器均匀地发布在所有主机上或是想确保有足够的资源来响应操作时，需使用Reserve-cpu这个参数。</p>\n<p>例如：</p>\n<pre><code>docker service update --limit-cpu 0.25\n--reserve-cpu 0.1\nwebapp\n</code></pre>\n<h3 id=\"监控连接\"><a href=\"#监控连接\" class=\"headerlink\" title=\"监控连接\"></a>监控连接</h3><p>曾经在Swarm网络上遇到过一些问题。很多次所有的流量都被路由到同一个容器实例上，而同时有9个容器实例正常且健康的。这种情况下——即流量持续导到一个实例上，做扩容或者缩容操作的时候，加上这个参数–endpoint-mode 。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html\">https://www.ibm.com/developerworks/cn/cloud/library/1511_zhangyq_dockerswarm/index.html</a></p>\n<p><a href=\"http://dockone.io/article/1486\">http://dockone.io/article/1486</a></p>\n<p><a href=\"http://dockone.io/article/2318\">http://dockone.io/article/2318</a></p>\n<p><a href=\"https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/\">https://rock-it.pl/my-experience-with-docker-swarm-when-you-need-it/</a></p>\n<p><a href=\"\">Docker技术入门于实战~Swarm章节</a></p>\n"},{"layout":"post","title":"jira 配置AD域","date":"2018-12-06T02:23:54.000Z","author":"owelinux","excerpt":"jira 配置AD域","mathjax":true,"_content":"\n* content\n{:toc}\n\n# jira 配置AD域\n\njira内部认证几种方式：\n\n1、Microsoft 活动目录\n\n是配置Windows的AD账号活动目录的，但是我们不选择这个选项，原因：配置此选项，Jira系统会把Windows目录下的所有账户都同步到Jira用户库，这些用户都被视为活跃用户，如果你的Jira是买的正版，肯定有用户的上限，一旦同步过来的账户超过了上线，超过上限的用户就无法登录Jira，提示用户数达到上限。如果你是破解版的Jira，建议配置这个，方便用户同步和认证。如果是正版用户，推荐配置第三个选项【内部LDAP认证】，原因看下文。\n\n2、LDAP\n\n此配置如上一样的用户同步模式，看自己是否正版用户，自行抉择。\n\n3、内部LDAP认证\n\n重点来了，这个选项的配置的好处是：被加到用户组Jira_users的用户，不会全部同步到Jira用户库中，只有登陆到Jira的用户才会被记录到Jira的用户库，这样就减少了授权用户的资源浪费，因为大多数互联网公司，肯定是使用Jira的用户不到公司总数的1/4，要是选择第1、2种方式，是资源的浪费，不建议。\n\n4、5、配置不做介绍，因为没用过，不过理解的应该是Jira公司自己提供的认证系统。\n\n\n##  jira 配置AD域\n\n### 1、建立AD账户和相应的群组\n在Windows AD中创建一个组，如：Jira_users，然后把需要登录Jira的AD账号，添加为此组成员。\n\n\n### 配置jira的认证目录\n\n以管理员登陆--管理--用户管理--用户目录--添加目录\n![](https://owelinux.github.io/images/2018-12-06-article40-linux-jira-ad/jira-ad.png)\n\n其余配置均使用默认，然后点击测试，提示连接测试成功，说明配置正确，没有问题。再点击【测试并保存】，如果正常返回到【用户管理】页面，说明第二步配置正确完成。\n\n###  给用户组分配权限\n\n第一步：\n管理员身份登陆---【系统】---【安全】---【全局权限】---【添加权限】---【权限】---【选择“JIRA 管理员”】--【用户组选择】--【添加】。\n\n第二步：\n管理员身份登陆---【应用程序】---【应用程序访问权】---【选择组】----【添加“JIRA Software”权限】，此权限可以授权用户能够能录Jira。\n\n## 参考文档\n\n* [http://www.bigyoung.cn/676.html](http://www.bigyoung.cn/676.html)\n\n* [https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync](https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync)","source":"_posts/2018-12-06-article40-linux-jira-ad.md","raw":"---\nlayout: post\ntitle:  \"jira 配置AD域\"\ndate:   2018-12-06 10:23:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: jira 配置AD域\nmathjax: true\n---\n\n* content\n{:toc}\n\n# jira 配置AD域\n\njira内部认证几种方式：\n\n1、Microsoft 活动目录\n\n是配置Windows的AD账号活动目录的，但是我们不选择这个选项，原因：配置此选项，Jira系统会把Windows目录下的所有账户都同步到Jira用户库，这些用户都被视为活跃用户，如果你的Jira是买的正版，肯定有用户的上限，一旦同步过来的账户超过了上线，超过上限的用户就无法登录Jira，提示用户数达到上限。如果你是破解版的Jira，建议配置这个，方便用户同步和认证。如果是正版用户，推荐配置第三个选项【内部LDAP认证】，原因看下文。\n\n2、LDAP\n\n此配置如上一样的用户同步模式，看自己是否正版用户，自行抉择。\n\n3、内部LDAP认证\n\n重点来了，这个选项的配置的好处是：被加到用户组Jira_users的用户，不会全部同步到Jira用户库中，只有登陆到Jira的用户才会被记录到Jira的用户库，这样就减少了授权用户的资源浪费，因为大多数互联网公司，肯定是使用Jira的用户不到公司总数的1/4，要是选择第1、2种方式，是资源的浪费，不建议。\n\n4、5、配置不做介绍，因为没用过，不过理解的应该是Jira公司自己提供的认证系统。\n\n\n##  jira 配置AD域\n\n### 1、建立AD账户和相应的群组\n在Windows AD中创建一个组，如：Jira_users，然后把需要登录Jira的AD账号，添加为此组成员。\n\n\n### 配置jira的认证目录\n\n以管理员登陆--管理--用户管理--用户目录--添加目录\n![](https://owelinux.github.io/images/2018-12-06-article40-linux-jira-ad/jira-ad.png)\n\n其余配置均使用默认，然后点击测试，提示连接测试成功，说明配置正确，没有问题。再点击【测试并保存】，如果正常返回到【用户管理】页面，说明第二步配置正确完成。\n\n###  给用户组分配权限\n\n第一步：\n管理员身份登陆---【系统】---【安全】---【全局权限】---【添加权限】---【权限】---【选择“JIRA 管理员”】--【用户组选择】--【添加】。\n\n第二步：\n管理员身份登陆---【应用程序】---【应用程序访问权】---【选择组】----【添加“JIRA Software”权限】，此权限可以授权用户能够能录Jira。\n\n## 参考文档\n\n* [http://www.bigyoung.cn/676.html](http://www.bigyoung.cn/676.html)\n\n* [https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync](https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync)","slug":"2018-12-06-article40-linux-jira-ad","published":1,"updated":"2021-02-09T02:00:24.578Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq0v002vyc975dl2g7ud","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"jira-配置AD域\"><a href=\"#jira-配置AD域\" class=\"headerlink\" title=\"jira 配置AD域\"></a>jira 配置AD域</h1><p>jira内部认证几种方式：</p>\n<p>1、Microsoft 活动目录</p>\n<p>是配置Windows的AD账号活动目录的，但是我们不选择这个选项，原因：配置此选项，Jira系统会把Windows目录下的所有账户都同步到Jira用户库，这些用户都被视为活跃用户，如果你的Jira是买的正版，肯定有用户的上限，一旦同步过来的账户超过了上线，超过上限的用户就无法登录Jira，提示用户数达到上限。如果你是破解版的Jira，建议配置这个，方便用户同步和认证。如果是正版用户，推荐配置第三个选项【内部LDAP认证】，原因看下文。</p>\n<p>2、LDAP</p>\n<p>此配置如上一样的用户同步模式，看自己是否正版用户，自行抉择。</p>\n<p>3、内部LDAP认证</p>\n<p>重点来了，这个选项的配置的好处是：被加到用户组Jira_users的用户，不会全部同步到Jira用户库中，只有登陆到Jira的用户才会被记录到Jira的用户库，这样就减少了授权用户的资源浪费，因为大多数互联网公司，肯定是使用Jira的用户不到公司总数的1/4，要是选择第1、2种方式，是资源的浪费，不建议。</p>\n<p>4、5、配置不做介绍，因为没用过，不过理解的应该是Jira公司自己提供的认证系统。</p>\n<h2 id=\"jira-配置AD域-1\"><a href=\"#jira-配置AD域-1\" class=\"headerlink\" title=\"jira 配置AD域\"></a>jira 配置AD域</h2><h3 id=\"1、建立AD账户和相应的群组\"><a href=\"#1、建立AD账户和相应的群组\" class=\"headerlink\" title=\"1、建立AD账户和相应的群组\"></a>1、建立AD账户和相应的群组</h3><p>在Windows AD中创建一个组，如：Jira_users，然后把需要登录Jira的AD账号，添加为此组成员。</p>\n<h3 id=\"配置jira的认证目录\"><a href=\"#配置jira的认证目录\" class=\"headerlink\" title=\"配置jira的认证目录\"></a>配置jira的认证目录</h3><p>以管理员登陆–管理–用户管理–用户目录–添加目录<br><img src=\"https://owelinux.github.io/images/2018-12-06-article40-linux-jira-ad/jira-ad.png\"></p>\n<p>其余配置均使用默认，然后点击测试，提示连接测试成功，说明配置正确，没有问题。再点击【测试并保存】，如果正常返回到【用户管理】页面，说明第二步配置正确完成。</p>\n<h3 id=\"给用户组分配权限\"><a href=\"#给用户组分配权限\" class=\"headerlink\" title=\"给用户组分配权限\"></a>给用户组分配权限</h3><p>第一步：<br>管理员身份登陆—【系统】—【安全】—【全局权限】—【添加权限】—【权限】—【选择“JIRA 管理员”】–【用户组选择】–【添加】。</p>\n<p>第二步：<br>管理员身份登陆—【应用程序】—【应用程序访问权】—【选择组】—-【添加“JIRA Software”权限】，此权限可以授权用户能够能录Jira。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"http://www.bigyoung.cn/676.html\">http://www.bigyoung.cn/676.html</a></p>\n</li>\n<li><p><a href=\"https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync\">https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync</a></p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"jira-配置AD域\"><a href=\"#jira-配置AD域\" class=\"headerlink\" title=\"jira 配置AD域\"></a>jira 配置AD域</h1><p>jira内部认证几种方式：</p>\n<p>1、Microsoft 活动目录</p>\n<p>是配置Windows的AD账号活动目录的，但是我们不选择这个选项，原因：配置此选项，Jira系统会把Windows目录下的所有账户都同步到Jira用户库，这些用户都被视为活跃用户，如果你的Jira是买的正版，肯定有用户的上限，一旦同步过来的账户超过了上线，超过上限的用户就无法登录Jira，提示用户数达到上限。如果你是破解版的Jira，建议配置这个，方便用户同步和认证。如果是正版用户，推荐配置第三个选项【内部LDAP认证】，原因看下文。</p>\n<p>2、LDAP</p>\n<p>此配置如上一样的用户同步模式，看自己是否正版用户，自行抉择。</p>\n<p>3、内部LDAP认证</p>\n<p>重点来了，这个选项的配置的好处是：被加到用户组Jira_users的用户，不会全部同步到Jira用户库中，只有登陆到Jira的用户才会被记录到Jira的用户库，这样就减少了授权用户的资源浪费，因为大多数互联网公司，肯定是使用Jira的用户不到公司总数的1/4，要是选择第1、2种方式，是资源的浪费，不建议。</p>\n<p>4、5、配置不做介绍，因为没用过，不过理解的应该是Jira公司自己提供的认证系统。</p>\n<h2 id=\"jira-配置AD域-1\"><a href=\"#jira-配置AD域-1\" class=\"headerlink\" title=\"jira 配置AD域\"></a>jira 配置AD域</h2><h3 id=\"1、建立AD账户和相应的群组\"><a href=\"#1、建立AD账户和相应的群组\" class=\"headerlink\" title=\"1、建立AD账户和相应的群组\"></a>1、建立AD账户和相应的群组</h3><p>在Windows AD中创建一个组，如：Jira_users，然后把需要登录Jira的AD账号，添加为此组成员。</p>\n<h3 id=\"配置jira的认证目录\"><a href=\"#配置jira的认证目录\" class=\"headerlink\" title=\"配置jira的认证目录\"></a>配置jira的认证目录</h3><p>以管理员登陆–管理–用户管理–用户目录–添加目录<br><img src=\"https://owelinux.github.io/images/2018-12-06-article40-linux-jira-ad/jira-ad.png\"></p>\n<p>其余配置均使用默认，然后点击测试，提示连接测试成功，说明配置正确，没有问题。再点击【测试并保存】，如果正常返回到【用户管理】页面，说明第二步配置正确完成。</p>\n<h3 id=\"给用户组分配权限\"><a href=\"#给用户组分配权限\" class=\"headerlink\" title=\"给用户组分配权限\"></a>给用户组分配权限</h3><p>第一步：<br>管理员身份登陆—【系统】—【安全】—【全局权限】—【添加权限】—【权限】—【选择“JIRA 管理员”】–【用户组选择】–【添加】。</p>\n<p>第二步：<br>管理员身份登陆—【应用程序】—【应用程序访问权】—【选择组】—-【添加“JIRA Software”权限】，此权限可以授权用户能够能录Jira。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"http://www.bigyoung.cn/676.html\">http://www.bigyoung.cn/676.html</a></p>\n</li>\n<li><p><a href=\"https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync\">https://serviceaide.atlassian.net/wiki/spaces/CloudSMGoldfishCN/pages/3703745/ADSync</a></p>\n</li>\n</ul>\n"},{"layout":"post","title":"JIRA 7.13.0 实践笔记","date":"2018-12-05T02:23:54.000Z","author":"owelinux","excerpt":"JIRA 7.13.0 实践笔记","mathjax":true,"_content":"\n* content\n{:toc}\n\n# JIRA 7.13.0 实践笔记 \n\njira有以下几种安装方式：\n\n* Docker容器部署\n\n* K8s helm部署\n\n* k8s 部署\n\n* 直接安装 \n\n其中helm安装：[helm安装](https://itnext.io/jira-on-kubernetes-by-helm-8a38357da4e),下面详细介绍容器部署。\n\n## 镜像构建配置\n\n### Jira容器构建准备\n\n破解文件下载：[jira7.2_hack.zip](https://github.com/idoall/docker/blob/master/ubuntu16.04-jira/7.2.7/files/usr/src/_jira/jira7.2_hack.zip)\n\n```\ngit clone https://github.com/cptactionhank/docker-atlassian-jira-software\n\ncd docker-atlassian-jira-software\n\ncp atlassian-extras-3.2.jar atlassian-universal-plugin-manager-plugin-2.22.9.jar ./ \n```\n\n### 定义 setenv.sh\n\n修改默认使用jvm内存(将内存参数以变量传递给容器外部调用)：\nvim setenv.sh\n```\n#\n# One way to set the JIRA HOME path is here via this variable.  Simply uncomment it and set a valid path like /jira/home.  You can of course set it outside in the command terminal.  That will also work.\n#\n#JIRA_HOME=\"\"\n\n#\n#  Occasionally Atlassian Support may recommend that you set some specific JVM arguments.  You can use this variable below to do that.\n#\nJVM_SUPPORT_RECOMMENDED_ARGS=\"\"\n\n#\n# The following 2 settings control the minimum and maximum given to the JIRA Java virtual machine.  In larger JIRA instances, the maximum amount will need to be increased.\n#\nJVM_MINIMUM_MEMORY=${JVM_XMS:-384m}\nJVM_MAXIMUM_MEMORY=${JVM_XMX:-768m}\n\n#\n# The following setting configures the size of JVM code cache.  A high value of reserved size allows Jira to work with more installed apps.\n#\nJVM_CODE_CACHE_ARGS='-XX:InitialCodeCacheSize=32m -XX:ReservedCodeCacheSize=512m'\n\n#\n# The following are the required arguments for JIRA.\n#\nJVM_REQUIRED_ARGS='-Djava.awt.headless=true -Datlassian.standalone=JIRA -Dorg.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER=true -Dmail.mime.decodeparameters=true -Dorg.dom4j.factory=com.atlassian.core.xml.InterningDocumentFactory'\n\n# Uncomment this setting if you want to import data without notifications\n#\n#DISABLE_NOTIFICATIONS=\" -Datlassian.mail.senddisabled=true -Datlassian.mail.fetchdisabled=true -Datlassian.mail.popdisabled=true\"\n\n\n#-----------------------------------------------------------------------------------\n#\n# In general don't make changes below here\n#\n#-----------------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------------\n# Prevents the JVM from suppressing stack traces if a given type of exception\n# occurs frequently, which could make it harder for support to diagnose a problem.\n#-----------------------------------------------------------------------------------\nJVM_EXTRA_ARGS=\"-XX:-OmitStackTraceInFastThrow\"\n\nPRGDIR=`dirname \"$0\"`\ncat \"${PRGDIR}\"/jirabanner.txt\n\nJIRA_HOME_MINUSD=\"\"\nif [ \"$JIRA_HOME\" != \"\" ]; then\n    echo $JIRA_HOME | grep -q \" \"\n    if [ $? -eq 0 ]; then\n            echo \"\"\n            echo \"--------------------------------------------------------------------------------------------------------------------\"\n                echo \"   WARNING : You cannot have a JIRA_HOME environment variable set with spaces in it.  This variable is being ignored\"\n            echo \"--------------------------------------------------------------------------------------------------------------------\"\n    else\n                JIRA_HOME_MINUSD=-Djira.home=$JIRA_HOME\n    fi\nfi\n\nJAVA_OPTS=\"-Xms${JVM_MINIMUM_MEMORY} -Xmx${JVM_MAXIMUM_MEMORY} ${JVM_CODE_CACHE_ARGS} ${JAVA_OPTS} ${JVM_REQUIRED_ARGS} ${DISABLE_NOTIFICATIONS} ${JVM_SUPPORT_RECOMMENDED_ARGS} ${JVM_EXTRA_ARGS} ${JIRA_HOME_MINUSD} ${START_JIRA_JAVA_OPTS}\"\n\nexport JAVA_OPTS\n\n# DO NOT remove the following line\n# !INSTALLER SET JAVA_HOME\n\necho \"\"\necho \"If you encounter issues starting or stopping JIRA, please see the Troubleshooting guide at http://confluence.atlassian.com/display/JIRA/Installation+Troubleshooting+Guide\"\necho \"\"\nif [ \"$JIRA_HOME_MINUSD\" != \"\" ]; then\n    echo \"Using JIRA_HOME:       $JIRA_HOME\"\nfi\n\n# set the location of the pid file\nif [ -z \"$CATALINA_PID\" ] ; then\n    if [ -n \"$CATALINA_BASE\" ] ; then\n        CATALINA_PID=\"$CATALINA_BASE\"/work/catalina.pid\n    elif [ -n \"$CATALINA_HOME\" ] ; then\n        CATALINA_PID=\"$CATALINA_HOME\"/work/catalina.pid\n    fi\nfi\nexport CATALINA_PID\n\nif [ -z \"$CATALINA_BASE\" ]; then\n  if [ -z \"$CATALINA_HOME\" ]; then\n    LOGBASE=$PRGDIR\n    LOGTAIL=..\n  else\n    LOGBASE=$CATALINA_HOME\n    LOGTAIL=.\n  fi\nelse\n  LOGBASE=$CATALINA_BASE\n  LOGTAIL=.\nfi\n\nPUSHED_DIR=`pwd`\ncd $LOGBASE\ncd $LOGTAIL\nLOGBASEABS=`pwd`\ncd $PUSHED_DIR\n\necho \"\"\necho \"Server startup logs are located in $LOGBASEABS/logs/catalina.out\"\n\n# Set the JVM arguments used to start JIRA. For a description of the options, see\n# http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\n\n#-----------------------------------------------------------------------------------\n# This allows us to actually debug GC related issues by correlating timestamps\n# with other parts of the application logs.\n#-----------------------------------------------------------------------------------\nGC_JVM_PARAMETERS=\"\"\nGC_JVM_PARAMETERS=\"-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause ${GC_JVM_PARAMETERS}\"\nGC_JVM_PARAMETERS=\"-Xloggc:$LOGBASEABS/logs/atlassian-jira-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M ${GC_JVM_PARAMETERS}\"\n\nCATALINA_OPTS=\"${GC_JVM_PARAMETERS} ${CATALINA_OPTS}\"\nexport CATALINA_OPTS\n```\n\n### 定义Dockerfile\n\n```\nFROM openjdk:8-alpine\n\n# Configuration variables.\nENV JIRA_HOME     /var/atlassian/jira\nENV JIRA_INSTALL  /opt/atlassian/jira\nENV JIRA_VERSION  7.13.0\n\n# Install Atlassian JIRA and helper tools and setup initial home\n# directory structure.\nRUN set -x \\\n    && apk add --no-cache curl xmlstarlet bash ttf-dejavu libc6-compat \\\n    && mkdir -p                \"${JIRA_HOME}\" \\\n    && mkdir -p                \"${JIRA_HOME}/caches/indexes\" \\\n    && chmod -R 700            \"${JIRA_HOME}\" \\\n    && mkdir -p                \"${JIRA_INSTALL}/conf/Catalina\" \\\n    && curl -Ls                \"https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.13.0.tar.gz\" | tar -xz --directory \"${JIRA_INSTALL}\" --strip-components=1 --no-same-owner \\\n    && curl -Ls                \"https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz\" | tar -xz --directory \"${JIRA_INSTALL}/lib\" --strip-components=1 --no-same-owner \"mysql-connector-java-5.1.38/mysql-connector-java-5.1.38-bin.jar\" \\\n    && rm -f                   \"${JIRA_INSTALL}/lib/postgresql-9.1-903.jdbc4-atlassian-hosted.jar\" \\\n    && curl -Ls                \"https://jdbc.postgresql.org/download/postgresql-42.2.1.jar\" -o \"${JIRA_INSTALL}/lib/postgresql-42.2.1.jar\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/conf\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/logs\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/temp\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/work\" \\\n    && sed --in-place          \"s/java version/openjdk version/g\" \"${JIRA_INSTALL}/bin/check-java.sh\" \\\n    && echo -e                 \"\\njira.home=$JIRA_HOME\" >> \"${JIRA_INSTALL}/atlassian-jira/WEB-INF/classes/jira-application.properties\" \\\n    && touch -d \"@0\"           \"${JIRA_INSTALL}/conf/server.xml\"\n\n# Use the default unprivileged account. This could be considered bad practice\n# on systems where multiple processes end up being executed by 'daemon' but\n# here we only ever run one process anyway.\n#USER daemon:daemon\n\n# Expose default HTTP connector port.\nEXPOSE 8080\n\n# Set volume mount points for installation and home directory. Changes to the\n# home directory needs to be persisted as well as parts of the installation\n# directory due to eg. logs.\nVOLUME [\"/var/atlassian/jira\", \"/opt/atlassian/jira/logs\"]\n\n# Set the default working directory as the installation directory.\nWORKDIR /var/atlassian/jira\n\nCOPY \"docker-entrypoint.sh\" \"/\"\nCOPY atlassian-extras-3.2.jar ${JIRA_INSTALL}/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar \nCOPY atlassian-universal-plugin-manager-plugin-2.22.9.jar ${JIRA_INSTALL}/atlassian-jira/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.9.jar\nCOPY setenv.sh ${JIRA_INSTALL}/bin/setenv.sh\nCOPY server.xml ${JIRA_INSTALL}/conf/server.xml\n\nENTRYPOINT [\"/docker-entrypoint.sh\"]\n\n# Run Atlassian JIRA as a foreground process by default.\nCMD [\"/opt/atlassian/jira/bin/start-jira.sh\", \"-fg\"]\n```\n\n### 定义 server.xml\n自定义server.xml文件，需求后续可以配置https访问\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n    <Listener className=\"org.apache.catalina.startup.VersionLoggerListener\"/>\n    <Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\"/>\n    <Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\"/>\n    <Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\"/>\n    <Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\"/>\n\n    <Service name=\"Catalina\">\n        <Connector port=\"8080\" relaxedPathChars=\"[]|\" relaxedQueryChars=\"[]|{}^&#x5c;&#x60;&quot;&lt;&gt;\"\n                   maxThreads=\"150\" minSpareThreads=\"25\" connectionTimeout=\"20000\" enableLookups=\"false\"\n                   maxHttpHeaderSize=\"8192\" protocol=\"HTTP/1.1\" useBodyEncodingForURI=\"true\" redirectPort=\"8443\"\n                   acceptCount=\"100\" disableUploadTimeout=\"true\" bindOnInit=\"false\"/>\n\n        <Engine name=\"Catalina\" defaultHost=\"localhost\">\n            <Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\">\n\n                <Context path=\"\" docBase=\"${catalina.home}/atlassian-jira\" reloadable=\"false\" useHttpOnly=\"true\">\n                    <Resource name=\"UserTransaction\" auth=\"Container\" type=\"javax.transaction.UserTransaction\"\n                              factory=\"org.objectweb.jotm.UserTransactionFactory\" jotm.timeout=\"60\"/>\n                    <Manager pathname=\"\"/>\n                    <JarScanner scanManifest=\"false\"/>\n                </Context>\n\n            </Host>\n            <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                   pattern=\"%a %{jira.request.id}r %{jira.request.username}r %t &quot;%m %U%q %H&quot; %s %b %D &quot;%{Referer}i&quot; &quot;%{User-Agent}i&quot; &quot;%{jira.request.assession.id}r&quot;\"/>\n        </Engine>\n    </Service>\n</Server>\n```\n### 构建镜像\n```\ndocker build -t jira:7.13.0 .\n```\n\n## Mysql本地安装\n\n### yum 部署mysql\n\n```\ncurl -LO http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\nyum localinstall mysql57-community-release-el7-11.noarch.rpm\nyum install mysql-community-server\nsystemctl enable mysqld\nsystemctl start mysqld\nsystemctl status mysqld\n# 查看密码\ngrep 'temporary password' /var/log/mysqld.log\n# 登录 MySQL 并修改密码\n\nmysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';\n```\n\n### 配置mysql数据库：\n```\n创建数据库：\n\nmysql> CREATE DATABASE jira  DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;\n\n授连接次数据库的权限：\n\nmysql>  grant all privileges on jira.* to jira@'.%' identified by 'jira';\nmysql> flush privileges;\n```\n\n注意： jira7.13.0版本不支持utf8_general_ci的校验规则，因此创建数据库时必须指明utf8_bin校验规则！！\n\n\n## 部署镜像\n\n### Docker 本地部署\n```\ndocker run --publish 8080:8080 --name jira -d local-jira:7.3.8\n```\n\n### 使用docker-compose方式\n\n构建docker-compose.yml\n```\njira:\n  image: jira:7.13.0\n  restart: always\n  environment:\n    - JVM_XMX=2048m\n    - JVM_XMS=1024m\n  ports:\n    - '8080:8080'\n  links:\n    - db\n  volumes:\n    - ./data/jira:/var/atlassian/jira\n    - ./data/logs:/opt/atlassian/jira/logs\n\ndb:\n  image: mysql:5.7\n  restart: always\n  environment:\n    - MYSQL_USER=jira\n    - MYSQL_PASSWORD=jira\n    - MYSQL_DATABASE=jira\n    - MYSQL_ROOT_PASSWORD=jira\n  volumes:\n    - ./data/mysql:/var/lib/mysql\n\n```\n\n### 采用k8s集群方式运行\n\n此环境在阿里云K8s容器平台部署\n\n#### 创建pv\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: hangzhou-b-ssd  \nparameters:\n  cachingmode: None\n  kind: Managed\n  storageaccounttype: Standard_LRS\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n```\n\n#### 创建pvc\n```\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: jira-data\nspec:\n  accessModes:\n   - \"ReadWriteOnce\"\n  resources:\n    requests:\n       storage: \"100Gi\"  \n  storageClassName: \"hangzhou-b-ssd\"\n```\n#### 创建service\n```\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    service.beta.kubernetes.io/alicloud-loadbalancer-cert-id: \"cert-id\"\n    service.beta.kubernetes.io/alicloud-loadbalancer-protocol-port: \"https:443,http:80\"\n  name: jira-svc\n  namespace: default\nspec:\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: jira-svc\n  sessionAffinity: None\n  type: LoadBalancer       \n```\n这里采用阿里自带负载均衡方式部署，然后域名解析到负载均衡外网ip\n\n#### 创建Deployment\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jira-deployment\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jira-svc\n  template:\n    metadata:\n      labels:\n        app: jira-svc\n    spec:\n      containers:\n        - name: jira-svc\n          image: jira:7.13.0\n          imagePullPolicy: Always\n          env:\n          - name: JVM_XMX\n            value: \"2048m\"\n          - name: JVM_XMS\n            value: \"1024m\"\n          ports:\n            - containerPort: 8080\n          volumeMounts:\n          - mountPath: \"/var/atlassian/jira\"\n            name: jira-data         \n      volumes:\n      - name: jira-data\n        persistentVolumeClaim:\n          claimName: jira-data  \n```\n#### 部署\n```\nkubectl apply -f .\n```\n\n\n## 破解\n\n首先按照安装步骤一步一步进行，到证书授权的时候，点击申请证书，然后得到许可证，填入即可，最后在应用程序--版本和许可证，可看到技术服务器截止日期 08/二月/33，即破解成功！(插件破解：免费试用--获取申请码---填入申请码---破解成功)\n\n## 注意的问题\n\n注意：jira插件管理中，atlassian-universal-plugin-manager-plugin插件绝对不要更新，否则插件破解会失效。\n\n补充说明：\n\n1、插件破解原理：\n\natlassian-universal-plugin-manager-plugin插件是进行插件管理的，只需要破解了这个插件，剩下的所有插件都自动破解完成了\n\n2、如果破解不成功、插件管理版本高于2.22.4、或者不小心更新了atlassian-universal-plugin-manager-plugin这个插件怎么办？\n\n遇到这种情况，需要到jira的安装目录和数据目录下，替换掉atlassian-universal-plugin-manager-plugin相关的所有文件。\n\n具体操作步骤：\n\n（1）到jira安装目录和数据目录下find出所有相关文件：\n（2）替换、删除相关文件，保险起见，可在删除前对数据进行备份。 \n（3）重启jira\n（4）到插件管理中心查看插件授权期限，变为2099年\n\n如何修改内存？\n\nvim /opt/atlassian/jira/bin/setenv.sh\n```\nJVM_MINIMUM_MEMORY=${JVM_XMS:-384m}\nJVM_MAXIMUM_MEMORY=${JVM_XMX:-768m}\n```\n\n如何解决mysql ssl报错?\n\nvim /var/atlassian/jira/dbconfig.xml\n```\n<url>jdbc:mysql://address=(protocol=tcp)(host=mysql_hostname)(port=mysql_port)/jira?useUnicode=true&amp;characterEncoding=UTF8&amp;sessionVariables=default_storage_engine=InnoDB&amp;useSSL=false</url>\n```\n## 参考文档：\n* [https://www.jianshu.com/p/744c23f93dfc](https://www.jianshu.com/p/744c23f93dfc)\n\n* [https://cloud.tencent.com/developer/article/1027457](https://cloud.tencent.com/developer/article/1027457)\n\n* [https://paper.tuisec.win/detail/29d80901a36cf52](https://paper.tuisec.win/detail/29d80901a36cf52)","source":"_posts/2018-12-05-article39-linux-jira.md","raw":"---\nlayout: post\ntitle:  \"JIRA 7.13.0 实践笔记\"\ndate:   2018-12-05 10:23:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: JIRA 7.13.0 实践笔记\nmathjax: true\n---\n\n* content\n{:toc}\n\n# JIRA 7.13.0 实践笔记 \n\njira有以下几种安装方式：\n\n* Docker容器部署\n\n* K8s helm部署\n\n* k8s 部署\n\n* 直接安装 \n\n其中helm安装：[helm安装](https://itnext.io/jira-on-kubernetes-by-helm-8a38357da4e),下面详细介绍容器部署。\n\n## 镜像构建配置\n\n### Jira容器构建准备\n\n破解文件下载：[jira7.2_hack.zip](https://github.com/idoall/docker/blob/master/ubuntu16.04-jira/7.2.7/files/usr/src/_jira/jira7.2_hack.zip)\n\n```\ngit clone https://github.com/cptactionhank/docker-atlassian-jira-software\n\ncd docker-atlassian-jira-software\n\ncp atlassian-extras-3.2.jar atlassian-universal-plugin-manager-plugin-2.22.9.jar ./ \n```\n\n### 定义 setenv.sh\n\n修改默认使用jvm内存(将内存参数以变量传递给容器外部调用)：\nvim setenv.sh\n```\n#\n# One way to set the JIRA HOME path is here via this variable.  Simply uncomment it and set a valid path like /jira/home.  You can of course set it outside in the command terminal.  That will also work.\n#\n#JIRA_HOME=\"\"\n\n#\n#  Occasionally Atlassian Support may recommend that you set some specific JVM arguments.  You can use this variable below to do that.\n#\nJVM_SUPPORT_RECOMMENDED_ARGS=\"\"\n\n#\n# The following 2 settings control the minimum and maximum given to the JIRA Java virtual machine.  In larger JIRA instances, the maximum amount will need to be increased.\n#\nJVM_MINIMUM_MEMORY=${JVM_XMS:-384m}\nJVM_MAXIMUM_MEMORY=${JVM_XMX:-768m}\n\n#\n# The following setting configures the size of JVM code cache.  A high value of reserved size allows Jira to work with more installed apps.\n#\nJVM_CODE_CACHE_ARGS='-XX:InitialCodeCacheSize=32m -XX:ReservedCodeCacheSize=512m'\n\n#\n# The following are the required arguments for JIRA.\n#\nJVM_REQUIRED_ARGS='-Djava.awt.headless=true -Datlassian.standalone=JIRA -Dorg.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER=true -Dmail.mime.decodeparameters=true -Dorg.dom4j.factory=com.atlassian.core.xml.InterningDocumentFactory'\n\n# Uncomment this setting if you want to import data without notifications\n#\n#DISABLE_NOTIFICATIONS=\" -Datlassian.mail.senddisabled=true -Datlassian.mail.fetchdisabled=true -Datlassian.mail.popdisabled=true\"\n\n\n#-----------------------------------------------------------------------------------\n#\n# In general don't make changes below here\n#\n#-----------------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------------\n# Prevents the JVM from suppressing stack traces if a given type of exception\n# occurs frequently, which could make it harder for support to diagnose a problem.\n#-----------------------------------------------------------------------------------\nJVM_EXTRA_ARGS=\"-XX:-OmitStackTraceInFastThrow\"\n\nPRGDIR=`dirname \"$0\"`\ncat \"${PRGDIR}\"/jirabanner.txt\n\nJIRA_HOME_MINUSD=\"\"\nif [ \"$JIRA_HOME\" != \"\" ]; then\n    echo $JIRA_HOME | grep -q \" \"\n    if [ $? -eq 0 ]; then\n            echo \"\"\n            echo \"--------------------------------------------------------------------------------------------------------------------\"\n                echo \"   WARNING : You cannot have a JIRA_HOME environment variable set with spaces in it.  This variable is being ignored\"\n            echo \"--------------------------------------------------------------------------------------------------------------------\"\n    else\n                JIRA_HOME_MINUSD=-Djira.home=$JIRA_HOME\n    fi\nfi\n\nJAVA_OPTS=\"-Xms${JVM_MINIMUM_MEMORY} -Xmx${JVM_MAXIMUM_MEMORY} ${JVM_CODE_CACHE_ARGS} ${JAVA_OPTS} ${JVM_REQUIRED_ARGS} ${DISABLE_NOTIFICATIONS} ${JVM_SUPPORT_RECOMMENDED_ARGS} ${JVM_EXTRA_ARGS} ${JIRA_HOME_MINUSD} ${START_JIRA_JAVA_OPTS}\"\n\nexport JAVA_OPTS\n\n# DO NOT remove the following line\n# !INSTALLER SET JAVA_HOME\n\necho \"\"\necho \"If you encounter issues starting or stopping JIRA, please see the Troubleshooting guide at http://confluence.atlassian.com/display/JIRA/Installation+Troubleshooting+Guide\"\necho \"\"\nif [ \"$JIRA_HOME_MINUSD\" != \"\" ]; then\n    echo \"Using JIRA_HOME:       $JIRA_HOME\"\nfi\n\n# set the location of the pid file\nif [ -z \"$CATALINA_PID\" ] ; then\n    if [ -n \"$CATALINA_BASE\" ] ; then\n        CATALINA_PID=\"$CATALINA_BASE\"/work/catalina.pid\n    elif [ -n \"$CATALINA_HOME\" ] ; then\n        CATALINA_PID=\"$CATALINA_HOME\"/work/catalina.pid\n    fi\nfi\nexport CATALINA_PID\n\nif [ -z \"$CATALINA_BASE\" ]; then\n  if [ -z \"$CATALINA_HOME\" ]; then\n    LOGBASE=$PRGDIR\n    LOGTAIL=..\n  else\n    LOGBASE=$CATALINA_HOME\n    LOGTAIL=.\n  fi\nelse\n  LOGBASE=$CATALINA_BASE\n  LOGTAIL=.\nfi\n\nPUSHED_DIR=`pwd`\ncd $LOGBASE\ncd $LOGTAIL\nLOGBASEABS=`pwd`\ncd $PUSHED_DIR\n\necho \"\"\necho \"Server startup logs are located in $LOGBASEABS/logs/catalina.out\"\n\n# Set the JVM arguments used to start JIRA. For a description of the options, see\n# http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\n\n#-----------------------------------------------------------------------------------\n# This allows us to actually debug GC related issues by correlating timestamps\n# with other parts of the application logs.\n#-----------------------------------------------------------------------------------\nGC_JVM_PARAMETERS=\"\"\nGC_JVM_PARAMETERS=\"-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause ${GC_JVM_PARAMETERS}\"\nGC_JVM_PARAMETERS=\"-Xloggc:$LOGBASEABS/logs/atlassian-jira-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M ${GC_JVM_PARAMETERS}\"\n\nCATALINA_OPTS=\"${GC_JVM_PARAMETERS} ${CATALINA_OPTS}\"\nexport CATALINA_OPTS\n```\n\n### 定义Dockerfile\n\n```\nFROM openjdk:8-alpine\n\n# Configuration variables.\nENV JIRA_HOME     /var/atlassian/jira\nENV JIRA_INSTALL  /opt/atlassian/jira\nENV JIRA_VERSION  7.13.0\n\n# Install Atlassian JIRA and helper tools and setup initial home\n# directory structure.\nRUN set -x \\\n    && apk add --no-cache curl xmlstarlet bash ttf-dejavu libc6-compat \\\n    && mkdir -p                \"${JIRA_HOME}\" \\\n    && mkdir -p                \"${JIRA_HOME}/caches/indexes\" \\\n    && chmod -R 700            \"${JIRA_HOME}\" \\\n    && mkdir -p                \"${JIRA_INSTALL}/conf/Catalina\" \\\n    && curl -Ls                \"https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.13.0.tar.gz\" | tar -xz --directory \"${JIRA_INSTALL}\" --strip-components=1 --no-same-owner \\\n    && curl -Ls                \"https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz\" | tar -xz --directory \"${JIRA_INSTALL}/lib\" --strip-components=1 --no-same-owner \"mysql-connector-java-5.1.38/mysql-connector-java-5.1.38-bin.jar\" \\\n    && rm -f                   \"${JIRA_INSTALL}/lib/postgresql-9.1-903.jdbc4-atlassian-hosted.jar\" \\\n    && curl -Ls                \"https://jdbc.postgresql.org/download/postgresql-42.2.1.jar\" -o \"${JIRA_INSTALL}/lib/postgresql-42.2.1.jar\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/conf\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/logs\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/temp\" \\\n    && chmod -R 700            \"${JIRA_INSTALL}/work\" \\\n    && sed --in-place          \"s/java version/openjdk version/g\" \"${JIRA_INSTALL}/bin/check-java.sh\" \\\n    && echo -e                 \"\\njira.home=$JIRA_HOME\" >> \"${JIRA_INSTALL}/atlassian-jira/WEB-INF/classes/jira-application.properties\" \\\n    && touch -d \"@0\"           \"${JIRA_INSTALL}/conf/server.xml\"\n\n# Use the default unprivileged account. This could be considered bad practice\n# on systems where multiple processes end up being executed by 'daemon' but\n# here we only ever run one process anyway.\n#USER daemon:daemon\n\n# Expose default HTTP connector port.\nEXPOSE 8080\n\n# Set volume mount points for installation and home directory. Changes to the\n# home directory needs to be persisted as well as parts of the installation\n# directory due to eg. logs.\nVOLUME [\"/var/atlassian/jira\", \"/opt/atlassian/jira/logs\"]\n\n# Set the default working directory as the installation directory.\nWORKDIR /var/atlassian/jira\n\nCOPY \"docker-entrypoint.sh\" \"/\"\nCOPY atlassian-extras-3.2.jar ${JIRA_INSTALL}/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar \nCOPY atlassian-universal-plugin-manager-plugin-2.22.9.jar ${JIRA_INSTALL}/atlassian-jira/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.9.jar\nCOPY setenv.sh ${JIRA_INSTALL}/bin/setenv.sh\nCOPY server.xml ${JIRA_INSTALL}/conf/server.xml\n\nENTRYPOINT [\"/docker-entrypoint.sh\"]\n\n# Run Atlassian JIRA as a foreground process by default.\nCMD [\"/opt/atlassian/jira/bin/start-jira.sh\", \"-fg\"]\n```\n\n### 定义 server.xml\n自定义server.xml文件，需求后续可以配置https访问\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n    <Listener className=\"org.apache.catalina.startup.VersionLoggerListener\"/>\n    <Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\"/>\n    <Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\"/>\n    <Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\"/>\n    <Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\"/>\n\n    <Service name=\"Catalina\">\n        <Connector port=\"8080\" relaxedPathChars=\"[]|\" relaxedQueryChars=\"[]|{}^&#x5c;&#x60;&quot;&lt;&gt;\"\n                   maxThreads=\"150\" minSpareThreads=\"25\" connectionTimeout=\"20000\" enableLookups=\"false\"\n                   maxHttpHeaderSize=\"8192\" protocol=\"HTTP/1.1\" useBodyEncodingForURI=\"true\" redirectPort=\"8443\"\n                   acceptCount=\"100\" disableUploadTimeout=\"true\" bindOnInit=\"false\"/>\n\n        <Engine name=\"Catalina\" defaultHost=\"localhost\">\n            <Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\">\n\n                <Context path=\"\" docBase=\"${catalina.home}/atlassian-jira\" reloadable=\"false\" useHttpOnly=\"true\">\n                    <Resource name=\"UserTransaction\" auth=\"Container\" type=\"javax.transaction.UserTransaction\"\n                              factory=\"org.objectweb.jotm.UserTransactionFactory\" jotm.timeout=\"60\"/>\n                    <Manager pathname=\"\"/>\n                    <JarScanner scanManifest=\"false\"/>\n                </Context>\n\n            </Host>\n            <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                   pattern=\"%a %{jira.request.id}r %{jira.request.username}r %t &quot;%m %U%q %H&quot; %s %b %D &quot;%{Referer}i&quot; &quot;%{User-Agent}i&quot; &quot;%{jira.request.assession.id}r&quot;\"/>\n        </Engine>\n    </Service>\n</Server>\n```\n### 构建镜像\n```\ndocker build -t jira:7.13.0 .\n```\n\n## Mysql本地安装\n\n### yum 部署mysql\n\n```\ncurl -LO http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\nyum localinstall mysql57-community-release-el7-11.noarch.rpm\nyum install mysql-community-server\nsystemctl enable mysqld\nsystemctl start mysqld\nsystemctl status mysqld\n# 查看密码\ngrep 'temporary password' /var/log/mysqld.log\n# 登录 MySQL 并修改密码\n\nmysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';\n```\n\n### 配置mysql数据库：\n```\n创建数据库：\n\nmysql> CREATE DATABASE jira  DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;\n\n授连接次数据库的权限：\n\nmysql>  grant all privileges on jira.* to jira@'.%' identified by 'jira';\nmysql> flush privileges;\n```\n\n注意： jira7.13.0版本不支持utf8_general_ci的校验规则，因此创建数据库时必须指明utf8_bin校验规则！！\n\n\n## 部署镜像\n\n### Docker 本地部署\n```\ndocker run --publish 8080:8080 --name jira -d local-jira:7.3.8\n```\n\n### 使用docker-compose方式\n\n构建docker-compose.yml\n```\njira:\n  image: jira:7.13.0\n  restart: always\n  environment:\n    - JVM_XMX=2048m\n    - JVM_XMS=1024m\n  ports:\n    - '8080:8080'\n  links:\n    - db\n  volumes:\n    - ./data/jira:/var/atlassian/jira\n    - ./data/logs:/opt/atlassian/jira/logs\n\ndb:\n  image: mysql:5.7\n  restart: always\n  environment:\n    - MYSQL_USER=jira\n    - MYSQL_PASSWORD=jira\n    - MYSQL_DATABASE=jira\n    - MYSQL_ROOT_PASSWORD=jira\n  volumes:\n    - ./data/mysql:/var/lib/mysql\n\n```\n\n### 采用k8s集群方式运行\n\n此环境在阿里云K8s容器平台部署\n\n#### 创建pv\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: hangzhou-b-ssd  \nparameters:\n  cachingmode: None\n  kind: Managed\n  storageaccounttype: Standard_LRS\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n```\n\n#### 创建pvc\n```\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: jira-data\nspec:\n  accessModes:\n   - \"ReadWriteOnce\"\n  resources:\n    requests:\n       storage: \"100Gi\"  \n  storageClassName: \"hangzhou-b-ssd\"\n```\n#### 创建service\n```\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    service.beta.kubernetes.io/alicloud-loadbalancer-cert-id: \"cert-id\"\n    service.beta.kubernetes.io/alicloud-loadbalancer-protocol-port: \"https:443,http:80\"\n  name: jira-svc\n  namespace: default\nspec:\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: jira-svc\n  sessionAffinity: None\n  type: LoadBalancer       \n```\n这里采用阿里自带负载均衡方式部署，然后域名解析到负载均衡外网ip\n\n#### 创建Deployment\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jira-deployment\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jira-svc\n  template:\n    metadata:\n      labels:\n        app: jira-svc\n    spec:\n      containers:\n        - name: jira-svc\n          image: jira:7.13.0\n          imagePullPolicy: Always\n          env:\n          - name: JVM_XMX\n            value: \"2048m\"\n          - name: JVM_XMS\n            value: \"1024m\"\n          ports:\n            - containerPort: 8080\n          volumeMounts:\n          - mountPath: \"/var/atlassian/jira\"\n            name: jira-data         \n      volumes:\n      - name: jira-data\n        persistentVolumeClaim:\n          claimName: jira-data  \n```\n#### 部署\n```\nkubectl apply -f .\n```\n\n\n## 破解\n\n首先按照安装步骤一步一步进行，到证书授权的时候，点击申请证书，然后得到许可证，填入即可，最后在应用程序--版本和许可证，可看到技术服务器截止日期 08/二月/33，即破解成功！(插件破解：免费试用--获取申请码---填入申请码---破解成功)\n\n## 注意的问题\n\n注意：jira插件管理中，atlassian-universal-plugin-manager-plugin插件绝对不要更新，否则插件破解会失效。\n\n补充说明：\n\n1、插件破解原理：\n\natlassian-universal-plugin-manager-plugin插件是进行插件管理的，只需要破解了这个插件，剩下的所有插件都自动破解完成了\n\n2、如果破解不成功、插件管理版本高于2.22.4、或者不小心更新了atlassian-universal-plugin-manager-plugin这个插件怎么办？\n\n遇到这种情况，需要到jira的安装目录和数据目录下，替换掉atlassian-universal-plugin-manager-plugin相关的所有文件。\n\n具体操作步骤：\n\n（1）到jira安装目录和数据目录下find出所有相关文件：\n（2）替换、删除相关文件，保险起见，可在删除前对数据进行备份。 \n（3）重启jira\n（4）到插件管理中心查看插件授权期限，变为2099年\n\n如何修改内存？\n\nvim /opt/atlassian/jira/bin/setenv.sh\n```\nJVM_MINIMUM_MEMORY=${JVM_XMS:-384m}\nJVM_MAXIMUM_MEMORY=${JVM_XMX:-768m}\n```\n\n如何解决mysql ssl报错?\n\nvim /var/atlassian/jira/dbconfig.xml\n```\n<url>jdbc:mysql://address=(protocol=tcp)(host=mysql_hostname)(port=mysql_port)/jira?useUnicode=true&amp;characterEncoding=UTF8&amp;sessionVariables=default_storage_engine=InnoDB&amp;useSSL=false</url>\n```\n## 参考文档：\n* [https://www.jianshu.com/p/744c23f93dfc](https://www.jianshu.com/p/744c23f93dfc)\n\n* [https://cloud.tencent.com/developer/article/1027457](https://cloud.tencent.com/developer/article/1027457)\n\n* [https://paper.tuisec.win/detail/29d80901a36cf52](https://paper.tuisec.win/detail/29d80901a36cf52)","slug":"2018-12-05-article39-linux-jira","published":1,"updated":"2021-02-09T02:00:24.578Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq100030yc97bv00hbit","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"JIRA-7-13-0-实践笔记\"><a href=\"#JIRA-7-13-0-实践笔记\" class=\"headerlink\" title=\"JIRA 7.13.0 实践笔记\"></a>JIRA 7.13.0 实践笔记</h1><p>jira有以下几种安装方式：</p>\n<ul>\n<li><p>Docker容器部署</p>\n</li>\n<li><p>K8s helm部署</p>\n</li>\n<li><p>k8s 部署</p>\n</li>\n<li><p>直接安装 </p>\n</li>\n</ul>\n<p>其中helm安装：<a href=\"https://itnext.io/jira-on-kubernetes-by-helm-8a38357da4e\">helm安装</a>,下面详细介绍容器部署。</p>\n<h2 id=\"镜像构建配置\"><a href=\"#镜像构建配置\" class=\"headerlink\" title=\"镜像构建配置\"></a>镜像构建配置</h2><h3 id=\"Jira容器构建准备\"><a href=\"#Jira容器构建准备\" class=\"headerlink\" title=\"Jira容器构建准备\"></a>Jira容器构建准备</h3><p>破解文件下载：<a href=\"https://github.com/idoall/docker/blob/master/ubuntu16.04-jira/7.2.7/files/usr/src/_jira/jira7.2_hack.zip\">jira7.2_hack.zip</a></p>\n<pre><code>git clone https://github.com/cptactionhank/docker-atlassian-jira-software\n\ncd docker-atlassian-jira-software\n\ncp atlassian-extras-3.2.jar atlassian-universal-plugin-manager-plugin-2.22.9.jar ./ \n</code></pre>\n<h3 id=\"定义-setenv-sh\"><a href=\"#定义-setenv-sh\" class=\"headerlink\" title=\"定义 setenv.sh\"></a>定义 setenv.sh</h3><p>修改默认使用jvm内存(将内存参数以变量传递给容器外部调用)：<br>vim setenv.sh</p>\n<pre><code>#\n# One way to set the JIRA HOME path is here via this variable.  Simply uncomment it and set a valid path like /jira/home.  You can of course set it outside in the command terminal.  That will also work.\n#\n#JIRA_HOME=&quot;&quot;\n\n#\n#  Occasionally Atlassian Support may recommend that you set some specific JVM arguments.  You can use this variable below to do that.\n#\nJVM_SUPPORT_RECOMMENDED_ARGS=&quot;&quot;\n\n#\n# The following 2 settings control the minimum and maximum given to the JIRA Java virtual machine.  In larger JIRA instances, the maximum amount will need to be increased.\n#\nJVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;\nJVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;\n\n#\n# The following setting configures the size of JVM code cache.  A high value of reserved size allows Jira to work with more installed apps.\n#\nJVM_CODE_CACHE_ARGS=&#39;-XX:InitialCodeCacheSize=32m -XX:ReservedCodeCacheSize=512m&#39;\n\n#\n# The following are the required arguments for JIRA.\n#\nJVM_REQUIRED_ARGS=&#39;-Djava.awt.headless=true -Datlassian.standalone=JIRA -Dorg.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER=true -Dmail.mime.decodeparameters=true -Dorg.dom4j.factory=com.atlassian.core.xml.InterningDocumentFactory&#39;\n\n# Uncomment this setting if you want to import data without notifications\n#\n#DISABLE_NOTIFICATIONS=&quot; -Datlassian.mail.senddisabled=true -Datlassian.mail.fetchdisabled=true -Datlassian.mail.popdisabled=true&quot;\n\n\n#-----------------------------------------------------------------------------------\n#\n# In general don&#39;t make changes below here\n#\n#-----------------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------------\n# Prevents the JVM from suppressing stack traces if a given type of exception\n# occurs frequently, which could make it harder for support to diagnose a problem.\n#-----------------------------------------------------------------------------------\nJVM_EXTRA_ARGS=&quot;-XX:-OmitStackTraceInFastThrow&quot;\n\nPRGDIR=`dirname &quot;$0&quot;`\ncat &quot;$&#123;PRGDIR&#125;&quot;/jirabanner.txt\n\nJIRA_HOME_MINUSD=&quot;&quot;\nif [ &quot;$JIRA_HOME&quot; != &quot;&quot; ]; then\n    echo $JIRA_HOME | grep -q &quot; &quot;\n    if [ $? -eq 0 ]; then\n            echo &quot;&quot;\n            echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;\n                echo &quot;   WARNING : You cannot have a JIRA_HOME environment variable set with spaces in it.  This variable is being ignored&quot;\n            echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;\n    else\n                JIRA_HOME_MINUSD=-Djira.home=$JIRA_HOME\n    fi\nfi\n\nJAVA_OPTS=&quot;-Xms$&#123;JVM_MINIMUM_MEMORY&#125; -Xmx$&#123;JVM_MAXIMUM_MEMORY&#125; $&#123;JVM_CODE_CACHE_ARGS&#125; $&#123;JAVA_OPTS&#125; $&#123;JVM_REQUIRED_ARGS&#125; $&#123;DISABLE_NOTIFICATIONS&#125; $&#123;JVM_SUPPORT_RECOMMENDED_ARGS&#125; $&#123;JVM_EXTRA_ARGS&#125; $&#123;JIRA_HOME_MINUSD&#125; $&#123;START_JIRA_JAVA_OPTS&#125;&quot;\n\nexport JAVA_OPTS\n\n# DO NOT remove the following line\n# !INSTALLER SET JAVA_HOME\n\necho &quot;&quot;\necho &quot;If you encounter issues starting or stopping JIRA, please see the Troubleshooting guide at http://confluence.atlassian.com/display/JIRA/Installation+Troubleshooting+Guide&quot;\necho &quot;&quot;\nif [ &quot;$JIRA_HOME_MINUSD&quot; != &quot;&quot; ]; then\n    echo &quot;Using JIRA_HOME:       $JIRA_HOME&quot;\nfi\n\n# set the location of the pid file\nif [ -z &quot;$CATALINA_PID&quot; ] ; then\n    if [ -n &quot;$CATALINA_BASE&quot; ] ; then\n        CATALINA_PID=&quot;$CATALINA_BASE&quot;/work/catalina.pid\n    elif [ -n &quot;$CATALINA_HOME&quot; ] ; then\n        CATALINA_PID=&quot;$CATALINA_HOME&quot;/work/catalina.pid\n    fi\nfi\nexport CATALINA_PID\n\nif [ -z &quot;$CATALINA_BASE&quot; ]; then\n  if [ -z &quot;$CATALINA_HOME&quot; ]; then\n    LOGBASE=$PRGDIR\n    LOGTAIL=..\n  else\n    LOGBASE=$CATALINA_HOME\n    LOGTAIL=.\n  fi\nelse\n  LOGBASE=$CATALINA_BASE\n  LOGTAIL=.\nfi\n\nPUSHED_DIR=`pwd`\ncd $LOGBASE\ncd $LOGTAIL\nLOGBASEABS=`pwd`\ncd $PUSHED_DIR\n\necho &quot;&quot;\necho &quot;Server startup logs are located in $LOGBASEABS/logs/catalina.out&quot;\n\n# Set the JVM arguments used to start JIRA. For a description of the options, see\n# http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\n\n#-----------------------------------------------------------------------------------\n# This allows us to actually debug GC related issues by correlating timestamps\n# with other parts of the application logs.\n#-----------------------------------------------------------------------------------\nGC_JVM_PARAMETERS=&quot;&quot;\nGC_JVM_PARAMETERS=&quot;-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause $&#123;GC_JVM_PARAMETERS&#125;&quot;\nGC_JVM_PARAMETERS=&quot;-Xloggc:$LOGBASEABS/logs/atlassian-jira-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M $&#123;GC_JVM_PARAMETERS&#125;&quot;\n\nCATALINA_OPTS=&quot;$&#123;GC_JVM_PARAMETERS&#125; $&#123;CATALINA_OPTS&#125;&quot;\nexport CATALINA_OPTS\n</code></pre>\n<h3 id=\"定义Dockerfile\"><a href=\"#定义Dockerfile\" class=\"headerlink\" title=\"定义Dockerfile\"></a>定义Dockerfile</h3><pre><code>FROM openjdk:8-alpine\n\n# Configuration variables.\nENV JIRA_HOME     /var/atlassian/jira\nENV JIRA_INSTALL  /opt/atlassian/jira\nENV JIRA_VERSION  7.13.0\n\n# Install Atlassian JIRA and helper tools and setup initial home\n# directory structure.\nRUN set -x \\\n    &amp;&amp; apk add --no-cache curl xmlstarlet bash ttf-dejavu libc6-compat \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;&quot; \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;/caches/indexes&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_HOME&#125;&quot; \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_INSTALL&#125;/conf/Catalina&quot; \\\n    &amp;&amp; curl -Ls                &quot;https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.13.0.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;&quot; --strip-components=1 --no-same-owner \\\n    &amp;&amp; curl -Ls                &quot;https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;/lib&quot; --strip-components=1 --no-same-owner &quot;mysql-connector-java-5.1.38/mysql-connector-java-5.1.38-bin.jar&quot; \\\n    &amp;&amp; rm -f                   &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-9.1-903.jdbc4-atlassian-hosted.jar&quot; \\\n    &amp;&amp; curl -Ls                &quot;https://jdbc.postgresql.org/download/postgresql-42.2.1.jar&quot; -o &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-42.2.1.jar&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/conf&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/logs&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/temp&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/work&quot; \\\n    &amp;&amp; sed --in-place          &quot;s/java version/openjdk version/g&quot; &quot;$&#123;JIRA_INSTALL&#125;/bin/check-java.sh&quot; \\\n    &amp;&amp; echo -e                 &quot;\\njira.home=$JIRA_HOME&quot; &gt;&gt; &quot;$&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/classes/jira-application.properties&quot; \\\n    &amp;&amp; touch -d &quot;@0&quot;           &quot;$&#123;JIRA_INSTALL&#125;/conf/server.xml&quot;\n\n# Use the default unprivileged account. This could be considered bad practice\n# on systems where multiple processes end up being executed by &#39;daemon&#39; but\n# here we only ever run one process anyway.\n#USER daemon:daemon\n\n# Expose default HTTP connector port.\nEXPOSE 8080\n\n# Set volume mount points for installation and home directory. Changes to the\n# home directory needs to be persisted as well as parts of the installation\n# directory due to eg. logs.\nVOLUME [&quot;/var/atlassian/jira&quot;, &quot;/opt/atlassian/jira/logs&quot;]\n\n# Set the default working directory as the installation directory.\nWORKDIR /var/atlassian/jira\n\nCOPY &quot;docker-entrypoint.sh&quot; &quot;/&quot;\nCOPY atlassian-extras-3.2.jar $&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar \nCOPY atlassian-universal-plugin-manager-plugin-2.22.9.jar $&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.9.jar\nCOPY setenv.sh $&#123;JIRA_INSTALL&#125;/bin/setenv.sh\nCOPY server.xml $&#123;JIRA_INSTALL&#125;/conf/server.xml\n\nENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]\n\n# Run Atlassian JIRA as a foreground process by default.\nCMD [&quot;/opt/atlassian/jira/bin/start-jira.sh&quot;, &quot;-fg&quot;]\n</code></pre>\n<h3 id=\"定义-server-xml\"><a href=\"#定义-server-xml\" class=\"headerlink\" title=\"定义 server.xml\"></a>定义 server.xml</h3><p>自定义server.xml文件，需求后续可以配置https访问</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;\n&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;\n    &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot;/&gt;\n\n    &lt;Service name=&quot;Catalina&quot;&gt;\n        &lt;Connector port=&quot;8080&quot; relaxedPathChars=&quot;[]|&quot; relaxedQueryChars=&quot;[]|&#123;&#125;^&amp;#x5c;&amp;#x60;&amp;quot;&amp;lt;&amp;gt;&quot;\n                   maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot; connectionTimeout=&quot;20000&quot; enableLookups=&quot;false&quot;\n                   maxHttpHeaderSize=&quot;8192&quot; protocol=&quot;HTTP/1.1&quot; useBodyEncodingForURI=&quot;true&quot; redirectPort=&quot;8443&quot;\n                   acceptCount=&quot;100&quot; disableUploadTimeout=&quot;true&quot; bindOnInit=&quot;false&quot;/&gt;\n\n        &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;\n            &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;\n\n                &lt;Context path=&quot;&quot; docBase=&quot;$&#123;catalina.home&#125;/atlassian-jira&quot; reloadable=&quot;false&quot; useHttpOnly=&quot;true&quot;&gt;\n                    &lt;Resource name=&quot;UserTransaction&quot; auth=&quot;Container&quot; type=&quot;javax.transaction.UserTransaction&quot;\n                              factory=&quot;org.objectweb.jotm.UserTransactionFactory&quot; jotm.timeout=&quot;60&quot;/&gt;\n                    &lt;Manager pathname=&quot;&quot;/&gt;\n                    &lt;JarScanner scanManifest=&quot;false&quot;/&gt;\n                &lt;/Context&gt;\n\n            &lt;/Host&gt;\n            &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot;\n                   pattern=&quot;%a %&#123;jira.request.id&#125;r %&#123;jira.request.username&#125;r %t &amp;quot;%m %U%q %H&amp;quot; %s %b %D &amp;quot;%&#123;Referer&#125;i&amp;quot; &amp;quot;%&#123;User-Agent&#125;i&amp;quot; &amp;quot;%&#123;jira.request.assession.id&#125;r&amp;quot;&quot;/&gt;\n        &lt;/Engine&gt;\n    &lt;/Service&gt;\n&lt;/Server&gt;\n</code></pre>\n<h3 id=\"构建镜像\"><a href=\"#构建镜像\" class=\"headerlink\" title=\"构建镜像\"></a>构建镜像</h3><pre><code>docker build -t jira:7.13.0 .\n</code></pre>\n<h2 id=\"Mysql本地安装\"><a href=\"#Mysql本地安装\" class=\"headerlink\" title=\"Mysql本地安装\"></a>Mysql本地安装</h2><h3 id=\"yum-部署mysql\"><a href=\"#yum-部署mysql\" class=\"headerlink\" title=\"yum 部署mysql\"></a>yum 部署mysql</h3><pre><code>curl -LO http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\nyum localinstall mysql57-community-release-el7-11.noarch.rpm\nyum install mysql-community-server\nsystemctl enable mysqld\nsystemctl start mysqld\nsystemctl status mysqld\n# 查看密码\ngrep &#39;temporary password&#39; /var/log/mysqld.log\n# 登录 MySQL 并修改密码\n\nmysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;;\n</code></pre>\n<h3 id=\"配置mysql数据库：\"><a href=\"#配置mysql数据库：\" class=\"headerlink\" title=\"配置mysql数据库：\"></a>配置mysql数据库：</h3><pre><code>创建数据库：\n\nmysql&gt; CREATE DATABASE jira  DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;\n\n授连接次数据库的权限：\n\nmysql&gt;  grant all privileges on jira.* to jira@&#39;.%&#39; identified by &#39;jira&#39;;\nmysql&gt; flush privileges;\n</code></pre>\n<p>注意： jira7.13.0版本不支持utf8_general_ci的校验规则，因此创建数据库时必须指明utf8_bin校验规则！！</p>\n<h2 id=\"部署镜像\"><a href=\"#部署镜像\" class=\"headerlink\" title=\"部署镜像\"></a>部署镜像</h2><h3 id=\"Docker-本地部署\"><a href=\"#Docker-本地部署\" class=\"headerlink\" title=\"Docker 本地部署\"></a>Docker 本地部署</h3><pre><code>docker run --publish 8080:8080 --name jira -d local-jira:7.3.8\n</code></pre>\n<h3 id=\"使用docker-compose方式\"><a href=\"#使用docker-compose方式\" class=\"headerlink\" title=\"使用docker-compose方式\"></a>使用docker-compose方式</h3><p>构建docker-compose.yml</p>\n<pre><code>jira:\n  image: jira:7.13.0\n  restart: always\n  environment:\n    - JVM_XMX=2048m\n    - JVM_XMS=1024m\n  ports:\n    - &#39;8080:8080&#39;\n  links:\n    - db\n  volumes:\n    - ./data/jira:/var/atlassian/jira\n    - ./data/logs:/opt/atlassian/jira/logs\n\ndb:\n  image: mysql:5.7\n  restart: always\n  environment:\n    - MYSQL_USER=jira\n    - MYSQL_PASSWORD=jira\n    - MYSQL_DATABASE=jira\n    - MYSQL_ROOT_PASSWORD=jira\n  volumes:\n    - ./data/mysql:/var/lib/mysql\n</code></pre>\n<h3 id=\"采用k8s集群方式运行\"><a href=\"#采用k8s集群方式运行\" class=\"headerlink\" title=\"采用k8s集群方式运行\"></a>采用k8s集群方式运行</h3><p>此环境在阿里云K8s容器平台部署</p>\n<h4 id=\"创建pv\"><a href=\"#创建pv\" class=\"headerlink\" title=\"创建pv\"></a>创建pv</h4><pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: hangzhou-b-ssd  \nparameters:\n  cachingmode: None\n  kind: Managed\n  storageaccounttype: Standard_LRS\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n</code></pre>\n<h4 id=\"创建pvc\"><a href=\"#创建pvc\" class=\"headerlink\" title=\"创建pvc\"></a>创建pvc</h4><pre><code>kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: jira-data\nspec:\n  accessModes:\n   - &quot;ReadWriteOnce&quot;\n  resources:\n    requests:\n       storage: &quot;100Gi&quot;  \n  storageClassName: &quot;hangzhou-b-ssd&quot;\n</code></pre>\n<h4 id=\"创建service\"><a href=\"#创建service\" class=\"headerlink\" title=\"创建service\"></a>创建service</h4><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    service.beta.kubernetes.io/alicloud-loadbalancer-cert-id: &quot;cert-id&quot;\n    service.beta.kubernetes.io/alicloud-loadbalancer-protocol-port: &quot;https:443,http:80&quot;\n  name: jira-svc\n  namespace: default\nspec:\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: jira-svc\n  sessionAffinity: None\n  type: LoadBalancer       \n</code></pre>\n<p>这里采用阿里自带负载均衡方式部署，然后域名解析到负载均衡外网ip</p>\n<h4 id=\"创建Deployment\"><a href=\"#创建Deployment\" class=\"headerlink\" title=\"创建Deployment\"></a>创建Deployment</h4><pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jira-deployment\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jira-svc\n  template:\n    metadata:\n      labels:\n        app: jira-svc\n    spec:\n      containers:\n        - name: jira-svc\n          image: jira:7.13.0\n          imagePullPolicy: Always\n          env:\n          - name: JVM_XMX\n            value: &quot;2048m&quot;\n          - name: JVM_XMS\n            value: &quot;1024m&quot;\n          ports:\n            - containerPort: 8080\n          volumeMounts:\n          - mountPath: &quot;/var/atlassian/jira&quot;\n            name: jira-data         \n      volumes:\n      - name: jira-data\n        persistentVolumeClaim:\n          claimName: jira-data  \n</code></pre>\n<h4 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h4><pre><code>kubectl apply -f .\n</code></pre>\n<h2 id=\"破解\"><a href=\"#破解\" class=\"headerlink\" title=\"破解\"></a>破解</h2><p>首先按照安装步骤一步一步进行，到证书授权的时候，点击申请证书，然后得到许可证，填入即可，最后在应用程序–版本和许可证，可看到技术服务器截止日期 08/二月/33，即破解成功！(插件破解：免费试用–获取申请码—填入申请码—破解成功)</p>\n<h2 id=\"注意的问题\"><a href=\"#注意的问题\" class=\"headerlink\" title=\"注意的问题\"></a>注意的问题</h2><p>注意：jira插件管理中，atlassian-universal-plugin-manager-plugin插件绝对不要更新，否则插件破解会失效。</p>\n<p>补充说明：</p>\n<p>1、插件破解原理：</p>\n<p>atlassian-universal-plugin-manager-plugin插件是进行插件管理的，只需要破解了这个插件，剩下的所有插件都自动破解完成了</p>\n<p>2、如果破解不成功、插件管理版本高于2.22.4、或者不小心更新了atlassian-universal-plugin-manager-plugin这个插件怎么办？</p>\n<p>遇到这种情况，需要到jira的安装目录和数据目录下，替换掉atlassian-universal-plugin-manager-plugin相关的所有文件。</p>\n<p>具体操作步骤：</p>\n<p>（1）到jira安装目录和数据目录下find出所有相关文件：<br>（2）替换、删除相关文件，保险起见，可在删除前对数据进行备份。<br>（3）重启jira<br>（4）到插件管理中心查看插件授权期限，变为2099年</p>\n<p>如何修改内存？</p>\n<p>vim /opt/atlassian/jira/bin/setenv.sh</p>\n<pre><code>JVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;\nJVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;\n</code></pre>\n<p>如何解决mysql ssl报错?</p>\n<p>vim /var/atlassian/jira/dbconfig.xml</p>\n<pre><code>&lt;url&gt;jdbc:mysql://address=(protocol=tcp)(host=mysql_hostname)(port=mysql_port)/jira?useUnicode=true&amp;amp;characterEncoding=UTF8&amp;amp;sessionVariables=default_storage_engine=InnoDB&amp;amp;useSSL=false&lt;/url&gt;\n</code></pre>\n<h2 id=\"参考文档：\"><a href=\"#参考文档：\" class=\"headerlink\" title=\"参考文档：\"></a>参考文档：</h2><ul>\n<li><p><a href=\"https://www.jianshu.com/p/744c23f93dfc\">https://www.jianshu.com/p/744c23f93dfc</a></p>\n</li>\n<li><p><a href=\"https://cloud.tencent.com/developer/article/1027457\">https://cloud.tencent.com/developer/article/1027457</a></p>\n</li>\n<li><p><a href=\"https://paper.tuisec.win/detail/29d80901a36cf52\">https://paper.tuisec.win/detail/29d80901a36cf52</a></p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"JIRA-7-13-0-实践笔记\"><a href=\"#JIRA-7-13-0-实践笔记\" class=\"headerlink\" title=\"JIRA 7.13.0 实践笔记\"></a>JIRA 7.13.0 实践笔记</h1><p>jira有以下几种安装方式：</p>\n<ul>\n<li><p>Docker容器部署</p>\n</li>\n<li><p>K8s helm部署</p>\n</li>\n<li><p>k8s 部署</p>\n</li>\n<li><p>直接安装 </p>\n</li>\n</ul>\n<p>其中helm安装：<a href=\"https://itnext.io/jira-on-kubernetes-by-helm-8a38357da4e\">helm安装</a>,下面详细介绍容器部署。</p>\n<h2 id=\"镜像构建配置\"><a href=\"#镜像构建配置\" class=\"headerlink\" title=\"镜像构建配置\"></a>镜像构建配置</h2><h3 id=\"Jira容器构建准备\"><a href=\"#Jira容器构建准备\" class=\"headerlink\" title=\"Jira容器构建准备\"></a>Jira容器构建准备</h3><p>破解文件下载：<a href=\"https://github.com/idoall/docker/blob/master/ubuntu16.04-jira/7.2.7/files/usr/src/_jira/jira7.2_hack.zip\">jira7.2_hack.zip</a></p>\n<pre><code>git clone https://github.com/cptactionhank/docker-atlassian-jira-software\n\ncd docker-atlassian-jira-software\n\ncp atlassian-extras-3.2.jar atlassian-universal-plugin-manager-plugin-2.22.9.jar ./ \n</code></pre>\n<h3 id=\"定义-setenv-sh\"><a href=\"#定义-setenv-sh\" class=\"headerlink\" title=\"定义 setenv.sh\"></a>定义 setenv.sh</h3><p>修改默认使用jvm内存(将内存参数以变量传递给容器外部调用)：<br>vim setenv.sh</p>\n<pre><code>#\n# One way to set the JIRA HOME path is here via this variable.  Simply uncomment it and set a valid path like /jira/home.  You can of course set it outside in the command terminal.  That will also work.\n#\n#JIRA_HOME=&quot;&quot;\n\n#\n#  Occasionally Atlassian Support may recommend that you set some specific JVM arguments.  You can use this variable below to do that.\n#\nJVM_SUPPORT_RECOMMENDED_ARGS=&quot;&quot;\n\n#\n# The following 2 settings control the minimum and maximum given to the JIRA Java virtual machine.  In larger JIRA instances, the maximum amount will need to be increased.\n#\nJVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;\nJVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;\n\n#\n# The following setting configures the size of JVM code cache.  A high value of reserved size allows Jira to work with more installed apps.\n#\nJVM_CODE_CACHE_ARGS=&#39;-XX:InitialCodeCacheSize=32m -XX:ReservedCodeCacheSize=512m&#39;\n\n#\n# The following are the required arguments for JIRA.\n#\nJVM_REQUIRED_ARGS=&#39;-Djava.awt.headless=true -Datlassian.standalone=JIRA -Dorg.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER=true -Dmail.mime.decodeparameters=true -Dorg.dom4j.factory=com.atlassian.core.xml.InterningDocumentFactory&#39;\n\n# Uncomment this setting if you want to import data without notifications\n#\n#DISABLE_NOTIFICATIONS=&quot; -Datlassian.mail.senddisabled=true -Datlassian.mail.fetchdisabled=true -Datlassian.mail.popdisabled=true&quot;\n\n\n#-----------------------------------------------------------------------------------\n#\n# In general don&#39;t make changes below here\n#\n#-----------------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------------\n# Prevents the JVM from suppressing stack traces if a given type of exception\n# occurs frequently, which could make it harder for support to diagnose a problem.\n#-----------------------------------------------------------------------------------\nJVM_EXTRA_ARGS=&quot;-XX:-OmitStackTraceInFastThrow&quot;\n\nPRGDIR=`dirname &quot;$0&quot;`\ncat &quot;$&#123;PRGDIR&#125;&quot;/jirabanner.txt\n\nJIRA_HOME_MINUSD=&quot;&quot;\nif [ &quot;$JIRA_HOME&quot; != &quot;&quot; ]; then\n    echo $JIRA_HOME | grep -q &quot; &quot;\n    if [ $? -eq 0 ]; then\n            echo &quot;&quot;\n            echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;\n                echo &quot;   WARNING : You cannot have a JIRA_HOME environment variable set with spaces in it.  This variable is being ignored&quot;\n            echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;\n    else\n                JIRA_HOME_MINUSD=-Djira.home=$JIRA_HOME\n    fi\nfi\n\nJAVA_OPTS=&quot;-Xms$&#123;JVM_MINIMUM_MEMORY&#125; -Xmx$&#123;JVM_MAXIMUM_MEMORY&#125; $&#123;JVM_CODE_CACHE_ARGS&#125; $&#123;JAVA_OPTS&#125; $&#123;JVM_REQUIRED_ARGS&#125; $&#123;DISABLE_NOTIFICATIONS&#125; $&#123;JVM_SUPPORT_RECOMMENDED_ARGS&#125; $&#123;JVM_EXTRA_ARGS&#125; $&#123;JIRA_HOME_MINUSD&#125; $&#123;START_JIRA_JAVA_OPTS&#125;&quot;\n\nexport JAVA_OPTS\n\n# DO NOT remove the following line\n# !INSTALLER SET JAVA_HOME\n\necho &quot;&quot;\necho &quot;If you encounter issues starting or stopping JIRA, please see the Troubleshooting guide at http://confluence.atlassian.com/display/JIRA/Installation+Troubleshooting+Guide&quot;\necho &quot;&quot;\nif [ &quot;$JIRA_HOME_MINUSD&quot; != &quot;&quot; ]; then\n    echo &quot;Using JIRA_HOME:       $JIRA_HOME&quot;\nfi\n\n# set the location of the pid file\nif [ -z &quot;$CATALINA_PID&quot; ] ; then\n    if [ -n &quot;$CATALINA_BASE&quot; ] ; then\n        CATALINA_PID=&quot;$CATALINA_BASE&quot;/work/catalina.pid\n    elif [ -n &quot;$CATALINA_HOME&quot; ] ; then\n        CATALINA_PID=&quot;$CATALINA_HOME&quot;/work/catalina.pid\n    fi\nfi\nexport CATALINA_PID\n\nif [ -z &quot;$CATALINA_BASE&quot; ]; then\n  if [ -z &quot;$CATALINA_HOME&quot; ]; then\n    LOGBASE=$PRGDIR\n    LOGTAIL=..\n  else\n    LOGBASE=$CATALINA_HOME\n    LOGTAIL=.\n  fi\nelse\n  LOGBASE=$CATALINA_BASE\n  LOGTAIL=.\nfi\n\nPUSHED_DIR=`pwd`\ncd $LOGBASE\ncd $LOGTAIL\nLOGBASEABS=`pwd`\ncd $PUSHED_DIR\n\necho &quot;&quot;\necho &quot;Server startup logs are located in $LOGBASEABS/logs/catalina.out&quot;\n\n# Set the JVM arguments used to start JIRA. For a description of the options, see\n# http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\n\n#-----------------------------------------------------------------------------------\n# This allows us to actually debug GC related issues by correlating timestamps\n# with other parts of the application logs.\n#-----------------------------------------------------------------------------------\nGC_JVM_PARAMETERS=&quot;&quot;\nGC_JVM_PARAMETERS=&quot;-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause $&#123;GC_JVM_PARAMETERS&#125;&quot;\nGC_JVM_PARAMETERS=&quot;-Xloggc:$LOGBASEABS/logs/atlassian-jira-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M $&#123;GC_JVM_PARAMETERS&#125;&quot;\n\nCATALINA_OPTS=&quot;$&#123;GC_JVM_PARAMETERS&#125; $&#123;CATALINA_OPTS&#125;&quot;\nexport CATALINA_OPTS\n</code></pre>\n<h3 id=\"定义Dockerfile\"><a href=\"#定义Dockerfile\" class=\"headerlink\" title=\"定义Dockerfile\"></a>定义Dockerfile</h3><pre><code>FROM openjdk:8-alpine\n\n# Configuration variables.\nENV JIRA_HOME     /var/atlassian/jira\nENV JIRA_INSTALL  /opt/atlassian/jira\nENV JIRA_VERSION  7.13.0\n\n# Install Atlassian JIRA and helper tools and setup initial home\n# directory structure.\nRUN set -x \\\n    &amp;&amp; apk add --no-cache curl xmlstarlet bash ttf-dejavu libc6-compat \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;&quot; \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;/caches/indexes&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_HOME&#125;&quot; \\\n    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_INSTALL&#125;/conf/Catalina&quot; \\\n    &amp;&amp; curl -Ls                &quot;https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.13.0.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;&quot; --strip-components=1 --no-same-owner \\\n    &amp;&amp; curl -Ls                &quot;https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;/lib&quot; --strip-components=1 --no-same-owner &quot;mysql-connector-java-5.1.38/mysql-connector-java-5.1.38-bin.jar&quot; \\\n    &amp;&amp; rm -f                   &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-9.1-903.jdbc4-atlassian-hosted.jar&quot; \\\n    &amp;&amp; curl -Ls                &quot;https://jdbc.postgresql.org/download/postgresql-42.2.1.jar&quot; -o &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-42.2.1.jar&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/conf&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/logs&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/temp&quot; \\\n    &amp;&amp; chmod -R 700            &quot;$&#123;JIRA_INSTALL&#125;/work&quot; \\\n    &amp;&amp; sed --in-place          &quot;s/java version/openjdk version/g&quot; &quot;$&#123;JIRA_INSTALL&#125;/bin/check-java.sh&quot; \\\n    &amp;&amp; echo -e                 &quot;\\njira.home=$JIRA_HOME&quot; &gt;&gt; &quot;$&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/classes/jira-application.properties&quot; \\\n    &amp;&amp; touch -d &quot;@0&quot;           &quot;$&#123;JIRA_INSTALL&#125;/conf/server.xml&quot;\n\n# Use the default unprivileged account. This could be considered bad practice\n# on systems where multiple processes end up being executed by &#39;daemon&#39; but\n# here we only ever run one process anyway.\n#USER daemon:daemon\n\n# Expose default HTTP connector port.\nEXPOSE 8080\n\n# Set volume mount points for installation and home directory. Changes to the\n# home directory needs to be persisted as well as parts of the installation\n# directory due to eg. logs.\nVOLUME [&quot;/var/atlassian/jira&quot;, &quot;/opt/atlassian/jira/logs&quot;]\n\n# Set the default working directory as the installation directory.\nWORKDIR /var/atlassian/jira\n\nCOPY &quot;docker-entrypoint.sh&quot; &quot;/&quot;\nCOPY atlassian-extras-3.2.jar $&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar \nCOPY atlassian-universal-plugin-manager-plugin-2.22.9.jar $&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.9.jar\nCOPY setenv.sh $&#123;JIRA_INSTALL&#125;/bin/setenv.sh\nCOPY server.xml $&#123;JIRA_INSTALL&#125;/conf/server.xml\n\nENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]\n\n# Run Atlassian JIRA as a foreground process by default.\nCMD [&quot;/opt/atlassian/jira/bin/start-jira.sh&quot;, &quot;-fg&quot;]\n</code></pre>\n<h3 id=\"定义-server-xml\"><a href=\"#定义-server-xml\" class=\"headerlink\" title=\"定义 server.xml\"></a>定义 server.xml</h3><p>自定义server.xml文件，需求后续可以配置https访问</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;\n&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;\n    &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot;/&gt;\n    &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot;/&gt;\n\n    &lt;Service name=&quot;Catalina&quot;&gt;\n        &lt;Connector port=&quot;8080&quot; relaxedPathChars=&quot;[]|&quot; relaxedQueryChars=&quot;[]|&#123;&#125;^&amp;#x5c;&amp;#x60;&amp;quot;&amp;lt;&amp;gt;&quot;\n                   maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot; connectionTimeout=&quot;20000&quot; enableLookups=&quot;false&quot;\n                   maxHttpHeaderSize=&quot;8192&quot; protocol=&quot;HTTP/1.1&quot; useBodyEncodingForURI=&quot;true&quot; redirectPort=&quot;8443&quot;\n                   acceptCount=&quot;100&quot; disableUploadTimeout=&quot;true&quot; bindOnInit=&quot;false&quot;/&gt;\n\n        &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;\n            &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;\n\n                &lt;Context path=&quot;&quot; docBase=&quot;$&#123;catalina.home&#125;/atlassian-jira&quot; reloadable=&quot;false&quot; useHttpOnly=&quot;true&quot;&gt;\n                    &lt;Resource name=&quot;UserTransaction&quot; auth=&quot;Container&quot; type=&quot;javax.transaction.UserTransaction&quot;\n                              factory=&quot;org.objectweb.jotm.UserTransactionFactory&quot; jotm.timeout=&quot;60&quot;/&gt;\n                    &lt;Manager pathname=&quot;&quot;/&gt;\n                    &lt;JarScanner scanManifest=&quot;false&quot;/&gt;\n                &lt;/Context&gt;\n\n            &lt;/Host&gt;\n            &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot;\n                   pattern=&quot;%a %&#123;jira.request.id&#125;r %&#123;jira.request.username&#125;r %t &amp;quot;%m %U%q %H&amp;quot; %s %b %D &amp;quot;%&#123;Referer&#125;i&amp;quot; &amp;quot;%&#123;User-Agent&#125;i&amp;quot; &amp;quot;%&#123;jira.request.assession.id&#125;r&amp;quot;&quot;/&gt;\n        &lt;/Engine&gt;\n    &lt;/Service&gt;\n&lt;/Server&gt;\n</code></pre>\n<h3 id=\"构建镜像\"><a href=\"#构建镜像\" class=\"headerlink\" title=\"构建镜像\"></a>构建镜像</h3><pre><code>docker build -t jira:7.13.0 .\n</code></pre>\n<h2 id=\"Mysql本地安装\"><a href=\"#Mysql本地安装\" class=\"headerlink\" title=\"Mysql本地安装\"></a>Mysql本地安装</h2><h3 id=\"yum-部署mysql\"><a href=\"#yum-部署mysql\" class=\"headerlink\" title=\"yum 部署mysql\"></a>yum 部署mysql</h3><pre><code>curl -LO http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\nyum localinstall mysql57-community-release-el7-11.noarch.rpm\nyum install mysql-community-server\nsystemctl enable mysqld\nsystemctl start mysqld\nsystemctl status mysqld\n# 查看密码\ngrep &#39;temporary password&#39; /var/log/mysqld.log\n# 登录 MySQL 并修改密码\n\nmysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;;\n</code></pre>\n<h3 id=\"配置mysql数据库：\"><a href=\"#配置mysql数据库：\" class=\"headerlink\" title=\"配置mysql数据库：\"></a>配置mysql数据库：</h3><pre><code>创建数据库：\n\nmysql&gt; CREATE DATABASE jira  DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;\n\n授连接次数据库的权限：\n\nmysql&gt;  grant all privileges on jira.* to jira@&#39;.%&#39; identified by &#39;jira&#39;;\nmysql&gt; flush privileges;\n</code></pre>\n<p>注意： jira7.13.0版本不支持utf8_general_ci的校验规则，因此创建数据库时必须指明utf8_bin校验规则！！</p>\n<h2 id=\"部署镜像\"><a href=\"#部署镜像\" class=\"headerlink\" title=\"部署镜像\"></a>部署镜像</h2><h3 id=\"Docker-本地部署\"><a href=\"#Docker-本地部署\" class=\"headerlink\" title=\"Docker 本地部署\"></a>Docker 本地部署</h3><pre><code>docker run --publish 8080:8080 --name jira -d local-jira:7.3.8\n</code></pre>\n<h3 id=\"使用docker-compose方式\"><a href=\"#使用docker-compose方式\" class=\"headerlink\" title=\"使用docker-compose方式\"></a>使用docker-compose方式</h3><p>构建docker-compose.yml</p>\n<pre><code>jira:\n  image: jira:7.13.0\n  restart: always\n  environment:\n    - JVM_XMX=2048m\n    - JVM_XMS=1024m\n  ports:\n    - &#39;8080:8080&#39;\n  links:\n    - db\n  volumes:\n    - ./data/jira:/var/atlassian/jira\n    - ./data/logs:/opt/atlassian/jira/logs\n\ndb:\n  image: mysql:5.7\n  restart: always\n  environment:\n    - MYSQL_USER=jira\n    - MYSQL_PASSWORD=jira\n    - MYSQL_DATABASE=jira\n    - MYSQL_ROOT_PASSWORD=jira\n  volumes:\n    - ./data/mysql:/var/lib/mysql\n</code></pre>\n<h3 id=\"采用k8s集群方式运行\"><a href=\"#采用k8s集群方式运行\" class=\"headerlink\" title=\"采用k8s集群方式运行\"></a>采用k8s集群方式运行</h3><p>此环境在阿里云K8s容器平台部署</p>\n<h4 id=\"创建pv\"><a href=\"#创建pv\" class=\"headerlink\" title=\"创建pv\"></a>创建pv</h4><pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: hangzhou-b-ssd  \nparameters:\n  cachingmode: None\n  kind: Managed\n  storageaccounttype: Standard_LRS\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n</code></pre>\n<h4 id=\"创建pvc\"><a href=\"#创建pvc\" class=\"headerlink\" title=\"创建pvc\"></a>创建pvc</h4><pre><code>kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: jira-data\nspec:\n  accessModes:\n   - &quot;ReadWriteOnce&quot;\n  resources:\n    requests:\n       storage: &quot;100Gi&quot;  \n  storageClassName: &quot;hangzhou-b-ssd&quot;\n</code></pre>\n<h4 id=\"创建service\"><a href=\"#创建service\" class=\"headerlink\" title=\"创建service\"></a>创建service</h4><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    service.beta.kubernetes.io/alicloud-loadbalancer-cert-id: &quot;cert-id&quot;\n    service.beta.kubernetes.io/alicloud-loadbalancer-protocol-port: &quot;https:443,http:80&quot;\n  name: jira-svc\n  namespace: default\nspec:\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: jira-svc\n  sessionAffinity: None\n  type: LoadBalancer       \n</code></pre>\n<p>这里采用阿里自带负载均衡方式部署，然后域名解析到负载均衡外网ip</p>\n<h4 id=\"创建Deployment\"><a href=\"#创建Deployment\" class=\"headerlink\" title=\"创建Deployment\"></a>创建Deployment</h4><pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jira-deployment\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jira-svc\n  template:\n    metadata:\n      labels:\n        app: jira-svc\n    spec:\n      containers:\n        - name: jira-svc\n          image: jira:7.13.0\n          imagePullPolicy: Always\n          env:\n          - name: JVM_XMX\n            value: &quot;2048m&quot;\n          - name: JVM_XMS\n            value: &quot;1024m&quot;\n          ports:\n            - containerPort: 8080\n          volumeMounts:\n          - mountPath: &quot;/var/atlassian/jira&quot;\n            name: jira-data         \n      volumes:\n      - name: jira-data\n        persistentVolumeClaim:\n          claimName: jira-data  \n</code></pre>\n<h4 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h4><pre><code>kubectl apply -f .\n</code></pre>\n<h2 id=\"破解\"><a href=\"#破解\" class=\"headerlink\" title=\"破解\"></a>破解</h2><p>首先按照安装步骤一步一步进行，到证书授权的时候，点击申请证书，然后得到许可证，填入即可，最后在应用程序–版本和许可证，可看到技术服务器截止日期 08/二月/33，即破解成功！(插件破解：免费试用–获取申请码—填入申请码—破解成功)</p>\n<h2 id=\"注意的问题\"><a href=\"#注意的问题\" class=\"headerlink\" title=\"注意的问题\"></a>注意的问题</h2><p>注意：jira插件管理中，atlassian-universal-plugin-manager-plugin插件绝对不要更新，否则插件破解会失效。</p>\n<p>补充说明：</p>\n<p>1、插件破解原理：</p>\n<p>atlassian-universal-plugin-manager-plugin插件是进行插件管理的，只需要破解了这个插件，剩下的所有插件都自动破解完成了</p>\n<p>2、如果破解不成功、插件管理版本高于2.22.4、或者不小心更新了atlassian-universal-plugin-manager-plugin这个插件怎么办？</p>\n<p>遇到这种情况，需要到jira的安装目录和数据目录下，替换掉atlassian-universal-plugin-manager-plugin相关的所有文件。</p>\n<p>具体操作步骤：</p>\n<p>（1）到jira安装目录和数据目录下find出所有相关文件：<br>（2）替换、删除相关文件，保险起见，可在删除前对数据进行备份。<br>（3）重启jira<br>（4）到插件管理中心查看插件授权期限，变为2099年</p>\n<p>如何修改内存？</p>\n<p>vim /opt/atlassian/jira/bin/setenv.sh</p>\n<pre><code>JVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;\nJVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;\n</code></pre>\n<p>如何解决mysql ssl报错?</p>\n<p>vim /var/atlassian/jira/dbconfig.xml</p>\n<pre><code>&lt;url&gt;jdbc:mysql://address=(protocol=tcp)(host=mysql_hostname)(port=mysql_port)/jira?useUnicode=true&amp;amp;characterEncoding=UTF8&amp;amp;sessionVariables=default_storage_engine=InnoDB&amp;amp;useSSL=false&lt;/url&gt;\n</code></pre>\n<h2 id=\"参考文档：\"><a href=\"#参考文档：\" class=\"headerlink\" title=\"参考文档：\"></a>参考文档：</h2><ul>\n<li><p><a href=\"https://www.jianshu.com/p/744c23f93dfc\">https://www.jianshu.com/p/744c23f93dfc</a></p>\n</li>\n<li><p><a href=\"https://cloud.tencent.com/developer/article/1027457\">https://cloud.tencent.com/developer/article/1027457</a></p>\n</li>\n<li><p><a href=\"https://paper.tuisec.win/detail/29d80901a36cf52\">https://paper.tuisec.win/detail/29d80901a36cf52</a></p>\n</li>\n</ul>\n"},{"layout":"post","title":"GitLab Helm Charts 配置AD域","date":"2018-12-06T02:23:54.000Z","author":"owelinux","excerpt":"GitLab Helm Charts 配置AD域","mathjax":true,"_content":"\n* content\n{:toc}\n\n# GitLab Helm Charts 配置AD域\n\ngitlab部署方式有很多种，比如：官方yum安装、docker容器部署、k8s部署、k8s helm chart部署\n\n\n## 1）在Active Directory中创建用户以执行LDAP查询\n\n不要将Gitlab配置为使用管理员帐户执行LDAP查询。而是设置一个没有域权限的新用户：\n\na. 登录到您的域控制器，然后加载Active Directory用户和计算机\n\nb. 创建一个名为“NoPermissions”的新组\n\nc. 创建一个名为“ldapsearch”的新用户\n\nd. 编辑“ldapsearch”用户组。将默认组设置为“NoPermissions”，并从“Domain User”组中删除该用户。\n\n## 2）编辑您的Gitlab Omnibus配置\n\n### 适用于yum安装、容器部署方式\n\na. 在Gitlab服务器上，编辑Gitlab配置文件：\n\nvim /etc/gitlab/gitlab.rb\n\n并添加以下设置：\n```\ngitlab_rails [ 'ldap_enabled' ] = true \ngitlab_rails [ 'ldap_servers' ] = YAML.load << - EOS ＃记得用\nmain 下面的'EOS'关闭这个块：\n标签： 'ActiveDirectory' \n主机： 'YOUR-AD-SERVER.CORP .COM' \n端口： 389 #Change到636如果使用LDAPS \n方法： '纯' ＃更改为“TLS”如果使用LDAPS \nUID ： 'sAMAccountName赋' ＃不要更改此\nbind_dn ： CN = ldapsearch的，CN =用户，DC = CORP，DC = COM”\n密码：'YOURPASSWORDHERE' \n超时： 10 \nactive_directory ： true \nallow_username_or_email_login ： false \nblock_auto_created_users ： false \nbase ： 'CN = Users，DC = CORP，DC = COM' \n＃可选：下一行指定只有用户组“gitlab-users”的成员才能对Gitlab进行身份验证：\n#user_filter：'（memberOf：1.2.840.113556.1.4.1941：= CN = GITLAB-USERS，CN = Users，DC = CORP，DC = COM）'\nEOS\n```\n注意： 配置文件是  间隔敏感的！必须有：\n\n* “主要”之前的一个空格\n* “main”下面每个属性前的两个空格\n* “EOS”之前没有空格\n\nb. gitlab-ctl重新配置\n\nc. 测试与AD服务器的LDAP连接：\n\ngitlab-rake gitlab：ldap：check\n\n### 适用于k8s Helm chart方式部署\n在使用helm chart方式部署后，通过修改value.ymal文件添加AD域配置，通过模板渲染到相应配置中\n```\nglobal:\n  appConfig:\n    ldap:\n      servers:\n        main:\n          label: 'LDAP'\n          host: x.x.x.x\n          port: 389\n          uid: 'sAMAccountName'\n          method: 'plain'\n          bind_dn: 'mysoft\\xxxx'\n          password: 'xxxx'\n          verify_certificates: true\n          allow_username_or_email_login: true\n          lowercase_usernames: true\n          block_auto_reated_users: false\n          active_directory: true\n          base: 'DC=xxxx,DC=com,DC=cn'\n  hosts:\n    domain: xxxx.com.cn\n  edition: ce\n```\n \n\n## 3）故障排除\n\na. Gitlab服务器连接到AD服务器上的LDAP端口情况\n\ntelnet your-ad-server.corp.com 389\n\nb. ldapsearch用户和基本DN是否正确的,可以使用LDAP管理工具验证专有名称。\n\n* Using AdFind (Windows) [AdFind](http://www.joeware.net/freetools/tools/adfind/index.htm)\n\n* Using ldapsearch (Unix)[LDAPUtils](https://wiki.debian.org/LDAP/LDAPUtils)\n\nc. 检查配置文件是否使用正确的YAML格式\n\n\n\n## 参考文档\n\n* [https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/](https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/)\n\n* [https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/](https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/) ","source":"_posts/2018-12-11-article41-linux-gitlab-ad.md","raw":"---\nlayout: post\ntitle:  \"GitLab Helm Charts 配置AD域\"\ndate:   2018-12-06 10:23:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: GitLab Helm Charts 配置AD域\nmathjax: true\n---\n\n* content\n{:toc}\n\n# GitLab Helm Charts 配置AD域\n\ngitlab部署方式有很多种，比如：官方yum安装、docker容器部署、k8s部署、k8s helm chart部署\n\n\n## 1）在Active Directory中创建用户以执行LDAP查询\n\n不要将Gitlab配置为使用管理员帐户执行LDAP查询。而是设置一个没有域权限的新用户：\n\na. 登录到您的域控制器，然后加载Active Directory用户和计算机\n\nb. 创建一个名为“NoPermissions”的新组\n\nc. 创建一个名为“ldapsearch”的新用户\n\nd. 编辑“ldapsearch”用户组。将默认组设置为“NoPermissions”，并从“Domain User”组中删除该用户。\n\n## 2）编辑您的Gitlab Omnibus配置\n\n### 适用于yum安装、容器部署方式\n\na. 在Gitlab服务器上，编辑Gitlab配置文件：\n\nvim /etc/gitlab/gitlab.rb\n\n并添加以下设置：\n```\ngitlab_rails [ 'ldap_enabled' ] = true \ngitlab_rails [ 'ldap_servers' ] = YAML.load << - EOS ＃记得用\nmain 下面的'EOS'关闭这个块：\n标签： 'ActiveDirectory' \n主机： 'YOUR-AD-SERVER.CORP .COM' \n端口： 389 #Change到636如果使用LDAPS \n方法： '纯' ＃更改为“TLS”如果使用LDAPS \nUID ： 'sAMAccountName赋' ＃不要更改此\nbind_dn ： CN = ldapsearch的，CN =用户，DC = CORP，DC = COM”\n密码：'YOURPASSWORDHERE' \n超时： 10 \nactive_directory ： true \nallow_username_or_email_login ： false \nblock_auto_created_users ： false \nbase ： 'CN = Users，DC = CORP，DC = COM' \n＃可选：下一行指定只有用户组“gitlab-users”的成员才能对Gitlab进行身份验证：\n#user_filter：'（memberOf：1.2.840.113556.1.4.1941：= CN = GITLAB-USERS，CN = Users，DC = CORP，DC = COM）'\nEOS\n```\n注意： 配置文件是  间隔敏感的！必须有：\n\n* “主要”之前的一个空格\n* “main”下面每个属性前的两个空格\n* “EOS”之前没有空格\n\nb. gitlab-ctl重新配置\n\nc. 测试与AD服务器的LDAP连接：\n\ngitlab-rake gitlab：ldap：check\n\n### 适用于k8s Helm chart方式部署\n在使用helm chart方式部署后，通过修改value.ymal文件添加AD域配置，通过模板渲染到相应配置中\n```\nglobal:\n  appConfig:\n    ldap:\n      servers:\n        main:\n          label: 'LDAP'\n          host: x.x.x.x\n          port: 389\n          uid: 'sAMAccountName'\n          method: 'plain'\n          bind_dn: 'mysoft\\xxxx'\n          password: 'xxxx'\n          verify_certificates: true\n          allow_username_or_email_login: true\n          lowercase_usernames: true\n          block_auto_reated_users: false\n          active_directory: true\n          base: 'DC=xxxx,DC=com,DC=cn'\n  hosts:\n    domain: xxxx.com.cn\n  edition: ce\n```\n \n\n## 3）故障排除\n\na. Gitlab服务器连接到AD服务器上的LDAP端口情况\n\ntelnet your-ad-server.corp.com 389\n\nb. ldapsearch用户和基本DN是否正确的,可以使用LDAP管理工具验证专有名称。\n\n* Using AdFind (Windows) [AdFind](http://www.joeware.net/freetools/tools/adfind/index.htm)\n\n* Using ldapsearch (Unix)[LDAPUtils](https://wiki.debian.org/LDAP/LDAPUtils)\n\nc. 检查配置文件是否使用正确的YAML格式\n\n\n\n## 参考文档\n\n* [https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/](https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/)\n\n* [https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/](https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/) ","slug":"2018-12-11-article41-linux-gitlab-ad","published":1,"updated":"2021-02-09T02:00:24.579Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq110033yc974xbk02cr","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"GitLab-Helm-Charts-配置AD域\"><a href=\"#GitLab-Helm-Charts-配置AD域\" class=\"headerlink\" title=\"GitLab Helm Charts 配置AD域\"></a>GitLab Helm Charts 配置AD域</h1><p>gitlab部署方式有很多种，比如：官方yum安装、docker容器部署、k8s部署、k8s helm chart部署</p>\n<h2 id=\"1）在Active-Directory中创建用户以执行LDAP查询\"><a href=\"#1）在Active-Directory中创建用户以执行LDAP查询\" class=\"headerlink\" title=\"1）在Active Directory中创建用户以执行LDAP查询\"></a>1）在Active Directory中创建用户以执行LDAP查询</h2><p>不要将Gitlab配置为使用管理员帐户执行LDAP查询。而是设置一个没有域权限的新用户：</p>\n<p>a. 登录到您的域控制器，然后加载Active Directory用户和计算机</p>\n<p>b. 创建一个名为“NoPermissions”的新组</p>\n<p>c. 创建一个名为“ldapsearch”的新用户</p>\n<p>d. 编辑“ldapsearch”用户组。将默认组设置为“NoPermissions”，并从“Domain User”组中删除该用户。</p>\n<h2 id=\"2）编辑您的Gitlab-Omnibus配置\"><a href=\"#2）编辑您的Gitlab-Omnibus配置\" class=\"headerlink\" title=\"2）编辑您的Gitlab Omnibus配置\"></a>2）编辑您的Gitlab Omnibus配置</h2><h3 id=\"适用于yum安装、容器部署方式\"><a href=\"#适用于yum安装、容器部署方式\" class=\"headerlink\" title=\"适用于yum安装、容器部署方式\"></a>适用于yum安装、容器部署方式</h3><p>a. 在Gitlab服务器上，编辑Gitlab配置文件：</p>\n<p>vim /etc/gitlab/gitlab.rb</p>\n<p>并添加以下设置：</p>\n<pre><code>gitlab_rails [ &#39;ldap_enabled&#39; ] = true \ngitlab_rails [ &#39;ldap_servers&#39; ] = YAML.load &lt;&lt; - EOS ＃记得用\nmain 下面的&#39;EOS&#39;关闭这个块：\n标签： &#39;ActiveDirectory&#39; \n主机： &#39;YOUR-AD-SERVER.CORP .COM&#39; \n端口： 389 #Change到636如果使用LDAPS \n方法： &#39;纯&#39; ＃更改为“TLS”如果使用LDAPS \nUID ： &#39;sAMAccountName赋&#39; ＃不要更改此\nbind_dn ： CN = ldapsearch的，CN =用户，DC = CORP，DC = COM”\n密码：&#39;YOURPASSWORDHERE&#39; \n超时： 10 \nactive_directory ： true \nallow_username_or_email_login ： false \nblock_auto_created_users ： false \nbase ： &#39;CN = Users，DC = CORP，DC = COM&#39; \n＃可选：下一行指定只有用户组“gitlab-users”的成员才能对Gitlab进行身份验证：\n#user_filter：&#39;（memberOf：1.2.840.113556.1.4.1941：= CN = GITLAB-USERS，CN = Users，DC = CORP，DC = COM）&#39;\nEOS\n</code></pre>\n<p>注意： 配置文件是  间隔敏感的！必须有：</p>\n<ul>\n<li>“主要”之前的一个空格</li>\n<li>“main”下面每个属性前的两个空格</li>\n<li>“EOS”之前没有空格</li>\n</ul>\n<p>b. gitlab-ctl重新配置</p>\n<p>c. 测试与AD服务器的LDAP连接：</p>\n<p>gitlab-rake gitlab：ldap：check</p>\n<h3 id=\"适用于k8s-Helm-chart方式部署\"><a href=\"#适用于k8s-Helm-chart方式部署\" class=\"headerlink\" title=\"适用于k8s Helm chart方式部署\"></a>适用于k8s Helm chart方式部署</h3><p>在使用helm chart方式部署后，通过修改value.ymal文件添加AD域配置，通过模板渲染到相应配置中</p>\n<pre><code>global:\n  appConfig:\n    ldap:\n      servers:\n        main:\n          label: &#39;LDAP&#39;\n          host: x.x.x.x\n          port: 389\n          uid: &#39;sAMAccountName&#39;\n          method: &#39;plain&#39;\n          bind_dn: &#39;mysoft\\xxxx&#39;\n          password: &#39;xxxx&#39;\n          verify_certificates: true\n          allow_username_or_email_login: true\n          lowercase_usernames: true\n          block_auto_reated_users: false\n          active_directory: true\n          base: &#39;DC=xxxx,DC=com,DC=cn&#39;\n  hosts:\n    domain: xxxx.com.cn\n  edition: ce\n</code></pre>\n<h2 id=\"3）故障排除\"><a href=\"#3）故障排除\" class=\"headerlink\" title=\"3）故障排除\"></a>3）故障排除</h2><p>a. Gitlab服务器连接到AD服务器上的LDAP端口情况</p>\n<p>telnet your-ad-server.corp.com 389</p>\n<p>b. ldapsearch用户和基本DN是否正确的,可以使用LDAP管理工具验证专有名称。</p>\n<ul>\n<li><p>Using AdFind (Windows) <a href=\"http://www.joeware.net/freetools/tools/adfind/index.htm\">AdFind</a></p>\n</li>\n<li><p>Using ldapsearch (Unix)<a href=\"https://wiki.debian.org/LDAP/LDAPUtils\">LDAPUtils</a></p>\n</li>\n</ul>\n<p>c. 检查配置文件是否使用正确的YAML格式</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/\">https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/</a></p>\n</li>\n<li><p><a href=\"https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/\">https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/</a> </p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"GitLab-Helm-Charts-配置AD域\"><a href=\"#GitLab-Helm-Charts-配置AD域\" class=\"headerlink\" title=\"GitLab Helm Charts 配置AD域\"></a>GitLab Helm Charts 配置AD域</h1><p>gitlab部署方式有很多种，比如：官方yum安装、docker容器部署、k8s部署、k8s helm chart部署</p>\n<h2 id=\"1）在Active-Directory中创建用户以执行LDAP查询\"><a href=\"#1）在Active-Directory中创建用户以执行LDAP查询\" class=\"headerlink\" title=\"1）在Active Directory中创建用户以执行LDAP查询\"></a>1）在Active Directory中创建用户以执行LDAP查询</h2><p>不要将Gitlab配置为使用管理员帐户执行LDAP查询。而是设置一个没有域权限的新用户：</p>\n<p>a. 登录到您的域控制器，然后加载Active Directory用户和计算机</p>\n<p>b. 创建一个名为“NoPermissions”的新组</p>\n<p>c. 创建一个名为“ldapsearch”的新用户</p>\n<p>d. 编辑“ldapsearch”用户组。将默认组设置为“NoPermissions”，并从“Domain User”组中删除该用户。</p>\n<h2 id=\"2）编辑您的Gitlab-Omnibus配置\"><a href=\"#2）编辑您的Gitlab-Omnibus配置\" class=\"headerlink\" title=\"2）编辑您的Gitlab Omnibus配置\"></a>2）编辑您的Gitlab Omnibus配置</h2><h3 id=\"适用于yum安装、容器部署方式\"><a href=\"#适用于yum安装、容器部署方式\" class=\"headerlink\" title=\"适用于yum安装、容器部署方式\"></a>适用于yum安装、容器部署方式</h3><p>a. 在Gitlab服务器上，编辑Gitlab配置文件：</p>\n<p>vim /etc/gitlab/gitlab.rb</p>\n<p>并添加以下设置：</p>\n<pre><code>gitlab_rails [ &#39;ldap_enabled&#39; ] = true \ngitlab_rails [ &#39;ldap_servers&#39; ] = YAML.load &lt;&lt; - EOS ＃记得用\nmain 下面的&#39;EOS&#39;关闭这个块：\n标签： &#39;ActiveDirectory&#39; \n主机： &#39;YOUR-AD-SERVER.CORP .COM&#39; \n端口： 389 #Change到636如果使用LDAPS \n方法： &#39;纯&#39; ＃更改为“TLS”如果使用LDAPS \nUID ： &#39;sAMAccountName赋&#39; ＃不要更改此\nbind_dn ： CN = ldapsearch的，CN =用户，DC = CORP，DC = COM”\n密码：&#39;YOURPASSWORDHERE&#39; \n超时： 10 \nactive_directory ： true \nallow_username_or_email_login ： false \nblock_auto_created_users ： false \nbase ： &#39;CN = Users，DC = CORP，DC = COM&#39; \n＃可选：下一行指定只有用户组“gitlab-users”的成员才能对Gitlab进行身份验证：\n#user_filter：&#39;（memberOf：1.2.840.113556.1.4.1941：= CN = GITLAB-USERS，CN = Users，DC = CORP，DC = COM）&#39;\nEOS\n</code></pre>\n<p>注意： 配置文件是  间隔敏感的！必须有：</p>\n<ul>\n<li>“主要”之前的一个空格</li>\n<li>“main”下面每个属性前的两个空格</li>\n<li>“EOS”之前没有空格</li>\n</ul>\n<p>b. gitlab-ctl重新配置</p>\n<p>c. 测试与AD服务器的LDAP连接：</p>\n<p>gitlab-rake gitlab：ldap：check</p>\n<h3 id=\"适用于k8s-Helm-chart方式部署\"><a href=\"#适用于k8s-Helm-chart方式部署\" class=\"headerlink\" title=\"适用于k8s Helm chart方式部署\"></a>适用于k8s Helm chart方式部署</h3><p>在使用helm chart方式部署后，通过修改value.ymal文件添加AD域配置，通过模板渲染到相应配置中</p>\n<pre><code>global:\n  appConfig:\n    ldap:\n      servers:\n        main:\n          label: &#39;LDAP&#39;\n          host: x.x.x.x\n          port: 389\n          uid: &#39;sAMAccountName&#39;\n          method: &#39;plain&#39;\n          bind_dn: &#39;mysoft\\xxxx&#39;\n          password: &#39;xxxx&#39;\n          verify_certificates: true\n          allow_username_or_email_login: true\n          lowercase_usernames: true\n          block_auto_reated_users: false\n          active_directory: true\n          base: &#39;DC=xxxx,DC=com,DC=cn&#39;\n  hosts:\n    domain: xxxx.com.cn\n  edition: ce\n</code></pre>\n<h2 id=\"3）故障排除\"><a href=\"#3）故障排除\" class=\"headerlink\" title=\"3）故障排除\"></a>3）故障排除</h2><p>a. Gitlab服务器连接到AD服务器上的LDAP端口情况</p>\n<p>telnet your-ad-server.corp.com 389</p>\n<p>b. ldapsearch用户和基本DN是否正确的,可以使用LDAP管理工具验证专有名称。</p>\n<ul>\n<li><p>Using AdFind (Windows) <a href=\"http://www.joeware.net/freetools/tools/adfind/index.htm\">AdFind</a></p>\n</li>\n<li><p>Using ldapsearch (Unix)<a href=\"https://wiki.debian.org/LDAP/LDAPUtils\">LDAPUtils</a></p>\n</li>\n</ul>\n<p>c. 检查配置文件是否使用正确的YAML格式</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/\">https://www.caseylabs.com/setup-gitlab-ce-with-active-directory-authentication/</a></p>\n</li>\n<li><p><a href=\"https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/\">https://docs.gitlab.com/ee/administration/auth/how_to_configure_ldap_gitlab_ce/</a> </p>\n</li>\n</ul>\n"},{"layout":"post","title":"kubernetes 之 Ingress 使用总结","date":"2018-12-27T03:21:54.000Z","author":"owelinux","excerpt":"kubernetes 之 Ingress 使用总结","mathjax":true,"_content":"\n* content\n{:toc}\n\n# kubernetes 之 Ingress 使用总结\n\n\n## 前言\nKubernetes暴露服务的方式有多种，如LoadBalancer、NodePort、Ingress等。LoadBalancer一般用于云平台，平常一般用NodePort暴露服务，非常方便。但是由于NodePort需要指定宿主机端口，一旦服务多起来，多个端口就难以管理。那么，这种情况下，使用Ingress暴露服务更加合适。\n\n\n## Ingress组成\nIngress由三部分组成：\n\n* 反向代理负载均衡器\n  \n    比如Nginx、Haproxy、Apache、traefik等\n\n* Ingress Controller \n    \n    通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload 一下 使用配置生效。以此来达到域名分配置及动态更新的问题。\n    \n\n* Ingress\n\n    kubernetes的一个资源对象，用于编写定义规则 \n\n如下是一个很简单的ingress.yml配置：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /testpath\n        backend:\n           serviceName: test\n           servicePort: 80\n```\n\n若需要添加新的转发规则，只需修改上述文件，然后执行kubectl apply -f ingress.yml即可，或者执行kubectl edit直接编辑后保存，通过kubectl logs可以看到ingress-controller的Nginx配置是否更新成功。Ingress可以和Ingress Controller不在同一namespace，但必须与声明的服务在同一namespace。同样，一个集群内也可以部署多个Ingress，一个Controller可以匹配多个Ingress。\n\n## 部署\n\n部署一些必要的服务:\n\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/tcp-services-configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/udp-services-configmap.yaml \\\n    | kubectl apply -f -\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/service-nodeport.yaml \\\n    | kubectl apply -f - \n```\n上面的default-backend.yml用于部署默认服务，当ingress找不到相应的请求时会返回默认服务，官方的默认服务返回404，也可以定制自己的默认服务。\n\n基于RBAC部署Ingress Controller：\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/with-rbac.yaml \\\n    | kubectl apply -f -\n```\n也可以基于非RBAC模式部署：\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/without-rbac.yaml \\\n    | kubectl apply -f -\n```\n部署Ingress，假设集群内已经存在一个test服务，创建ingress.yml声明的规则如下：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-nginx\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - backend:\n           serviceName: test\n           servicePort: 80\n```\n至此，ingress就部署完成了。配置hosts到Controller的PodIP，然后集群外访问test.com就可以访问test服务了。注意：因为官方的Ingress Controller默认并没有开启hostNetwork模式，所以这里hosts配置的是Controller的PodIP。但是考虑到Pod重新调度后其IP会更改，那么hosts配置也要同时更改，所以一般建议开启hostNetwork模式，使Controller监听宿主机的端口，这样配置hosts时只需要配置Pod所在的节点IP即可。有人会说，如果Pod重新调度到其他节点了，hosts配置不是也要改变吗？不错，这种情况下，我们可以通过nodeSelector指定Ingress Controller调度到某个节点。这样hosts配置就不用变了。修改如下：\n```\n...\nnodeSelector:                   # 指定Ingress Controller调度到某个节点\n  nodeName: myNodeName\nhostNetwork: true               # 开启hostNetwork模式\ncontainers:\n  - name: nginx-ingress-controller\n    image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.10.2\n    args:\n      - /nginx-ingress-controller\n      - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n      - --configmap=$(POD_NAMESPACE)/nginx-configuration\n      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n      - --annotations-prefix=nginx.ingress.kubernetes.io\n···\n```\n\n## Ingress Controller匹配Ingress\n当集群内创建多个Controller时，如何使某个Controller只监听对应的Ingress呢？这里就需要在Ingress中指定annotations，如下：\n```\nmetadata:\n  name: nginx-ingress      \n  namespace: ingress-nginx      \n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"                  # 指定ingress.class为nginx\n```\n然后在Controller中指定参数--ingress-class=nginx：\n```\nargs:\n  - /nginx-ingress-controller\n  - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n  - --configmap=$(POD_NAMESPACE)/nginx-configuration\n  - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n  - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n  - --annotations-prefix=nginx.ingress.kubernetes.io\n  - --ingress-class=nginx-prod                                 # 指定ingress-class值为nginx，与对应的Ingress匹配\n```\n最后需要在rbac中指定参数 - \"ingress-controller-leader-nginx-prod\" [参考](https://github.com/kubeapps/kubeapps/issues/120)\n```\n    resources:\n      - configmaps\n    resourceNames:\n      # Defaults to \"<election-id>-<ingress-class>\"\n      # Here: \"<ingress-controller-leader>-<nginx>\"\n      # This has to be adapted if you change either parameter\n      # when launching the nginx-ingress-controller.\n      - \"ingress-controller-leader-nginx-prod\"\n```\n\n\n这样，该Controller就只监听带有kubernetes.io/ingress.class: \"nginx\"annotations的Ingress了。我们可以声明多个带有相同annotations的Ingress，它们都会被对应Controller监听。Controller中的nginx默认监听80和443端口，若要更改可以通过--http-port和--https-port参数来指定，更多参数可以在[这里](https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/cli-arguments.md)找到。\n\n在实际应用场景，常常会把多个服务部署在不同的namespace，来达到隔离服务的目的，比如A服务部署在namespace-A，B服务部署在namespace-B。这种情况下，就需要声明Ingress-A、Ingress-B两个Ingress分别用于暴露A服务和B服务，且Ingress-A必须处于namespace-A，Ingress-B必须处于namespace-B。否则Controller无法正确解析Ingress的规则。\n\n## Ingress 开启 TLS / HTTPS\n\n\n```\n# 使用以下命令生成自签名证书和私钥\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ${KEY_FILE} -out ${CERT_FILE} -subj \"/CN=${HOST}/O=${HOST}\"`\n\n# 通过以下方式在集群中创建密钥\nkubectl create secret tls ${CERT_NAME} --key ${KEY_FILE} --cert ${CERT_FILE}\n```\n\n创建完成后证书类型应该是 kubernetes.io/tls.\n\n注：默认情况下，如果为该Ingress启用了TLS，则控制器会使用308永久重定向响应将HTTP客户端重定向到HTTPS端口443。\n\n可以使用ssl-redirect: \"false\" 在NGINX config map文件声明，也可以使用nginx.ingress.kubernetes.io/ssl-redirect: \"false\" 特定资源中的注释per-Ingress 禁用此功能\n\n创建一个支持https的域名：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx-test\n  name: mp-test\n  namespace: default\nspec:\n  rules:\n    - host: mp-test.test.com\n      http:\n        paths:\n          - backend:\n              serviceName: modeling-platform\n              servicePort: 80\n  tls:\n    - hosts:\n        - mp-test.test.com\n      secretName: test.com         \n```\n\n## 总结\n* 集群内可以声明多个Ingress和多个Ingress Controller\n\n* 一个Ingress Controller可以监听多个Ingress\n\n* Ingress和其定义的服务必须处于同一namespace\n\n## 参考文档\n\n[http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/](http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/)\n\n[https://www.cnblogs.com/xzkzzz/p/9577640.html](https://www.cnblogs.com/xzkzzz/p/9577640.html)\n\n[https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html](https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html)","source":"_posts/2018-12-27-article43-k8s-Ingress.md","raw":"---\nlayout: post\ntitle:  \"kubernetes 之 Ingress 使用总结\"\ndate:   2018-12-27 11:21:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: kubernetes 之 Ingress 使用总结\nmathjax: true\n---\n\n* content\n{:toc}\n\n# kubernetes 之 Ingress 使用总结\n\n\n## 前言\nKubernetes暴露服务的方式有多种，如LoadBalancer、NodePort、Ingress等。LoadBalancer一般用于云平台，平常一般用NodePort暴露服务，非常方便。但是由于NodePort需要指定宿主机端口，一旦服务多起来，多个端口就难以管理。那么，这种情况下，使用Ingress暴露服务更加合适。\n\n\n## Ingress组成\nIngress由三部分组成：\n\n* 反向代理负载均衡器\n  \n    比如Nginx、Haproxy、Apache、traefik等\n\n* Ingress Controller \n    \n    通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload 一下 使用配置生效。以此来达到域名分配置及动态更新的问题。\n    \n\n* Ingress\n\n    kubernetes的一个资源对象，用于编写定义规则 \n\n如下是一个很简单的ingress.yml配置：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /testpath\n        backend:\n           serviceName: test\n           servicePort: 80\n```\n\n若需要添加新的转发规则，只需修改上述文件，然后执行kubectl apply -f ingress.yml即可，或者执行kubectl edit直接编辑后保存，通过kubectl logs可以看到ingress-controller的Nginx配置是否更新成功。Ingress可以和Ingress Controller不在同一namespace，但必须与声明的服务在同一namespace。同样，一个集群内也可以部署多个Ingress，一个Controller可以匹配多个Ingress。\n\n## 部署\n\n部署一些必要的服务:\n\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/tcp-services-configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/udp-services-configmap.yaml \\\n    | kubectl apply -f -\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/service-nodeport.yaml \\\n    | kubectl apply -f - \n```\n上面的default-backend.yml用于部署默认服务，当ingress找不到相应的请求时会返回默认服务，官方的默认服务返回404，也可以定制自己的默认服务。\n\n基于RBAC部署Ingress Controller：\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/with-rbac.yaml \\\n    | kubectl apply -f -\n```\n也可以基于非RBAC模式部署：\n```\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/without-rbac.yaml \\\n    | kubectl apply -f -\n```\n部署Ingress，假设集群内已经存在一个test服务，创建ingress.yml声明的规则如下：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-nginx\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - backend:\n           serviceName: test\n           servicePort: 80\n```\n至此，ingress就部署完成了。配置hosts到Controller的PodIP，然后集群外访问test.com就可以访问test服务了。注意：因为官方的Ingress Controller默认并没有开启hostNetwork模式，所以这里hosts配置的是Controller的PodIP。但是考虑到Pod重新调度后其IP会更改，那么hosts配置也要同时更改，所以一般建议开启hostNetwork模式，使Controller监听宿主机的端口，这样配置hosts时只需要配置Pod所在的节点IP即可。有人会说，如果Pod重新调度到其他节点了，hosts配置不是也要改变吗？不错，这种情况下，我们可以通过nodeSelector指定Ingress Controller调度到某个节点。这样hosts配置就不用变了。修改如下：\n```\n...\nnodeSelector:                   # 指定Ingress Controller调度到某个节点\n  nodeName: myNodeName\nhostNetwork: true               # 开启hostNetwork模式\ncontainers:\n  - name: nginx-ingress-controller\n    image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.10.2\n    args:\n      - /nginx-ingress-controller\n      - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n      - --configmap=$(POD_NAMESPACE)/nginx-configuration\n      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n      - --annotations-prefix=nginx.ingress.kubernetes.io\n···\n```\n\n## Ingress Controller匹配Ingress\n当集群内创建多个Controller时，如何使某个Controller只监听对应的Ingress呢？这里就需要在Ingress中指定annotations，如下：\n```\nmetadata:\n  name: nginx-ingress      \n  namespace: ingress-nginx      \n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"                  # 指定ingress.class为nginx\n```\n然后在Controller中指定参数--ingress-class=nginx：\n```\nargs:\n  - /nginx-ingress-controller\n  - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n  - --configmap=$(POD_NAMESPACE)/nginx-configuration\n  - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n  - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n  - --annotations-prefix=nginx.ingress.kubernetes.io\n  - --ingress-class=nginx-prod                                 # 指定ingress-class值为nginx，与对应的Ingress匹配\n```\n最后需要在rbac中指定参数 - \"ingress-controller-leader-nginx-prod\" [参考](https://github.com/kubeapps/kubeapps/issues/120)\n```\n    resources:\n      - configmaps\n    resourceNames:\n      # Defaults to \"<election-id>-<ingress-class>\"\n      # Here: \"<ingress-controller-leader>-<nginx>\"\n      # This has to be adapted if you change either parameter\n      # when launching the nginx-ingress-controller.\n      - \"ingress-controller-leader-nginx-prod\"\n```\n\n\n这样，该Controller就只监听带有kubernetes.io/ingress.class: \"nginx\"annotations的Ingress了。我们可以声明多个带有相同annotations的Ingress，它们都会被对应Controller监听。Controller中的nginx默认监听80和443端口，若要更改可以通过--http-port和--https-port参数来指定，更多参数可以在[这里](https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/cli-arguments.md)找到。\n\n在实际应用场景，常常会把多个服务部署在不同的namespace，来达到隔离服务的目的，比如A服务部署在namespace-A，B服务部署在namespace-B。这种情况下，就需要声明Ingress-A、Ingress-B两个Ingress分别用于暴露A服务和B服务，且Ingress-A必须处于namespace-A，Ingress-B必须处于namespace-B。否则Controller无法正确解析Ingress的规则。\n\n## Ingress 开启 TLS / HTTPS\n\n\n```\n# 使用以下命令生成自签名证书和私钥\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ${KEY_FILE} -out ${CERT_FILE} -subj \"/CN=${HOST}/O=${HOST}\"`\n\n# 通过以下方式在集群中创建密钥\nkubectl create secret tls ${CERT_NAME} --key ${KEY_FILE} --cert ${CERT_FILE}\n```\n\n创建完成后证书类型应该是 kubernetes.io/tls.\n\n注：默认情况下，如果为该Ingress启用了TLS，则控制器会使用308永久重定向响应将HTTP客户端重定向到HTTPS端口443。\n\n可以使用ssl-redirect: \"false\" 在NGINX config map文件声明，也可以使用nginx.ingress.kubernetes.io/ssl-redirect: \"false\" 特定资源中的注释per-Ingress 禁用此功能\n\n创建一个支持https的域名：\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx-test\n  name: mp-test\n  namespace: default\nspec:\n  rules:\n    - host: mp-test.test.com\n      http:\n        paths:\n          - backend:\n              serviceName: modeling-platform\n              servicePort: 80\n  tls:\n    - hosts:\n        - mp-test.test.com\n      secretName: test.com         \n```\n\n## 总结\n* 集群内可以声明多个Ingress和多个Ingress Controller\n\n* 一个Ingress Controller可以监听多个Ingress\n\n* Ingress和其定义的服务必须处于同一namespace\n\n## 参考文档\n\n[http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/](http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/)\n\n[https://www.cnblogs.com/xzkzzz/p/9577640.html](https://www.cnblogs.com/xzkzzz/p/9577640.html)\n\n[https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html](https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html)","slug":"2018-12-27-article43-k8s-Ingress","published":1,"updated":"2021-02-09T02:00:24.579Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq120037yc978hu3bcec","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"kubernetes-之-Ingress-使用总结\"><a href=\"#kubernetes-之-Ingress-使用总结\" class=\"headerlink\" title=\"kubernetes 之 Ingress 使用总结\"></a>kubernetes 之 Ingress 使用总结</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>Kubernetes暴露服务的方式有多种，如LoadBalancer、NodePort、Ingress等。LoadBalancer一般用于云平台，平常一般用NodePort暴露服务，非常方便。但是由于NodePort需要指定宿主机端口，一旦服务多起来，多个端口就难以管理。那么，这种情况下，使用Ingress暴露服务更加合适。</p>\n<h2 id=\"Ingress组成\"><a href=\"#Ingress组成\" class=\"headerlink\" title=\"Ingress组成\"></a>Ingress组成</h2><p>Ingress由三部分组成：</p>\n<ul>\n<li><p>反向代理负载均衡器</p>\n<p>  比如Nginx、Haproxy、Apache、traefik等</p>\n</li>\n<li><p>Ingress Controller </p>\n<p>  通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload 一下 使用配置生效。以此来达到域名分配置及动态更新的问题。</p>\n</li>\n<li><p>Ingress</p>\n<p>  kubernetes的一个资源对象，用于编写定义规则 </p>\n</li>\n</ul>\n<p>如下是一个很简单的ingress.yml配置：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /testpath\n        backend:\n           serviceName: test\n           servicePort: 80\n</code></pre>\n<p>若需要添加新的转发规则，只需修改上述文件，然后执行kubectl apply -f ingress.yml即可，或者执行kubectl edit直接编辑后保存，通过kubectl logs可以看到ingress-controller的Nginx配置是否更新成功。Ingress可以和Ingress Controller不在同一namespace，但必须与声明的服务在同一namespace。同样，一个集群内也可以部署多个Ingress，一个Controller可以匹配多个Ingress。</p>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><p>部署一些必要的服务:</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/tcp-services-configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/udp-services-configmap.yaml \\\n    | kubectl apply -f -\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/service-nodeport.yaml \\\n    | kubectl apply -f - \n</code></pre>\n<p>上面的default-backend.yml用于部署默认服务，当ingress找不到相应的请求时会返回默认服务，官方的默认服务返回404，也可以定制自己的默认服务。</p>\n<p>基于RBAC部署Ingress Controller：</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/with-rbac.yaml \\\n    | kubectl apply -f -\n</code></pre>\n<p>也可以基于非RBAC模式部署：</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/without-rbac.yaml \\\n    | kubectl apply -f -\n</code></pre>\n<p>部署Ingress，假设集群内已经存在一个test服务，创建ingress.yml声明的规则如下：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-nginx\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - backend:\n           serviceName: test\n           servicePort: 80\n</code></pre>\n<p>至此，ingress就部署完成了。配置hosts到Controller的PodIP，然后集群外访问test.com就可以访问test服务了。注意：因为官方的Ingress Controller默认并没有开启hostNetwork模式，所以这里hosts配置的是Controller的PodIP。但是考虑到Pod重新调度后其IP会更改，那么hosts配置也要同时更改，所以一般建议开启hostNetwork模式，使Controller监听宿主机的端口，这样配置hosts时只需要配置Pod所在的节点IP即可。有人会说，如果Pod重新调度到其他节点了，hosts配置不是也要改变吗？不错，这种情况下，我们可以通过nodeSelector指定Ingress Controller调度到某个节点。这样hosts配置就不用变了。修改如下：</p>\n<pre><code>...\nnodeSelector:                   # 指定Ingress Controller调度到某个节点\n  nodeName: myNodeName\nhostNetwork: true               # 开启hostNetwork模式\ncontainers:\n  - name: nginx-ingress-controller\n    image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.10.2\n    args:\n      - /nginx-ingress-controller\n      - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n      - --configmap=$(POD_NAMESPACE)/nginx-configuration\n      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n      - --annotations-prefix=nginx.ingress.kubernetes.io\n···\n</code></pre>\n<h2 id=\"Ingress-Controller匹配Ingress\"><a href=\"#Ingress-Controller匹配Ingress\" class=\"headerlink\" title=\"Ingress Controller匹配Ingress\"></a>Ingress Controller匹配Ingress</h2><p>当集群内创建多个Controller时，如何使某个Controller只监听对应的Ingress呢？这里就需要在Ingress中指定annotations，如下：</p>\n<pre><code>metadata:\n  name: nginx-ingress      \n  namespace: ingress-nginx      \n  annotations:\n    kubernetes.io/ingress.class: &quot;nginx&quot;                  # 指定ingress.class为nginx\n</code></pre>\n<p>然后在Controller中指定参数–ingress-class=nginx：</p>\n<pre><code>args:\n  - /nginx-ingress-controller\n  - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n  - --configmap=$(POD_NAMESPACE)/nginx-configuration\n  - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n  - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n  - --annotations-prefix=nginx.ingress.kubernetes.io\n  - --ingress-class=nginx-prod                                 # 指定ingress-class值为nginx，与对应的Ingress匹配\n</code></pre>\n<p>最后需要在rbac中指定参数 - “ingress-controller-leader-nginx-prod” <a href=\"https://github.com/kubeapps/kubeapps/issues/120\">参考</a></p>\n<pre><code>    resources:\n      - configmaps\n    resourceNames:\n      # Defaults to &quot;&lt;election-id&gt;-&lt;ingress-class&gt;&quot;\n      # Here: &quot;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&quot;\n      # This has to be adapted if you change either parameter\n      # when launching the nginx-ingress-controller.\n      - &quot;ingress-controller-leader-nginx-prod&quot;\n</code></pre>\n<p>这样，该Controller就只监听带有kubernetes.io/ingress.class: “nginx”annotations的Ingress了。我们可以声明多个带有相同annotations的Ingress，它们都会被对应Controller监听。Controller中的nginx默认监听80和443端口，若要更改可以通过–http-port和–https-port参数来指定，更多参数可以在<a href=\"https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/cli-arguments.md\">这里</a>找到。</p>\n<p>在实际应用场景，常常会把多个服务部署在不同的namespace，来达到隔离服务的目的，比如A服务部署在namespace-A，B服务部署在namespace-B。这种情况下，就需要声明Ingress-A、Ingress-B两个Ingress分别用于暴露A服务和B服务，且Ingress-A必须处于namespace-A，Ingress-B必须处于namespace-B。否则Controller无法正确解析Ingress的规则。</p>\n<h2 id=\"Ingress-开启-TLS-HTTPS\"><a href=\"#Ingress-开启-TLS-HTTPS\" class=\"headerlink\" title=\"Ingress 开启 TLS / HTTPS\"></a>Ingress 开启 TLS / HTTPS</h2><pre><code># 使用以下命令生成自签名证书和私钥\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout $&#123;KEY_FILE&#125; -out $&#123;CERT_FILE&#125; -subj &quot;/CN=$&#123;HOST&#125;/O=$&#123;HOST&#125;&quot;`\n\n# 通过以下方式在集群中创建密钥\nkubectl create secret tls $&#123;CERT_NAME&#125; --key $&#123;KEY_FILE&#125; --cert $&#123;CERT_FILE&#125;\n</code></pre>\n<p>创建完成后证书类型应该是 kubernetes.io/tls.</p>\n<p>注：默认情况下，如果为该Ingress启用了TLS，则控制器会使用308永久重定向响应将HTTP客户端重定向到HTTPS端口443。</p>\n<p>可以使用ssl-redirect: “false” 在NGINX config map文件声明，也可以使用nginx.ingress.kubernetes.io/ssl-redirect: “false” 特定资源中的注释per-Ingress 禁用此功能</p>\n<p>创建一个支持https的域名：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx-test\n  name: mp-test\n  namespace: default\nspec:\n  rules:\n    - host: mp-test.test.com\n      http:\n        paths:\n          - backend:\n              serviceName: modeling-platform\n              servicePort: 80\n  tls:\n    - hosts:\n        - mp-test.test.com\n      secretName: test.com         \n</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li><p>集群内可以声明多个Ingress和多个Ingress Controller</p>\n</li>\n<li><p>一个Ingress Controller可以监听多个Ingress</p>\n</li>\n<li><p>Ingress和其定义的服务必须处于同一namespace</p>\n</li>\n</ul>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/\">http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/</a></p>\n<p><a href=\"https://www.cnblogs.com/xzkzzz/p/9577640.html\">https://www.cnblogs.com/xzkzzz/p/9577640.html</a></p>\n<p><a href=\"https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html\">https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"kubernetes-之-Ingress-使用总结\"><a href=\"#kubernetes-之-Ingress-使用总结\" class=\"headerlink\" title=\"kubernetes 之 Ingress 使用总结\"></a>kubernetes 之 Ingress 使用总结</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>Kubernetes暴露服务的方式有多种，如LoadBalancer、NodePort、Ingress等。LoadBalancer一般用于云平台，平常一般用NodePort暴露服务，非常方便。但是由于NodePort需要指定宿主机端口，一旦服务多起来，多个端口就难以管理。那么，这种情况下，使用Ingress暴露服务更加合适。</p>\n<h2 id=\"Ingress组成\"><a href=\"#Ingress组成\" class=\"headerlink\" title=\"Ingress组成\"></a>Ingress组成</h2><p>Ingress由三部分组成：</p>\n<ul>\n<li><p>反向代理负载均衡器</p>\n<p>  比如Nginx、Haproxy、Apache、traefik等</p>\n</li>\n<li><p>Ingress Controller </p>\n<p>  通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload 一下 使用配置生效。以此来达到域名分配置及动态更新的问题。</p>\n</li>\n<li><p>Ingress</p>\n<p>  kubernetes的一个资源对象，用于编写定义规则 </p>\n</li>\n</ul>\n<p>如下是一个很简单的ingress.yml配置：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /testpath\n        backend:\n           serviceName: test\n           servicePort: 80\n</code></pre>\n<p>若需要添加新的转发规则，只需修改上述文件，然后执行kubectl apply -f ingress.yml即可，或者执行kubectl edit直接编辑后保存，通过kubectl logs可以看到ingress-controller的Nginx配置是否更新成功。Ingress可以和Ingress Controller不在同一namespace，但必须与声明的服务在同一namespace。同样，一个集群内也可以部署多个Ingress，一个Controller可以匹配多个Ingress。</p>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><p>部署一些必要的服务:</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/tcp-services-configmap.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/udp-services-configmap.yaml \\\n    | kubectl apply -f -\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/service-nodeport.yaml \\\n    | kubectl apply -f - \n</code></pre>\n<p>上面的default-backend.yml用于部署默认服务，当ingress找不到相应的请求时会返回默认服务，官方的默认服务返回404，也可以定制自己的默认服务。</p>\n<p>基于RBAC部署Ingress Controller：</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml \\\n    | kubectl apply -f -\n\ncurl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/with-rbac.yaml \\\n    | kubectl apply -f -\n</code></pre>\n<p>也可以基于非RBAC模式部署：</p>\n<pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/without-rbac.yaml \\\n    | kubectl apply -f -\n</code></pre>\n<p>部署Ingress，假设集群内已经存在一个test服务，创建ingress.yml声明的规则如下：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-nginx\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - backend:\n           serviceName: test\n           servicePort: 80\n</code></pre>\n<p>至此，ingress就部署完成了。配置hosts到Controller的PodIP，然后集群外访问test.com就可以访问test服务了。注意：因为官方的Ingress Controller默认并没有开启hostNetwork模式，所以这里hosts配置的是Controller的PodIP。但是考虑到Pod重新调度后其IP会更改，那么hosts配置也要同时更改，所以一般建议开启hostNetwork模式，使Controller监听宿主机的端口，这样配置hosts时只需要配置Pod所在的节点IP即可。有人会说，如果Pod重新调度到其他节点了，hosts配置不是也要改变吗？不错，这种情况下，我们可以通过nodeSelector指定Ingress Controller调度到某个节点。这样hosts配置就不用变了。修改如下：</p>\n<pre><code>...\nnodeSelector:                   # 指定Ingress Controller调度到某个节点\n  nodeName: myNodeName\nhostNetwork: true               # 开启hostNetwork模式\ncontainers:\n  - name: nginx-ingress-controller\n    image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.10.2\n    args:\n      - /nginx-ingress-controller\n      - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n      - --configmap=$(POD_NAMESPACE)/nginx-configuration\n      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n      - --annotations-prefix=nginx.ingress.kubernetes.io\n···\n</code></pre>\n<h2 id=\"Ingress-Controller匹配Ingress\"><a href=\"#Ingress-Controller匹配Ingress\" class=\"headerlink\" title=\"Ingress Controller匹配Ingress\"></a>Ingress Controller匹配Ingress</h2><p>当集群内创建多个Controller时，如何使某个Controller只监听对应的Ingress呢？这里就需要在Ingress中指定annotations，如下：</p>\n<pre><code>metadata:\n  name: nginx-ingress      \n  namespace: ingress-nginx      \n  annotations:\n    kubernetes.io/ingress.class: &quot;nginx&quot;                  # 指定ingress.class为nginx\n</code></pre>\n<p>然后在Controller中指定参数–ingress-class=nginx：</p>\n<pre><code>args:\n  - /nginx-ingress-controller\n  - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n  - --configmap=$(POD_NAMESPACE)/nginx-configuration\n  - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n  - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n  - --annotations-prefix=nginx.ingress.kubernetes.io\n  - --ingress-class=nginx-prod                                 # 指定ingress-class值为nginx，与对应的Ingress匹配\n</code></pre>\n<p>最后需要在rbac中指定参数 - “ingress-controller-leader-nginx-prod” <a href=\"https://github.com/kubeapps/kubeapps/issues/120\">参考</a></p>\n<pre><code>    resources:\n      - configmaps\n    resourceNames:\n      # Defaults to &quot;&lt;election-id&gt;-&lt;ingress-class&gt;&quot;\n      # Here: &quot;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&quot;\n      # This has to be adapted if you change either parameter\n      # when launching the nginx-ingress-controller.\n      - &quot;ingress-controller-leader-nginx-prod&quot;\n</code></pre>\n<p>这样，该Controller就只监听带有kubernetes.io/ingress.class: “nginx”annotations的Ingress了。我们可以声明多个带有相同annotations的Ingress，它们都会被对应Controller监听。Controller中的nginx默认监听80和443端口，若要更改可以通过–http-port和–https-port参数来指定，更多参数可以在<a href=\"https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/cli-arguments.md\">这里</a>找到。</p>\n<p>在实际应用场景，常常会把多个服务部署在不同的namespace，来达到隔离服务的目的，比如A服务部署在namespace-A，B服务部署在namespace-B。这种情况下，就需要声明Ingress-A、Ingress-B两个Ingress分别用于暴露A服务和B服务，且Ingress-A必须处于namespace-A，Ingress-B必须处于namespace-B。否则Controller无法正确解析Ingress的规则。</p>\n<h2 id=\"Ingress-开启-TLS-HTTPS\"><a href=\"#Ingress-开启-TLS-HTTPS\" class=\"headerlink\" title=\"Ingress 开启 TLS / HTTPS\"></a>Ingress 开启 TLS / HTTPS</h2><pre><code># 使用以下命令生成自签名证书和私钥\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout $&#123;KEY_FILE&#125; -out $&#123;CERT_FILE&#125; -subj &quot;/CN=$&#123;HOST&#125;/O=$&#123;HOST&#125;&quot;`\n\n# 通过以下方式在集群中创建密钥\nkubectl create secret tls $&#123;CERT_NAME&#125; --key $&#123;KEY_FILE&#125; --cert $&#123;CERT_FILE&#125;\n</code></pre>\n<p>创建完成后证书类型应该是 kubernetes.io/tls.</p>\n<p>注：默认情况下，如果为该Ingress启用了TLS，则控制器会使用308永久重定向响应将HTTP客户端重定向到HTTPS端口443。</p>\n<p>可以使用ssl-redirect: “false” 在NGINX config map文件声明，也可以使用nginx.ingress.kubernetes.io/ssl-redirect: “false” 特定资源中的注释per-Ingress 禁用此功能</p>\n<p>创建一个支持https的域名：</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx-test\n  name: mp-test\n  namespace: default\nspec:\n  rules:\n    - host: mp-test.test.com\n      http:\n        paths:\n          - backend:\n              serviceName: modeling-platform\n              servicePort: 80\n  tls:\n    - hosts:\n        - mp-test.test.com\n      secretName: test.com         \n</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li><p>集群内可以声明多个Ingress和多个Ingress Controller</p>\n</li>\n<li><p>一个Ingress Controller可以监听多个Ingress</p>\n</li>\n<li><p>Ingress和其定义的服务必须处于同一namespace</p>\n</li>\n</ul>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/\">http://bazingafeng.com/2018/02/10/deploy-ingress-in-kubernetes/</a></p>\n<p><a href=\"https://www.cnblogs.com/xzkzzz/p/9577640.html\">https://www.cnblogs.com/xzkzzz/p/9577640.html</a></p>\n<p><a href=\"https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html\">https://confluence.atlassian.com/adminjiraserver071/connecting-to-an-ldap-directory-802592350.html</a></p>\n"},{"layout":"post","title":"k8s pvc扩容","date":"2018-12-27T03:21:54.000Z","author":"owelinux","excerpt":"k8s pvc扩容","mathjax":true,"_content":"\n* content\n{:toc}\n\n# k8s pvc扩容\n\nhttps://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes","source":"_posts/2018-12-28-article44-k8s-pvc.md","raw":"---\nlayout: post\ntitle:  \"k8s pvc扩容\"\ndate:   2018-12-27 11:21:54\nauthor: owelinux\ncategories: linux \ntags:  linux  \nexcerpt: k8s pvc扩容\nmathjax: true\n---\n\n* content\n{:toc}\n\n# k8s pvc扩容\n\nhttps://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes","slug":"2018-12-28-article44-k8s-pvc","published":1,"updated":"2021-02-09T02:00:24.579Z","comments":1,"photos":[],"link":"","_id":"ckm1fhq13003ayc972r0dh6vn","content":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"k8s-pvc扩容\"><a href=\"#k8s-pvc扩容\" class=\"headerlink\" title=\"k8s pvc扩容\"></a>k8s pvc扩容</h1><p><a href=\"https://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes\">https://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"more":"<ul>\n<li>content<br>{:toc}</li>\n</ul>\n<h1 id=\"k8s-pvc扩容\"><a href=\"#k8s-pvc扩容\" class=\"headerlink\" title=\"k8s pvc扩容\"></a>k8s pvc扩容</h1><p><a href=\"https://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes\">https://gitlab.com/charts/gitlab/tree/master/doc/advanced/persistent-volumes</a></p>\n"},{"title":"jekyll+github搭建博客","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-14T02:14:54.000Z","password":null,"summary":null,"_content":"\n博客有很多搭建方式，以下简单说一下jekyll+github搭建方法。\n\n### 1. 安装 ruby 和 jekyll 环境\n\n这一步和第5步主要是为了让博客系统在本地跑起来，如果不想在本地运行，可以无视这两步，但我还是强烈建议试着先在本地跑起来，没有什么问题后再推送的 GitHub 上。\n\nWindows 用户可以直接使用 [RubyInstaller](http://rubyinstaller.org/) 安装 ruby 环境。后续的操作中可能还会提示安装 DevKit，根据提示操作即可。\n\n建议使用 [RubyGems 镜像- Ruby China](https://gems.ruby-china.org/) 安装 jekyll。\n\n更换 gen源 命令如下\n```\ngem update --system # 尽可能用比较新的RubyGems 版本，建议 2.6.x 以上\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem sources -l  # 确保只有 gems.ruby-china.com\nbundle config mirror.https://rubygems.org https://gems.ruby-china.com # 采用 Bundler 的 Gem 源代码镜像命令\n```\n\n\n安装 jekyll 命令如下\n\n```\ngem install jekyll\n```\n\n详情可以查看 jekyll 官网。[https://jekyllrb.com/](https://jekyllrb.com/) 或 中文翻译版 jekyll 官网[http://jekyllcn.com/](http://jekyllcn.com/) （中文文档翻译落后于英文官网，有兴趣有时间的小伙伴可以参与翻译，为开源世界贡献一份力哦~）\n\n在 mac OS X El Capitan 系统下安装可能会出现问题，解决方案详情见 jekyll 官网: [ https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011]( https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011)\n\n对 jekyll 本身感兴趣的同学可以看看 jekyll 源码: [https://github.com/jekyll/jekyll](https://github.com/jekyll/jekyll)\n\n![jekyll logo](http://jekyllcn.com/img/logo-2x.png)\n\n### 2. 选择自己喜欢的博客主题\n\n可以直接 clone 、下载 或 fork 这个仓库的代码即可\n\n### 3. 修改参数\n\n主要修改 `_config.yml` 中的参数和自己的网站小图`favicon.ico`\n\n`_config.yml`文件中\n\n#### 基本信息\n\n主要用于网站头部header。\n\n```yml\n# Site settings\ntitle: HyG\nbrief-intro: xxxx\nbaseurl: \"\" # the subpath of your site, e.g. /blog\nurl: \"http://username.github.io\" # the base hostname & protocol for your site\n```\n\n#### 链接信息\n\n主要用于网站底部footer。\n\n```yml\n# other links\ntwitter_username: username\nfacebook_username: username\ngithub_username:  username\nemail: username@qq.com\nweibo_username: username\nzhihu_username: username\nlinkedIn_username: username\ndribbble_username:\n\ndescription_footer: 本站记录xxx！\n```\n\n#### 评论信息\n\n获取`short_name`的方法：\n\n访问 https://disqus.com/ 或 http://duoshuo.com/ 根据提示操作即可。\n\n```yml\n# comments\n# two ways to comment, only choose one, and use your own short name\n# 两种评论插件，选一个就好了，使用自己的 short_name\nduoshuo_shortname: #hygblog\ndisqus_shortname: shortname\n```\n\n运行成功后，可以在 disqus 或 多说 的后台管理页看到相关信息。\n\n#### 统计信息\n\n获取 百度统计id 或 Google Analytics id 的方法：\n\n访问 http://tongji.baidu.com/ 或 https://www.google.com/analytics/ 根据提示操作即可。当然，如果不想添加统计信息，这两个参数可以不填。\n\n```yml\n# statistic analysis 统计代码\n# 百度统计 id，将统计代码替换为自己的百度统计id，即\n# hm.src = \"//hm.baidu.com/hm.js?xxxxxxxxxxxx\";\n# xxxxx字符串\nbaidu_tongji_id: xxxx\ngoogle_analytics_id: xxxx # google 分析追踪id\n```\n\n成功后，进入自己的百度统计或 Google Analytics 后台管理，即可看到网站的访问量、访客等相关信息。\n\n### 4. 写文章\n\n`_posts`目录下存放文章信息，文章头部注明 layout(布局)、title、date、categories、tags、author(可选)、mathjax(可选，点击[这里](https://www.mathjax.org/)查看更多关于`Mathjax`)，如下：\n\n```\n---\nlayout: post\ntitle:  \"建站日志\"\ndate:   2018-03-12 11:40:18 +0800\ncategories: jekyll\ntags: jekyll markdown Foxit RubyGems\nauthor: 晚点咖啡\nmathjax: true\n---\n```\n\n下面这两行代码为产生目录时使用\n```\n* content\n{:toc}\n```\n\n文章中存在的4次换行为摘要分割符，换行前的内容会以摘要的形式显示在主页Home上，进入文章页不影响。\n\n换行符的设置见配置文件`_config.yml`的 excerpt，如下：\n\n```yml\n# excerpt\nexcerpt_separator: \"\\n\\n\\n\\n\"\n```\n\n使用 markdown 语法写文章。\n\n代码风格与 GitHub 上 README 或 issue 中的一致。使用3个\\`\\`\\`的方式。\n\n### 5. 本地运行\n\n本地执行\n\n```\njekyll s\n```\n\n显示\n\n```\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n            Source: E:/GitWorkSpace/blog\n       Destination: E:/GitWorkSpace/blog/_site\n Incremental build: disabled. Enable with --incremental\n      Generating...\n                    done in 6.33 seconds.\n  Please add the following to your Gemfile to avoid polling for changes:\n    gem 'wdm', '>= 0.1.0' if Gem.win_platform?\n Auto-regeneration: enabled for 'E:/GitWorkSpace/blog'\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n    Server address: http://127.0.0.1:4000/\n  Server running... press ctrl-c to stop.\n```\n\n在本地访问 localhost:4000 即可看到博客主页。\n\n若安装了 Foxit 福昕pdf阅读器可能会占用4000端口，关闭 Foxit服务 或切换 jekyll 端口即可解决。详情见文章：[对这个 jekyll 博客主题的改版和重构](http://gaohaoyang.github.io/2016/03/12/jekyll-theme-version-2.0/)\n\n若正在使用全局代理，可能会报错502，关闭全局代理即可。\n\n### 6. 发布到 GitHub\n\n没什么问题，推送到自己的博客仓库即可。\n\n### 7. 参考资料\n[http://gaohaoyang.github.io](http://gaohaoyang.github.io)","source":"_posts/blog-jekyll.md","raw":"---\ntitle: jekyll+github搭建博客\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2018-07-14 10:14:54\npassword:\nsummary:\ntags:\n- 博客\ncategories:\n- 随笔\n---\n\n博客有很多搭建方式，以下简单说一下jekyll+github搭建方法。\n\n### 1. 安装 ruby 和 jekyll 环境\n\n这一步和第5步主要是为了让博客系统在本地跑起来，如果不想在本地运行，可以无视这两步，但我还是强烈建议试着先在本地跑起来，没有什么问题后再推送的 GitHub 上。\n\nWindows 用户可以直接使用 [RubyInstaller](http://rubyinstaller.org/) 安装 ruby 环境。后续的操作中可能还会提示安装 DevKit，根据提示操作即可。\n\n建议使用 [RubyGems 镜像- Ruby China](https://gems.ruby-china.org/) 安装 jekyll。\n\n更换 gen源 命令如下\n```\ngem update --system # 尽可能用比较新的RubyGems 版本，建议 2.6.x 以上\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem sources -l  # 确保只有 gems.ruby-china.com\nbundle config mirror.https://rubygems.org https://gems.ruby-china.com # 采用 Bundler 的 Gem 源代码镜像命令\n```\n\n\n安装 jekyll 命令如下\n\n```\ngem install jekyll\n```\n\n详情可以查看 jekyll 官网。[https://jekyllrb.com/](https://jekyllrb.com/) 或 中文翻译版 jekyll 官网[http://jekyllcn.com/](http://jekyllcn.com/) （中文文档翻译落后于英文官网，有兴趣有时间的小伙伴可以参与翻译，为开源世界贡献一份力哦~）\n\n在 mac OS X El Capitan 系统下安装可能会出现问题，解决方案详情见 jekyll 官网: [ https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011]( https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011)\n\n对 jekyll 本身感兴趣的同学可以看看 jekyll 源码: [https://github.com/jekyll/jekyll](https://github.com/jekyll/jekyll)\n\n![jekyll logo](http://jekyllcn.com/img/logo-2x.png)\n\n### 2. 选择自己喜欢的博客主题\n\n可以直接 clone 、下载 或 fork 这个仓库的代码即可\n\n### 3. 修改参数\n\n主要修改 `_config.yml` 中的参数和自己的网站小图`favicon.ico`\n\n`_config.yml`文件中\n\n#### 基本信息\n\n主要用于网站头部header。\n\n```yml\n# Site settings\ntitle: HyG\nbrief-intro: xxxx\nbaseurl: \"\" # the subpath of your site, e.g. /blog\nurl: \"http://username.github.io\" # the base hostname & protocol for your site\n```\n\n#### 链接信息\n\n主要用于网站底部footer。\n\n```yml\n# other links\ntwitter_username: username\nfacebook_username: username\ngithub_username:  username\nemail: username@qq.com\nweibo_username: username\nzhihu_username: username\nlinkedIn_username: username\ndribbble_username:\n\ndescription_footer: 本站记录xxx！\n```\n\n#### 评论信息\n\n获取`short_name`的方法：\n\n访问 https://disqus.com/ 或 http://duoshuo.com/ 根据提示操作即可。\n\n```yml\n# comments\n# two ways to comment, only choose one, and use your own short name\n# 两种评论插件，选一个就好了，使用自己的 short_name\nduoshuo_shortname: #hygblog\ndisqus_shortname: shortname\n```\n\n运行成功后，可以在 disqus 或 多说 的后台管理页看到相关信息。\n\n#### 统计信息\n\n获取 百度统计id 或 Google Analytics id 的方法：\n\n访问 http://tongji.baidu.com/ 或 https://www.google.com/analytics/ 根据提示操作即可。当然，如果不想添加统计信息，这两个参数可以不填。\n\n```yml\n# statistic analysis 统计代码\n# 百度统计 id，将统计代码替换为自己的百度统计id，即\n# hm.src = \"//hm.baidu.com/hm.js?xxxxxxxxxxxx\";\n# xxxxx字符串\nbaidu_tongji_id: xxxx\ngoogle_analytics_id: xxxx # google 分析追踪id\n```\n\n成功后，进入自己的百度统计或 Google Analytics 后台管理，即可看到网站的访问量、访客等相关信息。\n\n### 4. 写文章\n\n`_posts`目录下存放文章信息，文章头部注明 layout(布局)、title、date、categories、tags、author(可选)、mathjax(可选，点击[这里](https://www.mathjax.org/)查看更多关于`Mathjax`)，如下：\n\n```\n---\nlayout: post\ntitle:  \"建站日志\"\ndate:   2018-03-12 11:40:18 +0800\ncategories: jekyll\ntags: jekyll markdown Foxit RubyGems\nauthor: 晚点咖啡\nmathjax: true\n---\n```\n\n下面这两行代码为产生目录时使用\n```\n* content\n{:toc}\n```\n\n文章中存在的4次换行为摘要分割符，换行前的内容会以摘要的形式显示在主页Home上，进入文章页不影响。\n\n换行符的设置见配置文件`_config.yml`的 excerpt，如下：\n\n```yml\n# excerpt\nexcerpt_separator: \"\\n\\n\\n\\n\"\n```\n\n使用 markdown 语法写文章。\n\n代码风格与 GitHub 上 README 或 issue 中的一致。使用3个\\`\\`\\`的方式。\n\n### 5. 本地运行\n\n本地执行\n\n```\njekyll s\n```\n\n显示\n\n```\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n            Source: E:/GitWorkSpace/blog\n       Destination: E:/GitWorkSpace/blog/_site\n Incremental build: disabled. Enable with --incremental\n      Generating...\n                    done in 6.33 seconds.\n  Please add the following to your Gemfile to avoid polling for changes:\n    gem 'wdm', '>= 0.1.0' if Gem.win_platform?\n Auto-regeneration: enabled for 'E:/GitWorkSpace/blog'\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n    Server address: http://127.0.0.1:4000/\n  Server running... press ctrl-c to stop.\n```\n\n在本地访问 localhost:4000 即可看到博客主页。\n\n若安装了 Foxit 福昕pdf阅读器可能会占用4000端口，关闭 Foxit服务 或切换 jekyll 端口即可解决。详情见文章：[对这个 jekyll 博客主题的改版和重构](http://gaohaoyang.github.io/2016/03/12/jekyll-theme-version-2.0/)\n\n若正在使用全局代理，可能会报错502，关闭全局代理即可。\n\n### 6. 发布到 GitHub\n\n没什么问题，推送到自己的博客仓库即可。\n\n### 7. 参考资料\n[http://gaohaoyang.github.io](http://gaohaoyang.github.io)","slug":"blog-jekyll","published":1,"updated":"2021-02-20T09:35:44.544Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1t0049yc97c1na5i76","content":"<p>博客有很多搭建方式，以下简单说一下jekyll+github搭建方法。</p>\n<h3 id=\"1-安装-ruby-和-jekyll-环境\"><a href=\"#1-安装-ruby-和-jekyll-环境\" class=\"headerlink\" title=\"1. 安装 ruby 和 jekyll 环境\"></a>1. 安装 ruby 和 jekyll 环境</h3><p>这一步和第5步主要是为了让博客系统在本地跑起来，如果不想在本地运行，可以无视这两步，但我还是强烈建议试着先在本地跑起来，没有什么问题后再推送的 GitHub 上。</p>\n<p>Windows 用户可以直接使用 <a href=\"http://rubyinstaller.org/\">RubyInstaller</a> 安装 ruby 环境。后续的操作中可能还会提示安装 DevKit，根据提示操作即可。</p>\n<p>建议使用 <a href=\"https://gems.ruby-china.org/\">RubyGems 镜像- Ruby China</a> 安装 jekyll。</p>\n<p>更换 gen源 命令如下</p>\n<pre><code>gem update --system # 尽可能用比较新的RubyGems 版本，建议 2.6.x 以上\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem sources -l  # 确保只有 gems.ruby-china.com\nbundle config mirror.https://rubygems.org https://gems.ruby-china.com # 采用 Bundler 的 Gem 源代码镜像命令\n</code></pre>\n<p>安装 jekyll 命令如下</p>\n<pre><code>gem install jekyll\n</code></pre>\n<p>详情可以查看 jekyll 官网。<a href=\"https://jekyllrb.com/\">https://jekyllrb.com/</a> 或 中文翻译版 jekyll 官网<a href=\"http://jekyllcn.com/\">http://jekyllcn.com/</a> （中文文档翻译落后于英文官网，有兴趣有时间的小伙伴可以参与翻译，为开源世界贡献一份力哦~）</p>\n<p>在 mac OS X El Capitan 系统下安装可能会出现问题，解决方案详情见 jekyll 官网: <a href=\"https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011\"> https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011</a></p>\n<p>对 jekyll 本身感兴趣的同学可以看看 jekyll 源码: <a href=\"https://github.com/jekyll/jekyll\">https://github.com/jekyll/jekyll</a></p>\n<p><img src=\"http://jekyllcn.com/img/logo-2x.png\" alt=\"jekyll logo\"></p>\n<h3 id=\"2-选择自己喜欢的博客主题\"><a href=\"#2-选择自己喜欢的博客主题\" class=\"headerlink\" title=\"2. 选择自己喜欢的博客主题\"></a>2. 选择自己喜欢的博客主题</h3><p>可以直接 clone 、下载 或 fork 这个仓库的代码即可</p>\n<h3 id=\"3-修改参数\"><a href=\"#3-修改参数\" class=\"headerlink\" title=\"3. 修改参数\"></a>3. 修改参数</h3><p>主要修改 <code>_config.yml</code> 中的参数和自己的网站小图<code>favicon.ico</code></p>\n<p><code>_config.yml</code>文件中</p>\n<h4 id=\"基本信息\"><a href=\"#基本信息\" class=\"headerlink\" title=\"基本信息\"></a>基本信息</h4><p>主要用于网站头部header。</p>\n<pre class=\"line-numbers language-yml\"><code class=\"language-yml\"># Site settings\ntitle: HyG\nbrief-intro: xxxx\nbaseurl: \"\" # the subpath of your site, e.g. /blog\nurl: \"http://username.github.io\" # the base hostname & protocol for your site\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"链接信息\"><a href=\"#链接信息\" class=\"headerlink\" title=\"链接信息\"></a>链接信息</h4><p>主要用于网站底部footer。</p>\n<pre class=\"line-numbers language-yml\"><code class=\"language-yml\"># other links\ntwitter_username: username\nfacebook_username: username\ngithub_username:  username\nemail: username@qq.com\nweibo_username: username\nzhihu_username: username\nlinkedIn_username: username\ndribbble_username:\n\ndescription_footer: 本站记录xxx！\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"评论信息\"><a href=\"#评论信息\" class=\"headerlink\" title=\"评论信息\"></a>评论信息</h4><p>获取<code>short_name</code>的方法：</p>\n<p>访问 <a href=\"https://disqus.com/\">https://disqus.com/</a> 或 <a href=\"http://duoshuo.com/\">http://duoshuo.com/</a> 根据提示操作即可。</p>\n<pre class=\"line-numbers language-yml\"><code class=\"language-yml\"># comments\n# two ways to comment, only choose one, and use your own short name\n# 两种评论插件，选一个就好了，使用自己的 short_name\nduoshuo_shortname: #hygblog\ndisqus_shortname: shortname\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>运行成功后，可以在 disqus 或 多说 的后台管理页看到相关信息。</p>\n<h4 id=\"统计信息\"><a href=\"#统计信息\" class=\"headerlink\" title=\"统计信息\"></a>统计信息</h4><p>获取 百度统计id 或 Google Analytics id 的方法：</p>\n<p>访问 <a href=\"http://tongji.baidu.com/\">http://tongji.baidu.com/</a> 或 <a href=\"https://www.google.com/analytics/\">https://www.google.com/analytics/</a> 根据提示操作即可。当然，如果不想添加统计信息，这两个参数可以不填。</p>\n<pre class=\"line-numbers language-yml\"><code class=\"language-yml\"># statistic analysis 统计代码\n# 百度统计 id，将统计代码替换为自己的百度统计id，即\n# hm.src = \"//hm.baidu.com/hm.js?xxxxxxxxxxxx\";\n# xxxxx字符串\nbaidu_tongji_id: xxxx\ngoogle_analytics_id: xxxx # google 分析追踪id\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>成功后，进入自己的百度统计或 Google Analytics 后台管理，即可看到网站的访问量、访客等相关信息。</p>\n<h3 id=\"4-写文章\"><a href=\"#4-写文章\" class=\"headerlink\" title=\"4. 写文章\"></a>4. 写文章</h3><p><code>_posts</code>目录下存放文章信息，文章头部注明 layout(布局)、title、date、categories、tags、author(可选)、mathjax(可选，点击<a href=\"https://www.mathjax.org/\">这里</a>查看更多关于<code>Mathjax</code>)，如下：</p>\n<pre><code>---\nlayout: post\ntitle:  &quot;建站日志&quot;\ndate:   2018-03-12 11:40:18 +0800\ncategories: jekyll\ntags: jekyll markdown Foxit RubyGems\nauthor: 晚点咖啡\nmathjax: true\n---\n</code></pre>\n<p>下面这两行代码为产生目录时使用</p>\n<pre><code>* content\n&#123;:toc&#125;\n</code></pre>\n<p>文章中存在的4次换行为摘要分割符，换行前的内容会以摘要的形式显示在主页Home上，进入文章页不影响。</p>\n<p>换行符的设置见配置文件<code>_config.yml</code>的 excerpt，如下：</p>\n<pre class=\"line-numbers language-yml\"><code class=\"language-yml\"># excerpt\nexcerpt_separator: \"\\n\\n\\n\\n\"\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>使用 markdown 语法写文章。</p>\n<p>代码风格与 GitHub 上 README 或 issue 中的一致。使用3个```的方式。</p>\n<h3 id=\"5-本地运行\"><a href=\"#5-本地运行\" class=\"headerlink\" title=\"5. 本地运行\"></a>5. 本地运行</h3><p>本地执行</p>\n<pre><code>jekyll s\n</code></pre>\n<p>显示</p>\n<pre><code>Configuration file: E:/GitWorkSpace/blog/_config.yml\n            Source: E:/GitWorkSpace/blog\n       Destination: E:/GitWorkSpace/blog/_site\n Incremental build: disabled. Enable with --incremental\n      Generating...\n                    done in 6.33 seconds.\n  Please add the following to your Gemfile to avoid polling for changes:\n    gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform?\n Auto-regeneration: enabled for &#39;E:/GitWorkSpace/blog&#39;\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n    Server address: http://127.0.0.1:4000/\n  Server running... press ctrl-c to stop.\n</code></pre>\n<p>在本地访问 localhost:4000 即可看到博客主页。</p>\n<p>若安装了 Foxit 福昕pdf阅读器可能会占用4000端口，关闭 Foxit服务 或切换 jekyll 端口即可解决。详情见文章：<a href=\"http://gaohaoyang.github.io/2016/03/12/jekyll-theme-version-2.0/\">对这个 jekyll 博客主题的改版和重构</a></p>\n<p>若正在使用全局代理，可能会报错502，关闭全局代理即可。</p>\n<h3 id=\"6-发布到-GitHub\"><a href=\"#6-发布到-GitHub\" class=\"headerlink\" title=\"6. 发布到 GitHub\"></a>6. 发布到 GitHub</h3><p>没什么问题，推送到自己的博客仓库即可。</p>\n<h3 id=\"7-参考资料\"><a href=\"#7-参考资料\" class=\"headerlink\" title=\"7. 参考资料\"></a>7. 参考资料</h3><p><a href=\"http://gaohaoyang.github.io/\">http://gaohaoyang.github.io</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>博客有很多搭建方式，以下简单说一下jekyll+github搭建方法。</p>\n<h3 id=\"1-安装-ruby-和-jekyll-环境\"><a href=\"#1-安装-ruby-和-jekyll-环境\" class=\"headerlink\" title=\"1. 安装 ruby 和 jekyll 环境\"></a>1. 安装 ruby 和 jekyll 环境</h3><p>这一步和第5步主要是为了让博客系统在本地跑起来，如果不想在本地运行，可以无视这两步，但我还是强烈建议试着先在本地跑起来，没有什么问题后再推送的 GitHub 上。</p>\n<p>Windows 用户可以直接使用 <a href=\"http://rubyinstaller.org/\">RubyInstaller</a> 安装 ruby 环境。后续的操作中可能还会提示安装 DevKit，根据提示操作即可。</p>\n<p>建议使用 <a href=\"https://gems.ruby-china.org/\">RubyGems 镜像- Ruby China</a> 安装 jekyll。</p>\n<p>更换 gen源 命令如下</p>\n<pre><code>gem update --system # 尽可能用比较新的RubyGems 版本，建议 2.6.x 以上\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem sources -l  # 确保只有 gems.ruby-china.com\nbundle config mirror.https://rubygems.org https://gems.ruby-china.com # 采用 Bundler 的 Gem 源代码镜像命令\n</code></pre>\n<p>安装 jekyll 命令如下</p>\n<pre><code>gem install jekyll\n</code></pre>\n<p>详情可以查看 jekyll 官网。<a href=\"https://jekyllrb.com/\">https://jekyllrb.com/</a> 或 中文翻译版 jekyll 官网<a href=\"http://jekyllcn.com/\">http://jekyllcn.com/</a> （中文文档翻译落后于英文官网，有兴趣有时间的小伙伴可以参与翻译，为开源世界贡献一份力哦~）</p>\n<p>在 mac OS X El Capitan 系统下安装可能会出现问题，解决方案详情见 jekyll 官网: <a href=\"https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011\"> https://jekyllrb.com/docs/troubleshooting/#jekyll-amp-mac-os-x-1011</a></p>\n<p>对 jekyll 本身感兴趣的同学可以看看 jekyll 源码: <a href=\"https://github.com/jekyll/jekyll\">https://github.com/jekyll/jekyll</a></p>\n<p><img src=\"http://jekyllcn.com/img/logo-2x.png\" alt=\"jekyll logo\"></p>\n<h3 id=\"2-选择自己喜欢的博客主题\"><a href=\"#2-选择自己喜欢的博客主题\" class=\"headerlink\" title=\"2. 选择自己喜欢的博客主题\"></a>2. 选择自己喜欢的博客主题</h3><p>可以直接 clone 、下载 或 fork 这个仓库的代码即可</p>\n<h3 id=\"3-修改参数\"><a href=\"#3-修改参数\" class=\"headerlink\" title=\"3. 修改参数\"></a>3. 修改参数</h3><p>主要修改 <code>_config.yml</code> 中的参数和自己的网站小图<code>favicon.ico</code></p>\n<p><code>_config.yml</code>文件中</p>\n<h4 id=\"基本信息\"><a href=\"#基本信息\" class=\"headerlink\" title=\"基本信息\"></a>基本信息</h4><p>主要用于网站头部header。</p>\n<pre><code class=\"yml\"># Site settings\ntitle: HyG\nbrief-intro: xxxx\nbaseurl: &quot;&quot; # the subpath of your site, e.g. /blog\nurl: &quot;http://username.github.io&quot; # the base hostname &amp; protocol for your site\n</code></pre>\n<h4 id=\"链接信息\"><a href=\"#链接信息\" class=\"headerlink\" title=\"链接信息\"></a>链接信息</h4><p>主要用于网站底部footer。</p>\n<pre><code class=\"yml\"># other links\ntwitter_username: username\nfacebook_username: username\ngithub_username:  username\nemail: username@qq.com\nweibo_username: username\nzhihu_username: username\nlinkedIn_username: username\ndribbble_username:\n\ndescription_footer: 本站记录xxx！\n</code></pre>\n<h4 id=\"评论信息\"><a href=\"#评论信息\" class=\"headerlink\" title=\"评论信息\"></a>评论信息</h4><p>获取<code>short_name</code>的方法：</p>\n<p>访问 <a href=\"https://disqus.com/\">https://disqus.com/</a> 或 <a href=\"http://duoshuo.com/\">http://duoshuo.com/</a> 根据提示操作即可。</p>\n<pre><code class=\"yml\"># comments\n# two ways to comment, only choose one, and use your own short name\n# 两种评论插件，选一个就好了，使用自己的 short_name\nduoshuo_shortname: #hygblog\ndisqus_shortname: shortname\n</code></pre>\n<p>运行成功后，可以在 disqus 或 多说 的后台管理页看到相关信息。</p>\n<h4 id=\"统计信息\"><a href=\"#统计信息\" class=\"headerlink\" title=\"统计信息\"></a>统计信息</h4><p>获取 百度统计id 或 Google Analytics id 的方法：</p>\n<p>访问 <a href=\"http://tongji.baidu.com/\">http://tongji.baidu.com/</a> 或 <a href=\"https://www.google.com/analytics/\">https://www.google.com/analytics/</a> 根据提示操作即可。当然，如果不想添加统计信息，这两个参数可以不填。</p>\n<pre><code class=\"yml\"># statistic analysis 统计代码\n# 百度统计 id，将统计代码替换为自己的百度统计id，即\n# hm.src = &quot;//hm.baidu.com/hm.js?xxxxxxxxxxxx&quot;;\n# xxxxx字符串\nbaidu_tongji_id: xxxx\ngoogle_analytics_id: xxxx # google 分析追踪id\n</code></pre>\n<p>成功后，进入自己的百度统计或 Google Analytics 后台管理，即可看到网站的访问量、访客等相关信息。</p>\n<h3 id=\"4-写文章\"><a href=\"#4-写文章\" class=\"headerlink\" title=\"4. 写文章\"></a>4. 写文章</h3><p><code>_posts</code>目录下存放文章信息，文章头部注明 layout(布局)、title、date、categories、tags、author(可选)、mathjax(可选，点击<a href=\"https://www.mathjax.org/\">这里</a>查看更多关于<code>Mathjax</code>)，如下：</p>\n<pre><code>---\nlayout: post\ntitle:  &quot;建站日志&quot;\ndate:   2018-03-12 11:40:18 +0800\ncategories: jekyll\ntags: jekyll markdown Foxit RubyGems\nauthor: 晚点咖啡\nmathjax: true\n---\n</code></pre>\n<p>下面这两行代码为产生目录时使用</p>\n<pre><code>* content\n&#123;:toc&#125;\n</code></pre>\n<p>文章中存在的4次换行为摘要分割符，换行前的内容会以摘要的形式显示在主页Home上，进入文章页不影响。</p>\n<p>换行符的设置见配置文件<code>_config.yml</code>的 excerpt，如下：</p>\n<pre><code class=\"yml\"># excerpt\nexcerpt_separator: &quot;\\n\\n\\n\\n&quot;\n</code></pre>\n<p>使用 markdown 语法写文章。</p>\n<p>代码风格与 GitHub 上 README 或 issue 中的一致。使用3个```的方式。</p>\n<h3 id=\"5-本地运行\"><a href=\"#5-本地运行\" class=\"headerlink\" title=\"5. 本地运行\"></a>5. 本地运行</h3><p>本地执行</p>\n<pre><code>jekyll s\n</code></pre>\n<p>显示</p>\n<pre><code>Configuration file: E:/GitWorkSpace/blog/_config.yml\n            Source: E:/GitWorkSpace/blog\n       Destination: E:/GitWorkSpace/blog/_site\n Incremental build: disabled. Enable with --incremental\n      Generating...\n                    done in 6.33 seconds.\n  Please add the following to your Gemfile to avoid polling for changes:\n    gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform?\n Auto-regeneration: enabled for &#39;E:/GitWorkSpace/blog&#39;\nConfiguration file: E:/GitWorkSpace/blog/_config.yml\n    Server address: http://127.0.0.1:4000/\n  Server running... press ctrl-c to stop.\n</code></pre>\n<p>在本地访问 localhost:4000 即可看到博客主页。</p>\n<p>若安装了 Foxit 福昕pdf阅读器可能会占用4000端口，关闭 Foxit服务 或切换 jekyll 端口即可解决。详情见文章：<a href=\"http://gaohaoyang.github.io/2016/03/12/jekyll-theme-version-2.0/\">对这个 jekyll 博客主题的改版和重构</a></p>\n<p>若正在使用全局代理，可能会报错502，关闭全局代理即可。</p>\n<h3 id=\"6-发布到-GitHub\"><a href=\"#6-发布到-GitHub\" class=\"headerlink\" title=\"6. 发布到 GitHub\"></a>6. 发布到 GitHub</h3><p>没什么问题，推送到自己的博客仓库即可。</p>\n<h3 id=\"7-参考资料\"><a href=\"#7-参考资料\" class=\"headerlink\" title=\"7. 参考资料\"></a>7. 参考资料</h3><p><a href=\"http://gaohaoyang.github.io/\">http://gaohaoyang.github.io</a></p>\n"},{"_content":"# jenkins devops piplne发送邮件配置\n\n\n## 准备工作\n* 安装email-ext-plugin插件\n* 配置jenkins\n* pipline发送邮件\n\n\n## 安装email-ext-plugin插件\njenkins --> 系统管理 --> 系统设置 --> Extended E-mail Notification\n\n\n## 配置jenkins\nDefault Subject\n```\n构建通知:$PROJECT_NAME - Build # $BUILD_NUMBER - $BUILD_STATUS!\n```\nDefault Content\n```\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n</head>\n<body leftmargin=\"8\" marginwidth=\"0\" topmargin=\"8\" marginheight=\"4\"\n    offset=\"0\">\n    <table width=\"95%\" cellpadding=\"0\" cellspacing=\"0\"\n        style=\"font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif\">\n        <tr>\n            <td><br />\n            <b><font color=\"#0B610B\">构建信息</font></b>\n            <hr size=\"2\" width=\"100%\" align=\"center\" /></td>\n        </tr>\n        <tr>\n            <td>\n                <ul> \n                    <li>项目名称：${PROJECT_NAME}</li>\n                    <li>构建结果:  <span style=\"color:red\"> ${BUILD_STATUS}</span></li>  \n                    <li>构建编号：第${BUILD_NUMBER}次构建 </li>\n                    <li>触发原因 ：${CAUSE}</li>\n                    <li>GIT 地址： ${gitlabSourceRepoHomepage}</li>                    \n                    <li>GIT 分支：${gitlabSourceBranch}</li>\n                    <li>镜像标签：${tag}</li>\n                    <li>变更记录: ${CHANGES,showPaths=true,showDependencies=true,format=\"<pre><ul><li>提交ID: %r</li><li>提交人：%a</li><li>提交时间：%d</li><li>提交信息：%m</li><li>提交文件：%p</li></ul></pre>\",pathFormat=\"%p <br />\"}\n                </ul>\n            </td>\n        </tr>\n        <tr>  \n          <td><b><font color=\"#0B610B\">变更集</font></b>  \n            <hr size=\"2\" width=\"100%\" align=\"center\" />\n          </td>  \n        </tr>          \n        <tr>  \n          <td>${JELLY_SCRIPT,template=\"html\"}<br/>  \n            <hr size=\"2\" width=\"100%\" align=\"center\" />\n          </td>  \n        </tr> \n        <tr>\n            <td><b><font color=\"#0B610B\">构建日志 :</font></b>\n            <hr size=\"2\" width=\"100%\" align=\"center\" /></td>\n        </tr>\n        <tr>\n            <td><textarea cols=\"150\" rows=\"30\" readonly=\"readonly\"\n                    style=\"font-family: Courier New\">${BUILD_LOG}</textarea>\n            </td>\n        </tr>\n    </table>\n</body>\n</html>\n```\n\n## pipline\n```\ndef label = \"mypod-${UUID.randomUUID().toString()}\"\ndef tag = '1'\ndef tomail = 'xxx@xxx.com'\nif (gitlabSourceBranch=='T1'){\n   tag = 'test'\n} else\nif (gitlabSourceBranch=='R1'){\n    print(gitlabSourceBranch)\n} else {\n    print(\"请使用关键分支push触发构建\")\n    currentBuild.result = 'SUCCESS'\n    return\n}\n\npodTemplate(label: label,cloud: 'kubernetes',containers: [\n    containerTemplate(\n        name: 'jnlp',\n        alwaysPullImage: true, \n        image: 'registry.cn-hangzhou.aliyuncs.com/mypaas/jenkins-jnlp:latest', \n        privileged: false, \n        ttyEnabled: true, \n        workingDir: '/home/jenkins')\n    ], \n    name: \"jnlp-${appName}\",\n    namespace: 'default',  \n    podRetention: never(), \n    volumes: [\n        hostPathVolume(hostPath: '/var/run/docker.sock', mountPath: '/var/run/docker.sock'), \n        persistentVolumeClaim(claimName: 'jenkins-code-nas', mountPath: '/home/jenkins', readOnly: false)])\n{     \n    node(label) {\n\t  try {    \n        stage('Clone') {\n            echo \"1.Clone Stage\"\n            git credentialsId: 'xxx', url: 'git@xxx.git',branch:gitlabSourceBranch\n        }\n    \n    // get tag\n        if (gitlabSourceBranch=='T1'){\n           tag = 'test'\n        } else\n        if (gitlabSourceBranch=='R1'){\n            script {\n                tag = sh(returnStdout: true, script: 'cat release.tag').trim()\n                }\n        } \n        print(tag)     \n        \n\t\tstage('PHPUNIT Test') {\n            echo \"2.Test Stage\"\n            sh 'printenv'\n        }\n        // mail stage\n        emailext ( \n            body: '''\n            ${DEFAULT_CONTENT}\n            ''', \n            recipientProviders: [developers()], \n            subject: '${DEFAULT_SUBJECT}', \n            to: \"${tomail}\"\n            )         \n      } catch (any) {\n        currentBuild.result = 'FAILURE'\n        throw any\n    } finally {\n        if (currentBuild.result == 'FAILURE') {  \n          emailext ( \n            body: '''\n            ${DEFAULT_CONTENT}\n            ''', \n            recipientProviders: [developers()], \n            subject: '${DEFAULT_SUBJECT}', \n            to: \"${tomail}\"\n            )\n        }      \n      }        \n    }    \n}        \n```\n\n## 参考文档\n\n* [https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates](https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates)\n\n* [https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5](https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5)","source":"_posts/jenkins-email.md","raw":"# jenkins devops piplne发送邮件配置\n\n\n## 准备工作\n* 安装email-ext-plugin插件\n* 配置jenkins\n* pipline发送邮件\n\n\n## 安装email-ext-plugin插件\njenkins --> 系统管理 --> 系统设置 --> Extended E-mail Notification\n\n\n## 配置jenkins\nDefault Subject\n```\n构建通知:$PROJECT_NAME - Build # $BUILD_NUMBER - $BUILD_STATUS!\n```\nDefault Content\n```\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n</head>\n<body leftmargin=\"8\" marginwidth=\"0\" topmargin=\"8\" marginheight=\"4\"\n    offset=\"0\">\n    <table width=\"95%\" cellpadding=\"0\" cellspacing=\"0\"\n        style=\"font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif\">\n        <tr>\n            <td><br />\n            <b><font color=\"#0B610B\">构建信息</font></b>\n            <hr size=\"2\" width=\"100%\" align=\"center\" /></td>\n        </tr>\n        <tr>\n            <td>\n                <ul> \n                    <li>项目名称：${PROJECT_NAME}</li>\n                    <li>构建结果:  <span style=\"color:red\"> ${BUILD_STATUS}</span></li>  \n                    <li>构建编号：第${BUILD_NUMBER}次构建 </li>\n                    <li>触发原因 ：${CAUSE}</li>\n                    <li>GIT 地址： ${gitlabSourceRepoHomepage}</li>                    \n                    <li>GIT 分支：${gitlabSourceBranch}</li>\n                    <li>镜像标签：${tag}</li>\n                    <li>变更记录: ${CHANGES,showPaths=true,showDependencies=true,format=\"<pre><ul><li>提交ID: %r</li><li>提交人：%a</li><li>提交时间：%d</li><li>提交信息：%m</li><li>提交文件：%p</li></ul></pre>\",pathFormat=\"%p <br />\"}\n                </ul>\n            </td>\n        </tr>\n        <tr>  \n          <td><b><font color=\"#0B610B\">变更集</font></b>  \n            <hr size=\"2\" width=\"100%\" align=\"center\" />\n          </td>  \n        </tr>          \n        <tr>  \n          <td>${JELLY_SCRIPT,template=\"html\"}<br/>  \n            <hr size=\"2\" width=\"100%\" align=\"center\" />\n          </td>  \n        </tr> \n        <tr>\n            <td><b><font color=\"#0B610B\">构建日志 :</font></b>\n            <hr size=\"2\" width=\"100%\" align=\"center\" /></td>\n        </tr>\n        <tr>\n            <td><textarea cols=\"150\" rows=\"30\" readonly=\"readonly\"\n                    style=\"font-family: Courier New\">${BUILD_LOG}</textarea>\n            </td>\n        </tr>\n    </table>\n</body>\n</html>\n```\n\n## pipline\n```\ndef label = \"mypod-${UUID.randomUUID().toString()}\"\ndef tag = '1'\ndef tomail = 'xxx@xxx.com'\nif (gitlabSourceBranch=='T1'){\n   tag = 'test'\n} else\nif (gitlabSourceBranch=='R1'){\n    print(gitlabSourceBranch)\n} else {\n    print(\"请使用关键分支push触发构建\")\n    currentBuild.result = 'SUCCESS'\n    return\n}\n\npodTemplate(label: label,cloud: 'kubernetes',containers: [\n    containerTemplate(\n        name: 'jnlp',\n        alwaysPullImage: true, \n        image: 'registry.cn-hangzhou.aliyuncs.com/mypaas/jenkins-jnlp:latest', \n        privileged: false, \n        ttyEnabled: true, \n        workingDir: '/home/jenkins')\n    ], \n    name: \"jnlp-${appName}\",\n    namespace: 'default',  \n    podRetention: never(), \n    volumes: [\n        hostPathVolume(hostPath: '/var/run/docker.sock', mountPath: '/var/run/docker.sock'), \n        persistentVolumeClaim(claimName: 'jenkins-code-nas', mountPath: '/home/jenkins', readOnly: false)])\n{     \n    node(label) {\n\t  try {    \n        stage('Clone') {\n            echo \"1.Clone Stage\"\n            git credentialsId: 'xxx', url: 'git@xxx.git',branch:gitlabSourceBranch\n        }\n    \n    // get tag\n        if (gitlabSourceBranch=='T1'){\n           tag = 'test'\n        } else\n        if (gitlabSourceBranch=='R1'){\n            script {\n                tag = sh(returnStdout: true, script: 'cat release.tag').trim()\n                }\n        } \n        print(tag)     \n        \n\t\tstage('PHPUNIT Test') {\n            echo \"2.Test Stage\"\n            sh 'printenv'\n        }\n        // mail stage\n        emailext ( \n            body: '''\n            ${DEFAULT_CONTENT}\n            ''', \n            recipientProviders: [developers()], \n            subject: '${DEFAULT_SUBJECT}', \n            to: \"${tomail}\"\n            )         \n      } catch (any) {\n        currentBuild.result = 'FAILURE'\n        throw any\n    } finally {\n        if (currentBuild.result == 'FAILURE') {  \n          emailext ( \n            body: '''\n            ${DEFAULT_CONTENT}\n            ''', \n            recipientProviders: [developers()], \n            subject: '${DEFAULT_SUBJECT}', \n            to: \"${tomail}\"\n            )\n        }      \n      }        \n    }    \n}        \n```\n\n## 参考文档\n\n* [https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates](https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates)\n\n* [https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5](https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5)","slug":"jenkins-email","published":1,"date":"2021-02-09T02:00:24.581Z","updated":"2021-02-09T02:00:24.581Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1u004ayc9740gx57mo","content":"<h1 id=\"jenkins-devops-piplne发送邮件配置\"><a href=\"#jenkins-devops-piplne发送邮件配置\" class=\"headerlink\" title=\"jenkins devops piplne发送邮件配置\"></a>jenkins devops piplne发送邮件配置</h1><h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><ul>\n<li>安装email-ext-plugin插件</li>\n<li>配置jenkins</li>\n<li>pipline发送邮件</li>\n</ul>\n<h2 id=\"安装email-ext-plugin插件\"><a href=\"#安装email-ext-plugin插件\" class=\"headerlink\" title=\"安装email-ext-plugin插件\"></a>安装email-ext-plugin插件</h2><p>jenkins –&gt; 系统管理 –&gt; 系统设置 –&gt; Extended E-mail Notification</p>\n<h2 id=\"配置jenkins\"><a href=\"#配置jenkins\" class=\"headerlink\" title=\"配置jenkins\"></a>配置jenkins</h2><p>Default Subject</p>\n<pre><code>构建通知:$PROJECT_NAME - Build # $BUILD_NUMBER - $BUILD_STATUS!\n</code></pre>\n<p>Default Content</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta charset=&quot;UTF-8&quot;&gt;\n&lt;/head&gt;\n&lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot;\n    offset=&quot;0&quot;&gt;\n    &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;\n        style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;br /&gt;\n            &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建信息&lt;/font&gt;&lt;/b&gt;\n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;\n                &lt;ul&gt; \n                    &lt;li&gt;项目名称：$&#123;PROJECT_NAME&#125;&lt;/li&gt;\n                    &lt;li&gt;构建结果:  &lt;span style=&quot;color:red&quot;&gt; $&#123;BUILD_STATUS&#125;&lt;/span&gt;&lt;/li&gt;  \n                    &lt;li&gt;构建编号：第$&#123;BUILD_NUMBER&#125;次构建 &lt;/li&gt;\n                    &lt;li&gt;触发原因 ：$&#123;CAUSE&#125;&lt;/li&gt;\n                    &lt;li&gt;GIT 地址： $&#123;gitlabSourceRepoHomepage&#125;&lt;/li&gt;                    \n                    &lt;li&gt;GIT 分支：$&#123;gitlabSourceBranch&#125;&lt;/li&gt;\n                    &lt;li&gt;镜像标签：$&#123;tag&#125;&lt;/li&gt;\n                    &lt;li&gt;变更记录: $&#123;CHANGES,showPaths=true,showDependencies=true,format=&quot;&lt;pre&gt;&lt;ul&gt;&lt;li&gt;提交ID: %r&lt;/li&gt;&lt;li&gt;提交人：%a&lt;/li&gt;&lt;li&gt;提交时间：%d&lt;/li&gt;&lt;li&gt;提交信息：%m&lt;/li&gt;&lt;li&gt;提交文件：%p&lt;/li&gt;&lt;/ul&gt;&lt;/pre&gt;&quot;,pathFormat=&quot;%p &lt;br /&gt;&quot;&#125;\n                &lt;/ul&gt;\n            &lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;  \n          &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;变更集&lt;/font&gt;&lt;/b&gt;  \n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;\n          &lt;/td&gt;  \n        &lt;/tr&gt;          \n        &lt;tr&gt;  \n          &lt;td&gt;$&#123;JELLY_SCRIPT,template=&quot;html&quot;&#125;&lt;br/&gt;  \n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;\n          &lt;/td&gt;  \n        &lt;/tr&gt; \n        &lt;tr&gt;\n            &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建日志 :&lt;/font&gt;&lt;/b&gt;\n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;textarea cols=&quot;150&quot; rows=&quot;30&quot; readonly=&quot;readonly&quot;\n                    style=&quot;font-family: Courier New&quot;&gt;$&#123;BUILD_LOG&#125;&lt;/textarea&gt;\n            &lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<h2 id=\"pipline\"><a href=\"#pipline\" class=\"headerlink\" title=\"pipline\"></a>pipline</h2><pre><code>def label = &quot;mypod-$&#123;UUID.randomUUID().toString()&#125;&quot;\ndef tag = &#39;1&#39;\ndef tomail = &#39;xxx@xxx.com&#39;\nif (gitlabSourceBranch==&#39;T1&#39;)&#123;\n   tag = &#39;test&#39;\n&#125; else\nif (gitlabSourceBranch==&#39;R1&#39;)&#123;\n    print(gitlabSourceBranch)\n&#125; else &#123;\n    print(&quot;请使用关键分支push触发构建&quot;)\n    currentBuild.result = &#39;SUCCESS&#39;\n    return\n&#125;\n\npodTemplate(label: label,cloud: &#39;kubernetes&#39;,containers: [\n    containerTemplate(\n        name: &#39;jnlp&#39;,\n        alwaysPullImage: true, \n        image: &#39;registry.cn-hangzhou.aliyuncs.com/mypaas/jenkins-jnlp:latest&#39;, \n        privileged: false, \n        ttyEnabled: true, \n        workingDir: &#39;/home/jenkins&#39;)\n    ], \n    name: &quot;jnlp-$&#123;appName&#125;&quot;,\n    namespace: &#39;default&#39;,  \n    podRetention: never(), \n    volumes: [\n        hostPathVolume(hostPath: &#39;/var/run/docker.sock&#39;, mountPath: &#39;/var/run/docker.sock&#39;), \n        persistentVolumeClaim(claimName: &#39;jenkins-code-nas&#39;, mountPath: &#39;/home/jenkins&#39;, readOnly: false)])\n&#123;     \n    node(label) &#123;\n      try &#123;    \n        stage(&#39;Clone&#39;) &#123;\n            echo &quot;1.Clone Stage&quot;\n            git credentialsId: &#39;xxx&#39;, url: &#39;git@xxx.git&#39;,branch:gitlabSourceBranch\n        &#125;\n    \n    // get tag\n        if (gitlabSourceBranch==&#39;T1&#39;)&#123;\n           tag = &#39;test&#39;\n        &#125; else\n        if (gitlabSourceBranch==&#39;R1&#39;)&#123;\n            script &#123;\n                tag = sh(returnStdout: true, script: &#39;cat release.tag&#39;).trim()\n                &#125;\n        &#125; \n        print(tag)     \n        \n        stage(&#39;PHPUNIT Test&#39;) &#123;\n            echo &quot;2.Test Stage&quot;\n            sh &#39;printenv&#39;\n        &#125;\n        // mail stage\n        emailext ( \n            body: &#39;&#39;&#39;\n            $&#123;DEFAULT_CONTENT&#125;\n            &#39;&#39;&#39;, \n            recipientProviders: [developers()], \n            subject: &#39;$&#123;DEFAULT_SUBJECT&#125;&#39;, \n            to: &quot;$&#123;tomail&#125;&quot;\n            )         \n      &#125; catch (any) &#123;\n        currentBuild.result = &#39;FAILURE&#39;\n        throw any\n    &#125; finally &#123;\n        if (currentBuild.result == &#39;FAILURE&#39;) &#123;  \n          emailext ( \n            body: &#39;&#39;&#39;\n            $&#123;DEFAULT_CONTENT&#125;\n            &#39;&#39;&#39;, \n            recipientProviders: [developers()], \n            subject: &#39;$&#123;DEFAULT_SUBJECT&#125;&#39;, \n            to: &quot;$&#123;tomail&#125;&quot;\n            )\n        &#125;      \n      &#125;        \n    &#125;    \n&#125;        \n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates\">https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates</a></p>\n</li>\n<li><p><a href=\"https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5\">https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5</a></p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"jenkins-devops-piplne发送邮件配置\"><a href=\"#jenkins-devops-piplne发送邮件配置\" class=\"headerlink\" title=\"jenkins devops piplne发送邮件配置\"></a>jenkins devops piplne发送邮件配置</h1><h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><ul>\n<li>安装email-ext-plugin插件</li>\n<li>配置jenkins</li>\n<li>pipline发送邮件</li>\n</ul>\n<h2 id=\"安装email-ext-plugin插件\"><a href=\"#安装email-ext-plugin插件\" class=\"headerlink\" title=\"安装email-ext-plugin插件\"></a>安装email-ext-plugin插件</h2><p>jenkins –&gt; 系统管理 –&gt; 系统设置 –&gt; Extended E-mail Notification</p>\n<h2 id=\"配置jenkins\"><a href=\"#配置jenkins\" class=\"headerlink\" title=\"配置jenkins\"></a>配置jenkins</h2><p>Default Subject</p>\n<pre><code>构建通知:$PROJECT_NAME - Build # $BUILD_NUMBER - $BUILD_STATUS!\n</code></pre>\n<p>Default Content</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta charset=&quot;UTF-8&quot;&gt;\n&lt;/head&gt;\n&lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot;\n    offset=&quot;0&quot;&gt;\n    &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;\n        style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;br /&gt;\n            &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建信息&lt;/font&gt;&lt;/b&gt;\n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;\n                &lt;ul&gt; \n                    &lt;li&gt;项目名称：$&#123;PROJECT_NAME&#125;&lt;/li&gt;\n                    &lt;li&gt;构建结果:  &lt;span style=&quot;color:red&quot;&gt; $&#123;BUILD_STATUS&#125;&lt;/span&gt;&lt;/li&gt;  \n                    &lt;li&gt;构建编号：第$&#123;BUILD_NUMBER&#125;次构建 &lt;/li&gt;\n                    &lt;li&gt;触发原因 ：$&#123;CAUSE&#125;&lt;/li&gt;\n                    &lt;li&gt;GIT 地址： $&#123;gitlabSourceRepoHomepage&#125;&lt;/li&gt;                    \n                    &lt;li&gt;GIT 分支：$&#123;gitlabSourceBranch&#125;&lt;/li&gt;\n                    &lt;li&gt;镜像标签：$&#123;tag&#125;&lt;/li&gt;\n                    &lt;li&gt;变更记录: $&#123;CHANGES,showPaths=true,showDependencies=true,format=&quot;&lt;pre&gt;&lt;ul&gt;&lt;li&gt;提交ID: %r&lt;/li&gt;&lt;li&gt;提交人：%a&lt;/li&gt;&lt;li&gt;提交时间：%d&lt;/li&gt;&lt;li&gt;提交信息：%m&lt;/li&gt;&lt;li&gt;提交文件：%p&lt;/li&gt;&lt;/ul&gt;&lt;/pre&gt;&quot;,pathFormat=&quot;%p &lt;br /&gt;&quot;&#125;\n                &lt;/ul&gt;\n            &lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;  \n          &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;变更集&lt;/font&gt;&lt;/b&gt;  \n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;\n          &lt;/td&gt;  \n        &lt;/tr&gt;          \n        &lt;tr&gt;  \n          &lt;td&gt;$&#123;JELLY_SCRIPT,template=&quot;html&quot;&#125;&lt;br/&gt;  \n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;\n          &lt;/td&gt;  \n        &lt;/tr&gt; \n        &lt;tr&gt;\n            &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建日志 :&lt;/font&gt;&lt;/b&gt;\n            &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;textarea cols=&quot;150&quot; rows=&quot;30&quot; readonly=&quot;readonly&quot;\n                    style=&quot;font-family: Courier New&quot;&gt;$&#123;BUILD_LOG&#125;&lt;/textarea&gt;\n            &lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<h2 id=\"pipline\"><a href=\"#pipline\" class=\"headerlink\" title=\"pipline\"></a>pipline</h2><pre><code>def label = &quot;mypod-$&#123;UUID.randomUUID().toString()&#125;&quot;\ndef tag = &#39;1&#39;\ndef tomail = &#39;xxx@xxx.com&#39;\nif (gitlabSourceBranch==&#39;T1&#39;)&#123;\n   tag = &#39;test&#39;\n&#125; else\nif (gitlabSourceBranch==&#39;R1&#39;)&#123;\n    print(gitlabSourceBranch)\n&#125; else &#123;\n    print(&quot;请使用关键分支push触发构建&quot;)\n    currentBuild.result = &#39;SUCCESS&#39;\n    return\n&#125;\n\npodTemplate(label: label,cloud: &#39;kubernetes&#39;,containers: [\n    containerTemplate(\n        name: &#39;jnlp&#39;,\n        alwaysPullImage: true, \n        image: &#39;registry.cn-hangzhou.aliyuncs.com/mypaas/jenkins-jnlp:latest&#39;, \n        privileged: false, \n        ttyEnabled: true, \n        workingDir: &#39;/home/jenkins&#39;)\n    ], \n    name: &quot;jnlp-$&#123;appName&#125;&quot;,\n    namespace: &#39;default&#39;,  \n    podRetention: never(), \n    volumes: [\n        hostPathVolume(hostPath: &#39;/var/run/docker.sock&#39;, mountPath: &#39;/var/run/docker.sock&#39;), \n        persistentVolumeClaim(claimName: &#39;jenkins-code-nas&#39;, mountPath: &#39;/home/jenkins&#39;, readOnly: false)])\n&#123;     \n    node(label) &#123;\n      try &#123;    \n        stage(&#39;Clone&#39;) &#123;\n            echo &quot;1.Clone Stage&quot;\n            git credentialsId: &#39;xxx&#39;, url: &#39;git@xxx.git&#39;,branch:gitlabSourceBranch\n        &#125;\n    \n    // get tag\n        if (gitlabSourceBranch==&#39;T1&#39;)&#123;\n           tag = &#39;test&#39;\n        &#125; else\n        if (gitlabSourceBranch==&#39;R1&#39;)&#123;\n            script &#123;\n                tag = sh(returnStdout: true, script: &#39;cat release.tag&#39;).trim()\n                &#125;\n        &#125; \n        print(tag)     \n        \n        stage(&#39;PHPUNIT Test&#39;) &#123;\n            echo &quot;2.Test Stage&quot;\n            sh &#39;printenv&#39;\n        &#125;\n        // mail stage\n        emailext ( \n            body: &#39;&#39;&#39;\n            $&#123;DEFAULT_CONTENT&#125;\n            &#39;&#39;&#39;, \n            recipientProviders: [developers()], \n            subject: &#39;$&#123;DEFAULT_SUBJECT&#125;&#39;, \n            to: &quot;$&#123;tomail&#125;&quot;\n            )         \n      &#125; catch (any) &#123;\n        currentBuild.result = &#39;FAILURE&#39;\n        throw any\n    &#125; finally &#123;\n        if (currentBuild.result == &#39;FAILURE&#39;) &#123;  \n          emailext ( \n            body: &#39;&#39;&#39;\n            $&#123;DEFAULT_CONTENT&#125;\n            &#39;&#39;&#39;, \n            recipientProviders: [developers()], \n            subject: &#39;$&#123;DEFAULT_SUBJECT&#125;&#39;, \n            to: &quot;$&#123;tomail&#125;&quot;\n            )\n        &#125;      \n      &#125;        \n    &#125;    \n&#125;        \n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates\">https://github.com/jenkinsci/email-ext-plugin/tree/master/src/main/resources/hudson/plugins/emailext/templates</a></p>\n</li>\n<li><p><a href=\"https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5\">https://github.com/whihail/AutoArchive/wiki/%E5%AE%A2%E6%88%B7%E7%AB%AFJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97%E4%B9%8B%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5</a></p>\n</li>\n</ul>\n"},{"_content":"# Kubernetes 配置 kubeconfig 访问多个集群\n\n\n## test集群（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\ncurrent-context: test\nkind: Config\npreferences: {}\nusers:\n- name: test-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## prod集群（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: prod\nkind: Config\npreferences: {}\nusers:\n- name: prod-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## 合并后（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\n- cluster:\n    certificate-authority-data: CERTIFICATE_AUTHORITY_DATA\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: \"\" #默认集群设置为空\nkind: Config\npreferences: {}\nusers:\n- name: test\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n- name: prod\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## 查看集群\n```\nkubectl config get-contexts\n```\n## 切换集群\n```\nkubectl config use-context test\nkubectl config use-context prod\n```\n\n注：如果想限制用户的 Namespace，可以在 context 中加入namespaces 配置.\n```\n- context:\n    cluster: test\n    user: test-admin\n    namespace: default\n  name: test\n```\n\n## 参考文档\n\n[kubernetes官方文档](https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)","source":"_posts/k8s-cluster.md","raw":"# Kubernetes 配置 kubeconfig 访问多个集群\n\n\n## test集群（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\ncurrent-context: test\nkind: Config\npreferences: {}\nusers:\n- name: test-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## prod集群（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: prod\nkind: Config\npreferences: {}\nusers:\n- name: prod-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## 合并后（~/.kube/config）\n```\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\n- cluster:\n    certificate-authority-data: CERTIFICATE_AUTHORITY_DATA\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: \"\" #默认集群设置为空\nkind: Config\npreferences: {}\nusers:\n- name: test\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n- name: prod\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n```\n\n## 查看集群\n```\nkubectl config get-contexts\n```\n## 切换集群\n```\nkubectl config use-context test\nkubectl config use-context prod\n```\n\n注：如果想限制用户的 Namespace，可以在 context 中加入namespaces 配置.\n```\n- context:\n    cluster: test\n    user: test-admin\n    namespace: default\n  name: test\n```\n\n## 参考文档\n\n[kubernetes官方文档](https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)","slug":"k8s-cluster","published":1,"date":"2021-02-09T02:00:24.581Z","updated":"2021-02-09T02:00:24.581Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1v004dyc977bv2gfsl","content":"<h1 id=\"Kubernetes-配置-kubeconfig-访问多个集群\"><a href=\"#Kubernetes-配置-kubeconfig-访问多个集群\" class=\"headerlink\" title=\"Kubernetes 配置 kubeconfig 访问多个集群\"></a>Kubernetes 配置 kubeconfig 访问多个集群</h1><h2 id=\"test集群（-kube-config）\"><a href=\"#test集群（-kube-config）\" class=\"headerlink\" title=\"test集群（~/.kube/config）\"></a>test集群（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\ncurrent-context: test\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: test-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"prod集群（-kube-config）\"><a href=\"#prod集群（-kube-config）\" class=\"headerlink\" title=\"prod集群（~/.kube/config）\"></a>prod集群（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: prod\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: prod-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"合并后（-kube-config）\"><a href=\"#合并后（-kube-config）\" class=\"headerlink\" title=\"合并后（~/.kube/config）\"></a>合并后（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\n- cluster:\n    certificate-authority-data: CERTIFICATE_AUTHORITY_DATA\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: &quot;&quot; #默认集群设置为空\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: test\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n- name: prod\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"查看集群\"><a href=\"#查看集群\" class=\"headerlink\" title=\"查看集群\"></a>查看集群</h2><pre><code>kubectl config get-contexts\n</code></pre>\n<h2 id=\"切换集群\"><a href=\"#切换集群\" class=\"headerlink\" title=\"切换集群\"></a>切换集群</h2><pre><code>kubectl config use-context test\nkubectl config use-context prod\n</code></pre>\n<p>注：如果想限制用户的 Namespace，可以在 context 中加入namespaces 配置.</p>\n<pre><code>- context:\n    cluster: test\n    user: test-admin\n    namespace: default\n  name: test\n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\">kubernetes官方文档</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"Kubernetes-配置-kubeconfig-访问多个集群\"><a href=\"#Kubernetes-配置-kubeconfig-访问多个集群\" class=\"headerlink\" title=\"Kubernetes 配置 kubeconfig 访问多个集群\"></a>Kubernetes 配置 kubeconfig 访问多个集群</h1><h2 id=\"test集群（-kube-config）\"><a href=\"#test集群（-kube-config）\" class=\"headerlink\" title=\"test集群（~/.kube/config）\"></a>test集群（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\ncurrent-context: test\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: test-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"prod集群（-kube-config）\"><a href=\"#prod集群（-kube-config）\" class=\"headerlink\" title=\"prod集群（~/.kube/config）\"></a>prod集群（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: prod\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: prod-admin\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"合并后（-kube-config）\"><a href=\"#合并后（-kube-config）\" class=\"headerlink\" title=\"合并后（~/.kube/config）\"></a>合并后（~/.kube/config）</h2><pre><code>apiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://localhost:6443\n  name: test\n- cluster:\n    certificate-authority-data: CERTIFICATE_AUTHORITY_DATA\n    server: https://localhost:6443\n  name: prod\ncontexts:\n- context:\n    cluster: test\n    user: test-admin\n  name: test\n- context:\n    cluster: prod\n    user: prod-admin\n  name: prod\ncurrent-context: &quot;&quot; #默认集群设置为空\nkind: Config\npreferences: &#123;&#125;\nusers:\n- name: test\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n- name: prod\n  user:\n    client-certificate-data: CLIENT_CERTIFICATE_DATA\n    client-key-data: CLIENT_KEY_DATA\n</code></pre>\n<h2 id=\"查看集群\"><a href=\"#查看集群\" class=\"headerlink\" title=\"查看集群\"></a>查看集群</h2><pre><code>kubectl config get-contexts\n</code></pre>\n<h2 id=\"切换集群\"><a href=\"#切换集群\" class=\"headerlink\" title=\"切换集群\"></a>切换集群</h2><pre><code>kubectl config use-context test\nkubectl config use-context prod\n</code></pre>\n<p>注：如果想限制用户的 Namespace，可以在 context 中加入namespaces 配置.</p>\n<pre><code>- context:\n    cluster: test\n    user: test-admin\n    namespace: default\n  name: test\n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\">kubernetes官方文档</a></p>\n"},{"_content":"# K8S重启Deployment的方式\n\n有时候我们会需要重启Deployment，原因可能是：\n\ndocker image使用的是latest tag，这个latest在docker image registry已经更新了，我们需要重启deployment来使用新的latest\nPod运行缓慢但是还活着，我们就是想重启一下\nConfigMap/Secret变更了，想重启一下应用新配置\n上面两种情况的共同之处在于，Deployment spec没有发生任何变化，因此即使你kubectl appply -f deployment-spec.yaml也是没用的，因为K8S会认为你这个没有变化就什么都不做了。\n\n但是我们又不想使用手工删除Pod-让K8S新建Pod的方式来重启Deployment，最好的办法应该是像Updating a deployment一样，让K8S自己滚动的删除-新建Pod。\n\n下面介绍四种方式重启：\n\n    kubectl apply -f app.yaml\n    kubectl delete -f app.yaml| kubectl create -f app.yaml\n    kubectl get pod PODNAME  -o yaml | kubectl replace --force -f -\n    kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1\n    kubectl -n beta patch deployment modeling-platform --patch '{\"spec\": {\"template\": {\"spec\": {\"containers\": [{\"name\": \"modeling-platform\",\"image\": \"nginx:'${build_tag}'\",\"env\": [{\"name\":\"LAST_MANUAL_RESTART\",\"value\":\"'${BUILD_ID}'\"}]}]}}}}'\n\n\n## 参考文档\n\n* [https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/](https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/)\n\n* [https://chanjarster.github.io/post/k8s-restart-deployment/](https://chanjarster.github.io/post/k8s-restart-deployment/)","source":"_posts/k8s重启deployment.md","raw":"# K8S重启Deployment的方式\n\n有时候我们会需要重启Deployment，原因可能是：\n\ndocker image使用的是latest tag，这个latest在docker image registry已经更新了，我们需要重启deployment来使用新的latest\nPod运行缓慢但是还活着，我们就是想重启一下\nConfigMap/Secret变更了，想重启一下应用新配置\n上面两种情况的共同之处在于，Deployment spec没有发生任何变化，因此即使你kubectl appply -f deployment-spec.yaml也是没用的，因为K8S会认为你这个没有变化就什么都不做了。\n\n但是我们又不想使用手工删除Pod-让K8S新建Pod的方式来重启Deployment，最好的办法应该是像Updating a deployment一样，让K8S自己滚动的删除-新建Pod。\n\n下面介绍四种方式重启：\n\n    kubectl apply -f app.yaml\n    kubectl delete -f app.yaml| kubectl create -f app.yaml\n    kubectl get pod PODNAME  -o yaml | kubectl replace --force -f -\n    kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1\n    kubectl -n beta patch deployment modeling-platform --patch '{\"spec\": {\"template\": {\"spec\": {\"containers\": [{\"name\": \"modeling-platform\",\"image\": \"nginx:'${build_tag}'\",\"env\": [{\"name\":\"LAST_MANUAL_RESTART\",\"value\":\"'${BUILD_ID}'\"}]}]}}}}'\n\n\n## 参考文档\n\n* [https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/](https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/)\n\n* [https://chanjarster.github.io/post/k8s-restart-deployment/](https://chanjarster.github.io/post/k8s-restart-deployment/)","slug":"k8s重启deployment","published":1,"date":"2021-02-09T02:00:24.581Z","updated":"2021-02-09T02:00:24.582Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1w004eyc974cr9h1po","content":"<h1 id=\"K8S重启Deployment的方式\"><a href=\"#K8S重启Deployment的方式\" class=\"headerlink\" title=\"K8S重启Deployment的方式\"></a>K8S重启Deployment的方式</h1><p>有时候我们会需要重启Deployment，原因可能是：</p>\n<p>docker image使用的是latest tag，这个latest在docker image registry已经更新了，我们需要重启deployment来使用新的latest<br>Pod运行缓慢但是还活着，我们就是想重启一下<br>ConfigMap/Secret变更了，想重启一下应用新配置<br>上面两种情况的共同之处在于，Deployment spec没有发生任何变化，因此即使你kubectl appply -f deployment-spec.yaml也是没用的，因为K8S会认为你这个没有变化就什么都不做了。</p>\n<p>但是我们又不想使用手工删除Pod-让K8S新建Pod的方式来重启Deployment，最好的办法应该是像Updating a deployment一样，让K8S自己滚动的删除-新建Pod。</p>\n<p>下面介绍四种方式重启：</p>\n<pre><code>kubectl apply -f app.yaml\nkubectl delete -f app.yaml| kubectl create -f app.yaml\nkubectl get pod PODNAME  -o yaml | kubectl replace --force -f -\nkubectl set image deployment/nginx-deployment nginx=nginx:1.9.1\nkubectl -n beta patch deployment modeling-platform --patch &#39;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;spec&quot;: &#123;&quot;containers&quot;: [&#123;&quot;name&quot;: &quot;modeling-platform&quot;,&quot;image&quot;: &quot;nginx:&#39;$&#123;build_tag&#125;&#39;&quot;,&quot;env&quot;: [&#123;&quot;name&quot;:&quot;LAST_MANUAL_RESTART&quot;,&quot;value&quot;:&quot;&#39;$&#123;BUILD_ID&#125;&#39;&quot;&#125;]&#125;]&#125;&#125;&#125;&#125;&#39;\n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/\">https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/</a></p>\n</li>\n<li><p><a href=\"https://chanjarster.github.io/post/k8s-restart-deployment/\">https://chanjarster.github.io/post/k8s-restart-deployment/</a></p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"K8S重启Deployment的方式\"><a href=\"#K8S重启Deployment的方式\" class=\"headerlink\" title=\"K8S重启Deployment的方式\"></a>K8S重启Deployment的方式</h1><p>有时候我们会需要重启Deployment，原因可能是：</p>\n<p>docker image使用的是latest tag，这个latest在docker image registry已经更新了，我们需要重启deployment来使用新的latest<br>Pod运行缓慢但是还活着，我们就是想重启一下<br>ConfigMap/Secret变更了，想重启一下应用新配置<br>上面两种情况的共同之处在于，Deployment spec没有发生任何变化，因此即使你kubectl appply -f deployment-spec.yaml也是没用的，因为K8S会认为你这个没有变化就什么都不做了。</p>\n<p>但是我们又不想使用手工删除Pod-让K8S新建Pod的方式来重启Deployment，最好的办法应该是像Updating a deployment一样，让K8S自己滚动的删除-新建Pod。</p>\n<p>下面介绍四种方式重启：</p>\n<pre><code>kubectl apply -f app.yaml\nkubectl delete -f app.yaml| kubectl create -f app.yaml\nkubectl get pod PODNAME  -o yaml | kubectl replace --force -f -\nkubectl set image deployment/nginx-deployment nginx=nginx:1.9.1\nkubectl -n beta patch deployment modeling-platform --patch &#39;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;spec&quot;: &#123;&quot;containers&quot;: [&#123;&quot;name&quot;: &quot;modeling-platform&quot;,&quot;image&quot;: &quot;nginx:&#39;$&#123;build_tag&#125;&#39;&quot;,&quot;env&quot;: [&#123;&quot;name&quot;:&quot;LAST_MANUAL_RESTART&quot;,&quot;value&quot;:&quot;&#39;$&#123;BUILD_ID&#125;&#39;&quot;&#125;]&#125;]&#125;&#125;&#125;&#125;&#39;\n</code></pre>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><p><a href=\"https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/\">https://k8smeetup.github.io/docs/tasks/run-application/update-api-object-kubectl-patch/</a></p>\n</li>\n<li><p><a href=\"https://chanjarster.github.io/post/k8s-restart-deployment/\">https://chanjarster.github.io/post/k8s-restart-deployment/</a></p>\n</li>\n</ul>\n"},{"title":"linux系统调优指南(centos7.X)","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-18T07:14:54.000Z","password":null,"summary":null,"_content":"\n## 关闭不必要的服务(如打印服务等)\n```\nfor owelinux in `chkconfig --list | grep \"3:on\" | awk '{print $1}'`; do chkconfig $owelinux off; done\nfor owelinux in crond network sshd rsyslog sysstat iptables; do chkconfig $owelinux on; done\n```\n## 关闭不需要的tty\n```\n\\cp /etc/securetty  /etc/securetty.bak\n>/etc/securetty\necho \"tty1\" >>/etc/securetty\necho \"tty2\" >>/etc/securetty\necho \"tty3\" >>/etc/securetty\n```\n## 调整linux 文件描述符大小\n```\n\\cp /etc/security/limits.conf /etc/security/limits.conf.$(date +%F)\nulimit -HSn 65535\necho -ne \"\n* soft nofile 65535\n* hard nofile 65535\n\" >>/etc/security/limits.conf\necho \"ulimit -c unlimited\" >> /etc/profile\nsource /etc/profile\n```\n## 修改shell命令的history 记录个数和连接超时时间\n```\necho \"export HISTCONTROL=ignorespace\" >>/etc/profile\necho \"export HISTCONTROL=erasedups\" >>/etc/profile\necho \"HISTSIZE=500\" >> /etc/profile\n\n#修改帐户TMOUT值，设置自动注销时间\necho \"export TMOUT=300\" >>/etc/profile\necho \"set autologout=300\" >>/etc/csh.cshrc\nsource /etc/profile\n```\n## 清空系统版本信息加入登录警告\n```\n>/etc/motd\n>/etc/issue\n>/etc/redhat-release\necho \"Authorized uses only. All activity may be monitored   and reported.\" >>/etc/motd\necho \"Authorized uses only. All activity may be monitored   and reported.\" >> /etc/issue\necho \"Authorized uses only. All activity may be monitored   and reported.\" >> /etc/issue.net\nchown root:root /etc/motd /etc/issue  /etc/issue.net\nchmod 644 /etc/motd /etc/issue  /etc/issue.net\n```\n\n## 优化内核TCP参数\n```\ncat >>/etc/sysctl.conf<<EOF\nnet.ipv4.tcp_fin_timeout = 1\nnet.ipv4.tcp_keepalive_time = 1200\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 1\nnet.ipv4.tcp_syn_retries = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\nnet.core.netdev_max_backlog = 262144\nnet.ipv4.tcp_max_orphans = 3276800\nnet.ipv4.tcp_max_syn_backlog = 262144\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nEOF\n/sbin/sysctl -p\n```\n\n## 登录机器发邮件告警\n```\nyum -y install mailx\ncat >>/root/.bashrc << EOF\necho 'ALERT - Root Shell Access (Server Name) on:' \\`date\\`\\`who\\`\\`hostname\\` | mail -s \"Alert:Root Access from \\`who | cut -d \"(\" -f2 | cut -d \")\" #-f1\\`\" blue.yunwei@bluepay.asia\nEOF\n```\n\n## 定时校正服务器时间\n```\necho '0 * * * * /usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w > /dev/null 2>&1' >> /var/spool/cron/root\n/usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w\nsystemctl  restart crond\n```\n## 停止ipv6\n```\necho 1 > /proc/sys/net/ipv6/conf/all/disable_ipv6\n```\n## 修改yum源\n```\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\nyum -y reinstall epel-release\nyum clean all\nyum makecache\n```\n## 关闭Selinux\n```\nsetenforce 0\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config\n```\n## 安装必要的服务，更新系统软件\n```\nyum -y groupinstall \"Development tools\"\nyum -y install ntpdate sysstat lrzsz wget nmap tree curl  epel-release lsof nano bash-completion net-tools lsof vim-enhanced\n```\n## ssh优化，加快连接速度\n```\n#1、配置空闲登出的超时间隔:\n#2、禁用   .rhosts 文件\n#3、禁用基于主机的认证\n#4、禁止   root 帐号通过 SSH   登录\n#5、用警告的   Banner\n#6、iptables防火墙处理 SSH 端口22123\n#7、修改 SSH   端口和限制 IP 绑定：\n#8、禁用空密码：\n#9、记录日志：\n\nmv /etc/ssh/ /etc/sshbak\nmkdir -p /application/tools\ncd /application/tools\nyum -y install wget C gcc cc\nwget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-7.6p1.tar.gz\ntar -zxf openssh-7.6p1.tar.gz\ncd openssh-7.6p1\nyum install -y zlib-devel openssl-devel pam pam-devel\n./configure --prefix=/usr --sysconfdir=/etc/ssh --without-zlib-version-check  --with-pam\nchmod 600 /etc/ssh/*_key\nmake -j4\nrpm -e --nodeps `rpm -qa | grep openssh`\nmake install\nssh -V\ncp contrib/redhat/sshd.init /etc/init.d/sshd\nchkconfig --add sshd\n\nmv /etc/ssh/sshd_config /etc/ssh/sshd_config_`date +%F`\ncat >/etc/ssh/sshd_config<<EOF\nPort 22123\nPidFile /var/run/sshd.pid\nSyslogFacility AUTH\nLogLevel INFO\nLoginGraceTime 30\nPermitRootLogin no\nStrictModes yes\nMaxAuthTries 3\nMaxSessions 15\n#AllowUsers root lovelinux\nPubkeyAuthentication yes\nAuthorizedKeysFile  .ssh/authorized_keys\nPasswordAuthentication yes\nPermitEmptyPasswords no\nChallengeResponseAuthentication yes\nGSSAPIAuthentication no\nGSSAPICleanupCredentials yes\nUsePAM no\nClientAliveInterval 0\nClientAliveCountMax 3\nUseDNS no\nSubsystem   sftp    /usr/lib/ssh/sftp-server\nCiphers aes128-ctr,aes192-ctr,aes256-ctr\nMacs    hmac-sha2-256,hmac-sha2-512\nEOF\n\necho \"#save sshd messages also to sshd.log\" >>/etc/rsyslog.conf\necho \"local5.* /var/log/sshd.log\" >>/etc/rsyslog.conf\nsystemctl restart rsyslog\nsystemctl stop sshd && systemctl start sshd\nsystemctl reload sshd\n```\n## 删除系统不需要的用户和用户组\n```\n   for i in adm lp sync shutdown halt news uucp operator games gopher\n   do\n      userdel $i  2>/dev/null\n   done && action \"delete user: \" /bin/true || action \"delete user: \" /bin/false\n\n   for i in adm  news uucp games dip pppusers popusers slipusers\n   do\n      groupdel $i  2>/dev/null\n   done\n```\n## 修改密码认证的复杂度，和过期时间\n```\nmv /etc/pam.d/system-auth /etc/pam.d/system-auth_`date +%F`\ncat >/etc/pam.d/system-auth<<EOF\n#%PAM-1.0\n# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth required pam_tally.so onerr=fail deny=6 unlock_time=1800\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid >= 500 quiet\nauth        required      pam_deny.so\nauth    sufficient    /lib/security/pam_unix.so likeauth nullok\n\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid < 500 quiet\naccount     required      pam_permit.so\n\npassword    requisite     pam_cracklib.so try_first_pass retry=3  minlen=8 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1\npassword    sufficient    pam_unix.so sha512 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\n\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.soetc/pam.d/system-auth\nEOF\ncat >/etc/pam.d/sshd<<EOF\n#%PAM-1.0\n#auth       required pam_google_authenticator.so nullok\nauth       required     pam_sepermit.so\nauth       substack     password-auth\nauth       include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-auth      optional     pam_reauthorize.so prepare\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    required     pam_namespace.so\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\nsession    include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-session   optional     pam_reauthorize.so prepare\nEOF\n```\n## 使用noatime文件系统挂载选项\n## 删除CentOS自带的sendmail，改用postfix\n## 增加SWAP分区大小（一般是内存的2倍）\n```\ndd if=/dev/zero of=/mnt/swapfile bs=4M count=1024\nmkswap /mnt/swapfile\nswapon /mnt/swapfile\necho \"/mnt/swapfile swap swap defaults 0 0\" >>/etc/fstab\nmount -a\nfree -m | grep -i swap\n```\n## 使用iptables关闭不需要对外开放的端口\n```\nsystemctl disable firewalld\nsystemctl stop firewalld\n\nyum -y install iptables-services\nsystemctl start iptables\nsystemctl start ip6tables\nsystemctl enable iptables\nsystemctl enable ip6tables\n\niptables -F\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -p tcp --dport 22123 -j ACCEPT\niptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p icmp -j ACCEPT\niptables -A INPUT -j DROP\nservice iptables save\n```\n## 启动系统审计服务\n```\nyum install audit*.* -y\ncat >>/etc/audit/audit.rules<<EOF\n-w /var/log/audit/ -k LOG_audit\n-w /etc/audit/ -p wa -k CFG_audit\n-w /etc/sysconfig/auditd -p wa -k CFG_auditd.conf\n-w /etc/libaudit.conf -p wa -k CFG_libaudit.conf\n-w /etc/audisp/ -p wa -k CFG_audisp\n-w /etc/cups/ -p wa -k CFG_cups\n-w /etc/init.d/cups -p wa -k CFG_initd_cups\n-w /etc/netlabel.rules -p wa -k CFG_netlabel.rules\n-w /etc/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /usr/share/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /etc/selinux/semanage.conf -p wa -k CFG_MAC_policy\n-w /usr/sbin/stunnel -p x\n-w /etc/security/rbac-self-test.conf -p wa -k CFG_RBAC_self_test\n-w /etc/aide.conf -p wa -k CFG_aide.conf\n-w /etc/cron.allow -p wa -k CFG_cron.allow\n-w /etc/cron.deny -p wa -k CFG_cron.deny\n-w /etc/cron.d/ -p wa -k CFG_cron.d\n-w /etc/cron.daily/ -p wa -k CFG_cron.daily\n-w /etc/cron.hourly/ -p wa -k CFG_cron.hourly\n-w /etc/cron.monthly/ -p wa -k CFG_cron.monthly\n-w /etc/cron.weekly/ -p wa -k CFG_cron.weekly\n-w /etc/crontab -p wa -k CFG_crontab\n-w /var/spool/cron/root -k CFG_crontab_root\n-w /etc/group -p wa -k CFG_group\n-w /etc/passwd -p wa -k CFG_passwd\n-w /etc/gshadow -k CFG_gshadow\n-w /etc/shadow -k CFG_shadow\n-w /etc/security/opasswd -k CFG_opasswd\n-w /etc/login.defs -p wa -k CFG_login.defs\n-w /etc/securetty -p wa -k CFG_securetty\n-w /var/log/faillog -p wa -k LOG_faillog\n-w /var/log/lastlog -p wa -k LOG_lastlog\n-w /var/log/tallylog -p wa -k LOG_tallylog\n-w /etc/hosts -p wa -k CFG_hosts\n-w /etc/sysconfig/network-scripts/ -p wa -k CFG_network\n-w /etc/inittab -p wa -k CFG_inittab\n-w /etc/rc.d/init.d/ -p wa -k CFG_initscripts\n-w /etc/ld.so.conf -p wa -k CFG_ld.so.conf\n-w /etc/localtime -p wa -k CFG_localtime\n-w /etc/sysctl.conf -p wa -k CFG_sysctl.conf\n-w /etc/modprobe.conf -p wa -k CFG_modprobe.conf\n-w /etc/pam.d/ -p wa -k CFG_pam\n-w /etc/security/limits.conf -p wa -k CFG_pam\n-w /etc/security/pam_env.conf -p wa -k CFG_pam\n-w /etc/security/namespace.conf -p wa -k CFG_pam\n-w /etc/security/namespace.init -p wa -k CFG_pam\n-w /etc/aliases -p wa -k CFG_aliases\n-w /etc/postfix/ -p wa -k CFG_postfix\n-w /etc/ssh/sshd_config -k CFG_sshd_config\n-w /etc/vsftpd.ftpusers -k CFG_vsftpd.ftpusers\n-a exit,always -F arch=b32 -S sethostname\n-w /etc/issue -p wa -k CFG_issue\n-w /etc/issue.net -p wa -k CFG_issue.net\nEOF\nsystemctl enable auditd\nservice auditd  restart\n```\n## 部署完整性检查工具软件\n```\nyum -y install aide\n\n#1）执行初始化，建立第一份样本库\naide -i\nmv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n\n#2）更新到样本库\naide -u\ncd /var/lib/aide/\nmv aide.db.new.gz aide.db.gz\n\n#3）定期执行入侵检测，并发送报告\n# crontab -e\n#45 17 * * * /usr/sbin/aide -C -V4 | /bin/mail -s ”AIDE REPORT $（date +%Y%m%d）” abcdefg#163.com\necho '45 23 * * * aide -C >> /var/log/aide/`date +%Y%m%d`_aide.log' >> /var/spool/cron/root\n\n#记录aide可执行文件的md5 checksum：\nmd5sum /usr/sbin/aide\n```\n## 关闭ctrl+alt+del重启机器\n```\nrm -f /usr/lib/systemd/system/ctrl-alt-del.targe && init q\n#恢复  ln -s /usr/lib/systemd/system/reboot.target /usr/lib/systemd/system/ctrl-alt-del.target\n```\n## 文件加锁及修改默认权限\n```\n#1、限制   at/cron给授权的用户:\nrm -f /etc/cron.deny /etc/at.deny\necho root >/etc/cron.allow\necho root >/etc/at.allow\nchown root:root /etc/cron.allow /etc/at.allow\nchmod 400 /etc/cron.allow /etc/at.allow\n\n#2、Crontab文件限制访问权限:\nchown root:root /etc/crontab\nchmod 400 /etc/crontab\nchown -R root:root /var/spool/cron\nchmod -R go-rwx /var/spool/cron\nchown -R root:root /etc/cron.*\nchmod -R go-rwx /etc/cron.*\n\n#3、加锁重要口令文件和组文件\nchattr +i /etc/passwd\nchattr +i /etc/shadow\nchattr +i /etc/group\nchattr +i /etc/gshadow\nchattr +i /etc/xinetd.conf\nchattr +i /etc/services\n```","source":"_posts/linux-init7.md","raw":"---\ntitle: linux系统调优指南(centos7.X)\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate:   2018-07-18 15:14:54\npassword:\nsummary:\ntags:\n- 系统调优\ncategories:\n- linux\n---\n\n## 关闭不必要的服务(如打印服务等)\n```\nfor owelinux in `chkconfig --list | grep \"3:on\" | awk '{print $1}'`; do chkconfig $owelinux off; done\nfor owelinux in crond network sshd rsyslog sysstat iptables; do chkconfig $owelinux on; done\n```\n## 关闭不需要的tty\n```\n\\cp /etc/securetty  /etc/securetty.bak\n>/etc/securetty\necho \"tty1\" >>/etc/securetty\necho \"tty2\" >>/etc/securetty\necho \"tty3\" >>/etc/securetty\n```\n## 调整linux 文件描述符大小\n```\n\\cp /etc/security/limits.conf /etc/security/limits.conf.$(date +%F)\nulimit -HSn 65535\necho -ne \"\n* soft nofile 65535\n* hard nofile 65535\n\" >>/etc/security/limits.conf\necho \"ulimit -c unlimited\" >> /etc/profile\nsource /etc/profile\n```\n## 修改shell命令的history 记录个数和连接超时时间\n```\necho \"export HISTCONTROL=ignorespace\" >>/etc/profile\necho \"export HISTCONTROL=erasedups\" >>/etc/profile\necho \"HISTSIZE=500\" >> /etc/profile\n\n#修改帐户TMOUT值，设置自动注销时间\necho \"export TMOUT=300\" >>/etc/profile\necho \"set autologout=300\" >>/etc/csh.cshrc\nsource /etc/profile\n```\n## 清空系统版本信息加入登录警告\n```\n>/etc/motd\n>/etc/issue\n>/etc/redhat-release\necho \"Authorized uses only. All activity may be monitored   and reported.\" >>/etc/motd\necho \"Authorized uses only. All activity may be monitored   and reported.\" >> /etc/issue\necho \"Authorized uses only. All activity may be monitored   and reported.\" >> /etc/issue.net\nchown root:root /etc/motd /etc/issue  /etc/issue.net\nchmod 644 /etc/motd /etc/issue  /etc/issue.net\n```\n\n## 优化内核TCP参数\n```\ncat >>/etc/sysctl.conf<<EOF\nnet.ipv4.tcp_fin_timeout = 1\nnet.ipv4.tcp_keepalive_time = 1200\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 1\nnet.ipv4.tcp_syn_retries = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\nnet.core.netdev_max_backlog = 262144\nnet.ipv4.tcp_max_orphans = 3276800\nnet.ipv4.tcp_max_syn_backlog = 262144\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nEOF\n/sbin/sysctl -p\n```\n\n## 登录机器发邮件告警\n```\nyum -y install mailx\ncat >>/root/.bashrc << EOF\necho 'ALERT - Root Shell Access (Server Name) on:' \\`date\\`\\`who\\`\\`hostname\\` | mail -s \"Alert:Root Access from \\`who | cut -d \"(\" -f2 | cut -d \")\" #-f1\\`\" blue.yunwei@bluepay.asia\nEOF\n```\n\n## 定时校正服务器时间\n```\necho '0 * * * * /usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w > /dev/null 2>&1' >> /var/spool/cron/root\n/usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w\nsystemctl  restart crond\n```\n## 停止ipv6\n```\necho 1 > /proc/sys/net/ipv6/conf/all/disable_ipv6\n```\n## 修改yum源\n```\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\nyum -y reinstall epel-release\nyum clean all\nyum makecache\n```\n## 关闭Selinux\n```\nsetenforce 0\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config\n```\n## 安装必要的服务，更新系统软件\n```\nyum -y groupinstall \"Development tools\"\nyum -y install ntpdate sysstat lrzsz wget nmap tree curl  epel-release lsof nano bash-completion net-tools lsof vim-enhanced\n```\n## ssh优化，加快连接速度\n```\n#1、配置空闲登出的超时间隔:\n#2、禁用   .rhosts 文件\n#3、禁用基于主机的认证\n#4、禁止   root 帐号通过 SSH   登录\n#5、用警告的   Banner\n#6、iptables防火墙处理 SSH 端口22123\n#7、修改 SSH   端口和限制 IP 绑定：\n#8、禁用空密码：\n#9、记录日志：\n\nmv /etc/ssh/ /etc/sshbak\nmkdir -p /application/tools\ncd /application/tools\nyum -y install wget C gcc cc\nwget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-7.6p1.tar.gz\ntar -zxf openssh-7.6p1.tar.gz\ncd openssh-7.6p1\nyum install -y zlib-devel openssl-devel pam pam-devel\n./configure --prefix=/usr --sysconfdir=/etc/ssh --without-zlib-version-check  --with-pam\nchmod 600 /etc/ssh/*_key\nmake -j4\nrpm -e --nodeps `rpm -qa | grep openssh`\nmake install\nssh -V\ncp contrib/redhat/sshd.init /etc/init.d/sshd\nchkconfig --add sshd\n\nmv /etc/ssh/sshd_config /etc/ssh/sshd_config_`date +%F`\ncat >/etc/ssh/sshd_config<<EOF\nPort 22123\nPidFile /var/run/sshd.pid\nSyslogFacility AUTH\nLogLevel INFO\nLoginGraceTime 30\nPermitRootLogin no\nStrictModes yes\nMaxAuthTries 3\nMaxSessions 15\n#AllowUsers root lovelinux\nPubkeyAuthentication yes\nAuthorizedKeysFile  .ssh/authorized_keys\nPasswordAuthentication yes\nPermitEmptyPasswords no\nChallengeResponseAuthentication yes\nGSSAPIAuthentication no\nGSSAPICleanupCredentials yes\nUsePAM no\nClientAliveInterval 0\nClientAliveCountMax 3\nUseDNS no\nSubsystem   sftp    /usr/lib/ssh/sftp-server\nCiphers aes128-ctr,aes192-ctr,aes256-ctr\nMacs    hmac-sha2-256,hmac-sha2-512\nEOF\n\necho \"#save sshd messages also to sshd.log\" >>/etc/rsyslog.conf\necho \"local5.* /var/log/sshd.log\" >>/etc/rsyslog.conf\nsystemctl restart rsyslog\nsystemctl stop sshd && systemctl start sshd\nsystemctl reload sshd\n```\n## 删除系统不需要的用户和用户组\n```\n   for i in adm lp sync shutdown halt news uucp operator games gopher\n   do\n      userdel $i  2>/dev/null\n   done && action \"delete user: \" /bin/true || action \"delete user: \" /bin/false\n\n   for i in adm  news uucp games dip pppusers popusers slipusers\n   do\n      groupdel $i  2>/dev/null\n   done\n```\n## 修改密码认证的复杂度，和过期时间\n```\nmv /etc/pam.d/system-auth /etc/pam.d/system-auth_`date +%F`\ncat >/etc/pam.d/system-auth<<EOF\n#%PAM-1.0\n# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth required pam_tally.so onerr=fail deny=6 unlock_time=1800\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid >= 500 quiet\nauth        required      pam_deny.so\nauth    sufficient    /lib/security/pam_unix.so likeauth nullok\n\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid < 500 quiet\naccount     required      pam_permit.so\n\npassword    requisite     pam_cracklib.so try_first_pass retry=3  minlen=8 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1\npassword    sufficient    pam_unix.so sha512 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\n\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.soetc/pam.d/system-auth\nEOF\ncat >/etc/pam.d/sshd<<EOF\n#%PAM-1.0\n#auth       required pam_google_authenticator.so nullok\nauth       required     pam_sepermit.so\nauth       substack     password-auth\nauth       include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-auth      optional     pam_reauthorize.so prepare\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    required     pam_namespace.so\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\nsession    include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-session   optional     pam_reauthorize.so prepare\nEOF\n```\n## 使用noatime文件系统挂载选项\n## 删除CentOS自带的sendmail，改用postfix\n## 增加SWAP分区大小（一般是内存的2倍）\n```\ndd if=/dev/zero of=/mnt/swapfile bs=4M count=1024\nmkswap /mnt/swapfile\nswapon /mnt/swapfile\necho \"/mnt/swapfile swap swap defaults 0 0\" >>/etc/fstab\nmount -a\nfree -m | grep -i swap\n```\n## 使用iptables关闭不需要对外开放的端口\n```\nsystemctl disable firewalld\nsystemctl stop firewalld\n\nyum -y install iptables-services\nsystemctl start iptables\nsystemctl start ip6tables\nsystemctl enable iptables\nsystemctl enable ip6tables\n\niptables -F\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -p tcp --dport 22123 -j ACCEPT\niptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p icmp -j ACCEPT\niptables -A INPUT -j DROP\nservice iptables save\n```\n## 启动系统审计服务\n```\nyum install audit*.* -y\ncat >>/etc/audit/audit.rules<<EOF\n-w /var/log/audit/ -k LOG_audit\n-w /etc/audit/ -p wa -k CFG_audit\n-w /etc/sysconfig/auditd -p wa -k CFG_auditd.conf\n-w /etc/libaudit.conf -p wa -k CFG_libaudit.conf\n-w /etc/audisp/ -p wa -k CFG_audisp\n-w /etc/cups/ -p wa -k CFG_cups\n-w /etc/init.d/cups -p wa -k CFG_initd_cups\n-w /etc/netlabel.rules -p wa -k CFG_netlabel.rules\n-w /etc/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /usr/share/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /etc/selinux/semanage.conf -p wa -k CFG_MAC_policy\n-w /usr/sbin/stunnel -p x\n-w /etc/security/rbac-self-test.conf -p wa -k CFG_RBAC_self_test\n-w /etc/aide.conf -p wa -k CFG_aide.conf\n-w /etc/cron.allow -p wa -k CFG_cron.allow\n-w /etc/cron.deny -p wa -k CFG_cron.deny\n-w /etc/cron.d/ -p wa -k CFG_cron.d\n-w /etc/cron.daily/ -p wa -k CFG_cron.daily\n-w /etc/cron.hourly/ -p wa -k CFG_cron.hourly\n-w /etc/cron.monthly/ -p wa -k CFG_cron.monthly\n-w /etc/cron.weekly/ -p wa -k CFG_cron.weekly\n-w /etc/crontab -p wa -k CFG_crontab\n-w /var/spool/cron/root -k CFG_crontab_root\n-w /etc/group -p wa -k CFG_group\n-w /etc/passwd -p wa -k CFG_passwd\n-w /etc/gshadow -k CFG_gshadow\n-w /etc/shadow -k CFG_shadow\n-w /etc/security/opasswd -k CFG_opasswd\n-w /etc/login.defs -p wa -k CFG_login.defs\n-w /etc/securetty -p wa -k CFG_securetty\n-w /var/log/faillog -p wa -k LOG_faillog\n-w /var/log/lastlog -p wa -k LOG_lastlog\n-w /var/log/tallylog -p wa -k LOG_tallylog\n-w /etc/hosts -p wa -k CFG_hosts\n-w /etc/sysconfig/network-scripts/ -p wa -k CFG_network\n-w /etc/inittab -p wa -k CFG_inittab\n-w /etc/rc.d/init.d/ -p wa -k CFG_initscripts\n-w /etc/ld.so.conf -p wa -k CFG_ld.so.conf\n-w /etc/localtime -p wa -k CFG_localtime\n-w /etc/sysctl.conf -p wa -k CFG_sysctl.conf\n-w /etc/modprobe.conf -p wa -k CFG_modprobe.conf\n-w /etc/pam.d/ -p wa -k CFG_pam\n-w /etc/security/limits.conf -p wa -k CFG_pam\n-w /etc/security/pam_env.conf -p wa -k CFG_pam\n-w /etc/security/namespace.conf -p wa -k CFG_pam\n-w /etc/security/namespace.init -p wa -k CFG_pam\n-w /etc/aliases -p wa -k CFG_aliases\n-w /etc/postfix/ -p wa -k CFG_postfix\n-w /etc/ssh/sshd_config -k CFG_sshd_config\n-w /etc/vsftpd.ftpusers -k CFG_vsftpd.ftpusers\n-a exit,always -F arch=b32 -S sethostname\n-w /etc/issue -p wa -k CFG_issue\n-w /etc/issue.net -p wa -k CFG_issue.net\nEOF\nsystemctl enable auditd\nservice auditd  restart\n```\n## 部署完整性检查工具软件\n```\nyum -y install aide\n\n#1）执行初始化，建立第一份样本库\naide -i\nmv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n\n#2）更新到样本库\naide -u\ncd /var/lib/aide/\nmv aide.db.new.gz aide.db.gz\n\n#3）定期执行入侵检测，并发送报告\n# crontab -e\n#45 17 * * * /usr/sbin/aide -C -V4 | /bin/mail -s ”AIDE REPORT $（date +%Y%m%d）” abcdefg#163.com\necho '45 23 * * * aide -C >> /var/log/aide/`date +%Y%m%d`_aide.log' >> /var/spool/cron/root\n\n#记录aide可执行文件的md5 checksum：\nmd5sum /usr/sbin/aide\n```\n## 关闭ctrl+alt+del重启机器\n```\nrm -f /usr/lib/systemd/system/ctrl-alt-del.targe && init q\n#恢复  ln -s /usr/lib/systemd/system/reboot.target /usr/lib/systemd/system/ctrl-alt-del.target\n```\n## 文件加锁及修改默认权限\n```\n#1、限制   at/cron给授权的用户:\nrm -f /etc/cron.deny /etc/at.deny\necho root >/etc/cron.allow\necho root >/etc/at.allow\nchown root:root /etc/cron.allow /etc/at.allow\nchmod 400 /etc/cron.allow /etc/at.allow\n\n#2、Crontab文件限制访问权限:\nchown root:root /etc/crontab\nchmod 400 /etc/crontab\nchown -R root:root /var/spool/cron\nchmod -R go-rwx /var/spool/cron\nchown -R root:root /etc/cron.*\nchmod -R go-rwx /etc/cron.*\n\n#3、加锁重要口令文件和组文件\nchattr +i /etc/passwd\nchattr +i /etc/shadow\nchattr +i /etc/group\nchattr +i /etc/gshadow\nchattr +i /etc/xinetd.conf\nchattr +i /etc/services\n```","slug":"linux-init7","published":1,"updated":"2021-02-20T09:40:19.614Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1x004fyc9704a52a6e","content":"<h2 id=\"关闭不必要的服务-如打印服务等\"><a href=\"#关闭不必要的服务-如打印服务等\" class=\"headerlink\" title=\"关闭不必要的服务(如打印服务等)\"></a>关闭不必要的服务(如打印服务等)</h2><pre><code>for owelinux in `chkconfig --list | grep &quot;3:on&quot; | awk &#39;&#123;print $1&#125;&#39;`; do chkconfig $owelinux off; done\nfor owelinux in crond network sshd rsyslog sysstat iptables; do chkconfig $owelinux on; done\n</code></pre>\n<h2 id=\"关闭不需要的tty\"><a href=\"#关闭不需要的tty\" class=\"headerlink\" title=\"关闭不需要的tty\"></a>关闭不需要的tty</h2><pre><code>\\cp /etc/securetty  /etc/securetty.bak\n&gt;/etc/securetty\necho &quot;tty1&quot; &gt;&gt;/etc/securetty\necho &quot;tty2&quot; &gt;&gt;/etc/securetty\necho &quot;tty3&quot; &gt;&gt;/etc/securetty\n</code></pre>\n<h2 id=\"调整linux-文件描述符大小\"><a href=\"#调整linux-文件描述符大小\" class=\"headerlink\" title=\"调整linux 文件描述符大小\"></a>调整linux 文件描述符大小</h2><pre><code>\\cp /etc/security/limits.conf /etc/security/limits.conf.$(date +%F)\nulimit -HSn 65535\necho -ne &quot;\n* soft nofile 65535\n* hard nofile 65535\n&quot; &gt;&gt;/etc/security/limits.conf\necho &quot;ulimit -c unlimited&quot; &gt;&gt; /etc/profile\nsource /etc/profile\n</code></pre>\n<h2 id=\"修改shell命令的history-记录个数和连接超时时间\"><a href=\"#修改shell命令的history-记录个数和连接超时时间\" class=\"headerlink\" title=\"修改shell命令的history 记录个数和连接超时时间\"></a>修改shell命令的history 记录个数和连接超时时间</h2><pre><code>echo &quot;export HISTCONTROL=ignorespace&quot; &gt;&gt;/etc/profile\necho &quot;export HISTCONTROL=erasedups&quot; &gt;&gt;/etc/profile\necho &quot;HISTSIZE=500&quot; &gt;&gt; /etc/profile\n\n#修改帐户TMOUT值，设置自动注销时间\necho &quot;export TMOUT=300&quot; &gt;&gt;/etc/profile\necho &quot;set autologout=300&quot; &gt;&gt;/etc/csh.cshrc\nsource /etc/profile\n</code></pre>\n<h2 id=\"清空系统版本信息加入登录警告\"><a href=\"#清空系统版本信息加入登录警告\" class=\"headerlink\" title=\"清空系统版本信息加入登录警告\"></a>清空系统版本信息加入登录警告</h2><pre><code>&gt;/etc/motd\n&gt;/etc/issue\n&gt;/etc/redhat-release\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt;/etc/motd\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt; /etc/issue\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt; /etc/issue.net\nchown root:root /etc/motd /etc/issue  /etc/issue.net\nchmod 644 /etc/motd /etc/issue  /etc/issue.net\n</code></pre>\n<h2 id=\"优化内核TCP参数\"><a href=\"#优化内核TCP参数\" class=\"headerlink\" title=\"优化内核TCP参数\"></a>优化内核TCP参数</h2><pre><code>cat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF\nnet.ipv4.tcp_fin_timeout = 1\nnet.ipv4.tcp_keepalive_time = 1200\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 1\nnet.ipv4.tcp_syn_retries = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\nnet.core.netdev_max_backlog = 262144\nnet.ipv4.tcp_max_orphans = 3276800\nnet.ipv4.tcp_max_syn_backlog = 262144\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nEOF\n/sbin/sysctl -p\n</code></pre>\n<h2 id=\"登录机器发邮件告警\"><a href=\"#登录机器发邮件告警\" class=\"headerlink\" title=\"登录机器发邮件告警\"></a>登录机器发邮件告警</h2><pre><code>yum -y install mailx\ncat &gt;&gt;/root/.bashrc &lt;&lt; EOF\necho &#39;ALERT - Root Shell Access (Server Name) on:&#39; \\`date\\`\\`who\\`\\`hostname\\` | mail -s &quot;Alert:Root Access from \\`who | cut -d &quot;(&quot; -f2 | cut -d &quot;)&quot; #-f1\\`&quot; blue.yunwei@bluepay.asia\nEOF\n</code></pre>\n<h2 id=\"定时校正服务器时间\"><a href=\"#定时校正服务器时间\" class=\"headerlink\" title=\"定时校正服务器时间\"></a>定时校正服务器时间</h2><pre><code>echo &#39;0 * * * * /usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w &gt; /dev/null 2&gt;&amp;1&#39; &gt;&gt; /var/spool/cron/root\n/usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w\nsystemctl  restart crond\n</code></pre>\n<h2 id=\"停止ipv6\"><a href=\"#停止ipv6\" class=\"headerlink\" title=\"停止ipv6\"></a>停止ipv6</h2><pre><code>echo 1 &gt; /proc/sys/net/ipv6/conf/all/disable_ipv6\n</code></pre>\n<h2 id=\"修改yum源\"><a href=\"#修改yum源\" class=\"headerlink\" title=\"修改yum源\"></a>修改yum源</h2><pre><code>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\nyum -y reinstall epel-release\nyum clean all\nyum makecache\n</code></pre>\n<h2 id=\"关闭Selinux\"><a href=\"#关闭Selinux\" class=\"headerlink\" title=\"关闭Selinux\"></a>关闭Selinux</h2><pre><code>setenforce 0\nsed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/&#39; /etc/selinux/config\n</code></pre>\n<h2 id=\"安装必要的服务，更新系统软件\"><a href=\"#安装必要的服务，更新系统软件\" class=\"headerlink\" title=\"安装必要的服务，更新系统软件\"></a>安装必要的服务，更新系统软件</h2><pre><code>yum -y groupinstall &quot;Development tools&quot;\nyum -y install ntpdate sysstat lrzsz wget nmap tree curl  epel-release lsof nano bash-completion net-tools lsof vim-enhanced\n</code></pre>\n<h2 id=\"ssh优化，加快连接速度\"><a href=\"#ssh优化，加快连接速度\" class=\"headerlink\" title=\"ssh优化，加快连接速度\"></a>ssh优化，加快连接速度</h2><pre><code>#1、配置空闲登出的超时间隔:\n#2、禁用   .rhosts 文件\n#3、禁用基于主机的认证\n#4、禁止   root 帐号通过 SSH   登录\n#5、用警告的   Banner\n#6、iptables防火墙处理 SSH 端口22123\n#7、修改 SSH   端口和限制 IP 绑定：\n#8、禁用空密码：\n#9、记录日志：\n\nmv /etc/ssh/ /etc/sshbak\nmkdir -p /application/tools\ncd /application/tools\nyum -y install wget C gcc cc\nwget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-7.6p1.tar.gz\ntar -zxf openssh-7.6p1.tar.gz\ncd openssh-7.6p1\nyum install -y zlib-devel openssl-devel pam pam-devel\n./configure --prefix=/usr --sysconfdir=/etc/ssh --without-zlib-version-check  --with-pam\nchmod 600 /etc/ssh/*_key\nmake -j4\nrpm -e --nodeps `rpm -qa | grep openssh`\nmake install\nssh -V\ncp contrib/redhat/sshd.init /etc/init.d/sshd\nchkconfig --add sshd\n\nmv /etc/ssh/sshd_config /etc/ssh/sshd_config_`date +%F`\ncat &gt;/etc/ssh/sshd_config&lt;&lt;EOF\nPort 22123\nPidFile /var/run/sshd.pid\nSyslogFacility AUTH\nLogLevel INFO\nLoginGraceTime 30\nPermitRootLogin no\nStrictModes yes\nMaxAuthTries 3\nMaxSessions 15\n#AllowUsers root lovelinux\nPubkeyAuthentication yes\nAuthorizedKeysFile  .ssh/authorized_keys\nPasswordAuthentication yes\nPermitEmptyPasswords no\nChallengeResponseAuthentication yes\nGSSAPIAuthentication no\nGSSAPICleanupCredentials yes\nUsePAM no\nClientAliveInterval 0\nClientAliveCountMax 3\nUseDNS no\nSubsystem   sftp    /usr/lib/ssh/sftp-server\nCiphers aes128-ctr,aes192-ctr,aes256-ctr\nMacs    hmac-sha2-256,hmac-sha2-512\nEOF\n\necho &quot;#save sshd messages also to sshd.log&quot; &gt;&gt;/etc/rsyslog.conf\necho &quot;local5.* /var/log/sshd.log&quot; &gt;&gt;/etc/rsyslog.conf\nsystemctl restart rsyslog\nsystemctl stop sshd &amp;&amp; systemctl start sshd\nsystemctl reload sshd\n</code></pre>\n<h2 id=\"删除系统不需要的用户和用户组\"><a href=\"#删除系统不需要的用户和用户组\" class=\"headerlink\" title=\"删除系统不需要的用户和用户组\"></a>删除系统不需要的用户和用户组</h2><pre><code>   for i in adm lp sync shutdown halt news uucp operator games gopher\n   do\n      userdel $i  2&gt;/dev/null\n   done &amp;&amp; action &quot;delete user: &quot; /bin/true || action &quot;delete user: &quot; /bin/false\n\n   for i in adm  news uucp games dip pppusers popusers slipusers\n   do\n      groupdel $i  2&gt;/dev/null\n   done\n</code></pre>\n<h2 id=\"修改密码认证的复杂度，和过期时间\"><a href=\"#修改密码认证的复杂度，和过期时间\" class=\"headerlink\" title=\"修改密码认证的复杂度，和过期时间\"></a>修改密码认证的复杂度，和过期时间</h2><pre><code>mv /etc/pam.d/system-auth /etc/pam.d/system-auth_`date +%F`\ncat &gt;/etc/pam.d/system-auth&lt;&lt;EOF\n#%PAM-1.0\n# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth required pam_tally.so onerr=fail deny=6 unlock_time=1800\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid &gt;= 500 quiet\nauth        required      pam_deny.so\nauth    sufficient    /lib/security/pam_unix.so likeauth nullok\n\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid &lt; 500 quiet\naccount     required      pam_permit.so\n\npassword    requisite     pam_cracklib.so try_first_pass retry=3  minlen=8 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1\npassword    sufficient    pam_unix.so sha512 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\n\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.soetc/pam.d/system-auth\nEOF\ncat &gt;/etc/pam.d/sshd&lt;&lt;EOF\n#%PAM-1.0\n#auth       required pam_google_authenticator.so nullok\nauth       required     pam_sepermit.so\nauth       substack     password-auth\nauth       include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-auth      optional     pam_reauthorize.so prepare\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    required     pam_namespace.so\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\nsession    include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-session   optional     pam_reauthorize.so prepare\nEOF\n</code></pre>\n<h2 id=\"使用noatime文件系统挂载选项\"><a href=\"#使用noatime文件系统挂载选项\" class=\"headerlink\" title=\"使用noatime文件系统挂载选项\"></a>使用noatime文件系统挂载选项</h2><h2 id=\"删除CentOS自带的sendmail，改用postfix\"><a href=\"#删除CentOS自带的sendmail，改用postfix\" class=\"headerlink\" title=\"删除CentOS自带的sendmail，改用postfix\"></a>删除CentOS自带的sendmail，改用postfix</h2><h2 id=\"增加SWAP分区大小（一般是内存的2倍）\"><a href=\"#增加SWAP分区大小（一般是内存的2倍）\" class=\"headerlink\" title=\"增加SWAP分区大小（一般是内存的2倍）\"></a>增加SWAP分区大小（一般是内存的2倍）</h2><pre><code>dd if=/dev/zero of=/mnt/swapfile bs=4M count=1024\nmkswap /mnt/swapfile\nswapon /mnt/swapfile\necho &quot;/mnt/swapfile swap swap defaults 0 0&quot; &gt;&gt;/etc/fstab\nmount -a\nfree -m | grep -i swap\n</code></pre>\n<h2 id=\"使用iptables关闭不需要对外开放的端口\"><a href=\"#使用iptables关闭不需要对外开放的端口\" class=\"headerlink\" title=\"使用iptables关闭不需要对外开放的端口\"></a>使用iptables关闭不需要对外开放的端口</h2><pre><code>systemctl disable firewalld\nsystemctl stop firewalld\n\nyum -y install iptables-services\nsystemctl start iptables\nsystemctl start ip6tables\nsystemctl enable iptables\nsystemctl enable ip6tables\n\niptables -F\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -p tcp --dport 22123 -j ACCEPT\niptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p icmp -j ACCEPT\niptables -A INPUT -j DROP\nservice iptables save\n</code></pre>\n<h2 id=\"启动系统审计服务\"><a href=\"#启动系统审计服务\" class=\"headerlink\" title=\"启动系统审计服务\"></a>启动系统审计服务</h2><pre><code>yum install audit*.* -y\ncat &gt;&gt;/etc/audit/audit.rules&lt;&lt;EOF\n-w /var/log/audit/ -k LOG_audit\n-w /etc/audit/ -p wa -k CFG_audit\n-w /etc/sysconfig/auditd -p wa -k CFG_auditd.conf\n-w /etc/libaudit.conf -p wa -k CFG_libaudit.conf\n-w /etc/audisp/ -p wa -k CFG_audisp\n-w /etc/cups/ -p wa -k CFG_cups\n-w /etc/init.d/cups -p wa -k CFG_initd_cups\n-w /etc/netlabel.rules -p wa -k CFG_netlabel.rules\n-w /etc/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /usr/share/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /etc/selinux/semanage.conf -p wa -k CFG_MAC_policy\n-w /usr/sbin/stunnel -p x\n-w /etc/security/rbac-self-test.conf -p wa -k CFG_RBAC_self_test\n-w /etc/aide.conf -p wa -k CFG_aide.conf\n-w /etc/cron.allow -p wa -k CFG_cron.allow\n-w /etc/cron.deny -p wa -k CFG_cron.deny\n-w /etc/cron.d/ -p wa -k CFG_cron.d\n-w /etc/cron.daily/ -p wa -k CFG_cron.daily\n-w /etc/cron.hourly/ -p wa -k CFG_cron.hourly\n-w /etc/cron.monthly/ -p wa -k CFG_cron.monthly\n-w /etc/cron.weekly/ -p wa -k CFG_cron.weekly\n-w /etc/crontab -p wa -k CFG_crontab\n-w /var/spool/cron/root -k CFG_crontab_root\n-w /etc/group -p wa -k CFG_group\n-w /etc/passwd -p wa -k CFG_passwd\n-w /etc/gshadow -k CFG_gshadow\n-w /etc/shadow -k CFG_shadow\n-w /etc/security/opasswd -k CFG_opasswd\n-w /etc/login.defs -p wa -k CFG_login.defs\n-w /etc/securetty -p wa -k CFG_securetty\n-w /var/log/faillog -p wa -k LOG_faillog\n-w /var/log/lastlog -p wa -k LOG_lastlog\n-w /var/log/tallylog -p wa -k LOG_tallylog\n-w /etc/hosts -p wa -k CFG_hosts\n-w /etc/sysconfig/network-scripts/ -p wa -k CFG_network\n-w /etc/inittab -p wa -k CFG_inittab\n-w /etc/rc.d/init.d/ -p wa -k CFG_initscripts\n-w /etc/ld.so.conf -p wa -k CFG_ld.so.conf\n-w /etc/localtime -p wa -k CFG_localtime\n-w /etc/sysctl.conf -p wa -k CFG_sysctl.conf\n-w /etc/modprobe.conf -p wa -k CFG_modprobe.conf\n-w /etc/pam.d/ -p wa -k CFG_pam\n-w /etc/security/limits.conf -p wa -k CFG_pam\n-w /etc/security/pam_env.conf -p wa -k CFG_pam\n-w /etc/security/namespace.conf -p wa -k CFG_pam\n-w /etc/security/namespace.init -p wa -k CFG_pam\n-w /etc/aliases -p wa -k CFG_aliases\n-w /etc/postfix/ -p wa -k CFG_postfix\n-w /etc/ssh/sshd_config -k CFG_sshd_config\n-w /etc/vsftpd.ftpusers -k CFG_vsftpd.ftpusers\n-a exit,always -F arch=b32 -S sethostname\n-w /etc/issue -p wa -k CFG_issue\n-w /etc/issue.net -p wa -k CFG_issue.net\nEOF\nsystemctl enable auditd\nservice auditd  restart\n</code></pre>\n<h2 id=\"部署完整性检查工具软件\"><a href=\"#部署完整性检查工具软件\" class=\"headerlink\" title=\"部署完整性检查工具软件\"></a>部署完整性检查工具软件</h2><pre><code>yum -y install aide\n\n#1）执行初始化，建立第一份样本库\naide -i\nmv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n\n#2）更新到样本库\naide -u\ncd /var/lib/aide/\nmv aide.db.new.gz aide.db.gz\n\n#3）定期执行入侵检测，并发送报告\n# crontab -e\n#45 17 * * * /usr/sbin/aide -C -V4 | /bin/mail -s ”AIDE REPORT $（date +%Y%m%d）” abcdefg#163.com\necho &#39;45 23 * * * aide -C &gt;&gt; /var/log/aide/`date +%Y%m%d`_aide.log&#39; &gt;&gt; /var/spool/cron/root\n\n#记录aide可执行文件的md5 checksum：\nmd5sum /usr/sbin/aide\n</code></pre>\n<h2 id=\"关闭ctrl-alt-del重启机器\"><a href=\"#关闭ctrl-alt-del重启机器\" class=\"headerlink\" title=\"关闭ctrl+alt+del重启机器\"></a>关闭ctrl+alt+del重启机器</h2><pre><code>rm -f /usr/lib/systemd/system/ctrl-alt-del.targe &amp;&amp; init q\n#恢复  ln -s /usr/lib/systemd/system/reboot.target /usr/lib/systemd/system/ctrl-alt-del.target\n</code></pre>\n<h2 id=\"文件加锁及修改默认权限\"><a href=\"#文件加锁及修改默认权限\" class=\"headerlink\" title=\"文件加锁及修改默认权限\"></a>文件加锁及修改默认权限</h2><pre><code>#1、限制   at/cron给授权的用户:\nrm -f /etc/cron.deny /etc/at.deny\necho root &gt;/etc/cron.allow\necho root &gt;/etc/at.allow\nchown root:root /etc/cron.allow /etc/at.allow\nchmod 400 /etc/cron.allow /etc/at.allow\n\n#2、Crontab文件限制访问权限:\nchown root:root /etc/crontab\nchmod 400 /etc/crontab\nchown -R root:root /var/spool/cron\nchmod -R go-rwx /var/spool/cron\nchown -R root:root /etc/cron.*\nchmod -R go-rwx /etc/cron.*\n\n#3、加锁重要口令文件和组文件\nchattr +i /etc/passwd\nchattr +i /etc/shadow\nchattr +i /etc/group\nchattr +i /etc/gshadow\nchattr +i /etc/xinetd.conf\nchattr +i /etc/services\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"关闭不必要的服务-如打印服务等\"><a href=\"#关闭不必要的服务-如打印服务等\" class=\"headerlink\" title=\"关闭不必要的服务(如打印服务等)\"></a>关闭不必要的服务(如打印服务等)</h2><pre><code>for owelinux in `chkconfig --list | grep &quot;3:on&quot; | awk &#39;&#123;print $1&#125;&#39;`; do chkconfig $owelinux off; done\nfor owelinux in crond network sshd rsyslog sysstat iptables; do chkconfig $owelinux on; done\n</code></pre>\n<h2 id=\"关闭不需要的tty\"><a href=\"#关闭不需要的tty\" class=\"headerlink\" title=\"关闭不需要的tty\"></a>关闭不需要的tty</h2><pre><code>\\cp /etc/securetty  /etc/securetty.bak\n&gt;/etc/securetty\necho &quot;tty1&quot; &gt;&gt;/etc/securetty\necho &quot;tty2&quot; &gt;&gt;/etc/securetty\necho &quot;tty3&quot; &gt;&gt;/etc/securetty\n</code></pre>\n<h2 id=\"调整linux-文件描述符大小\"><a href=\"#调整linux-文件描述符大小\" class=\"headerlink\" title=\"调整linux 文件描述符大小\"></a>调整linux 文件描述符大小</h2><pre><code>\\cp /etc/security/limits.conf /etc/security/limits.conf.$(date +%F)\nulimit -HSn 65535\necho -ne &quot;\n* soft nofile 65535\n* hard nofile 65535\n&quot; &gt;&gt;/etc/security/limits.conf\necho &quot;ulimit -c unlimited&quot; &gt;&gt; /etc/profile\nsource /etc/profile\n</code></pre>\n<h2 id=\"修改shell命令的history-记录个数和连接超时时间\"><a href=\"#修改shell命令的history-记录个数和连接超时时间\" class=\"headerlink\" title=\"修改shell命令的history 记录个数和连接超时时间\"></a>修改shell命令的history 记录个数和连接超时时间</h2><pre><code>echo &quot;export HISTCONTROL=ignorespace&quot; &gt;&gt;/etc/profile\necho &quot;export HISTCONTROL=erasedups&quot; &gt;&gt;/etc/profile\necho &quot;HISTSIZE=500&quot; &gt;&gt; /etc/profile\n\n#修改帐户TMOUT值，设置自动注销时间\necho &quot;export TMOUT=300&quot; &gt;&gt;/etc/profile\necho &quot;set autologout=300&quot; &gt;&gt;/etc/csh.cshrc\nsource /etc/profile\n</code></pre>\n<h2 id=\"清空系统版本信息加入登录警告\"><a href=\"#清空系统版本信息加入登录警告\" class=\"headerlink\" title=\"清空系统版本信息加入登录警告\"></a>清空系统版本信息加入登录警告</h2><pre><code>&gt;/etc/motd\n&gt;/etc/issue\n&gt;/etc/redhat-release\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt;/etc/motd\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt; /etc/issue\necho &quot;Authorized uses only. All activity may be monitored   and reported.&quot; &gt;&gt; /etc/issue.net\nchown root:root /etc/motd /etc/issue  /etc/issue.net\nchmod 644 /etc/motd /etc/issue  /etc/issue.net\n</code></pre>\n<h2 id=\"优化内核TCP参数\"><a href=\"#优化内核TCP参数\" class=\"headerlink\" title=\"优化内核TCP参数\"></a>优化内核TCP参数</h2><pre><code>cat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF\nnet.ipv4.tcp_fin_timeout = 1\nnet.ipv4.tcp_keepalive_time = 1200\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 1\nnet.ipv4.tcp_syn_retries = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\nnet.core.netdev_max_backlog = 262144\nnet.ipv4.tcp_max_orphans = 3276800\nnet.ipv4.tcp_max_syn_backlog = 262144\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nEOF\n/sbin/sysctl -p\n</code></pre>\n<h2 id=\"登录机器发邮件告警\"><a href=\"#登录机器发邮件告警\" class=\"headerlink\" title=\"登录机器发邮件告警\"></a>登录机器发邮件告警</h2><pre><code>yum -y install mailx\ncat &gt;&gt;/root/.bashrc &lt;&lt; EOF\necho &#39;ALERT - Root Shell Access (Server Name) on:&#39; \\`date\\`\\`who\\`\\`hostname\\` | mail -s &quot;Alert:Root Access from \\`who | cut -d &quot;(&quot; -f2 | cut -d &quot;)&quot; #-f1\\`&quot; blue.yunwei@bluepay.asia\nEOF\n</code></pre>\n<h2 id=\"定时校正服务器时间\"><a href=\"#定时校正服务器时间\" class=\"headerlink\" title=\"定时校正服务器时间\"></a>定时校正服务器时间</h2><pre><code>echo &#39;0 * * * * /usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w &gt; /dev/null 2&gt;&amp;1&#39; &gt;&gt; /var/spool/cron/root\n/usr/sbin/ntpdate -u  0.cn.pool.ntp.org;/sbin/hwclock -w\nsystemctl  restart crond\n</code></pre>\n<h2 id=\"停止ipv6\"><a href=\"#停止ipv6\" class=\"headerlink\" title=\"停止ipv6\"></a>停止ipv6</h2><pre><code>echo 1 &gt; /proc/sys/net/ipv6/conf/all/disable_ipv6\n</code></pre>\n<h2 id=\"修改yum源\"><a href=\"#修改yum源\" class=\"headerlink\" title=\"修改yum源\"></a>修改yum源</h2><pre><code>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\nyum -y reinstall epel-release\nyum clean all\nyum makecache\n</code></pre>\n<h2 id=\"关闭Selinux\"><a href=\"#关闭Selinux\" class=\"headerlink\" title=\"关闭Selinux\"></a>关闭Selinux</h2><pre><code>setenforce 0\nsed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/&#39; /etc/selinux/config\n</code></pre>\n<h2 id=\"安装必要的服务，更新系统软件\"><a href=\"#安装必要的服务，更新系统软件\" class=\"headerlink\" title=\"安装必要的服务，更新系统软件\"></a>安装必要的服务，更新系统软件</h2><pre><code>yum -y groupinstall &quot;Development tools&quot;\nyum -y install ntpdate sysstat lrzsz wget nmap tree curl  epel-release lsof nano bash-completion net-tools lsof vim-enhanced\n</code></pre>\n<h2 id=\"ssh优化，加快连接速度\"><a href=\"#ssh优化，加快连接速度\" class=\"headerlink\" title=\"ssh优化，加快连接速度\"></a>ssh优化，加快连接速度</h2><pre><code>#1、配置空闲登出的超时间隔:\n#2、禁用   .rhosts 文件\n#3、禁用基于主机的认证\n#4、禁止   root 帐号通过 SSH   登录\n#5、用警告的   Banner\n#6、iptables防火墙处理 SSH 端口22123\n#7、修改 SSH   端口和限制 IP 绑定：\n#8、禁用空密码：\n#9、记录日志：\n\nmv /etc/ssh/ /etc/sshbak\nmkdir -p /application/tools\ncd /application/tools\nyum -y install wget C gcc cc\nwget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-7.6p1.tar.gz\ntar -zxf openssh-7.6p1.tar.gz\ncd openssh-7.6p1\nyum install -y zlib-devel openssl-devel pam pam-devel\n./configure --prefix=/usr --sysconfdir=/etc/ssh --without-zlib-version-check  --with-pam\nchmod 600 /etc/ssh/*_key\nmake -j4\nrpm -e --nodeps `rpm -qa | grep openssh`\nmake install\nssh -V\ncp contrib/redhat/sshd.init /etc/init.d/sshd\nchkconfig --add sshd\n\nmv /etc/ssh/sshd_config /etc/ssh/sshd_config_`date +%F`\ncat &gt;/etc/ssh/sshd_config&lt;&lt;EOF\nPort 22123\nPidFile /var/run/sshd.pid\nSyslogFacility AUTH\nLogLevel INFO\nLoginGraceTime 30\nPermitRootLogin no\nStrictModes yes\nMaxAuthTries 3\nMaxSessions 15\n#AllowUsers root lovelinux\nPubkeyAuthentication yes\nAuthorizedKeysFile  .ssh/authorized_keys\nPasswordAuthentication yes\nPermitEmptyPasswords no\nChallengeResponseAuthentication yes\nGSSAPIAuthentication no\nGSSAPICleanupCredentials yes\nUsePAM no\nClientAliveInterval 0\nClientAliveCountMax 3\nUseDNS no\nSubsystem   sftp    /usr/lib/ssh/sftp-server\nCiphers aes128-ctr,aes192-ctr,aes256-ctr\nMacs    hmac-sha2-256,hmac-sha2-512\nEOF\n\necho &quot;#save sshd messages also to sshd.log&quot; &gt;&gt;/etc/rsyslog.conf\necho &quot;local5.* /var/log/sshd.log&quot; &gt;&gt;/etc/rsyslog.conf\nsystemctl restart rsyslog\nsystemctl stop sshd &amp;&amp; systemctl start sshd\nsystemctl reload sshd\n</code></pre>\n<h2 id=\"删除系统不需要的用户和用户组\"><a href=\"#删除系统不需要的用户和用户组\" class=\"headerlink\" title=\"删除系统不需要的用户和用户组\"></a>删除系统不需要的用户和用户组</h2><pre><code>   for i in adm lp sync shutdown halt news uucp operator games gopher\n   do\n      userdel $i  2&gt;/dev/null\n   done &amp;&amp; action &quot;delete user: &quot; /bin/true || action &quot;delete user: &quot; /bin/false\n\n   for i in adm  news uucp games dip pppusers popusers slipusers\n   do\n      groupdel $i  2&gt;/dev/null\n   done\n</code></pre>\n<h2 id=\"修改密码认证的复杂度，和过期时间\"><a href=\"#修改密码认证的复杂度，和过期时间\" class=\"headerlink\" title=\"修改密码认证的复杂度，和过期时间\"></a>修改密码认证的复杂度，和过期时间</h2><pre><code>mv /etc/pam.d/system-auth /etc/pam.d/system-auth_`date +%F`\ncat &gt;/etc/pam.d/system-auth&lt;&lt;EOF\n#%PAM-1.0\n# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth required pam_tally.so onerr=fail deny=6 unlock_time=1800\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid &gt;= 500 quiet\nauth        required      pam_deny.so\nauth    sufficient    /lib/security/pam_unix.so likeauth nullok\n\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid &lt; 500 quiet\naccount     required      pam_permit.so\n\npassword    requisite     pam_cracklib.so try_first_pass retry=3  minlen=8 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1\npassword    sufficient    pam_unix.so sha512 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\n\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.soetc/pam.d/system-auth\nEOF\ncat &gt;/etc/pam.d/sshd&lt;&lt;EOF\n#%PAM-1.0\n#auth       required pam_google_authenticator.so nullok\nauth       required     pam_sepermit.so\nauth       substack     password-auth\nauth       include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-auth      optional     pam_reauthorize.so prepare\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    required     pam_namespace.so\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\nsession    include      postlogin\n# Used with polkit to reauthorize users in remote sessions\n-session   optional     pam_reauthorize.so prepare\nEOF\n</code></pre>\n<h2 id=\"使用noatime文件系统挂载选项\"><a href=\"#使用noatime文件系统挂载选项\" class=\"headerlink\" title=\"使用noatime文件系统挂载选项\"></a>使用noatime文件系统挂载选项</h2><h2 id=\"删除CentOS自带的sendmail，改用postfix\"><a href=\"#删除CentOS自带的sendmail，改用postfix\" class=\"headerlink\" title=\"删除CentOS自带的sendmail，改用postfix\"></a>删除CentOS自带的sendmail，改用postfix</h2><h2 id=\"增加SWAP分区大小（一般是内存的2倍）\"><a href=\"#增加SWAP分区大小（一般是内存的2倍）\" class=\"headerlink\" title=\"增加SWAP分区大小（一般是内存的2倍）\"></a>增加SWAP分区大小（一般是内存的2倍）</h2><pre><code>dd if=/dev/zero of=/mnt/swapfile bs=4M count=1024\nmkswap /mnt/swapfile\nswapon /mnt/swapfile\necho &quot;/mnt/swapfile swap swap defaults 0 0&quot; &gt;&gt;/etc/fstab\nmount -a\nfree -m | grep -i swap\n</code></pre>\n<h2 id=\"使用iptables关闭不需要对外开放的端口\"><a href=\"#使用iptables关闭不需要对外开放的端口\" class=\"headerlink\" title=\"使用iptables关闭不需要对外开放的端口\"></a>使用iptables关闭不需要对外开放的端口</h2><pre><code>systemctl disable firewalld\nsystemctl stop firewalld\n\nyum -y install iptables-services\nsystemctl start iptables\nsystemctl start ip6tables\nsystemctl enable iptables\nsystemctl enable ip6tables\n\niptables -F\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -p tcp --dport 22123 -j ACCEPT\niptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p icmp -j ACCEPT\niptables -A INPUT -j DROP\nservice iptables save\n</code></pre>\n<h2 id=\"启动系统审计服务\"><a href=\"#启动系统审计服务\" class=\"headerlink\" title=\"启动系统审计服务\"></a>启动系统审计服务</h2><pre><code>yum install audit*.* -y\ncat &gt;&gt;/etc/audit/audit.rules&lt;&lt;EOF\n-w /var/log/audit/ -k LOG_audit\n-w /etc/audit/ -p wa -k CFG_audit\n-w /etc/sysconfig/auditd -p wa -k CFG_auditd.conf\n-w /etc/libaudit.conf -p wa -k CFG_libaudit.conf\n-w /etc/audisp/ -p wa -k CFG_audisp\n-w /etc/cups/ -p wa -k CFG_cups\n-w /etc/init.d/cups -p wa -k CFG_initd_cups\n-w /etc/netlabel.rules -p wa -k CFG_netlabel.rules\n-w /etc/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /usr/share/selinux/mls/ -p wa -k CFG_MAC_policy\n-w /etc/selinux/semanage.conf -p wa -k CFG_MAC_policy\n-w /usr/sbin/stunnel -p x\n-w /etc/security/rbac-self-test.conf -p wa -k CFG_RBAC_self_test\n-w /etc/aide.conf -p wa -k CFG_aide.conf\n-w /etc/cron.allow -p wa -k CFG_cron.allow\n-w /etc/cron.deny -p wa -k CFG_cron.deny\n-w /etc/cron.d/ -p wa -k CFG_cron.d\n-w /etc/cron.daily/ -p wa -k CFG_cron.daily\n-w /etc/cron.hourly/ -p wa -k CFG_cron.hourly\n-w /etc/cron.monthly/ -p wa -k CFG_cron.monthly\n-w /etc/cron.weekly/ -p wa -k CFG_cron.weekly\n-w /etc/crontab -p wa -k CFG_crontab\n-w /var/spool/cron/root -k CFG_crontab_root\n-w /etc/group -p wa -k CFG_group\n-w /etc/passwd -p wa -k CFG_passwd\n-w /etc/gshadow -k CFG_gshadow\n-w /etc/shadow -k CFG_shadow\n-w /etc/security/opasswd -k CFG_opasswd\n-w /etc/login.defs -p wa -k CFG_login.defs\n-w /etc/securetty -p wa -k CFG_securetty\n-w /var/log/faillog -p wa -k LOG_faillog\n-w /var/log/lastlog -p wa -k LOG_lastlog\n-w /var/log/tallylog -p wa -k LOG_tallylog\n-w /etc/hosts -p wa -k CFG_hosts\n-w /etc/sysconfig/network-scripts/ -p wa -k CFG_network\n-w /etc/inittab -p wa -k CFG_inittab\n-w /etc/rc.d/init.d/ -p wa -k CFG_initscripts\n-w /etc/ld.so.conf -p wa -k CFG_ld.so.conf\n-w /etc/localtime -p wa -k CFG_localtime\n-w /etc/sysctl.conf -p wa -k CFG_sysctl.conf\n-w /etc/modprobe.conf -p wa -k CFG_modprobe.conf\n-w /etc/pam.d/ -p wa -k CFG_pam\n-w /etc/security/limits.conf -p wa -k CFG_pam\n-w /etc/security/pam_env.conf -p wa -k CFG_pam\n-w /etc/security/namespace.conf -p wa -k CFG_pam\n-w /etc/security/namespace.init -p wa -k CFG_pam\n-w /etc/aliases -p wa -k CFG_aliases\n-w /etc/postfix/ -p wa -k CFG_postfix\n-w /etc/ssh/sshd_config -k CFG_sshd_config\n-w /etc/vsftpd.ftpusers -k CFG_vsftpd.ftpusers\n-a exit,always -F arch=b32 -S sethostname\n-w /etc/issue -p wa -k CFG_issue\n-w /etc/issue.net -p wa -k CFG_issue.net\nEOF\nsystemctl enable auditd\nservice auditd  restart\n</code></pre>\n<h2 id=\"部署完整性检查工具软件\"><a href=\"#部署完整性检查工具软件\" class=\"headerlink\" title=\"部署完整性检查工具软件\"></a>部署完整性检查工具软件</h2><pre><code>yum -y install aide\n\n#1）执行初始化，建立第一份样本库\naide -i\nmv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n\n#2）更新到样本库\naide -u\ncd /var/lib/aide/\nmv aide.db.new.gz aide.db.gz\n\n#3）定期执行入侵检测，并发送报告\n# crontab -e\n#45 17 * * * /usr/sbin/aide -C -V4 | /bin/mail -s ”AIDE REPORT $（date +%Y%m%d）” abcdefg#163.com\necho &#39;45 23 * * * aide -C &gt;&gt; /var/log/aide/`date +%Y%m%d`_aide.log&#39; &gt;&gt; /var/spool/cron/root\n\n#记录aide可执行文件的md5 checksum：\nmd5sum /usr/sbin/aide\n</code></pre>\n<h2 id=\"关闭ctrl-alt-del重启机器\"><a href=\"#关闭ctrl-alt-del重启机器\" class=\"headerlink\" title=\"关闭ctrl+alt+del重启机器\"></a>关闭ctrl+alt+del重启机器</h2><pre><code>rm -f /usr/lib/systemd/system/ctrl-alt-del.targe &amp;&amp; init q\n#恢复  ln -s /usr/lib/systemd/system/reboot.target /usr/lib/systemd/system/ctrl-alt-del.target\n</code></pre>\n<h2 id=\"文件加锁及修改默认权限\"><a href=\"#文件加锁及修改默认权限\" class=\"headerlink\" title=\"文件加锁及修改默认权限\"></a>文件加锁及修改默认权限</h2><pre><code>#1、限制   at/cron给授权的用户:\nrm -f /etc/cron.deny /etc/at.deny\necho root &gt;/etc/cron.allow\necho root &gt;/etc/at.allow\nchown root:root /etc/cron.allow /etc/at.allow\nchmod 400 /etc/cron.allow /etc/at.allow\n\n#2、Crontab文件限制访问权限:\nchown root:root /etc/crontab\nchmod 400 /etc/crontab\nchown -R root:root /var/spool/cron\nchmod -R go-rwx /var/spool/cron\nchown -R root:root /etc/cron.*\nchmod -R go-rwx /etc/cron.*\n\n#3、加锁重要口令文件和组文件\nchattr +i /etc/passwd\nchattr +i /etc/shadow\nchattr +i /etc/group\nchattr +i /etc/gshadow\nchattr +i /etc/xinetd.conf\nchattr +i /etc/services\n</code></pre>\n"},{"title":"做运维需要注意什么？","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-17T02:14:54.000Z","password":null,"summary":null,"_content":"\n运维应该怎么分阶段学习？\n\n- 机器名不要设置为localhost。\n- 只读共享，不需要（ro，sync），只需（ro）即可。\n- 要学会规范，按照要求部署，哪怕一个字符都不要错。\n- 敲路径时候尽量复制粘贴。少自己敲字符。防止简单的字符错误。\n- 记得开机自动挂载放到/etc/rc.loacl（带注释）。不要放在fstab里（NFS不能放，本地系统可以放）。\n- 切换root方法，sudo su -\n- 每隔步骤操作后都要及时检查，确保每一步正确，起码不犯超级菜的错误。\n- NFS服务端共享目录可写时，不要给777权限，修改用户或属组nfsnobody。可读时权限属组都不需要动，就默认root即可。\n- 增加SecureCRT标签时，不需要新建标签。直接复制标签然后去改（配置现成的）。\n- 提前关闭iptables和防火墙，克隆虚拟机之前就优化好。\n- 确保所有服务器uid为65534的用户为nfsnobody或者所有服务器都有具备uid为65534这样的用户。\n- 模拟错误：模拟重现故障的能力是运维人员最重要的能力。","source":"_posts/linux-Precautions.md","raw":"---\ntitle: 做运维需要注意什么？\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2018-07-17 10:14:54\npassword:\nsummary:\ntags:\n- 学习方法\ncategories:\n- linux\n---\n\n运维应该怎么分阶段学习？\n\n- 机器名不要设置为localhost。\n- 只读共享，不需要（ro，sync），只需（ro）即可。\n- 要学会规范，按照要求部署，哪怕一个字符都不要错。\n- 敲路径时候尽量复制粘贴。少自己敲字符。防止简单的字符错误。\n- 记得开机自动挂载放到/etc/rc.loacl（带注释）。不要放在fstab里（NFS不能放，本地系统可以放）。\n- 切换root方法，sudo su -\n- 每隔步骤操作后都要及时检查，确保每一步正确，起码不犯超级菜的错误。\n- NFS服务端共享目录可写时，不要给777权限，修改用户或属组nfsnobody。可读时权限属组都不需要动，就默认root即可。\n- 增加SecureCRT标签时，不需要新建标签。直接复制标签然后去改（配置现成的）。\n- 提前关闭iptables和防火墙，克隆虚拟机之前就优化好。\n- 确保所有服务器uid为65534的用户为nfsnobody或者所有服务器都有具备uid为65534这样的用户。\n- 模拟错误：模拟重现故障的能力是运维人员最重要的能力。","slug":"linux-Precautions","published":1,"updated":"2021-02-20T09:38:11.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1x004hyc97hykh95re","content":"<p>运维应该怎么分阶段学习？</p>\n<ul>\n<li>机器名不要设置为localhost。</li>\n<li>只读共享，不需要（ro，sync），只需（ro）即可。</li>\n<li>要学会规范，按照要求部署，哪怕一个字符都不要错。</li>\n<li>敲路径时候尽量复制粘贴。少自己敲字符。防止简单的字符错误。</li>\n<li>记得开机自动挂载放到/etc/rc.loacl（带注释）。不要放在fstab里（NFS不能放，本地系统可以放）。</li>\n<li>切换root方法，sudo su -</li>\n<li>每隔步骤操作后都要及时检查，确保每一步正确，起码不犯超级菜的错误。</li>\n<li>NFS服务端共享目录可写时，不要给777权限，修改用户或属组nfsnobody。可读时权限属组都不需要动，就默认root即可。</li>\n<li>增加SecureCRT标签时，不需要新建标签。直接复制标签然后去改（配置现成的）。</li>\n<li>提前关闭iptables和防火墙，克隆虚拟机之前就优化好。</li>\n<li>确保所有服务器uid为65534的用户为nfsnobody或者所有服务器都有具备uid为65534这样的用户。</li>\n<li>模拟错误：模拟重现故障的能力是运维人员最重要的能力。</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>运维应该怎么分阶段学习？</p>\n<ul>\n<li>机器名不要设置为localhost。</li>\n<li>只读共享，不需要（ro，sync），只需（ro）即可。</li>\n<li>要学会规范，按照要求部署，哪怕一个字符都不要错。</li>\n<li>敲路径时候尽量复制粘贴。少自己敲字符。防止简单的字符错误。</li>\n<li>记得开机自动挂载放到/etc/rc.loacl（带注释）。不要放在fstab里（NFS不能放，本地系统可以放）。</li>\n<li>切换root方法，sudo su -</li>\n<li>每隔步骤操作后都要及时检查，确保每一步正确，起码不犯超级菜的错误。</li>\n<li>NFS服务端共享目录可写时，不要给777权限，修改用户或属组nfsnobody。可读时权限属组都不需要动，就默认root即可。</li>\n<li>增加SecureCRT标签时，不需要新建标签。直接复制标签然后去改（配置现成的）。</li>\n<li>提前关闭iptables和防火墙，克隆虚拟机之前就优化好。</li>\n<li>确保所有服务器uid为65534的用户为nfsnobody或者所有服务器都有具备uid为65534这样的用户。</li>\n<li>模拟错误：模拟重现故障的能力是运维人员最重要的能力。</li>\n</ul>\n"},{"_content":"\n# 精简 Docker 镜像的技巧\n\n精简 Docker 镜像的好处很多，不仅可以节省存储空间和带宽，还能减少安全隐患。优化镜像大小的手段多种多样，因服务所使用的基础开发语言不同而有差异。本文将介绍精简 Docker 镜像的几种通用方法。\n\n## 精简 Docker 镜像大小的必要性\nDocker 镜像由很多镜像层（Layers）组成（最多 127 层），镜像层依赖于一系列的底层技术，比如文件系统（filesystems）、写时复制（copy-on-write）、联合挂载（union mounts）等技术，你可以查看Docker 社区文档以了解更多有关 Docker 存储驱动的内容，这里就不再赘述技术细节。总的来说，Dockerfile 中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。\n\n下面是精简 Docker 镜像尺寸的好处：\n\n    1.减少构建时间\n    2.减少磁盘使用量\n    3.减少下载时间\n    4.因为包含文件少，攻击面减小，提高了安全性\n    5.提高部署速度\n## 编写小容量镜像的Dockerfile的技巧\n\n### 使用较小的基础镜像\n优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中 Alpine 更推荐使用。大小对比如下：alpine < ubuntu < debian < centos\n\n另外可以选择适合更小的基础镜像\n    \n1、scratch 镜像（空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang 程序，可以直接使用 scratch 作为基础镜像。）\n```\nFROME scratch\nARG ARCH\nADD bin/pause-${ARCH} /pause\nENTRYPOINT [\"/pause\"]\n```\n\n2、busybox 镜像（镜像里可以包含一些常用的 Linux 工具，busybox 镜像是个不错选择，镜像本身只有 1.16M，非常便于构建小镜像）\n\n### 将多个命令集放在一行\n大家在定义 Dockerfile 时，如果太多的使用 RUN 指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 Dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&&和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。。以Nginx的官方的Dockerfile为例：\n```\nFROM debian:jessie\nMAINTAINER NGINX Docker Maintainers \"docker-maint@nginx.com\"\nENV NGINX_VERSION 1.11.3-1~jessie\nRUN apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 \\\n\t&& echo \"deb http://nginx.org/packages/mainline/debian/ jessie nginx\" >> /etc/apt/sources.list \\\n\t&& apt-get update \\\n\t&& apt-get install --no-install-recommends --no-install-suggests -y \\\n\t\t\t\t\t\tca-certificates \\\n\t\t\t\t\t\tnginx=${NGINX_VERSION} \\\n\t\t\t\t\t\tnginx-module-xslt \\\n\t\t\t\t\t\tnginx-module-geoip \\\n\t\t\t\t\t\tnginx-module-image-filter \\\n\t\t\t\t\t\tnginx-module-perl \\\n\t\t\t\t\t\tnginx-module-njs \\\n\t\t\t\t\t\tgettext-base \\\n\t&& rm -rf /var/lib/apt/lists/*\n# forward request and error logs to docker log collector\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n\t&& ln -sf /dev/stderr /var/log/nginx/error.log\nEXPOSE 80 443\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### 使用多阶段构建\nDockerfile 中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个 Dockerfile 用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。Docker 17.05.0-ce 版本以后支持多阶段构建。使用多阶段构建，你可以在 Dockerfile 中使用多个 FROM 语句，每条 FROM 指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段 COPY 到另一个阶段，在最终镜像中只保留需要的内容。\n\n下面是一个使用 COPY --from 和 FROM … AS … 的 Dockerfile：\n```\n# Compile\nFROME golang:1.9.0 AS builder\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nCOPY . .\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nRUN make build && mv k8s-monitor /root\n\n# Package\n# Use scratch image\nFROM scratch\nWORKDIR /root/\nCOPY --from=builder /root .\nEXPOSE 800\nCMD [\"/root/k8s-monitor\"]\n```\n\n### 使用缓存加快构建速度\n\nDocker 在 build 镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点：\n\n* 不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开；\n\n* 因为 cache 缓存在运行 Docker build 命令的本地机器上，建议固定使用某台机器来进行 Docker build，以便利用 cache。\n\n```\nFROM openjdk:8-jre-alpine\nCOPY app/BOOT_INF/lib /app/BOOT_INF/lib/\nCOPY app/org /app/org\nCOPY app/META_INF /app/META_INF\nCOPY app/BOOT_INT/classes   /app/BOOT_INT/classes\nEXPOSE 8080\nCMD [\"java\",\"-cp\",\"/app\",\"org.springframework.boot.loader.JarLauncher\"]\n```\nDockerfile 我们把应用的内容分成 4 个部分 COPY 到镜像里面：其中前面 3 个基本不变，第 4 个是经常变化的自有代码。最后一行是解压缩后，启动 spring boot 应用的方式。\n\n### 清理缓存和不必要的文件\n\n（1）在执行 apt-get install -y 时增加选项 --no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行 apk add 时添加选项--no-cache 达到同样效果；\n\n（2）执行 yum install -y 时候， 可以同时安装多个工具，比如 yum install -y gcc gcc-c++ make …。将所有 yum install 任务放在一条 RUN 命令上执行，从而减少镜像层的数量；\n\n（3）组件的安装和清理要串联在一条指令里面，如 apk --update add php7 && rm -rf /var/cache/apk/* ，因为 Dockerfile的每条指令都会产生一个文件层，如果将 apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或 Debian可以使用 rm -rf /var/lib/apt/lists/* 清理镜像中缓存文件；CentOS 等系统使用 yum clean all 命令清理；alpine系统可使用apt-get purge -y package_name &&  apt-get autoremove && apt-get clean 来清除apt的缓存\n \n (4) 删除不必要的文档和日志：rm -rf /usr/share/doc/* /usr/share/man/* /usr/share/info/* 和删除log文件：find /var | grep '\\.log$' | xargs rm -v\n\n### 压缩镜像\nDocker 自带的一些命令还能协助压缩镜像，比如 export 和 import。\n可以使用如下命令：docker export image_name | docker import - new_image_name。\n\n## 参考文档\n[https://zhuanlan.zhihu.com/p/42815689](https://zhuanlan.zhihu.com/p/42815689)","source":"_posts/2019-01-04-article45-docker.md","raw":"\n# 精简 Docker 镜像的技巧\n\n精简 Docker 镜像的好处很多，不仅可以节省存储空间和带宽，还能减少安全隐患。优化镜像大小的手段多种多样，因服务所使用的基础开发语言不同而有差异。本文将介绍精简 Docker 镜像的几种通用方法。\n\n## 精简 Docker 镜像大小的必要性\nDocker 镜像由很多镜像层（Layers）组成（最多 127 层），镜像层依赖于一系列的底层技术，比如文件系统（filesystems）、写时复制（copy-on-write）、联合挂载（union mounts）等技术，你可以查看Docker 社区文档以了解更多有关 Docker 存储驱动的内容，这里就不再赘述技术细节。总的来说，Dockerfile 中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。\n\n下面是精简 Docker 镜像尺寸的好处：\n\n    1.减少构建时间\n    2.减少磁盘使用量\n    3.减少下载时间\n    4.因为包含文件少，攻击面减小，提高了安全性\n    5.提高部署速度\n## 编写小容量镜像的Dockerfile的技巧\n\n### 使用较小的基础镜像\n优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中 Alpine 更推荐使用。大小对比如下：alpine < ubuntu < debian < centos\n\n另外可以选择适合更小的基础镜像\n    \n1、scratch 镜像（空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang 程序，可以直接使用 scratch 作为基础镜像。）\n```\nFROME scratch\nARG ARCH\nADD bin/pause-${ARCH} /pause\nENTRYPOINT [\"/pause\"]\n```\n\n2、busybox 镜像（镜像里可以包含一些常用的 Linux 工具，busybox 镜像是个不错选择，镜像本身只有 1.16M，非常便于构建小镜像）\n\n### 将多个命令集放在一行\n大家在定义 Dockerfile 时，如果太多的使用 RUN 指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 Dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&&和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。。以Nginx的官方的Dockerfile为例：\n```\nFROM debian:jessie\nMAINTAINER NGINX Docker Maintainers \"docker-maint@nginx.com\"\nENV NGINX_VERSION 1.11.3-1~jessie\nRUN apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 \\\n\t&& echo \"deb http://nginx.org/packages/mainline/debian/ jessie nginx\" >> /etc/apt/sources.list \\\n\t&& apt-get update \\\n\t&& apt-get install --no-install-recommends --no-install-suggests -y \\\n\t\t\t\t\t\tca-certificates \\\n\t\t\t\t\t\tnginx=${NGINX_VERSION} \\\n\t\t\t\t\t\tnginx-module-xslt \\\n\t\t\t\t\t\tnginx-module-geoip \\\n\t\t\t\t\t\tnginx-module-image-filter \\\n\t\t\t\t\t\tnginx-module-perl \\\n\t\t\t\t\t\tnginx-module-njs \\\n\t\t\t\t\t\tgettext-base \\\n\t&& rm -rf /var/lib/apt/lists/*\n# forward request and error logs to docker log collector\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n\t&& ln -sf /dev/stderr /var/log/nginx/error.log\nEXPOSE 80 443\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### 使用多阶段构建\nDockerfile 中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个 Dockerfile 用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。Docker 17.05.0-ce 版本以后支持多阶段构建。使用多阶段构建，你可以在 Dockerfile 中使用多个 FROM 语句，每条 FROM 指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段 COPY 到另一个阶段，在最终镜像中只保留需要的内容。\n\n下面是一个使用 COPY --from 和 FROM … AS … 的 Dockerfile：\n```\n# Compile\nFROME golang:1.9.0 AS builder\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nCOPY . .\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nRUN make build && mv k8s-monitor /root\n\n# Package\n# Use scratch image\nFROM scratch\nWORKDIR /root/\nCOPY --from=builder /root .\nEXPOSE 800\nCMD [\"/root/k8s-monitor\"]\n```\n\n### 使用缓存加快构建速度\n\nDocker 在 build 镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点：\n\n* 不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开；\n\n* 因为 cache 缓存在运行 Docker build 命令的本地机器上，建议固定使用某台机器来进行 Docker build，以便利用 cache。\n\n```\nFROM openjdk:8-jre-alpine\nCOPY app/BOOT_INF/lib /app/BOOT_INF/lib/\nCOPY app/org /app/org\nCOPY app/META_INF /app/META_INF\nCOPY app/BOOT_INT/classes   /app/BOOT_INT/classes\nEXPOSE 8080\nCMD [\"java\",\"-cp\",\"/app\",\"org.springframework.boot.loader.JarLauncher\"]\n```\nDockerfile 我们把应用的内容分成 4 个部分 COPY 到镜像里面：其中前面 3 个基本不变，第 4 个是经常变化的自有代码。最后一行是解压缩后，启动 spring boot 应用的方式。\n\n### 清理缓存和不必要的文件\n\n（1）在执行 apt-get install -y 时增加选项 --no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行 apk add 时添加选项--no-cache 达到同样效果；\n\n（2）执行 yum install -y 时候， 可以同时安装多个工具，比如 yum install -y gcc gcc-c++ make …。将所有 yum install 任务放在一条 RUN 命令上执行，从而减少镜像层的数量；\n\n（3）组件的安装和清理要串联在一条指令里面，如 apk --update add php7 && rm -rf /var/cache/apk/* ，因为 Dockerfile的每条指令都会产生一个文件层，如果将 apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或 Debian可以使用 rm -rf /var/lib/apt/lists/* 清理镜像中缓存文件；CentOS 等系统使用 yum clean all 命令清理；alpine系统可使用apt-get purge -y package_name &&  apt-get autoremove && apt-get clean 来清除apt的缓存\n \n (4) 删除不必要的文档和日志：rm -rf /usr/share/doc/* /usr/share/man/* /usr/share/info/* 和删除log文件：find /var | grep '\\.log$' | xargs rm -v\n\n### 压缩镜像\nDocker 自带的一些命令还能协助压缩镜像，比如 export 和 import。\n可以使用如下命令：docker export image_name | docker import - new_image_name。\n\n## 参考文档\n[https://zhuanlan.zhihu.com/p/42815689](https://zhuanlan.zhihu.com/p/42815689)","slug":"2019-01-04-article45-docker","published":1,"date":"2021-02-09T02:00:24.580Z","updated":"2021-02-09T02:00:24.580Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq1z004jyc9729a6fb5s","content":"<h1 id=\"精简-Docker-镜像的技巧\"><a href=\"#精简-Docker-镜像的技巧\" class=\"headerlink\" title=\"精简 Docker 镜像的技巧\"></a>精简 Docker 镜像的技巧</h1><p>精简 Docker 镜像的好处很多，不仅可以节省存储空间和带宽，还能减少安全隐患。优化镜像大小的手段多种多样，因服务所使用的基础开发语言不同而有差异。本文将介绍精简 Docker 镜像的几种通用方法。</p>\n<h2 id=\"精简-Docker-镜像大小的必要性\"><a href=\"#精简-Docker-镜像大小的必要性\" class=\"headerlink\" title=\"精简 Docker 镜像大小的必要性\"></a>精简 Docker 镜像大小的必要性</h2><p>Docker 镜像由很多镜像层（Layers）组成（最多 127 层），镜像层依赖于一系列的底层技术，比如文件系统（filesystems）、写时复制（copy-on-write）、联合挂载（union mounts）等技术，你可以查看Docker 社区文档以了解更多有关 Docker 存储驱动的内容，这里就不再赘述技术细节。总的来说，Dockerfile 中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。</p>\n<p>下面是精简 Docker 镜像尺寸的好处：</p>\n<pre><code>1.减少构建时间\n2.减少磁盘使用量\n3.减少下载时间\n4.因为包含文件少，攻击面减小，提高了安全性\n5.提高部署速度\n</code></pre>\n<h2 id=\"编写小容量镜像的Dockerfile的技巧\"><a href=\"#编写小容量镜像的Dockerfile的技巧\" class=\"headerlink\" title=\"编写小容量镜像的Dockerfile的技巧\"></a>编写小容量镜像的Dockerfile的技巧</h2><h3 id=\"使用较小的基础镜像\"><a href=\"#使用较小的基础镜像\" class=\"headerlink\" title=\"使用较小的基础镜像\"></a>使用较小的基础镜像</h3><p>优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中 Alpine 更推荐使用。大小对比如下：alpine &lt; ubuntu &lt; debian &lt; centos</p>\n<p>另外可以选择适合更小的基础镜像</p>\n<p>1、scratch 镜像（空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang 程序，可以直接使用 scratch 作为基础镜像。）</p>\n<pre><code>FROME scratch\nARG ARCH\nADD bin/pause-$&#123;ARCH&#125; /pause\nENTRYPOINT [&quot;/pause&quot;]\n</code></pre>\n<p>2、busybox 镜像（镜像里可以包含一些常用的 Linux 工具，busybox 镜像是个不错选择，镜像本身只有 1.16M，非常便于构建小镜像）</p>\n<h3 id=\"将多个命令集放在一行\"><a href=\"#将多个命令集放在一行\" class=\"headerlink\" title=\"将多个命令集放在一行\"></a>将多个命令集放在一行</h3><p>大家在定义 Dockerfile 时，如果太多的使用 RUN 指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 Dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&amp;&amp;和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。。以Nginx的官方的Dockerfile为例：</p>\n<pre><code>FROM debian:jessie\nMAINTAINER NGINX Docker Maintainers &quot;docker-maint@nginx.com&quot;\nENV NGINX_VERSION 1.11.3-1~jessie\nRUN apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 \\\n    &amp;&amp; echo &quot;deb http://nginx.org/packages/mainline/debian/ jessie nginx&quot; &gt;&gt; /etc/apt/sources.list \\\n    &amp;&amp; apt-get update \\\n    &amp;&amp; apt-get install --no-install-recommends --no-install-suggests -y \\\n                        ca-certificates \\\n                        nginx=$&#123;NGINX_VERSION&#125; \\\n                        nginx-module-xslt \\\n                        nginx-module-geoip \\\n                        nginx-module-image-filter \\\n                        nginx-module-perl \\\n                        nginx-module-njs \\\n                        gettext-base \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n# forward request and error logs to docker log collector\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n    &amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.log\nEXPOSE 80 443\nCMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]\n</code></pre>\n<h3 id=\"使用多阶段构建\"><a href=\"#使用多阶段构建\" class=\"headerlink\" title=\"使用多阶段构建\"></a>使用多阶段构建</h3><p>Dockerfile 中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个 Dockerfile 用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。Docker 17.05.0-ce 版本以后支持多阶段构建。使用多阶段构建，你可以在 Dockerfile 中使用多个 FROM 语句，每条 FROM 指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段 COPY 到另一个阶段，在最终镜像中只保留需要的内容。</p>\n<p>下面是一个使用 COPY –from 和 FROM … AS … 的 Dockerfile：</p>\n<pre><code># Compile\nFROME golang:1.9.0 AS builder\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nCOPY . .\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nRUN make build &amp;&amp; mv k8s-monitor /root\n\n# Package\n# Use scratch image\nFROM scratch\nWORKDIR /root/\nCOPY --from=builder /root .\nEXPOSE 800\nCMD [&quot;/root/k8s-monitor&quot;]\n</code></pre>\n<h3 id=\"使用缓存加快构建速度\"><a href=\"#使用缓存加快构建速度\" class=\"headerlink\" title=\"使用缓存加快构建速度\"></a>使用缓存加快构建速度</h3><p>Docker 在 build 镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点：</p>\n<ul>\n<li><p>不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开；</p>\n</li>\n<li><p>因为 cache 缓存在运行 Docker build 命令的本地机器上，建议固定使用某台机器来进行 Docker build，以便利用 cache。</p>\n</li>\n</ul>\n<pre><code>FROM openjdk:8-jre-alpine\nCOPY app/BOOT_INF/lib /app/BOOT_INF/lib/\nCOPY app/org /app/org\nCOPY app/META_INF /app/META_INF\nCOPY app/BOOT_INT/classes   /app/BOOT_INT/classes\nEXPOSE 8080\nCMD [&quot;java&quot;,&quot;-cp&quot;,&quot;/app&quot;,&quot;org.springframework.boot.loader.JarLauncher&quot;]\n</code></pre>\n<p>Dockerfile 我们把应用的内容分成 4 个部分 COPY 到镜像里面：其中前面 3 个基本不变，第 4 个是经常变化的自有代码。最后一行是解压缩后，启动 spring boot 应用的方式。</p>\n<h3 id=\"清理缓存和不必要的文件\"><a href=\"#清理缓存和不必要的文件\" class=\"headerlink\" title=\"清理缓存和不必要的文件\"></a>清理缓存和不必要的文件</h3><p>（1）在执行 apt-get install -y 时增加选项 –no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行 apk add 时添加选项–no-cache 达到同样效果；</p>\n<p>（2）执行 yum install -y 时候， 可以同时安装多个工具，比如 yum install -y gcc gcc-c++ make …。将所有 yum install 任务放在一条 RUN 命令上执行，从而减少镜像层的数量；</p>\n<p>（3）组件的安装和清理要串联在一条指令里面，如 apk –update add php7 &amp;&amp; rm -rf /var/cache/apk/* ，因为 Dockerfile的每条指令都会产生一个文件层，如果将 apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或 Debian可以使用 rm -rf /var/lib/apt/lists/* 清理镜像中缓存文件；CentOS 等系统使用 yum clean all 命令清理；alpine系统可使用apt-get purge -y package_name &amp;&amp;  apt-get autoremove &amp;&amp; apt-get clean 来清除apt的缓存</p>\n<p> (4) 删除不必要的文档和日志：rm -rf /usr/share/doc/* /usr/share/man/* /usr/share/info/* 和删除log文件：find /var | grep ‘.log$’ | xargs rm -v</p>\n<h3 id=\"压缩镜像\"><a href=\"#压缩镜像\" class=\"headerlink\" title=\"压缩镜像\"></a>压缩镜像</h3><p>Docker 自带的一些命令还能协助压缩镜像，比如 export 和 import。<br>可以使用如下命令：docker export image_name | docker import - new_image_name。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://zhuanlan.zhihu.com/p/42815689\">https://zhuanlan.zhihu.com/p/42815689</a></p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"精简-Docker-镜像的技巧\"><a href=\"#精简-Docker-镜像的技巧\" class=\"headerlink\" title=\"精简 Docker 镜像的技巧\"></a>精简 Docker 镜像的技巧</h1><p>精简 Docker 镜像的好处很多，不仅可以节省存储空间和带宽，还能减少安全隐患。优化镜像大小的手段多种多样，因服务所使用的基础开发语言不同而有差异。本文将介绍精简 Docker 镜像的几种通用方法。</p>\n<h2 id=\"精简-Docker-镜像大小的必要性\"><a href=\"#精简-Docker-镜像大小的必要性\" class=\"headerlink\" title=\"精简 Docker 镜像大小的必要性\"></a>精简 Docker 镜像大小的必要性</h2><p>Docker 镜像由很多镜像层（Layers）组成（最多 127 层），镜像层依赖于一系列的底层技术，比如文件系统（filesystems）、写时复制（copy-on-write）、联合挂载（union mounts）等技术，你可以查看Docker 社区文档以了解更多有关 Docker 存储驱动的内容，这里就不再赘述技术细节。总的来说，Dockerfile 中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。</p>\n<p>下面是精简 Docker 镜像尺寸的好处：</p>\n<pre><code>1.减少构建时间\n2.减少磁盘使用量\n3.减少下载时间\n4.因为包含文件少，攻击面减小，提高了安全性\n5.提高部署速度\n</code></pre>\n<h2 id=\"编写小容量镜像的Dockerfile的技巧\"><a href=\"#编写小容量镜像的Dockerfile的技巧\" class=\"headerlink\" title=\"编写小容量镜像的Dockerfile的技巧\"></a>编写小容量镜像的Dockerfile的技巧</h2><h3 id=\"使用较小的基础镜像\"><a href=\"#使用较小的基础镜像\" class=\"headerlink\" title=\"使用较小的基础镜像\"></a>使用较小的基础镜像</h3><p>优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中 Alpine 更推荐使用。大小对比如下：alpine &lt; ubuntu &lt; debian &lt; centos</p>\n<p>另外可以选择适合更小的基础镜像</p>\n<p>1、scratch 镜像（空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang 程序，可以直接使用 scratch 作为基础镜像。）</p>\n<pre><code>FROME scratch\nARG ARCH\nADD bin/pause-$&#123;ARCH&#125; /pause\nENTRYPOINT [&quot;/pause&quot;]\n</code></pre>\n<p>2、busybox 镜像（镜像里可以包含一些常用的 Linux 工具，busybox 镜像是个不错选择，镜像本身只有 1.16M，非常便于构建小镜像）</p>\n<h3 id=\"将多个命令集放在一行\"><a href=\"#将多个命令集放在一行\" class=\"headerlink\" title=\"将多个命令集放在一行\"></a>将多个命令集放在一行</h3><p>大家在定义 Dockerfile 时，如果太多的使用 RUN 指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 Dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&amp;&amp;和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。。以Nginx的官方的Dockerfile为例：</p>\n<pre><code>FROM debian:jessie\nMAINTAINER NGINX Docker Maintainers &quot;docker-maint@nginx.com&quot;\nENV NGINX_VERSION 1.11.3-1~jessie\nRUN apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 \\\n    &amp;&amp; echo &quot;deb http://nginx.org/packages/mainline/debian/ jessie nginx&quot; &gt;&gt; /etc/apt/sources.list \\\n    &amp;&amp; apt-get update \\\n    &amp;&amp; apt-get install --no-install-recommends --no-install-suggests -y \\\n                        ca-certificates \\\n                        nginx=$&#123;NGINX_VERSION&#125; \\\n                        nginx-module-xslt \\\n                        nginx-module-geoip \\\n                        nginx-module-image-filter \\\n                        nginx-module-perl \\\n                        nginx-module-njs \\\n                        gettext-base \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n# forward request and error logs to docker log collector\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n    &amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.log\nEXPOSE 80 443\nCMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]\n</code></pre>\n<h3 id=\"使用多阶段构建\"><a href=\"#使用多阶段构建\" class=\"headerlink\" title=\"使用多阶段构建\"></a>使用多阶段构建</h3><p>Dockerfile 中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个 Dockerfile 用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。Docker 17.05.0-ce 版本以后支持多阶段构建。使用多阶段构建，你可以在 Dockerfile 中使用多个 FROM 语句，每条 FROM 指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段 COPY 到另一个阶段，在最终镜像中只保留需要的内容。</p>\n<p>下面是一个使用 COPY –from 和 FROM … AS … 的 Dockerfile：</p>\n<pre><code># Compile\nFROME golang:1.9.0 AS builder\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nCOPY . .\nWORKDIR /go/src/v9.git...com/.../k8s-monitor\nRUN make build &amp;&amp; mv k8s-monitor /root\n\n# Package\n# Use scratch image\nFROM scratch\nWORKDIR /root/\nCOPY --from=builder /root .\nEXPOSE 800\nCMD [&quot;/root/k8s-monitor&quot;]\n</code></pre>\n<h3 id=\"使用缓存加快构建速度\"><a href=\"#使用缓存加快构建速度\" class=\"headerlink\" title=\"使用缓存加快构建速度\"></a>使用缓存加快构建速度</h3><p>Docker 在 build 镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点：</p>\n<ul>\n<li><p>不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开；</p>\n</li>\n<li><p>因为 cache 缓存在运行 Docker build 命令的本地机器上，建议固定使用某台机器来进行 Docker build，以便利用 cache。</p>\n</li>\n</ul>\n<pre><code>FROM openjdk:8-jre-alpine\nCOPY app/BOOT_INF/lib /app/BOOT_INF/lib/\nCOPY app/org /app/org\nCOPY app/META_INF /app/META_INF\nCOPY app/BOOT_INT/classes   /app/BOOT_INT/classes\nEXPOSE 8080\nCMD [&quot;java&quot;,&quot;-cp&quot;,&quot;/app&quot;,&quot;org.springframework.boot.loader.JarLauncher&quot;]\n</code></pre>\n<p>Dockerfile 我们把应用的内容分成 4 个部分 COPY 到镜像里面：其中前面 3 个基本不变，第 4 个是经常变化的自有代码。最后一行是解压缩后，启动 spring boot 应用的方式。</p>\n<h3 id=\"清理缓存和不必要的文件\"><a href=\"#清理缓存和不必要的文件\" class=\"headerlink\" title=\"清理缓存和不必要的文件\"></a>清理缓存和不必要的文件</h3><p>（1）在执行 apt-get install -y 时增加选项 –no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行 apk add 时添加选项–no-cache 达到同样效果；</p>\n<p>（2）执行 yum install -y 时候， 可以同时安装多个工具，比如 yum install -y gcc gcc-c++ make …。将所有 yum install 任务放在一条 RUN 命令上执行，从而减少镜像层的数量；</p>\n<p>（3）组件的安装和清理要串联在一条指令里面，如 apk –update add php7 &amp;&amp; rm -rf /var/cache/apk/* ，因为 Dockerfile的每条指令都会产生一个文件层，如果将 apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或 Debian可以使用 rm -rf /var/lib/apt/lists/* 清理镜像中缓存文件；CentOS 等系统使用 yum clean all 命令清理；alpine系统可使用apt-get purge -y package_name &amp;&amp;  apt-get autoremove &amp;&amp; apt-get clean 来清除apt的缓存</p>\n<p> (4) 删除不必要的文档和日志：rm -rf /usr/share/doc/* /usr/share/man/* /usr/share/info/* 和删除log文件：find /var | grep ‘.log$’ | xargs rm -v</p>\n<h3 id=\"压缩镜像\"><a href=\"#压缩镜像\" class=\"headerlink\" title=\"压缩镜像\"></a>压缩镜像</h3><p>Docker 自带的一些命令还能协助压缩镜像，比如 export 和 import。<br>可以使用如下命令：docker export image_name | docker import - new_image_name。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://zhuanlan.zhihu.com/p/42815689\">https://zhuanlan.zhihu.com/p/42815689</a></p>\n"},{"title":"Lnmp一键部署脚本","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-16T14:34:54.000Z","password":null,"summary":null,"_content":"## Lnmp一键部署脚本\n\n```\n#!/bin/bash\n##DATE:2016-7-25\n##USER:owelinux\n###install wallet\n\n#######install mysql##################################################\nyum -y install cmake ncurses-devel  bison libaio  make gcc gcc-c++\nmkdir  -p /application/tools\ncd /application/tools\nwget http://pkgs.fedoraproject.org/repo/pkgs/community-mysql/mysql-boost-5.7.14.tar.gz/f90464874ee635ff63c436d1b64fe311/mysql-boost-5.7.14.tar.gz\ntar xvf mysql-boost-5.7.14.tar.gz\ncd mysql-5.7.14/\ncmake . -DCMAKE_INSTALL_PREFIX=/application/mysql/ \\\n-DMYSQL_DATADIR=/data/mysqlData/mysql21406/  \\\n-DWITH_MYISAM_STORAGE_ENGINE=1 \\\n-DWITH_INNOBASE_STORAGE_ENGINE=1  \\\n-DDEFAULT_CHARSET=utf8 \\\n-DDEFAULT_COLLATION=utf8_general_ci  \\\n-DDOWNLOAD_BOOST=1 \\\n-DDOWNLOAD_BOOST=1  \\\n-DWITH_BOOST=./boost/ #boost路径修改一下 指向你源码路径\nmake  -j4 && make install\n\ngroupadd mysql\nuseradd -M -g mysql -s /sbin/nologin mysql\nchown -R mysql:mysql /application/mysql\n\nmkdir -p /data/mysqlData/mysql21406\nmkdir /data/mysqlData/mysql21406/binlog\nmkdir /data/mysqlData/mysql21406/relaylog\nchmod 750 /data/mysqlData/mysql21406/binlog\nchmod 750 /data/mysqlData/mysql21406/relaylog\nchown -R mysql:mysql /data/mysqlData/*\n\n # 初始化mysql\n/application/mysql/bin/mysqld --initialize --user=mysql --basedir=/application/mysql/ --datadir=/data/mysqlData/mysql21406/data\n/application/mysql/bin/mysql_ssl_rsa_setup -d /data/mysqlData/mysql21406/data/\n\n#上传mys.cnf配置文件\ncd /data/mysqlData/mysql21406\nchown -R mysql:mysql /data/mysqlData/mysql21406\n\n# 修改配置文件\nvim /data/mysqlData/mysql21406/my.cnf\n\n# 启动mysql\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &\n/application/mysql/bin/mysql -uroot -S /data/mysqlData/mysql21406/mysql.sock -p\n\n# 设置root密码\nSET PASSWORD =PASSWORD('root');\nSET PASSWORD FOR username=PASSWORD('new password');\ncreate database zabbix character set utf8 collate utf8_bin;\ngrant all privileges on zabbix.* to 'zabbix'@'%'  identified by 'zabbix';\nflush privileges;\n\n\n# 设置开机自启动\necho \"export PATH=\\$PATH:/application/mysql/bin\">>/etc/profile\nsource /etc/profile\necho '/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &' >>/etc/rc.local\n\n#安装nginx######################################################\n#useradd -M -s /sbin/nologin nginx\n#mkdir -p /var/log/nginx\n#cd /application/tools\n#wget http://nginx.org/download/nginx-1.10.1.tar.gz\n#tar zxvf nginx-1.10.1.tar.gz\n#cd nginx-1.10.1\n#yum -y install epel-release\n#yum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel freetype freetype-devel\n#./configure --user=nginx --group=nginx --prefix=/application/nginx --with-http_stub_status_module --with-http_ssl_module\n#make && make install\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\n\n#安装openresty\nyum -y install epel-release\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel libxslt-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\nmkdir -p /application/tools\ncd /application/tools\nwget https://openresty.org/download/openresty-1.13.6.1.tar.gz\ntar zxvf openresty-1.13.6.1.tar.gz\ncd openresty-1.13.6.1\n./configure \\\n--prefix=/application/openresty \\\n--with-http_iconv_module \\\n--with-luajit \\\n--user=nginx \\\n--group=nginx \\\n--with-select_module \\\n--with-poll_module \\\n--with-threads \\\n--with-ipv6 \\\n--with-http_v2_module \\\n--with-http_ssl_module \\\n--with-http_realip_module \\\n--with-http_addition_module \\\n--with-http_xslt_module \\\n--with-http_xslt_module=dynamic \\\n--with-http_image_filter_module \\\n--with-http_image_filter_module=dynamic \\\n--with-http_sub_module \\\n--with-http_gunzip_module \\\n--with-http_gzip_static_module \\\n--with-http_auth_request_module \\\n--with-http_random_index_module \\\n--with-http_secure_link_module \\\n--with-http_degradation_module \\\n--with-http_slice_module \\\n--with-http_stub_status_module \\\n--with-http_perl_module \\\n--with-http_perl_module=dynamic \\\n--with-stream \\\n--with-stream=dynamic \\\n--with-stream_ssl_module \\\n--with-pcre \\\n--with-pcre-jit\ngmake -j4 && gmake install\n\nuseradd -s /sbin/nologin -M nginx\nln -sv /application/openresty/nginx  /application/nginx\nln -s /application/openresty/nginx/sbin/nginx  /usr/sbin/nginx \\\n/application/nginx/sbin/nginx\n\n# 设置开机自启动\necho \"export PATH=\\$PATH:/application/openresty/nginx/sbin\" >>/etc/profile\nsource /etc/profile\nchmod +x /etc/rc.local\necho \"/application/openresty/nginx/sbin/nginx\" >>/etc/rc.local\n\nmkdir -p /data/tmp/nginx/client_temp\nmkdir -p /data/tmp/nginx/proxy_temp\nchmod 711 /data/tmp/nginx\n\n#安装php###############################################\nyum -y install epel-release\n#cd /application/tools\n#wget http://www.atomicorp.com/installers/atomic\n#sh ./atomic\nyum -y install  gcc gcc-c++   C  autoconf  make mcrypt  mhash zlib zlib-devel pcre pcre-devel  libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers libxslt libxslt-devel libmcrypt libmcrypt-devel libpng12 libpng12-devel libcurl  libcurl-devel readline-devel libXpm-devel gmp gmp-devel  mysql-devel unixODBC unixODBC-devel pspell-devel net-snmp net-snmp-devel\ncd /application/tools\nwget http://cn2.php.net/distributions/php-7.1.2.tar.gz\ntar -zxvf php-7.1.2.tar.gz\ncd php-7.1.2\n./configure \\\n  --prefix=/application/php7 \\\n  --with-mysqli=mysqlnd \\\n  --with-pdo-mysql=mysqlnd \\\n  --with-iconv \\\n  --with-iconv-dir=/usr/local/libiconv \\\n  --with-freetype-dir \\\n  --without-pear \\\n  --with-fpm-user=nginx \\\n  --with-fpm-group=nginx \\\n  --with-jpeg-dir \\\n  --with-png-dir \\\n  --with-zlib \\\n  --with-zlib-dir \\\n  --with-bz2  \\\n  --with-xsl \\\n  --with-xmlrpc \\\n  --with-mhash \\\n  --with-mcrypt \\\n  --with-gd  \\\n  --with-openssl    \\\n  --with-libxml-dir \\\n  --with-readline \\\n  --with-gettext \\\n  --with-pcre-regex \\\n  --with-curl \\\n  --disable-rpath \\\n  --disable-ipv6  \\\n  --disable-debug \\\n  --enable-xml \\\n  --enable-bcmath \\\n  --enable-shmop \\\n  --enable-sysvsem \\\n  --enable-sysvmsg \\\n  --enable-sysvshm \\\n  --enable-mbregex \\\n  --enable-mysqlnd \\\n  --enable-fpm \\\n  --enable-mbstring \\\n  --enable-gd-native-ttf \\\n  --enable-pcntl \\\n  --enable-sockets \\\n  --enable-soap \\\n  --enable-short-tags \\\n  --enable-static \\\n  --enable-ftp \\\n  --enable-opcache=yes \\\n  --enable-json \\\n  --enable-zip\\\n  --enable-exif \\\n  --enable-inline-optimization\n#ln -s /application/mysql/lib/libmysqlclient.so.20 /usr/lib64\nmake -j4 && make install\n\necho \"export PATH=\"/application/php7/bin:\\$PATH\"\" >>/etc/profile\nsource /etc/profile\necho \"/application/php7/sbin/php-fpm\" >>/etc/rc.local\n\n####################################################\nphp7环境安装模块：\n# 安装emqttd\n#cd /application/tools\n#wget http://emqtt.io/static/brokers/emqttd-centos6.8-v2.1.0-beta.1.zip\n#unzip emqttd-centos6.8-v2.1.0-beta.1.zip\n#cd emqttd\n#./bin/emqttd start\n#./bin/emqttd_ctl status\n\n# 安装memcache、redis、yaf模块\n#cd /application/tools\n#wget http://pecl.php.net/get/memcache-2.2.5.tgz\n#tar xf memcache-2.2.5.tgz\n#cd memcache-2.2.5\n#/application/php/bin/phpize\n#./configure --with-php-config=/application/php/bin/php-config\n#make && make install\n\n# 安装yaf模块\ncd /application/tools\nwget https://pecl.php.net/get/yaf-3.0.5.tgz\ntar -zxvf yaf-3.0.5.tgz\ncd yaf-3.0.5\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装redis模块\ncd /application/tools\nwget https://github.com/phpredis/phpredis/archive/develop.zip\nunzip develop.zip\ncd phpredis-develop\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装seaslog模块\ncd /application/tools\nwget https://pecl.php.net/get/SeasLog-1.6.9.tgz\ntar -zxvf SeasLog-1.6.9.tgz\ncd SeasLog-1.6.9\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装rabbitmq模块\nyum -y install cmake\ncd /application/tools\nwget https://github.com/alanxz/rabbitmq-c/releases/download/v0.8.0/rabbitmq-c-0.8.0.tar.gz\ntar -zxvf rabbitmq-c-0.8.0.tar.gz\ncd rabbitmq-c-0.8.0\n#mkdir build && cd build\n#cmake -DCMAKE_INSTALL_PREFIX=/usr/local/librabbitmq ..\n#cmake --build .\n./configure --prefix=/usr/local/rabbitmq-c\nmake -j4 && make install\ncd /application/tools\nwget https://pecl.php.net/get/amqp-1.9.1.tgz\ntar -zxvf amqp-1.9.1.tgz\ncd amqp-1.9.1\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c/\nmake -j4 && make install\n\n##php7环境配置\ncd /application/tools/php-7.1.2\n\\cp php.ini-production  /application/php7/lib/php.ini\ncd /application/php7/etc\n\\cp php-fpm.conf.default php-fpm.conf\ncd /application/php7/etc/php-fpm.d/\n\\cp www.conf.default  www.conf\n/application/php7/sbin/php-fpm\n\n# 最后在php.ini定义加载模块就可以\ncat >>/application/php7/lib/php.ini<<EOF\ndate.timezone = \"Asia/Shanghai\"\nextension=redis.so\nextension=seaslog.so\nextension=yaf.so\nextension = amqp.so\nyaf.environ=cloud\n\nseaslog.default_basepath = /data/appLog/wallet            ;默认log根目录\nseaslog.default_logger = default                        ;默认logger目录\nseaslog.disting_type = 1                                ;是否以type分文件 1是 0否(默认)\nseaslog.disting_by_hour = 1                             ;是否每小时划分一个文件 1是 0否(默认)\nseaslog.use_buffer = 0                                  ;是否启用buffer 1是 0否(默认)\nseaslog.buffer_size = 100                               ;buffer中缓冲数量 默认0(不使用buffer_size)\nseaslog.level = 0                                       ;记录日志级别 默认0(所有日志)\nseaslog.trace_error = 1                                 ;自动记录错误 默认1(开启)\nseaslog.trace_exception = 0                             ;自动记录异常信息 默认0(关闭)\nseaslog.default_datetime_format = \"Y:m:d H:i:s\"         ;日期格式配置 默认\"Y:m:d H:i:s\"\nseaslog.appender = 1                                    ;日志存储介质 1File 2TCP 3UDP (默认为1)\nseaslog.remote_host = 127.0.0.1                         ;接收ip 默认127.0.0.1 (当使用TCP或UDP时必填)\nseaslog.remote_port = 514                               ;接收端口 默认514 (当使用TCP或UDP时必填)\nEOF\n#重启php-fpm\npkill php-fpm\n/application/php7/sbin/php-fpm\n\n# 服务开机自启动\ncat >>/etc/rc.local<<EOF\n/application/php/sbin/php-fpm\n/application/nginx/sbin/nginx\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &\nEOF\n\n# 内核调优\ncat >>/etc/sysctl.conf<<EOF\nnet.ipv4.tcp_max_syn_backlog = 65536\nnet.core.netdev_max_backlog =  32768\nnet.core.somaxconn = 32768\n\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\n\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 2\n\nnet.ipv4.tcp_tw_recycle = 1\n#net.ipv4.tcp_tw_len = 1\nnet.ipv4.tcp_tw_reuse = 1\n\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_max_orphans = 3276800\n\n#net.ipv4.tcp_fin_timeout = 30\n#net.ipv4.tcp_keepalive_time = 120\nnet.ipv4.ip_local_port_range = 1024  65535\nEOF\n/sbin/sysctl -p\n```","source":"_posts/linux-lnmp.md","raw":"---\ntitle: Lnmp一键部署脚本\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2018-07-16 22:34:54 +0800\npassword:\nsummary:\ntags:\n- lnmp\ncategories:\n- linux\n---\n## Lnmp一键部署脚本\n\n```\n#!/bin/bash\n##DATE:2016-7-25\n##USER:owelinux\n###install wallet\n\n#######install mysql##################################################\nyum -y install cmake ncurses-devel  bison libaio  make gcc gcc-c++\nmkdir  -p /application/tools\ncd /application/tools\nwget http://pkgs.fedoraproject.org/repo/pkgs/community-mysql/mysql-boost-5.7.14.tar.gz/f90464874ee635ff63c436d1b64fe311/mysql-boost-5.7.14.tar.gz\ntar xvf mysql-boost-5.7.14.tar.gz\ncd mysql-5.7.14/\ncmake . -DCMAKE_INSTALL_PREFIX=/application/mysql/ \\\n-DMYSQL_DATADIR=/data/mysqlData/mysql21406/  \\\n-DWITH_MYISAM_STORAGE_ENGINE=1 \\\n-DWITH_INNOBASE_STORAGE_ENGINE=1  \\\n-DDEFAULT_CHARSET=utf8 \\\n-DDEFAULT_COLLATION=utf8_general_ci  \\\n-DDOWNLOAD_BOOST=1 \\\n-DDOWNLOAD_BOOST=1  \\\n-DWITH_BOOST=./boost/ #boost路径修改一下 指向你源码路径\nmake  -j4 && make install\n\ngroupadd mysql\nuseradd -M -g mysql -s /sbin/nologin mysql\nchown -R mysql:mysql /application/mysql\n\nmkdir -p /data/mysqlData/mysql21406\nmkdir /data/mysqlData/mysql21406/binlog\nmkdir /data/mysqlData/mysql21406/relaylog\nchmod 750 /data/mysqlData/mysql21406/binlog\nchmod 750 /data/mysqlData/mysql21406/relaylog\nchown -R mysql:mysql /data/mysqlData/*\n\n # 初始化mysql\n/application/mysql/bin/mysqld --initialize --user=mysql --basedir=/application/mysql/ --datadir=/data/mysqlData/mysql21406/data\n/application/mysql/bin/mysql_ssl_rsa_setup -d /data/mysqlData/mysql21406/data/\n\n#上传mys.cnf配置文件\ncd /data/mysqlData/mysql21406\nchown -R mysql:mysql /data/mysqlData/mysql21406\n\n# 修改配置文件\nvim /data/mysqlData/mysql21406/my.cnf\n\n# 启动mysql\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &\n/application/mysql/bin/mysql -uroot -S /data/mysqlData/mysql21406/mysql.sock -p\n\n# 设置root密码\nSET PASSWORD =PASSWORD('root');\nSET PASSWORD FOR username=PASSWORD('new password');\ncreate database zabbix character set utf8 collate utf8_bin;\ngrant all privileges on zabbix.* to 'zabbix'@'%'  identified by 'zabbix';\nflush privileges;\n\n\n# 设置开机自启动\necho \"export PATH=\\$PATH:/application/mysql/bin\">>/etc/profile\nsource /etc/profile\necho '/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &' >>/etc/rc.local\n\n#安装nginx######################################################\n#useradd -M -s /sbin/nologin nginx\n#mkdir -p /var/log/nginx\n#cd /application/tools\n#wget http://nginx.org/download/nginx-1.10.1.tar.gz\n#tar zxvf nginx-1.10.1.tar.gz\n#cd nginx-1.10.1\n#yum -y install epel-release\n#yum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel freetype freetype-devel\n#./configure --user=nginx --group=nginx --prefix=/application/nginx --with-http_stub_status_module --with-http_ssl_module\n#make && make install\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\n\n#安装openresty\nyum -y install epel-release\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel libxslt-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\nmkdir -p /application/tools\ncd /application/tools\nwget https://openresty.org/download/openresty-1.13.6.1.tar.gz\ntar zxvf openresty-1.13.6.1.tar.gz\ncd openresty-1.13.6.1\n./configure \\\n--prefix=/application/openresty \\\n--with-http_iconv_module \\\n--with-luajit \\\n--user=nginx \\\n--group=nginx \\\n--with-select_module \\\n--with-poll_module \\\n--with-threads \\\n--with-ipv6 \\\n--with-http_v2_module \\\n--with-http_ssl_module \\\n--with-http_realip_module \\\n--with-http_addition_module \\\n--with-http_xslt_module \\\n--with-http_xslt_module=dynamic \\\n--with-http_image_filter_module \\\n--with-http_image_filter_module=dynamic \\\n--with-http_sub_module \\\n--with-http_gunzip_module \\\n--with-http_gzip_static_module \\\n--with-http_auth_request_module \\\n--with-http_random_index_module \\\n--with-http_secure_link_module \\\n--with-http_degradation_module \\\n--with-http_slice_module \\\n--with-http_stub_status_module \\\n--with-http_perl_module \\\n--with-http_perl_module=dynamic \\\n--with-stream \\\n--with-stream=dynamic \\\n--with-stream_ssl_module \\\n--with-pcre \\\n--with-pcre-jit\ngmake -j4 && gmake install\n\nuseradd -s /sbin/nologin -M nginx\nln -sv /application/openresty/nginx  /application/nginx\nln -s /application/openresty/nginx/sbin/nginx  /usr/sbin/nginx \\\n/application/nginx/sbin/nginx\n\n# 设置开机自启动\necho \"export PATH=\\$PATH:/application/openresty/nginx/sbin\" >>/etc/profile\nsource /etc/profile\nchmod +x /etc/rc.local\necho \"/application/openresty/nginx/sbin/nginx\" >>/etc/rc.local\n\nmkdir -p /data/tmp/nginx/client_temp\nmkdir -p /data/tmp/nginx/proxy_temp\nchmod 711 /data/tmp/nginx\n\n#安装php###############################################\nyum -y install epel-release\n#cd /application/tools\n#wget http://www.atomicorp.com/installers/atomic\n#sh ./atomic\nyum -y install  gcc gcc-c++   C  autoconf  make mcrypt  mhash zlib zlib-devel pcre pcre-devel  libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers libxslt libxslt-devel libmcrypt libmcrypt-devel libpng12 libpng12-devel libcurl  libcurl-devel readline-devel libXpm-devel gmp gmp-devel  mysql-devel unixODBC unixODBC-devel pspell-devel net-snmp net-snmp-devel\ncd /application/tools\nwget http://cn2.php.net/distributions/php-7.1.2.tar.gz\ntar -zxvf php-7.1.2.tar.gz\ncd php-7.1.2\n./configure \\\n  --prefix=/application/php7 \\\n  --with-mysqli=mysqlnd \\\n  --with-pdo-mysql=mysqlnd \\\n  --with-iconv \\\n  --with-iconv-dir=/usr/local/libiconv \\\n  --with-freetype-dir \\\n  --without-pear \\\n  --with-fpm-user=nginx \\\n  --with-fpm-group=nginx \\\n  --with-jpeg-dir \\\n  --with-png-dir \\\n  --with-zlib \\\n  --with-zlib-dir \\\n  --with-bz2  \\\n  --with-xsl \\\n  --with-xmlrpc \\\n  --with-mhash \\\n  --with-mcrypt \\\n  --with-gd  \\\n  --with-openssl    \\\n  --with-libxml-dir \\\n  --with-readline \\\n  --with-gettext \\\n  --with-pcre-regex \\\n  --with-curl \\\n  --disable-rpath \\\n  --disable-ipv6  \\\n  --disable-debug \\\n  --enable-xml \\\n  --enable-bcmath \\\n  --enable-shmop \\\n  --enable-sysvsem \\\n  --enable-sysvmsg \\\n  --enable-sysvshm \\\n  --enable-mbregex \\\n  --enable-mysqlnd \\\n  --enable-fpm \\\n  --enable-mbstring \\\n  --enable-gd-native-ttf \\\n  --enable-pcntl \\\n  --enable-sockets \\\n  --enable-soap \\\n  --enable-short-tags \\\n  --enable-static \\\n  --enable-ftp \\\n  --enable-opcache=yes \\\n  --enable-json \\\n  --enable-zip\\\n  --enable-exif \\\n  --enable-inline-optimization\n#ln -s /application/mysql/lib/libmysqlclient.so.20 /usr/lib64\nmake -j4 && make install\n\necho \"export PATH=\"/application/php7/bin:\\$PATH\"\" >>/etc/profile\nsource /etc/profile\necho \"/application/php7/sbin/php-fpm\" >>/etc/rc.local\n\n####################################################\nphp7环境安装模块：\n# 安装emqttd\n#cd /application/tools\n#wget http://emqtt.io/static/brokers/emqttd-centos6.8-v2.1.0-beta.1.zip\n#unzip emqttd-centos6.8-v2.1.0-beta.1.zip\n#cd emqttd\n#./bin/emqttd start\n#./bin/emqttd_ctl status\n\n# 安装memcache、redis、yaf模块\n#cd /application/tools\n#wget http://pecl.php.net/get/memcache-2.2.5.tgz\n#tar xf memcache-2.2.5.tgz\n#cd memcache-2.2.5\n#/application/php/bin/phpize\n#./configure --with-php-config=/application/php/bin/php-config\n#make && make install\n\n# 安装yaf模块\ncd /application/tools\nwget https://pecl.php.net/get/yaf-3.0.5.tgz\ntar -zxvf yaf-3.0.5.tgz\ncd yaf-3.0.5\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装redis模块\ncd /application/tools\nwget https://github.com/phpredis/phpredis/archive/develop.zip\nunzip develop.zip\ncd phpredis-develop\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装seaslog模块\ncd /application/tools\nwget https://pecl.php.net/get/SeasLog-1.6.9.tgz\ntar -zxvf SeasLog-1.6.9.tgz\ncd SeasLog-1.6.9\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake && make install\n\n# 安装rabbitmq模块\nyum -y install cmake\ncd /application/tools\nwget https://github.com/alanxz/rabbitmq-c/releases/download/v0.8.0/rabbitmq-c-0.8.0.tar.gz\ntar -zxvf rabbitmq-c-0.8.0.tar.gz\ncd rabbitmq-c-0.8.0\n#mkdir build && cd build\n#cmake -DCMAKE_INSTALL_PREFIX=/usr/local/librabbitmq ..\n#cmake --build .\n./configure --prefix=/usr/local/rabbitmq-c\nmake -j4 && make install\ncd /application/tools\nwget https://pecl.php.net/get/amqp-1.9.1.tgz\ntar -zxvf amqp-1.9.1.tgz\ncd amqp-1.9.1\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c/\nmake -j4 && make install\n\n##php7环境配置\ncd /application/tools/php-7.1.2\n\\cp php.ini-production  /application/php7/lib/php.ini\ncd /application/php7/etc\n\\cp php-fpm.conf.default php-fpm.conf\ncd /application/php7/etc/php-fpm.d/\n\\cp www.conf.default  www.conf\n/application/php7/sbin/php-fpm\n\n# 最后在php.ini定义加载模块就可以\ncat >>/application/php7/lib/php.ini<<EOF\ndate.timezone = \"Asia/Shanghai\"\nextension=redis.so\nextension=seaslog.so\nextension=yaf.so\nextension = amqp.so\nyaf.environ=cloud\n\nseaslog.default_basepath = /data/appLog/wallet            ;默认log根目录\nseaslog.default_logger = default                        ;默认logger目录\nseaslog.disting_type = 1                                ;是否以type分文件 1是 0否(默认)\nseaslog.disting_by_hour = 1                             ;是否每小时划分一个文件 1是 0否(默认)\nseaslog.use_buffer = 0                                  ;是否启用buffer 1是 0否(默认)\nseaslog.buffer_size = 100                               ;buffer中缓冲数量 默认0(不使用buffer_size)\nseaslog.level = 0                                       ;记录日志级别 默认0(所有日志)\nseaslog.trace_error = 1                                 ;自动记录错误 默认1(开启)\nseaslog.trace_exception = 0                             ;自动记录异常信息 默认0(关闭)\nseaslog.default_datetime_format = \"Y:m:d H:i:s\"         ;日期格式配置 默认\"Y:m:d H:i:s\"\nseaslog.appender = 1                                    ;日志存储介质 1File 2TCP 3UDP (默认为1)\nseaslog.remote_host = 127.0.0.1                         ;接收ip 默认127.0.0.1 (当使用TCP或UDP时必填)\nseaslog.remote_port = 514                               ;接收端口 默认514 (当使用TCP或UDP时必填)\nEOF\n#重启php-fpm\npkill php-fpm\n/application/php7/sbin/php-fpm\n\n# 服务开机自启动\ncat >>/etc/rc.local<<EOF\n/application/php/sbin/php-fpm\n/application/nginx/sbin/nginx\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &\nEOF\n\n# 内核调优\ncat >>/etc/sysctl.conf<<EOF\nnet.ipv4.tcp_max_syn_backlog = 65536\nnet.core.netdev_max_backlog =  32768\nnet.core.somaxconn = 32768\n\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\n\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 2\n\nnet.ipv4.tcp_tw_recycle = 1\n#net.ipv4.tcp_tw_len = 1\nnet.ipv4.tcp_tw_reuse = 1\n\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_max_orphans = 3276800\n\n#net.ipv4.tcp_fin_timeout = 30\n#net.ipv4.tcp_keepalive_time = 120\nnet.ipv4.ip_local_port_range = 1024  65535\nEOF\n/sbin/sysctl -p\n```","slug":"linux-lnmp","published":1,"updated":"2021-02-20T09:39:43.230Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq20004lyc973n7n4mew","content":"<h2 id=\"Lnmp一键部署脚本\"><a href=\"#Lnmp一键部署脚本\" class=\"headerlink\" title=\"Lnmp一键部署脚本\"></a>Lnmp一键部署脚本</h2><pre><code>#!/bin/bash\n##DATE:2016-7-25\n##USER:owelinux\n###install wallet\n\n#######install mysql##################################################\nyum -y install cmake ncurses-devel  bison libaio  make gcc gcc-c++\nmkdir  -p /application/tools\ncd /application/tools\nwget http://pkgs.fedoraproject.org/repo/pkgs/community-mysql/mysql-boost-5.7.14.tar.gz/f90464874ee635ff63c436d1b64fe311/mysql-boost-5.7.14.tar.gz\ntar xvf mysql-boost-5.7.14.tar.gz\ncd mysql-5.7.14/\ncmake . -DCMAKE_INSTALL_PREFIX=/application/mysql/ \\\n-DMYSQL_DATADIR=/data/mysqlData/mysql21406/  \\\n-DWITH_MYISAM_STORAGE_ENGINE=1 \\\n-DWITH_INNOBASE_STORAGE_ENGINE=1  \\\n-DDEFAULT_CHARSET=utf8 \\\n-DDEFAULT_COLLATION=utf8_general_ci  \\\n-DDOWNLOAD_BOOST=1 \\\n-DDOWNLOAD_BOOST=1  \\\n-DWITH_BOOST=./boost/ #boost路径修改一下 指向你源码路径\nmake  -j4 &amp;&amp; make install\n\ngroupadd mysql\nuseradd -M -g mysql -s /sbin/nologin mysql\nchown -R mysql:mysql /application/mysql\n\nmkdir -p /data/mysqlData/mysql21406\nmkdir /data/mysqlData/mysql21406/binlog\nmkdir /data/mysqlData/mysql21406/relaylog\nchmod 750 /data/mysqlData/mysql21406/binlog\nchmod 750 /data/mysqlData/mysql21406/relaylog\nchown -R mysql:mysql /data/mysqlData/*\n\n # 初始化mysql\n/application/mysql/bin/mysqld --initialize --user=mysql --basedir=/application/mysql/ --datadir=/data/mysqlData/mysql21406/data\n/application/mysql/bin/mysql_ssl_rsa_setup -d /data/mysqlData/mysql21406/data/\n\n#上传mys.cnf配置文件\ncd /data/mysqlData/mysql21406\nchown -R mysql:mysql /data/mysqlData/mysql21406\n\n# 修改配置文件\nvim /data/mysqlData/mysql21406/my.cnf\n\n# 启动mysql\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;\n/application/mysql/bin/mysql -uroot -S /data/mysqlData/mysql21406/mysql.sock -p\n\n# 设置root密码\nSET PASSWORD =PASSWORD(&#39;root&#39;);\nSET PASSWORD FOR username=PASSWORD(&#39;new password&#39;);\ncreate database zabbix character set utf8 collate utf8_bin;\ngrant all privileges on zabbix.* to &#39;zabbix&#39;@&#39;%&#39;  identified by &#39;zabbix&#39;;\nflush privileges;\n\n\n# 设置开机自启动\necho &quot;export PATH=\\$PATH:/application/mysql/bin&quot;&gt;&gt;/etc/profile\nsource /etc/profile\necho &#39;/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;&#39; &gt;&gt;/etc/rc.local\n\n#安装nginx######################################################\n#useradd -M -s /sbin/nologin nginx\n#mkdir -p /var/log/nginx\n#cd /application/tools\n#wget http://nginx.org/download/nginx-1.10.1.tar.gz\n#tar zxvf nginx-1.10.1.tar.gz\n#cd nginx-1.10.1\n#yum -y install epel-release\n#yum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel freetype freetype-devel\n#./configure --user=nginx --group=nginx --prefix=/application/nginx --with-http_stub_status_module --with-http_ssl_module\n#make &amp;&amp; make install\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\n\n#安装openresty\nyum -y install epel-release\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel libxslt-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\nmkdir -p /application/tools\ncd /application/tools\nwget https://openresty.org/download/openresty-1.13.6.1.tar.gz\ntar zxvf openresty-1.13.6.1.tar.gz\ncd openresty-1.13.6.1\n./configure \\\n--prefix=/application/openresty \\\n--with-http_iconv_module \\\n--with-luajit \\\n--user=nginx \\\n--group=nginx \\\n--with-select_module \\\n--with-poll_module \\\n--with-threads \\\n--with-ipv6 \\\n--with-http_v2_module \\\n--with-http_ssl_module \\\n--with-http_realip_module \\\n--with-http_addition_module \\\n--with-http_xslt_module \\\n--with-http_xslt_module=dynamic \\\n--with-http_image_filter_module \\\n--with-http_image_filter_module=dynamic \\\n--with-http_sub_module \\\n--with-http_gunzip_module \\\n--with-http_gzip_static_module \\\n--with-http_auth_request_module \\\n--with-http_random_index_module \\\n--with-http_secure_link_module \\\n--with-http_degradation_module \\\n--with-http_slice_module \\\n--with-http_stub_status_module \\\n--with-http_perl_module \\\n--with-http_perl_module=dynamic \\\n--with-stream \\\n--with-stream=dynamic \\\n--with-stream_ssl_module \\\n--with-pcre \\\n--with-pcre-jit\ngmake -j4 &amp;&amp; gmake install\n\nuseradd -s /sbin/nologin -M nginx\nln -sv /application/openresty/nginx  /application/nginx\nln -s /application/openresty/nginx/sbin/nginx  /usr/sbin/nginx \\\n/application/nginx/sbin/nginx\n\n# 设置开机自启动\necho &quot;export PATH=\\$PATH:/application/openresty/nginx/sbin&quot; &gt;&gt;/etc/profile\nsource /etc/profile\nchmod +x /etc/rc.local\necho &quot;/application/openresty/nginx/sbin/nginx&quot; &gt;&gt;/etc/rc.local\n\nmkdir -p /data/tmp/nginx/client_temp\nmkdir -p /data/tmp/nginx/proxy_temp\nchmod 711 /data/tmp/nginx\n\n#安装php###############################################\nyum -y install epel-release\n#cd /application/tools\n#wget http://www.atomicorp.com/installers/atomic\n#sh ./atomic\nyum -y install  gcc gcc-c++   C  autoconf  make mcrypt  mhash zlib zlib-devel pcre pcre-devel  libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers libxslt libxslt-devel libmcrypt libmcrypt-devel libpng12 libpng12-devel libcurl  libcurl-devel readline-devel libXpm-devel gmp gmp-devel  mysql-devel unixODBC unixODBC-devel pspell-devel net-snmp net-snmp-devel\ncd /application/tools\nwget http://cn2.php.net/distributions/php-7.1.2.tar.gz\ntar -zxvf php-7.1.2.tar.gz\ncd php-7.1.2\n./configure \\\n  --prefix=/application/php7 \\\n  --with-mysqli=mysqlnd \\\n  --with-pdo-mysql=mysqlnd \\\n  --with-iconv \\\n  --with-iconv-dir=/usr/local/libiconv \\\n  --with-freetype-dir \\\n  --without-pear \\\n  --with-fpm-user=nginx \\\n  --with-fpm-group=nginx \\\n  --with-jpeg-dir \\\n  --with-png-dir \\\n  --with-zlib \\\n  --with-zlib-dir \\\n  --with-bz2  \\\n  --with-xsl \\\n  --with-xmlrpc \\\n  --with-mhash \\\n  --with-mcrypt \\\n  --with-gd  \\\n  --with-openssl    \\\n  --with-libxml-dir \\\n  --with-readline \\\n  --with-gettext \\\n  --with-pcre-regex \\\n  --with-curl \\\n  --disable-rpath \\\n  --disable-ipv6  \\\n  --disable-debug \\\n  --enable-xml \\\n  --enable-bcmath \\\n  --enable-shmop \\\n  --enable-sysvsem \\\n  --enable-sysvmsg \\\n  --enable-sysvshm \\\n  --enable-mbregex \\\n  --enable-mysqlnd \\\n  --enable-fpm \\\n  --enable-mbstring \\\n  --enable-gd-native-ttf \\\n  --enable-pcntl \\\n  --enable-sockets \\\n  --enable-soap \\\n  --enable-short-tags \\\n  --enable-static \\\n  --enable-ftp \\\n  --enable-opcache=yes \\\n  --enable-json \\\n  --enable-zip\\\n  --enable-exif \\\n  --enable-inline-optimization\n#ln -s /application/mysql/lib/libmysqlclient.so.20 /usr/lib64\nmake -j4 &amp;&amp; make install\n\necho &quot;export PATH=&quot;/application/php7/bin:\\$PATH&quot;&quot; &gt;&gt;/etc/profile\nsource /etc/profile\necho &quot;/application/php7/sbin/php-fpm&quot; &gt;&gt;/etc/rc.local\n\n####################################################\nphp7环境安装模块：\n# 安装emqttd\n#cd /application/tools\n#wget http://emqtt.io/static/brokers/emqttd-centos6.8-v2.1.0-beta.1.zip\n#unzip emqttd-centos6.8-v2.1.0-beta.1.zip\n#cd emqttd\n#./bin/emqttd start\n#./bin/emqttd_ctl status\n\n# 安装memcache、redis、yaf模块\n#cd /application/tools\n#wget http://pecl.php.net/get/memcache-2.2.5.tgz\n#tar xf memcache-2.2.5.tgz\n#cd memcache-2.2.5\n#/application/php/bin/phpize\n#./configure --with-php-config=/application/php/bin/php-config\n#make &amp;&amp; make install\n\n# 安装yaf模块\ncd /application/tools\nwget https://pecl.php.net/get/yaf-3.0.5.tgz\ntar -zxvf yaf-3.0.5.tgz\ncd yaf-3.0.5\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装redis模块\ncd /application/tools\nwget https://github.com/phpredis/phpredis/archive/develop.zip\nunzip develop.zip\ncd phpredis-develop\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装seaslog模块\ncd /application/tools\nwget https://pecl.php.net/get/SeasLog-1.6.9.tgz\ntar -zxvf SeasLog-1.6.9.tgz\ncd SeasLog-1.6.9\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装rabbitmq模块\nyum -y install cmake\ncd /application/tools\nwget https://github.com/alanxz/rabbitmq-c/releases/download/v0.8.0/rabbitmq-c-0.8.0.tar.gz\ntar -zxvf rabbitmq-c-0.8.0.tar.gz\ncd rabbitmq-c-0.8.0\n#mkdir build &amp;&amp; cd build\n#cmake -DCMAKE_INSTALL_PREFIX=/usr/local/librabbitmq ..\n#cmake --build .\n./configure --prefix=/usr/local/rabbitmq-c\nmake -j4 &amp;&amp; make install\ncd /application/tools\nwget https://pecl.php.net/get/amqp-1.9.1.tgz\ntar -zxvf amqp-1.9.1.tgz\ncd amqp-1.9.1\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c/\nmake -j4 &amp;&amp; make install\n\n##php7环境配置\ncd /application/tools/php-7.1.2\n\\cp php.ini-production  /application/php7/lib/php.ini\ncd /application/php7/etc\n\\cp php-fpm.conf.default php-fpm.conf\ncd /application/php7/etc/php-fpm.d/\n\\cp www.conf.default  www.conf\n/application/php7/sbin/php-fpm\n\n# 最后在php.ini定义加载模块就可以\ncat &gt;&gt;/application/php7/lib/php.ini&lt;&lt;EOF\ndate.timezone = &quot;Asia/Shanghai&quot;\nextension=redis.so\nextension=seaslog.so\nextension=yaf.so\nextension = amqp.so\nyaf.environ=cloud\n\nseaslog.default_basepath = /data/appLog/wallet            ;默认log根目录\nseaslog.default_logger = default                        ;默认logger目录\nseaslog.disting_type = 1                                ;是否以type分文件 1是 0否(默认)\nseaslog.disting_by_hour = 1                             ;是否每小时划分一个文件 1是 0否(默认)\nseaslog.use_buffer = 0                                  ;是否启用buffer 1是 0否(默认)\nseaslog.buffer_size = 100                               ;buffer中缓冲数量 默认0(不使用buffer_size)\nseaslog.level = 0                                       ;记录日志级别 默认0(所有日志)\nseaslog.trace_error = 1                                 ;自动记录错误 默认1(开启)\nseaslog.trace_exception = 0                             ;自动记录异常信息 默认0(关闭)\nseaslog.default_datetime_format = &quot;Y:m:d H:i:s&quot;         ;日期格式配置 默认&quot;Y:m:d H:i:s&quot;\nseaslog.appender = 1                                    ;日志存储介质 1File 2TCP 3UDP (默认为1)\nseaslog.remote_host = 127.0.0.1                         ;接收ip 默认127.0.0.1 (当使用TCP或UDP时必填)\nseaslog.remote_port = 514                               ;接收端口 默认514 (当使用TCP或UDP时必填)\nEOF\n#重启php-fpm\npkill php-fpm\n/application/php7/sbin/php-fpm\n\n# 服务开机自启动\ncat &gt;&gt;/etc/rc.local&lt;&lt;EOF\n/application/php/sbin/php-fpm\n/application/nginx/sbin/nginx\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;\nEOF\n\n# 内核调优\ncat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF\nnet.ipv4.tcp_max_syn_backlog = 65536\nnet.core.netdev_max_backlog =  32768\nnet.core.somaxconn = 32768\n\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\n\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 2\n\nnet.ipv4.tcp_tw_recycle = 1\n#net.ipv4.tcp_tw_len = 1\nnet.ipv4.tcp_tw_reuse = 1\n\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_max_orphans = 3276800\n\n#net.ipv4.tcp_fin_timeout = 30\n#net.ipv4.tcp_keepalive_time = 120\nnet.ipv4.ip_local_port_range = 1024  65535\nEOF\n/sbin/sysctl -p\n</code></pre>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"Lnmp一键部署脚本\"><a href=\"#Lnmp一键部署脚本\" class=\"headerlink\" title=\"Lnmp一键部署脚本\"></a>Lnmp一键部署脚本</h2><pre><code>#!/bin/bash\n##DATE:2016-7-25\n##USER:owelinux\n###install wallet\n\n#######install mysql##################################################\nyum -y install cmake ncurses-devel  bison libaio  make gcc gcc-c++\nmkdir  -p /application/tools\ncd /application/tools\nwget http://pkgs.fedoraproject.org/repo/pkgs/community-mysql/mysql-boost-5.7.14.tar.gz/f90464874ee635ff63c436d1b64fe311/mysql-boost-5.7.14.tar.gz\ntar xvf mysql-boost-5.7.14.tar.gz\ncd mysql-5.7.14/\ncmake . -DCMAKE_INSTALL_PREFIX=/application/mysql/ \\\n-DMYSQL_DATADIR=/data/mysqlData/mysql21406/  \\\n-DWITH_MYISAM_STORAGE_ENGINE=1 \\\n-DWITH_INNOBASE_STORAGE_ENGINE=1  \\\n-DDEFAULT_CHARSET=utf8 \\\n-DDEFAULT_COLLATION=utf8_general_ci  \\\n-DDOWNLOAD_BOOST=1 \\\n-DDOWNLOAD_BOOST=1  \\\n-DWITH_BOOST=./boost/ #boost路径修改一下 指向你源码路径\nmake  -j4 &amp;&amp; make install\n\ngroupadd mysql\nuseradd -M -g mysql -s /sbin/nologin mysql\nchown -R mysql:mysql /application/mysql\n\nmkdir -p /data/mysqlData/mysql21406\nmkdir /data/mysqlData/mysql21406/binlog\nmkdir /data/mysqlData/mysql21406/relaylog\nchmod 750 /data/mysqlData/mysql21406/binlog\nchmod 750 /data/mysqlData/mysql21406/relaylog\nchown -R mysql:mysql /data/mysqlData/*\n\n # 初始化mysql\n/application/mysql/bin/mysqld --initialize --user=mysql --basedir=/application/mysql/ --datadir=/data/mysqlData/mysql21406/data\n/application/mysql/bin/mysql_ssl_rsa_setup -d /data/mysqlData/mysql21406/data/\n\n#上传mys.cnf配置文件\ncd /data/mysqlData/mysql21406\nchown -R mysql:mysql /data/mysqlData/mysql21406\n\n# 修改配置文件\nvim /data/mysqlData/mysql21406/my.cnf\n\n# 启动mysql\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;\n/application/mysql/bin/mysql -uroot -S /data/mysqlData/mysql21406/mysql.sock -p\n\n# 设置root密码\nSET PASSWORD =PASSWORD(&#39;root&#39;);\nSET PASSWORD FOR username=PASSWORD(&#39;new password&#39;);\ncreate database zabbix character set utf8 collate utf8_bin;\ngrant all privileges on zabbix.* to &#39;zabbix&#39;@&#39;%&#39;  identified by &#39;zabbix&#39;;\nflush privileges;\n\n\n# 设置开机自启动\necho &quot;export PATH=\\$PATH:/application/mysql/bin&quot;&gt;&gt;/etc/profile\nsource /etc/profile\necho &#39;/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;&#39; &gt;&gt;/etc/rc.local\n\n#安装nginx######################################################\n#useradd -M -s /sbin/nologin nginx\n#mkdir -p /var/log/nginx\n#cd /application/tools\n#wget http://nginx.org/download/nginx-1.10.1.tar.gz\n#tar zxvf nginx-1.10.1.tar.gz\n#cd nginx-1.10.1\n#yum -y install epel-release\n#yum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel freetype freetype-devel\n#./configure --user=nginx --group=nginx --prefix=/application/nginx --with-http_stub_status_module --with-http_ssl_module\n#make &amp;&amp; make install\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\n\n#安装openresty\nyum -y install epel-release\nyum -y install openssl openssl-devel  gcc C pcre pcre-devel bzip2-devel libcurl-devel libpng-devel libmcrypt-devel libxml2-devel libxslt-devel readline-devel gd-devel perl-devel perl-ExtUtils-Embed\nmkdir -p /application/tools\ncd /application/tools\nwget https://openresty.org/download/openresty-1.13.6.1.tar.gz\ntar zxvf openresty-1.13.6.1.tar.gz\ncd openresty-1.13.6.1\n./configure \\\n--prefix=/application/openresty \\\n--with-http_iconv_module \\\n--with-luajit \\\n--user=nginx \\\n--group=nginx \\\n--with-select_module \\\n--with-poll_module \\\n--with-threads \\\n--with-ipv6 \\\n--with-http_v2_module \\\n--with-http_ssl_module \\\n--with-http_realip_module \\\n--with-http_addition_module \\\n--with-http_xslt_module \\\n--with-http_xslt_module=dynamic \\\n--with-http_image_filter_module \\\n--with-http_image_filter_module=dynamic \\\n--with-http_sub_module \\\n--with-http_gunzip_module \\\n--with-http_gzip_static_module \\\n--with-http_auth_request_module \\\n--with-http_random_index_module \\\n--with-http_secure_link_module \\\n--with-http_degradation_module \\\n--with-http_slice_module \\\n--with-http_stub_status_module \\\n--with-http_perl_module \\\n--with-http_perl_module=dynamic \\\n--with-stream \\\n--with-stream=dynamic \\\n--with-stream_ssl_module \\\n--with-pcre \\\n--with-pcre-jit\ngmake -j4 &amp;&amp; gmake install\n\nuseradd -s /sbin/nologin -M nginx\nln -sv /application/openresty/nginx  /application/nginx\nln -s /application/openresty/nginx/sbin/nginx  /usr/sbin/nginx \\\n/application/nginx/sbin/nginx\n\n# 设置开机自启动\necho &quot;export PATH=\\$PATH:/application/openresty/nginx/sbin&quot; &gt;&gt;/etc/profile\nsource /etc/profile\nchmod +x /etc/rc.local\necho &quot;/application/openresty/nginx/sbin/nginx&quot; &gt;&gt;/etc/rc.local\n\nmkdir -p /data/tmp/nginx/client_temp\nmkdir -p /data/tmp/nginx/proxy_temp\nchmod 711 /data/tmp/nginx\n\n#安装php###############################################\nyum -y install epel-release\n#cd /application/tools\n#wget http://www.atomicorp.com/installers/atomic\n#sh ./atomic\nyum -y install  gcc gcc-c++   C  autoconf  make mcrypt  mhash zlib zlib-devel pcre pcre-devel  libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers libxslt libxslt-devel libmcrypt libmcrypt-devel libpng12 libpng12-devel libcurl  libcurl-devel readline-devel libXpm-devel gmp gmp-devel  mysql-devel unixODBC unixODBC-devel pspell-devel net-snmp net-snmp-devel\ncd /application/tools\nwget http://cn2.php.net/distributions/php-7.1.2.tar.gz\ntar -zxvf php-7.1.2.tar.gz\ncd php-7.1.2\n./configure \\\n  --prefix=/application/php7 \\\n  --with-mysqli=mysqlnd \\\n  --with-pdo-mysql=mysqlnd \\\n  --with-iconv \\\n  --with-iconv-dir=/usr/local/libiconv \\\n  --with-freetype-dir \\\n  --without-pear \\\n  --with-fpm-user=nginx \\\n  --with-fpm-group=nginx \\\n  --with-jpeg-dir \\\n  --with-png-dir \\\n  --with-zlib \\\n  --with-zlib-dir \\\n  --with-bz2  \\\n  --with-xsl \\\n  --with-xmlrpc \\\n  --with-mhash \\\n  --with-mcrypt \\\n  --with-gd  \\\n  --with-openssl    \\\n  --with-libxml-dir \\\n  --with-readline \\\n  --with-gettext \\\n  --with-pcre-regex \\\n  --with-curl \\\n  --disable-rpath \\\n  --disable-ipv6  \\\n  --disable-debug \\\n  --enable-xml \\\n  --enable-bcmath \\\n  --enable-shmop \\\n  --enable-sysvsem \\\n  --enable-sysvmsg \\\n  --enable-sysvshm \\\n  --enable-mbregex \\\n  --enable-mysqlnd \\\n  --enable-fpm \\\n  --enable-mbstring \\\n  --enable-gd-native-ttf \\\n  --enable-pcntl \\\n  --enable-sockets \\\n  --enable-soap \\\n  --enable-short-tags \\\n  --enable-static \\\n  --enable-ftp \\\n  --enable-opcache=yes \\\n  --enable-json \\\n  --enable-zip\\\n  --enable-exif \\\n  --enable-inline-optimization\n#ln -s /application/mysql/lib/libmysqlclient.so.20 /usr/lib64\nmake -j4 &amp;&amp; make install\n\necho &quot;export PATH=&quot;/application/php7/bin:\\$PATH&quot;&quot; &gt;&gt;/etc/profile\nsource /etc/profile\necho &quot;/application/php7/sbin/php-fpm&quot; &gt;&gt;/etc/rc.local\n\n####################################################\nphp7环境安装模块：\n# 安装emqttd\n#cd /application/tools\n#wget http://emqtt.io/static/brokers/emqttd-centos6.8-v2.1.0-beta.1.zip\n#unzip emqttd-centos6.8-v2.1.0-beta.1.zip\n#cd emqttd\n#./bin/emqttd start\n#./bin/emqttd_ctl status\n\n# 安装memcache、redis、yaf模块\n#cd /application/tools\n#wget http://pecl.php.net/get/memcache-2.2.5.tgz\n#tar xf memcache-2.2.5.tgz\n#cd memcache-2.2.5\n#/application/php/bin/phpize\n#./configure --with-php-config=/application/php/bin/php-config\n#make &amp;&amp; make install\n\n# 安装yaf模块\ncd /application/tools\nwget https://pecl.php.net/get/yaf-3.0.5.tgz\ntar -zxvf yaf-3.0.5.tgz\ncd yaf-3.0.5\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装redis模块\ncd /application/tools\nwget https://github.com/phpredis/phpredis/archive/develop.zip\nunzip develop.zip\ncd phpredis-develop\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装seaslog模块\ncd /application/tools\nwget https://pecl.php.net/get/SeasLog-1.6.9.tgz\ntar -zxvf SeasLog-1.6.9.tgz\ncd SeasLog-1.6.9\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config\nmake &amp;&amp; make install\n\n# 安装rabbitmq模块\nyum -y install cmake\ncd /application/tools\nwget https://github.com/alanxz/rabbitmq-c/releases/download/v0.8.0/rabbitmq-c-0.8.0.tar.gz\ntar -zxvf rabbitmq-c-0.8.0.tar.gz\ncd rabbitmq-c-0.8.0\n#mkdir build &amp;&amp; cd build\n#cmake -DCMAKE_INSTALL_PREFIX=/usr/local/librabbitmq ..\n#cmake --build .\n./configure --prefix=/usr/local/rabbitmq-c\nmake -j4 &amp;&amp; make install\ncd /application/tools\nwget https://pecl.php.net/get/amqp-1.9.1.tgz\ntar -zxvf amqp-1.9.1.tgz\ncd amqp-1.9.1\n/application/php7/bin/phpize\n./configure --with-php-config=/application/php7/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c/\nmake -j4 &amp;&amp; make install\n\n##php7环境配置\ncd /application/tools/php-7.1.2\n\\cp php.ini-production  /application/php7/lib/php.ini\ncd /application/php7/etc\n\\cp php-fpm.conf.default php-fpm.conf\ncd /application/php7/etc/php-fpm.d/\n\\cp www.conf.default  www.conf\n/application/php7/sbin/php-fpm\n\n# 最后在php.ini定义加载模块就可以\ncat &gt;&gt;/application/php7/lib/php.ini&lt;&lt;EOF\ndate.timezone = &quot;Asia/Shanghai&quot;\nextension=redis.so\nextension=seaslog.so\nextension=yaf.so\nextension = amqp.so\nyaf.environ=cloud\n\nseaslog.default_basepath = /data/appLog/wallet            ;默认log根目录\nseaslog.default_logger = default                        ;默认logger目录\nseaslog.disting_type = 1                                ;是否以type分文件 1是 0否(默认)\nseaslog.disting_by_hour = 1                             ;是否每小时划分一个文件 1是 0否(默认)\nseaslog.use_buffer = 0                                  ;是否启用buffer 1是 0否(默认)\nseaslog.buffer_size = 100                               ;buffer中缓冲数量 默认0(不使用buffer_size)\nseaslog.level = 0                                       ;记录日志级别 默认0(所有日志)\nseaslog.trace_error = 1                                 ;自动记录错误 默认1(开启)\nseaslog.trace_exception = 0                             ;自动记录异常信息 默认0(关闭)\nseaslog.default_datetime_format = &quot;Y:m:d H:i:s&quot;         ;日期格式配置 默认&quot;Y:m:d H:i:s&quot;\nseaslog.appender = 1                                    ;日志存储介质 1File 2TCP 3UDP (默认为1)\nseaslog.remote_host = 127.0.0.1                         ;接收ip 默认127.0.0.1 (当使用TCP或UDP时必填)\nseaslog.remote_port = 514                               ;接收端口 默认514 (当使用TCP或UDP时必填)\nEOF\n#重启php-fpm\npkill php-fpm\n/application/php7/sbin/php-fpm\n\n# 服务开机自启动\ncat &gt;&gt;/etc/rc.local&lt;&lt;EOF\n/application/php/sbin/php-fpm\n/application/nginx/sbin/nginx\n/application/mysql/bin/mysqld_safe --defaults-file=/data/mysqlData/mysql21406/my.cnf --user=mysql &amp;\nEOF\n\n# 内核调优\ncat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF\nnet.ipv4.tcp_max_syn_backlog = 65536\nnet.core.netdev_max_backlog =  32768\nnet.core.somaxconn = 32768\n\nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\n\nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 2\n\nnet.ipv4.tcp_tw_recycle = 1\n#net.ipv4.tcp_tw_len = 1\nnet.ipv4.tcp_tw_reuse = 1\n\nnet.ipv4.tcp_mem = 94500000 915000000 927000000\nnet.ipv4.tcp_max_orphans = 3276800\n\n#net.ipv4.tcp_fin_timeout = 30\n#net.ipv4.tcp_keepalive_time = 120\nnet.ipv4.ip_local_port_range = 1024  65535\nEOF\n/sbin/sysctl -p\n</code></pre>\n"},{"title":"菜鸟运维给小白上手建议","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-16T02:14:54.000Z","password":null,"summary":null,"_content":"\n运维应该怎么分阶段学习？\n\n## 第一阶段：Linux运维基本功\n大致的知识点有这些：\n计算机基础、Linux操作系统、网络基础、VIM编辑器、系统用户与权限、Linux文件系统与内核、系统服务与进程、MySQL数据库、LAMP环境配置+开源项目实战（YUM）\n推荐书籍： 大学计算机基础、跟鸟哥学linux（基础篇和网络篇）\n\n## 第二阶段：Linux运维进阶\n大致的知识点有这些：\nBind高级应用(DNS服务器）、Ftp服务+Nfs服务+Samba服务、Postfix服务+Dovecot服务（邮件服务器）、Shell基础、Ssh服务以及无密码登录、Linux系统安全（防火墙）以及日志、Linux下安装包的管理、压缩工具讲解、Rsync文件同步服务、终极项目：Pxe网络安装系统实战\n\n## 第三阶段：Linux运维高级\n大致的知识点有这些：\nPHP及JAVA环境部署调优、APACHE/NGINX/TOMCAT配置详解与调优、KeepAlived+LVS高可用负载均衡服务器、Nginx+HAProxy实现负载均衡服务器、Varnish/squid反向代理（介绍CDN知识与应用）、分布式存储集群（FastDFS）、Tomcat LB Cluster集群(加强）、ZooKeeper分布式、Zabbix监控、ELK日志分析搭建、Git版本控制软件、初级运维自动化 Saltstack Puppet（基础）、大型项目架构与性能调优（Nagios、Cacti、ONEAPM）、终极项目：阿里云产品实战（ECS、RDS、LSB、安全）\n\n## 第四阶段：DBA阶段\n大致的知识点有这些：\nMySQL基础操作、MySQL高级查询、MySQL权限管理、MySQL备份、还原与数据恢复、MySQL数据库管理工具介绍与实战、MySQL高级（索引与优化）、MySQL主从复制与读写分离、数据库中间件MyCAT，Altas，Amoeba实践与对比、Memcache技术Redis技术+集群、MongoDB技术+集群、终极项目：超大型数据库案例实战\n\n## 第五阶段：Shell编程阶段\n大致的知识点：\nShell编程进阶、Shell核心应用（集成到进阶）、正则表达式、文件操作实战（grep、sed、awk）、Shell实战（Zabbix扩展-Shell监控）\n\n## 第六阶段：Linux云计算阶段\n大致的知识点：\n虚拟化技术、SaltStack进阶、Openstack自动化运维、Docker实战Jenkins+MavenHadoop、云计算、DevOps、项目实战：Openstack + Docker运维实战","source":"_posts/linux-suggest.md","raw":"---\ntitle: 菜鸟运维给小白上手建议\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2018-07-16 10:14:54\npassword:\nsummary:\ntags:\n- 学习方法\ncategories:\n- linux\n---\n\n运维应该怎么分阶段学习？\n\n## 第一阶段：Linux运维基本功\n大致的知识点有这些：\n计算机基础、Linux操作系统、网络基础、VIM编辑器、系统用户与权限、Linux文件系统与内核、系统服务与进程、MySQL数据库、LAMP环境配置+开源项目实战（YUM）\n推荐书籍： 大学计算机基础、跟鸟哥学linux（基础篇和网络篇）\n\n## 第二阶段：Linux运维进阶\n大致的知识点有这些：\nBind高级应用(DNS服务器）、Ftp服务+Nfs服务+Samba服务、Postfix服务+Dovecot服务（邮件服务器）、Shell基础、Ssh服务以及无密码登录、Linux系统安全（防火墙）以及日志、Linux下安装包的管理、压缩工具讲解、Rsync文件同步服务、终极项目：Pxe网络安装系统实战\n\n## 第三阶段：Linux运维高级\n大致的知识点有这些：\nPHP及JAVA环境部署调优、APACHE/NGINX/TOMCAT配置详解与调优、KeepAlived+LVS高可用负载均衡服务器、Nginx+HAProxy实现负载均衡服务器、Varnish/squid反向代理（介绍CDN知识与应用）、分布式存储集群（FastDFS）、Tomcat LB Cluster集群(加强）、ZooKeeper分布式、Zabbix监控、ELK日志分析搭建、Git版本控制软件、初级运维自动化 Saltstack Puppet（基础）、大型项目架构与性能调优（Nagios、Cacti、ONEAPM）、终极项目：阿里云产品实战（ECS、RDS、LSB、安全）\n\n## 第四阶段：DBA阶段\n大致的知识点有这些：\nMySQL基础操作、MySQL高级查询、MySQL权限管理、MySQL备份、还原与数据恢复、MySQL数据库管理工具介绍与实战、MySQL高级（索引与优化）、MySQL主从复制与读写分离、数据库中间件MyCAT，Altas，Amoeba实践与对比、Memcache技术Redis技术+集群、MongoDB技术+集群、终极项目：超大型数据库案例实战\n\n## 第五阶段：Shell编程阶段\n大致的知识点：\nShell编程进阶、Shell核心应用（集成到进阶）、正则表达式、文件操作实战（grep、sed、awk）、Shell实战（Zabbix扩展-Shell监控）\n\n## 第六阶段：Linux云计算阶段\n大致的知识点：\n虚拟化技术、SaltStack进阶、Openstack自动化运维、Docker实战Jenkins+MavenHadoop、云计算、DevOps、项目实战：Openstack + Docker运维实战","slug":"linux-suggest","published":1,"updated":"2021-02-20T09:37:35.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq21004nyc97gin9febt","content":"<p>运维应该怎么分阶段学习？</p>\n<h2 id=\"第一阶段：Linux运维基本功\"><a href=\"#第一阶段：Linux运维基本功\" class=\"headerlink\" title=\"第一阶段：Linux运维基本功\"></a>第一阶段：Linux运维基本功</h2><p>大致的知识点有这些：<br>计算机基础、Linux操作系统、网络基础、VIM编辑器、系统用户与权限、Linux文件系统与内核、系统服务与进程、MySQL数据库、LAMP环境配置+开源项目实战（YUM）<br>推荐书籍： 大学计算机基础、跟鸟哥学linux（基础篇和网络篇）</p>\n<h2 id=\"第二阶段：Linux运维进阶\"><a href=\"#第二阶段：Linux运维进阶\" class=\"headerlink\" title=\"第二阶段：Linux运维进阶\"></a>第二阶段：Linux运维进阶</h2><p>大致的知识点有这些：<br>Bind高级应用(DNS服务器）、Ftp服务+Nfs服务+Samba服务、Postfix服务+Dovecot服务（邮件服务器）、Shell基础、Ssh服务以及无密码登录、Linux系统安全（防火墙）以及日志、Linux下安装包的管理、压缩工具讲解、Rsync文件同步服务、终极项目：Pxe网络安装系统实战</p>\n<h2 id=\"第三阶段：Linux运维高级\"><a href=\"#第三阶段：Linux运维高级\" class=\"headerlink\" title=\"第三阶段：Linux运维高级\"></a>第三阶段：Linux运维高级</h2><p>大致的知识点有这些：<br>PHP及JAVA环境部署调优、APACHE/NGINX/TOMCAT配置详解与调优、KeepAlived+LVS高可用负载均衡服务器、Nginx+HAProxy实现负载均衡服务器、Varnish/squid反向代理（介绍CDN知识与应用）、分布式存储集群（FastDFS）、Tomcat LB Cluster集群(加强）、ZooKeeper分布式、Zabbix监控、ELK日志分析搭建、Git版本控制软件、初级运维自动化 Saltstack Puppet（基础）、大型项目架构与性能调优（Nagios、Cacti、ONEAPM）、终极项目：阿里云产品实战（ECS、RDS、LSB、安全）</p>\n<h2 id=\"第四阶段：DBA阶段\"><a href=\"#第四阶段：DBA阶段\" class=\"headerlink\" title=\"第四阶段：DBA阶段\"></a>第四阶段：DBA阶段</h2><p>大致的知识点有这些：<br>MySQL基础操作、MySQL高级查询、MySQL权限管理、MySQL备份、还原与数据恢复、MySQL数据库管理工具介绍与实战、MySQL高级（索引与优化）、MySQL主从复制与读写分离、数据库中间件MyCAT，Altas，Amoeba实践与对比、Memcache技术Redis技术+集群、MongoDB技术+集群、终极项目：超大型数据库案例实战</p>\n<h2 id=\"第五阶段：Shell编程阶段\"><a href=\"#第五阶段：Shell编程阶段\" class=\"headerlink\" title=\"第五阶段：Shell编程阶段\"></a>第五阶段：Shell编程阶段</h2><p>大致的知识点：<br>Shell编程进阶、Shell核心应用（集成到进阶）、正则表达式、文件操作实战（grep、sed、awk）、Shell实战（Zabbix扩展-Shell监控）</p>\n<h2 id=\"第六阶段：Linux云计算阶段\"><a href=\"#第六阶段：Linux云计算阶段\" class=\"headerlink\" title=\"第六阶段：Linux云计算阶段\"></a>第六阶段：Linux云计算阶段</h2><p>大致的知识点：<br>虚拟化技术、SaltStack进阶、Openstack自动化运维、Docker实战Jenkins+MavenHadoop、云计算、DevOps、项目实战：Openstack + Docker运维实战</p>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>运维应该怎么分阶段学习？</p>\n<h2 id=\"第一阶段：Linux运维基本功\"><a href=\"#第一阶段：Linux运维基本功\" class=\"headerlink\" title=\"第一阶段：Linux运维基本功\"></a>第一阶段：Linux运维基本功</h2><p>大致的知识点有这些：<br>计算机基础、Linux操作系统、网络基础、VIM编辑器、系统用户与权限、Linux文件系统与内核、系统服务与进程、MySQL数据库、LAMP环境配置+开源项目实战（YUM）<br>推荐书籍： 大学计算机基础、跟鸟哥学linux（基础篇和网络篇）</p>\n<h2 id=\"第二阶段：Linux运维进阶\"><a href=\"#第二阶段：Linux运维进阶\" class=\"headerlink\" title=\"第二阶段：Linux运维进阶\"></a>第二阶段：Linux运维进阶</h2><p>大致的知识点有这些：<br>Bind高级应用(DNS服务器）、Ftp服务+Nfs服务+Samba服务、Postfix服务+Dovecot服务（邮件服务器）、Shell基础、Ssh服务以及无密码登录、Linux系统安全（防火墙）以及日志、Linux下安装包的管理、压缩工具讲解、Rsync文件同步服务、终极项目：Pxe网络安装系统实战</p>\n<h2 id=\"第三阶段：Linux运维高级\"><a href=\"#第三阶段：Linux运维高级\" class=\"headerlink\" title=\"第三阶段：Linux运维高级\"></a>第三阶段：Linux运维高级</h2><p>大致的知识点有这些：<br>PHP及JAVA环境部署调优、APACHE/NGINX/TOMCAT配置详解与调优、KeepAlived+LVS高可用负载均衡服务器、Nginx+HAProxy实现负载均衡服务器、Varnish/squid反向代理（介绍CDN知识与应用）、分布式存储集群（FastDFS）、Tomcat LB Cluster集群(加强）、ZooKeeper分布式、Zabbix监控、ELK日志分析搭建、Git版本控制软件、初级运维自动化 Saltstack Puppet（基础）、大型项目架构与性能调优（Nagios、Cacti、ONEAPM）、终极项目：阿里云产品实战（ECS、RDS、LSB、安全）</p>\n<h2 id=\"第四阶段：DBA阶段\"><a href=\"#第四阶段：DBA阶段\" class=\"headerlink\" title=\"第四阶段：DBA阶段\"></a>第四阶段：DBA阶段</h2><p>大致的知识点有这些：<br>MySQL基础操作、MySQL高级查询、MySQL权限管理、MySQL备份、还原与数据恢复、MySQL数据库管理工具介绍与实战、MySQL高级（索引与优化）、MySQL主从复制与读写分离、数据库中间件MyCAT，Altas，Amoeba实践与对比、Memcache技术Redis技术+集群、MongoDB技术+集群、终极项目：超大型数据库案例实战</p>\n<h2 id=\"第五阶段：Shell编程阶段\"><a href=\"#第五阶段：Shell编程阶段\" class=\"headerlink\" title=\"第五阶段：Shell编程阶段\"></a>第五阶段：Shell编程阶段</h2><p>大致的知识点：<br>Shell编程进阶、Shell核心应用（集成到进阶）、正则表达式、文件操作实战（grep、sed、awk）、Shell实战（Zabbix扩展-Shell监控）</p>\n<h2 id=\"第六阶段：Linux云计算阶段\"><a href=\"#第六阶段：Linux云计算阶段\" class=\"headerlink\" title=\"第六阶段：Linux云计算阶段\"></a>第六阶段：Linux云计算阶段</h2><p>大致的知识点：<br>虚拟化技术、SaltStack进阶、Openstack自动化运维、Docker实战Jenkins+MavenHadoop、云计算、DevOps、项目实战：Openstack + Docker运维实战</p>\n"},{"title":"运维必须熟悉的工具汇总","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2018-07-19T02:14:54.000Z","password":null,"summary":null,"_content":"\n- 操作系统：Centos※, Ubuntu, Redhat※, suse，Freebsd\n- 网站服务：Openresry(Nginx)※, Apache※, Lighttpd, Php※, Tomcat※, Resin\n- 数据库：MySQL※, MariaDB，PostgreSQL, InfluxDB, Oracle\n- DB中间件：MyCat, Amoeba, MySQL-proxy\n- 代理相关：Lvs+Keepalived, Haproxy(七层), Nginx（四层+七层）, Apache, Heartbeat, Squid（此行都是※）\n- 网站缓存：Squid※, Nginx※, Varnish\n- NOSQL库：Memcached※,Memcachedb,TokyoTyrant※,MongoDB※,Cassandra※,Redis※,CouchDB, Codis, Pika\n- 存储相关：Nfs※, Moosefs(mfs)※, Hadoop※, glusterfs※, Lustre, FastDFS\n- 版本管理：svn※, git※\n- 监控报警：Nagios※, Cacti※, Zabbix※, Munin, Hyperic, Mrtg, Graphite, smokping, Prometheus， Grafana\n- 域名解析：Bind※, Powerdns, Dnsmasq※\n- 同步软件:Rsync※,Inotify※,Sersync※,Drbd※,Csync2, Union,Lsyncd,Scp※\n- 批量管理：Ssh+Rsync+Sersync※, Saltstack※, Expect※, Puppet※, Ansible, Cfengine\n- 虚拟化：kvm※, Xen※, Docker, K8s\n- 云计算：Openstack※, Docker, Cloudstack\n- 内网软件：Iptables※, Zebra※, Iftraf, Ntop※, Tc※, Iftop, Traceroute, Jstack, Vmstat, Lsof, Sar, Iftop\n- 邮件软件：Qmail, Posfix※, Sendmail\n- 远程拨号：Openvpn※, Pptp, Openswan※, Ipip※\n- 统一认证：Openldap(可结合微软活动目录)※\n- 队列工具：ActiveMQ, RabbitMQ※, Metaq, MemcacheQ, Zeromq\n- 打包发布：Mvn※, Ants※, Jenkins※, Svn\n- 测试软件：Ab,Smokeping, Siege, JMeter, Webbench, LoadRunner, http_load（都是※）\n- 日志相关：Syslog, Rsyslog, Awstats, Flume logstash scribe Kafka, Storm，ELK(Elasticsearch+Logstash+Kibana)\n- DB代理：Mysql-proxy, Amoeba（更多还是程序实现读写分离）\n- 搜索软件：Sphinx,Xapian（大公司会自己开发类似百度的小规模内部搜索引擎）\n\n### 提示：\n- 以上所有软件参照老男孩老师整理归档，另外更新了最近几年工作中用的最多的。\n- 带※的为最近几年用的比较多，可信任使用的。\n- 需要了解具体，直接Google官方文档即可。\n- 以上软件掌握带*的就行，万变不离其宗，做到举一反三。","source":"_posts/linux-tools.md","raw":"---\ntitle: 运维必须熟悉的工具汇总\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2018-07-19 10:14:54\npassword:\nsummary:\ntags:\n- 运维工具\ncategories:\n- linux\n---\n\n- 操作系统：Centos※, Ubuntu, Redhat※, suse，Freebsd\n- 网站服务：Openresry(Nginx)※, Apache※, Lighttpd, Php※, Tomcat※, Resin\n- 数据库：MySQL※, MariaDB，PostgreSQL, InfluxDB, Oracle\n- DB中间件：MyCat, Amoeba, MySQL-proxy\n- 代理相关：Lvs+Keepalived, Haproxy(七层), Nginx（四层+七层）, Apache, Heartbeat, Squid（此行都是※）\n- 网站缓存：Squid※, Nginx※, Varnish\n- NOSQL库：Memcached※,Memcachedb,TokyoTyrant※,MongoDB※,Cassandra※,Redis※,CouchDB, Codis, Pika\n- 存储相关：Nfs※, Moosefs(mfs)※, Hadoop※, glusterfs※, Lustre, FastDFS\n- 版本管理：svn※, git※\n- 监控报警：Nagios※, Cacti※, Zabbix※, Munin, Hyperic, Mrtg, Graphite, smokping, Prometheus， Grafana\n- 域名解析：Bind※, Powerdns, Dnsmasq※\n- 同步软件:Rsync※,Inotify※,Sersync※,Drbd※,Csync2, Union,Lsyncd,Scp※\n- 批量管理：Ssh+Rsync+Sersync※, Saltstack※, Expect※, Puppet※, Ansible, Cfengine\n- 虚拟化：kvm※, Xen※, Docker, K8s\n- 云计算：Openstack※, Docker, Cloudstack\n- 内网软件：Iptables※, Zebra※, Iftraf, Ntop※, Tc※, Iftop, Traceroute, Jstack, Vmstat, Lsof, Sar, Iftop\n- 邮件软件：Qmail, Posfix※, Sendmail\n- 远程拨号：Openvpn※, Pptp, Openswan※, Ipip※\n- 统一认证：Openldap(可结合微软活动目录)※\n- 队列工具：ActiveMQ, RabbitMQ※, Metaq, MemcacheQ, Zeromq\n- 打包发布：Mvn※, Ants※, Jenkins※, Svn\n- 测试软件：Ab,Smokeping, Siege, JMeter, Webbench, LoadRunner, http_load（都是※）\n- 日志相关：Syslog, Rsyslog, Awstats, Flume logstash scribe Kafka, Storm，ELK(Elasticsearch+Logstash+Kibana)\n- DB代理：Mysql-proxy, Amoeba（更多还是程序实现读写分离）\n- 搜索软件：Sphinx,Xapian（大公司会自己开发类似百度的小规模内部搜索引擎）\n\n### 提示：\n- 以上所有软件参照老男孩老师整理归档，另外更新了最近几年工作中用的最多的。\n- 带※的为最近几年用的比较多，可信任使用的。\n- 需要了解具体，直接Google官方文档即可。\n- 以上软件掌握带*的就行，万变不离其宗，做到举一反三。","slug":"linux-tools","published":1,"updated":"2021-02-20T09:39:04.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq22004ryc97ecpt2u72","content":"<ul>\n<li>操作系统：Centos※, Ubuntu, Redhat※, suse，Freebsd</li>\n<li>网站服务：Openresry(Nginx)※, Apache※, Lighttpd, Php※, Tomcat※, Resin</li>\n<li>数据库：MySQL※, MariaDB，PostgreSQL, InfluxDB, Oracle</li>\n<li>DB中间件：MyCat, Amoeba, MySQL-proxy</li>\n<li>代理相关：Lvs+Keepalived, Haproxy(七层), Nginx（四层+七层）, Apache, Heartbeat, Squid（此行都是※）</li>\n<li>网站缓存：Squid※, Nginx※, Varnish</li>\n<li>NOSQL库：Memcached※,Memcachedb,TokyoTyrant※,MongoDB※,Cassandra※,Redis※,CouchDB, Codis, Pika</li>\n<li>存储相关：Nfs※, Moosefs(mfs)※, Hadoop※, glusterfs※, Lustre, FastDFS</li>\n<li>版本管理：svn※, git※</li>\n<li>监控报警：Nagios※, Cacti※, Zabbix※, Munin, Hyperic, Mrtg, Graphite, smokping, Prometheus， Grafana</li>\n<li>域名解析：Bind※, Powerdns, Dnsmasq※</li>\n<li>同步软件:Rsync※,Inotify※,Sersync※,Drbd※,Csync2, Union,Lsyncd,Scp※</li>\n<li>批量管理：Ssh+Rsync+Sersync※, Saltstack※, Expect※, Puppet※, Ansible, Cfengine</li>\n<li>虚拟化：kvm※, Xen※, Docker, K8s</li>\n<li>云计算：Openstack※, Docker, Cloudstack</li>\n<li>内网软件：Iptables※, Zebra※, Iftraf, Ntop※, Tc※, Iftop, Traceroute, Jstack, Vmstat, Lsof, Sar, Iftop</li>\n<li>邮件软件：Qmail, Posfix※, Sendmail</li>\n<li>远程拨号：Openvpn※, Pptp, Openswan※, Ipip※</li>\n<li>统一认证：Openldap(可结合微软活动目录)※</li>\n<li>队列工具：ActiveMQ, RabbitMQ※, Metaq, MemcacheQ, Zeromq</li>\n<li>打包发布：Mvn※, Ants※, Jenkins※, Svn</li>\n<li>测试软件：Ab,Smokeping, Siege, JMeter, Webbench, LoadRunner, http_load（都是※）</li>\n<li>日志相关：Syslog, Rsyslog, Awstats, Flume logstash scribe Kafka, Storm，ELK(Elasticsearch+Logstash+Kibana)</li>\n<li>DB代理：Mysql-proxy, Amoeba（更多还是程序实现读写分离）</li>\n<li>搜索软件：Sphinx,Xapian（大公司会自己开发类似百度的小规模内部搜索引擎）</li>\n</ul>\n<h3 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h3><ul>\n<li>以上所有软件参照老男孩老师整理归档，另外更新了最近几年工作中用的最多的。</li>\n<li>带※的为最近几年用的比较多，可信任使用的。</li>\n<li>需要了解具体，直接Google官方文档即可。</li>\n<li>以上软件掌握带*的就行，万变不离其宗，做到举一反三。</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<ul>\n<li>操作系统：Centos※, Ubuntu, Redhat※, suse，Freebsd</li>\n<li>网站服务：Openresry(Nginx)※, Apache※, Lighttpd, Php※, Tomcat※, Resin</li>\n<li>数据库：MySQL※, MariaDB，PostgreSQL, InfluxDB, Oracle</li>\n<li>DB中间件：MyCat, Amoeba, MySQL-proxy</li>\n<li>代理相关：Lvs+Keepalived, Haproxy(七层), Nginx（四层+七层）, Apache, Heartbeat, Squid（此行都是※）</li>\n<li>网站缓存：Squid※, Nginx※, Varnish</li>\n<li>NOSQL库：Memcached※,Memcachedb,TokyoTyrant※,MongoDB※,Cassandra※,Redis※,CouchDB, Codis, Pika</li>\n<li>存储相关：Nfs※, Moosefs(mfs)※, Hadoop※, glusterfs※, Lustre, FastDFS</li>\n<li>版本管理：svn※, git※</li>\n<li>监控报警：Nagios※, Cacti※, Zabbix※, Munin, Hyperic, Mrtg, Graphite, smokping, Prometheus， Grafana</li>\n<li>域名解析：Bind※, Powerdns, Dnsmasq※</li>\n<li>同步软件:Rsync※,Inotify※,Sersync※,Drbd※,Csync2, Union,Lsyncd,Scp※</li>\n<li>批量管理：Ssh+Rsync+Sersync※, Saltstack※, Expect※, Puppet※, Ansible, Cfengine</li>\n<li>虚拟化：kvm※, Xen※, Docker, K8s</li>\n<li>云计算：Openstack※, Docker, Cloudstack</li>\n<li>内网软件：Iptables※, Zebra※, Iftraf, Ntop※, Tc※, Iftop, Traceroute, Jstack, Vmstat, Lsof, Sar, Iftop</li>\n<li>邮件软件：Qmail, Posfix※, Sendmail</li>\n<li>远程拨号：Openvpn※, Pptp, Openswan※, Ipip※</li>\n<li>统一认证：Openldap(可结合微软活动目录)※</li>\n<li>队列工具：ActiveMQ, RabbitMQ※, Metaq, MemcacheQ, Zeromq</li>\n<li>打包发布：Mvn※, Ants※, Jenkins※, Svn</li>\n<li>测试软件：Ab,Smokeping, Siege, JMeter, Webbench, LoadRunner, http_load（都是※）</li>\n<li>日志相关：Syslog, Rsyslog, Awstats, Flume logstash scribe Kafka, Storm，ELK(Elasticsearch+Logstash+Kibana)</li>\n<li>DB代理：Mysql-proxy, Amoeba（更多还是程序实现读写分离）</li>\n<li>搜索软件：Sphinx,Xapian（大公司会自己开发类似百度的小规模内部搜索引擎）</li>\n</ul>\n<h3 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h3><ul>\n<li>以上所有软件参照老男孩老师整理归档，另外更新了最近几年工作中用的最多的。</li>\n<li>带※的为最近几年用的比较多，可信任使用的。</li>\n<li>需要了解具体，直接Google官方文档即可。</li>\n<li>以上软件掌握带*的就行，万变不离其宗，做到举一反三。</li>\n</ul>\n"},{"title":"个人收藏工具","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-02-18T06:46:25.000Z","password":null,"summary":null,"_content":"## 在线工具\n\n* [站长工具](http://tool.chinaz.com/)\n\n* [字节换算](http://www.bangnishouji.com/tools/Byte_calculate.html)\n\n* [unicode编码转换器](http://www.bangnishouji.com/tools/chtounicode.html)\n\n* [子网掩码计算器](http://www.bangnishouji.com/tools/subnet_mask.html)\n\n* [BASE64编码解码](http://www.bangnishouji.com/tools/base64.html)\n\n* [图床 https://sm.ms/](https://sm.ms/)\n\n* [Unix 时间戳 Unix timestamp](http://tool.chinaz.com/Tools/unixtime.aspx)\n\n* [在线正则表达式匹配](https://regex101.com/)\n\n* [http://regexr.com/](http://regexr.com/)\n\n* [json在线解析](https://www.json.cn/)\n\n* [google fonts](https://fonts.google.com/)\n\n* [Google Fonts 加速代理](https://fengmk2.com/blog/2016/google-fonts-mirror)\n\n* [时间服务器](http://www.pool.ntp.org)\n\n* [在线文件对比工具](http://www.newjson.com/Static/Tools/Diff.html)\n\n* [在线markdown1](https://pandao.github.io/editor.md/)\n\n* [在线markdown2](https://www.zybuluo.com/mdeditor)\n\n* [grokdebug](http://grokdebug.herokuapp.com/)\n\n### 网站\n* [在线网站速度检测工具](http://tools.pingdom.com/fpt)\n\n* [在线网站优化测试平台](https://www.dareboost.com)\n\n* [在线网站安全检测工具](http://www.urlvoid.com)\n\n* [网站SEO检测免费应用平台](http://www.woorank.com)\n\n## 运维工具\n\n### shell连接\n\n* [securecrt](https://www.vandyke.com/products/securecrt/index.html)\n\n* [xshell](https://www.netsarang.com/products/xsh_overview.html)\n\n### 文件对比\n\n* [Beyond](http://www.scootersoftware.com/download.php)\n\n### 文件查找\n\n* [Everying](https://www.voidtools.com/)\n\n### 文件去重\n* [https://www.duplicatecleaner.com/](https://www.duplicatecleaner.com/)\n\n### 代码编辑器\n\n* [jetbrains](https://www.jetbrains.com)\n\n### 密码管理\n\n* [keepass](https://keepass.info/)\n\n* [keepass中文](https://keepass.info/translations.html)\n\n### 文件编辑器\n* [notepad++](https://notepad-plus-plus.org/)\n\n* [emeditor](https://www.emeditor.com/)\n\n* [sublimetext](https://www.sublimetext.com/)\n\n### 笔记记录\n* [cherrytree](https://www.giuspen.com/cherrytree/#downl)\n\n### host切换\n* [SwitchHosts](https://github.com/oldj/SwitchHosts/releases)\n\n### 虚拟机\n* [vmware](https://my.vmware.com/group/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/14_0)\n\nVMware 2018 v14.x 永久许可证激活密钥\n\n* FF31K-AHZD1-H8ETZ-8WWEZ-WUUVA\n* CV7T2-6WY5Q-48EWP-ZXY7X-QGUWD\n\n## windos工具\n\n### 编辑\n\n* [MarkdownPad](http://www.markdownpad.com/)\n\n* [MarkPad](http://code52.org/DownmarkerWPF/)\n\n* [notepad++](https://notepad-plus-plus.org/)\n\n* [sublimetext](https://www.sublimetext.com/)\n\n### 浏览器\n\n* [Google](https://www.google.cn/chrome/index.html)\n\n* [Google离线版](https://www.chrome64bit.com/)\n\n* [Firefox](https://www.firefox.com.cn/)\n\n### 压缩工具\n\n* [7zip](https://www.7-zip.org/download.html)\n\n### 代码管理\n\n* [svn](https://tortoisesvn.net/)\n* [git](https://git-scm.com/)\n\n## 软件下载\n\n* [softpedia](https://www.softpedia.com/)\n\n* [nirsoft](https://www.nirsoft.net/)\n\n* [lo4d](https://www.lo4d.com/)\n\n\n## GitBook 及其插件\n\n* [Gitbook 的使用和常用插件 -赵达](http://zhaoda.net/2015/11/09/gitbook-plugins/)\n* [gitbook-plugin-expandable-chapters](https://plugins.gitbook.com/plugin/expandable-chapters)\n\n    折叠左侧目录章节。\n\n    <!-- ![](http://ww4.sinaimg.cn/large/7011d6cfjw1f08kmplbj1j20gn05l0tk.jpg) -->\n\n## Chrome 插件\n- [Octotree](https://chrome.google.com/webstore/detail/octotree/bkhaagjahfmjljalopjnoealnfndnagc)\n\n    - Code tree for GitHub and GitLab\n\n* [Chrome扩展及应用开发 -图灵电子书](http://www.ituring.com.cn/minibook/950)\n\n* [有哪些鲜为人知却非常有意思、好用的 Chrome 扩展？ -知乎](https://www.zhihu.com/question/23228162#answer-28057391)\n* [Dribbble New Tab](https://chrome.google.com/webstore/detail/dribbble-new-tab/hmhjbefkpednjogghoibpejdmemkinbn)\n\n    新建 tab 时，显示 dribbble 上的精选作品。\n\n## Other blogs\n\n- [COLORFUL xiaoa](http://www.xiaoa.name/)\n\n* [进击的马斯特 http://pinkyjie.com/](http://pinkyjie.com/)\n\n    马斯特，87年生人，爱溜冰的码农。技术： Javascript、Python、Mac、iOS\n","source":"_posts/个人收藏工具.md","raw":"---\ntitle: 个人收藏工具\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-02-18 14:46:25\npassword:\nsummary:\ntags:\ncategories:\n---\n## 在线工具\n\n* [站长工具](http://tool.chinaz.com/)\n\n* [字节换算](http://www.bangnishouji.com/tools/Byte_calculate.html)\n\n* [unicode编码转换器](http://www.bangnishouji.com/tools/chtounicode.html)\n\n* [子网掩码计算器](http://www.bangnishouji.com/tools/subnet_mask.html)\n\n* [BASE64编码解码](http://www.bangnishouji.com/tools/base64.html)\n\n* [图床 https://sm.ms/](https://sm.ms/)\n\n* [Unix 时间戳 Unix timestamp](http://tool.chinaz.com/Tools/unixtime.aspx)\n\n* [在线正则表达式匹配](https://regex101.com/)\n\n* [http://regexr.com/](http://regexr.com/)\n\n* [json在线解析](https://www.json.cn/)\n\n* [google fonts](https://fonts.google.com/)\n\n* [Google Fonts 加速代理](https://fengmk2.com/blog/2016/google-fonts-mirror)\n\n* [时间服务器](http://www.pool.ntp.org)\n\n* [在线文件对比工具](http://www.newjson.com/Static/Tools/Diff.html)\n\n* [在线markdown1](https://pandao.github.io/editor.md/)\n\n* [在线markdown2](https://www.zybuluo.com/mdeditor)\n\n* [grokdebug](http://grokdebug.herokuapp.com/)\n\n### 网站\n* [在线网站速度检测工具](http://tools.pingdom.com/fpt)\n\n* [在线网站优化测试平台](https://www.dareboost.com)\n\n* [在线网站安全检测工具](http://www.urlvoid.com)\n\n* [网站SEO检测免费应用平台](http://www.woorank.com)\n\n## 运维工具\n\n### shell连接\n\n* [securecrt](https://www.vandyke.com/products/securecrt/index.html)\n\n* [xshell](https://www.netsarang.com/products/xsh_overview.html)\n\n### 文件对比\n\n* [Beyond](http://www.scootersoftware.com/download.php)\n\n### 文件查找\n\n* [Everying](https://www.voidtools.com/)\n\n### 文件去重\n* [https://www.duplicatecleaner.com/](https://www.duplicatecleaner.com/)\n\n### 代码编辑器\n\n* [jetbrains](https://www.jetbrains.com)\n\n### 密码管理\n\n* [keepass](https://keepass.info/)\n\n* [keepass中文](https://keepass.info/translations.html)\n\n### 文件编辑器\n* [notepad++](https://notepad-plus-plus.org/)\n\n* [emeditor](https://www.emeditor.com/)\n\n* [sublimetext](https://www.sublimetext.com/)\n\n### 笔记记录\n* [cherrytree](https://www.giuspen.com/cherrytree/#downl)\n\n### host切换\n* [SwitchHosts](https://github.com/oldj/SwitchHosts/releases)\n\n### 虚拟机\n* [vmware](https://my.vmware.com/group/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/14_0)\n\nVMware 2018 v14.x 永久许可证激活密钥\n\n* FF31K-AHZD1-H8ETZ-8WWEZ-WUUVA\n* CV7T2-6WY5Q-48EWP-ZXY7X-QGUWD\n\n## windos工具\n\n### 编辑\n\n* [MarkdownPad](http://www.markdownpad.com/)\n\n* [MarkPad](http://code52.org/DownmarkerWPF/)\n\n* [notepad++](https://notepad-plus-plus.org/)\n\n* [sublimetext](https://www.sublimetext.com/)\n\n### 浏览器\n\n* [Google](https://www.google.cn/chrome/index.html)\n\n* [Google离线版](https://www.chrome64bit.com/)\n\n* [Firefox](https://www.firefox.com.cn/)\n\n### 压缩工具\n\n* [7zip](https://www.7-zip.org/download.html)\n\n### 代码管理\n\n* [svn](https://tortoisesvn.net/)\n* [git](https://git-scm.com/)\n\n## 软件下载\n\n* [softpedia](https://www.softpedia.com/)\n\n* [nirsoft](https://www.nirsoft.net/)\n\n* [lo4d](https://www.lo4d.com/)\n\n\n## GitBook 及其插件\n\n* [Gitbook 的使用和常用插件 -赵达](http://zhaoda.net/2015/11/09/gitbook-plugins/)\n* [gitbook-plugin-expandable-chapters](https://plugins.gitbook.com/plugin/expandable-chapters)\n\n    折叠左侧目录章节。\n\n    <!-- ![](http://ww4.sinaimg.cn/large/7011d6cfjw1f08kmplbj1j20gn05l0tk.jpg) -->\n\n## Chrome 插件\n- [Octotree](https://chrome.google.com/webstore/detail/octotree/bkhaagjahfmjljalopjnoealnfndnagc)\n\n    - Code tree for GitHub and GitLab\n\n* [Chrome扩展及应用开发 -图灵电子书](http://www.ituring.com.cn/minibook/950)\n\n* [有哪些鲜为人知却非常有意思、好用的 Chrome 扩展？ -知乎](https://www.zhihu.com/question/23228162#answer-28057391)\n* [Dribbble New Tab](https://chrome.google.com/webstore/detail/dribbble-new-tab/hmhjbefkpednjogghoibpejdmemkinbn)\n\n    新建 tab 时，显示 dribbble 上的精选作品。\n\n## Other blogs\n\n- [COLORFUL xiaoa](http://www.xiaoa.name/)\n\n* [进击的马斯特 http://pinkyjie.com/](http://pinkyjie.com/)\n\n    马斯特，87年生人，爱溜冰的码农。技术： Javascript、Python、Mac、iOS\n","slug":"个人收藏工具","published":1,"updated":"2021-02-18T06:47:38.413Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckm1fhq23004syc970rci02am","content":"<h2 id=\"在线工具\"><a href=\"#在线工具\" class=\"headerlink\" title=\"在线工具\"></a>在线工具</h2><ul>\n<li><p><a href=\"http://tool.chinaz.com/\">站长工具</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/Byte_calculate.html\">字节换算</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/chtounicode.html\">unicode编码转换器</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/subnet_mask.html\">子网掩码计算器</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/base64.html\">BASE64编码解码</a></p>\n</li>\n<li><p><a href=\"https://sm.ms/\">图床 https://sm.ms/</a></p>\n</li>\n<li><p><a href=\"http://tool.chinaz.com/Tools/unixtime.aspx\">Unix 时间戳 Unix timestamp</a></p>\n</li>\n<li><p><a href=\"https://regex101.com/\">在线正则表达式匹配</a></p>\n</li>\n<li><p><a href=\"http://regexr.com/\">http://regexr.com/</a></p>\n</li>\n<li><p><a href=\"https://www.json.cn/\">json在线解析</a></p>\n</li>\n<li><p><a href=\"https://fonts.google.com/\">google fonts</a></p>\n</li>\n<li><p><a href=\"https://fengmk2.com/blog/2016/google-fonts-mirror\">Google Fonts 加速代理</a></p>\n</li>\n<li><p><a href=\"http://www.pool.ntp.org/\">时间服务器</a></p>\n</li>\n<li><p><a href=\"http://www.newjson.com/Static/Tools/Diff.html\">在线文件对比工具</a></p>\n</li>\n<li><p><a href=\"https://pandao.github.io/editor.md/\">在线markdown1</a></p>\n</li>\n<li><p><a href=\"https://www.zybuluo.com/mdeditor\">在线markdown2</a></p>\n</li>\n<li><p><a href=\"http://grokdebug.herokuapp.com/\">grokdebug</a></p>\n</li>\n</ul>\n<h3 id=\"网站\"><a href=\"#网站\" class=\"headerlink\" title=\"网站\"></a>网站</h3><ul>\n<li><p><a href=\"http://tools.pingdom.com/fpt\">在线网站速度检测工具</a></p>\n</li>\n<li><p><a href=\"https://www.dareboost.com/\">在线网站优化测试平台</a></p>\n</li>\n<li><p><a href=\"http://www.urlvoid.com/\">在线网站安全检测工具</a></p>\n</li>\n<li><p><a href=\"http://www.woorank.com/\">网站SEO检测免费应用平台</a></p>\n</li>\n</ul>\n<h2 id=\"运维工具\"><a href=\"#运维工具\" class=\"headerlink\" title=\"运维工具\"></a>运维工具</h2><h3 id=\"shell连接\"><a href=\"#shell连接\" class=\"headerlink\" title=\"shell连接\"></a>shell连接</h3><ul>\n<li><p><a href=\"https://www.vandyke.com/products/securecrt/index.html\">securecrt</a></p>\n</li>\n<li><p><a href=\"https://www.netsarang.com/products/xsh_overview.html\">xshell</a></p>\n</li>\n</ul>\n<h3 id=\"文件对比\"><a href=\"#文件对比\" class=\"headerlink\" title=\"文件对比\"></a>文件对比</h3><ul>\n<li><a href=\"http://www.scootersoftware.com/download.php\">Beyond</a></li>\n</ul>\n<h3 id=\"文件查找\"><a href=\"#文件查找\" class=\"headerlink\" title=\"文件查找\"></a>文件查找</h3><ul>\n<li><a href=\"https://www.voidtools.com/\">Everying</a></li>\n</ul>\n<h3 id=\"文件去重\"><a href=\"#文件去重\" class=\"headerlink\" title=\"文件去重\"></a>文件去重</h3><ul>\n<li><a href=\"https://www.duplicatecleaner.com/\">https://www.duplicatecleaner.com/</a></li>\n</ul>\n<h3 id=\"代码编辑器\"><a href=\"#代码编辑器\" class=\"headerlink\" title=\"代码编辑器\"></a>代码编辑器</h3><ul>\n<li><a href=\"https://www.jetbrains.com/\">jetbrains</a></li>\n</ul>\n<h3 id=\"密码管理\"><a href=\"#密码管理\" class=\"headerlink\" title=\"密码管理\"></a>密码管理</h3><ul>\n<li><p><a href=\"https://keepass.info/\">keepass</a></p>\n</li>\n<li><p><a href=\"https://keepass.info/translations.html\">keepass中文</a></p>\n</li>\n</ul>\n<h3 id=\"文件编辑器\"><a href=\"#文件编辑器\" class=\"headerlink\" title=\"文件编辑器\"></a>文件编辑器</h3><ul>\n<li><p><a href=\"https://notepad-plus-plus.org/\">notepad++</a></p>\n</li>\n<li><p><a href=\"https://www.emeditor.com/\">emeditor</a></p>\n</li>\n<li><p><a href=\"https://www.sublimetext.com/\">sublimetext</a></p>\n</li>\n</ul>\n<h3 id=\"笔记记录\"><a href=\"#笔记记录\" class=\"headerlink\" title=\"笔记记录\"></a>笔记记录</h3><ul>\n<li><a href=\"https://www.giuspen.com/cherrytree/#downl\">cherrytree</a></li>\n</ul>\n<h3 id=\"host切换\"><a href=\"#host切换\" class=\"headerlink\" title=\"host切换\"></a>host切换</h3><ul>\n<li><a href=\"https://github.com/oldj/SwitchHosts/releases\">SwitchHosts</a></li>\n</ul>\n<h3 id=\"虚拟机\"><a href=\"#虚拟机\" class=\"headerlink\" title=\"虚拟机\"></a>虚拟机</h3><ul>\n<li><a href=\"https://my.vmware.com/group/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/14_0\">vmware</a></li>\n</ul>\n<p>VMware 2018 v14.x 永久许可证激活密钥</p>\n<ul>\n<li>FF31K-AHZD1-H8ETZ-8WWEZ-WUUVA</li>\n<li>CV7T2-6WY5Q-48EWP-ZXY7X-QGUWD</li>\n</ul>\n<h2 id=\"windos工具\"><a href=\"#windos工具\" class=\"headerlink\" title=\"windos工具\"></a>windos工具</h2><h3 id=\"编辑\"><a href=\"#编辑\" class=\"headerlink\" title=\"编辑\"></a>编辑</h3><ul>\n<li><p><a href=\"http://www.markdownpad.com/\">MarkdownPad</a></p>\n</li>\n<li><p><a href=\"http://code52.org/DownmarkerWPF/\">MarkPad</a></p>\n</li>\n<li><p><a href=\"https://notepad-plus-plus.org/\">notepad++</a></p>\n</li>\n<li><p><a href=\"https://www.sublimetext.com/\">sublimetext</a></p>\n</li>\n</ul>\n<h3 id=\"浏览器\"><a href=\"#浏览器\" class=\"headerlink\" title=\"浏览器\"></a>浏览器</h3><ul>\n<li><p><a href=\"https://www.google.cn/chrome/index.html\">Google</a></p>\n</li>\n<li><p><a href=\"https://www.chrome64bit.com/\">Google离线版</a></p>\n</li>\n<li><p><a href=\"https://www.firefox.com.cn/\">Firefox</a></p>\n</li>\n</ul>\n<h3 id=\"压缩工具\"><a href=\"#压缩工具\" class=\"headerlink\" title=\"压缩工具\"></a>压缩工具</h3><ul>\n<li><a href=\"https://www.7-zip.org/download.html\">7zip</a></li>\n</ul>\n<h3 id=\"代码管理\"><a href=\"#代码管理\" class=\"headerlink\" title=\"代码管理\"></a>代码管理</h3><ul>\n<li><a href=\"https://tortoisesvn.net/\">svn</a></li>\n<li><a href=\"https://git-scm.com/\">git</a></li>\n</ul>\n<h2 id=\"软件下载\"><a href=\"#软件下载\" class=\"headerlink\" title=\"软件下载\"></a>软件下载</h2><ul>\n<li><p><a href=\"https://www.softpedia.com/\">softpedia</a></p>\n</li>\n<li><p><a href=\"https://www.nirsoft.net/\">nirsoft</a></p>\n</li>\n<li><p><a href=\"https://www.lo4d.com/\">lo4d</a></p>\n</li>\n</ul>\n<h2 id=\"GitBook-及其插件\"><a href=\"#GitBook-及其插件\" class=\"headerlink\" title=\"GitBook 及其插件\"></a>GitBook 及其插件</h2><ul>\n<li><p><a href=\"http://zhaoda.net/2015/11/09/gitbook-plugins/\">Gitbook 的使用和常用插件 -赵达</a></p>\n</li>\n<li><p><a href=\"https://plugins.gitbook.com/plugin/expandable-chapters\">gitbook-plugin-expandable-chapters</a></p>\n<p>  折叠左侧目录章节。</p>\n  <!-- ![](http://ww4.sinaimg.cn/large/7011d6cfjw1f08kmplbj1j20gn05l0tk.jpg) -->\n\n</li>\n</ul>\n<h2 id=\"Chrome-插件\"><a href=\"#Chrome-插件\" class=\"headerlink\" title=\"Chrome 插件\"></a>Chrome 插件</h2><ul>\n<li><p><a href=\"https://chrome.google.com/webstore/detail/octotree/bkhaagjahfmjljalopjnoealnfndnagc\">Octotree</a></p>\n<ul>\n<li>Code tree for GitHub and GitLab</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><a href=\"http://www.ituring.com.cn/minibook/950\">Chrome扩展及应用开发 -图灵电子书</a></p>\n</li>\n<li><p><a href=\"https://www.zhihu.com/question/23228162#answer-28057391\">有哪些鲜为人知却非常有意思、好用的 Chrome 扩展？ -知乎</a></p>\n</li>\n<li><p><a href=\"https://chrome.google.com/webstore/detail/dribbble-new-tab/hmhjbefkpednjogghoibpejdmemkinbn\">Dribbble New Tab</a></p>\n<p>  新建 tab 时，显示 dribbble 上的精选作品。</p>\n</li>\n</ul>\n<h2 id=\"Other-blogs\"><a href=\"#Other-blogs\" class=\"headerlink\" title=\"Other blogs\"></a>Other blogs</h2><ul>\n<li><a href=\"http://www.xiaoa.name/\">COLORFUL xiaoa</a></li>\n</ul>\n<ul>\n<li><p><a href=\"http://pinkyjie.com/\">进击的马斯特 http://pinkyjie.com/</a></p>\n<p>  马斯特，87年生人，爱溜冰的码农。技术： Javascript、Python、Mac、iOS</p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"坚若磐石","url":"blog.linuxnb.com","title":"访问主页","introduction":"我们一直想学会平静，其实吧，这事儿不用学，经历的多了，就平静了。","avatar":"https://blog.linuxnb.com/favicon.ico"},{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}],"musics":[{"name":"两个世界","artist":"杨小壮","url":"/medias/music/两个世界.mp3","cover":"/medias/music/avatars/daoshu.jpg"},{"name":"then silence","artist":"Kjartan Salvesen","url":"/medias/music/then-silence.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"在线工具\"><a href=\"#在线工具\" class=\"headerlink\" title=\"在线工具\"></a>在线工具</h2><ul>\n<li><p><a href=\"http://tool.chinaz.com/\">站长工具</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/Byte_calculate.html\">字节换算</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/chtounicode.html\">unicode编码转换器</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/subnet_mask.html\">子网掩码计算器</a></p>\n</li>\n<li><p><a href=\"http://www.bangnishouji.com/tools/base64.html\">BASE64编码解码</a></p>\n</li>\n<li><p><a href=\"https://sm.ms/\">图床 https://sm.ms/</a></p>\n</li>\n<li><p><a href=\"http://tool.chinaz.com/Tools/unixtime.aspx\">Unix 时间戳 Unix timestamp</a></p>\n</li>\n<li><p><a href=\"https://regex101.com/\">在线正则表达式匹配</a></p>\n</li>\n<li><p><a href=\"http://regexr.com/\">http://regexr.com/</a></p>\n</li>\n<li><p><a href=\"https://www.json.cn/\">json在线解析</a></p>\n</li>\n<li><p><a href=\"https://fonts.google.com/\">google fonts</a></p>\n</li>\n<li><p><a href=\"https://fengmk2.com/blog/2016/google-fonts-mirror\">Google Fonts 加速代理</a></p>\n</li>\n<li><p><a href=\"http://www.pool.ntp.org/\">时间服务器</a></p>\n</li>\n<li><p><a href=\"http://www.newjson.com/Static/Tools/Diff.html\">在线文件对比工具</a></p>\n</li>\n<li><p><a href=\"https://pandao.github.io/editor.md/\">在线markdown1</a></p>\n</li>\n<li><p><a href=\"https://www.zybuluo.com/mdeditor\">在线markdown2</a></p>\n</li>\n<li><p><a href=\"http://grokdebug.herokuapp.com/\">grokdebug</a></p>\n</li>\n</ul>\n<h3 id=\"网站\"><a href=\"#网站\" class=\"headerlink\" title=\"网站\"></a>网站</h3><ul>\n<li><p><a href=\"http://tools.pingdom.com/fpt\">在线网站速度检测工具</a></p>\n</li>\n<li><p><a href=\"https://www.dareboost.com/\">在线网站优化测试平台</a></p>\n</li>\n<li><p><a href=\"http://www.urlvoid.com/\">在线网站安全检测工具</a></p>\n</li>\n<li><p><a href=\"http://www.woorank.com/\">网站SEO检测免费应用平台</a></p>\n</li>\n</ul>\n<h2 id=\"运维工具\"><a href=\"#运维工具\" class=\"headerlink\" title=\"运维工具\"></a>运维工具</h2><h3 id=\"shell连接\"><a href=\"#shell连接\" class=\"headerlink\" title=\"shell连接\"></a>shell连接</h3><ul>\n<li><p><a href=\"https://www.vandyke.com/products/securecrt/index.html\">securecrt</a></p>\n</li>\n<li><p><a href=\"https://www.netsarang.com/products/xsh_overview.html\">xshell</a></p>\n</li>\n</ul>\n<h3 id=\"文件对比\"><a href=\"#文件对比\" class=\"headerlink\" title=\"文件对比\"></a>文件对比</h3><ul>\n<li><a href=\"http://www.scootersoftware.com/download.php\">Beyond</a></li>\n</ul>\n<h3 id=\"文件查找\"><a href=\"#文件查找\" class=\"headerlink\" title=\"文件查找\"></a>文件查找</h3><ul>\n<li><a href=\"https://www.voidtools.com/\">Everying</a></li>\n</ul>\n<h3 id=\"文件去重\"><a href=\"#文件去重\" class=\"headerlink\" title=\"文件去重\"></a>文件去重</h3><ul>\n<li><a href=\"https://www.duplicatecleaner.com/\">https://www.duplicatecleaner.com/</a></li>\n</ul>\n<h3 id=\"代码编辑器\"><a href=\"#代码编辑器\" class=\"headerlink\" title=\"代码编辑器\"></a>代码编辑器</h3><ul>\n<li><a href=\"https://www.jetbrains.com/\">jetbrains</a></li>\n</ul>\n<h3 id=\"密码管理\"><a href=\"#密码管理\" class=\"headerlink\" title=\"密码管理\"></a>密码管理</h3><ul>\n<li><p><a href=\"https://keepass.info/\">keepass</a></p>\n</li>\n<li><p><a href=\"https://keepass.info/translations.html\">keepass中文</a></p>\n</li>\n</ul>\n<h3 id=\"文件编辑器\"><a href=\"#文件编辑器\" class=\"headerlink\" title=\"文件编辑器\"></a>文件编辑器</h3><ul>\n<li><p><a href=\"https://notepad-plus-plus.org/\">notepad++</a></p>\n</li>\n<li><p><a href=\"https://www.emeditor.com/\">emeditor</a></p>\n</li>\n<li><p><a href=\"https://www.sublimetext.com/\">sublimetext</a></p>\n</li>\n</ul>\n<h3 id=\"笔记记录\"><a href=\"#笔记记录\" class=\"headerlink\" title=\"笔记记录\"></a>笔记记录</h3><ul>\n<li><a href=\"https://www.giuspen.com/cherrytree/#downl\">cherrytree</a></li>\n</ul>\n<h3 id=\"host切换\"><a href=\"#host切换\" class=\"headerlink\" title=\"host切换\"></a>host切换</h3><ul>\n<li><a href=\"https://github.com/oldj/SwitchHosts/releases\">SwitchHosts</a></li>\n</ul>\n<h3 id=\"虚拟机\"><a href=\"#虚拟机\" class=\"headerlink\" title=\"虚拟机\"></a>虚拟机</h3><ul>\n<li><a href=\"https://my.vmware.com/group/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/14_0\">vmware</a></li>\n</ul>\n<p>VMware 2018 v14.x 永久许可证激活密钥</p>\n<ul>\n<li>FF31K-AHZD1-H8ETZ-8WWEZ-WUUVA</li>\n<li>CV7T2-6WY5Q-48EWP-ZXY7X-QGUWD</li>\n</ul>\n<h2 id=\"windos工具\"><a href=\"#windos工具\" class=\"headerlink\" title=\"windos工具\"></a>windos工具</h2><h3 id=\"编辑\"><a href=\"#编辑\" class=\"headerlink\" title=\"编辑\"></a>编辑</h3><ul>\n<li><p><a href=\"http://www.markdownpad.com/\">MarkdownPad</a></p>\n</li>\n<li><p><a href=\"http://code52.org/DownmarkerWPF/\">MarkPad</a></p>\n</li>\n<li><p><a href=\"https://notepad-plus-plus.org/\">notepad++</a></p>\n</li>\n<li><p><a href=\"https://www.sublimetext.com/\">sublimetext</a></p>\n</li>\n</ul>\n<h3 id=\"浏览器\"><a href=\"#浏览器\" class=\"headerlink\" title=\"浏览器\"></a>浏览器</h3><ul>\n<li><p><a href=\"https://www.google.cn/chrome/index.html\">Google</a></p>\n</li>\n<li><p><a href=\"https://www.chrome64bit.com/\">Google离线版</a></p>\n</li>\n<li><p><a href=\"https://www.firefox.com.cn/\">Firefox</a></p>\n</li>\n</ul>\n<h3 id=\"压缩工具\"><a href=\"#压缩工具\" class=\"headerlink\" title=\"压缩工具\"></a>压缩工具</h3><ul>\n<li><a href=\"https://www.7-zip.org/download.html\">7zip</a></li>\n</ul>\n<h3 id=\"代码管理\"><a href=\"#代码管理\" class=\"headerlink\" title=\"代码管理\"></a>代码管理</h3><ul>\n<li><a href=\"https://tortoisesvn.net/\">svn</a></li>\n<li><a href=\"https://git-scm.com/\">git</a></li>\n</ul>\n<h2 id=\"软件下载\"><a href=\"#软件下载\" class=\"headerlink\" title=\"软件下载\"></a>软件下载</h2><ul>\n<li><p><a href=\"https://www.softpedia.com/\">softpedia</a></p>\n</li>\n<li><p><a href=\"https://www.nirsoft.net/\">nirsoft</a></p>\n</li>\n<li><p><a href=\"https://www.lo4d.com/\">lo4d</a></p>\n</li>\n</ul>\n<h2 id=\"GitBook-及其插件\"><a href=\"#GitBook-及其插件\" class=\"headerlink\" title=\"GitBook 及其插件\"></a>GitBook 及其插件</h2><ul>\n<li><p><a href=\"http://zhaoda.net/2015/11/09/gitbook-plugins/\">Gitbook 的使用和常用插件 -赵达</a></p>\n</li>\n<li><p><a href=\"https://plugins.gitbook.com/plugin/expandable-chapters\">gitbook-plugin-expandable-chapters</a></p>\n<p>  折叠左侧目录章节。</p>\n  <!-- ![](http://ww4.sinaimg.cn/large/7011d6cfjw1f08kmplbj1j20gn05l0tk.jpg) -->\n\n</li>\n</ul>\n<h2 id=\"Chrome-插件\"><a href=\"#Chrome-插件\" class=\"headerlink\" title=\"Chrome 插件\"></a>Chrome 插件</h2><ul>\n<li><p><a href=\"https://chrome.google.com/webstore/detail/octotree/bkhaagjahfmjljalopjnoealnfndnagc\">Octotree</a></p>\n<ul>\n<li>Code tree for GitHub and GitLab</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><a href=\"http://www.ituring.com.cn/minibook/950\">Chrome扩展及应用开发 -图灵电子书</a></p>\n</li>\n<li><p><a href=\"https://www.zhihu.com/question/23228162#answer-28057391\">有哪些鲜为人知却非常有意思、好用的 Chrome 扩展？ -知乎</a></p>\n</li>\n<li><p><a href=\"https://chrome.google.com/webstore/detail/dribbble-new-tab/hmhjbefkpednjogghoibpejdmemkinbn\">Dribbble New Tab</a></p>\n<p>  新建 tab 时，显示 dribbble 上的精选作品。</p>\n</li>\n</ul>\n<h2 id=\"Other-blogs\"><a href=\"#Other-blogs\" class=\"headerlink\" title=\"Other blogs\"></a>Other blogs</h2><ul>\n<li><a href=\"http://www.xiaoa.name/\">COLORFUL xiaoa</a></li>\n</ul>\n<ul>\n<li><p><a href=\"http://pinkyjie.com/\">进击的马斯特 http://pinkyjie.com/</a></p>\n<p>  马斯特，87年生人，爱溜冰的码农。技术： Javascript、Python、Mac、iOS</p>\n</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckm1fhpzd0001yc976z9ae6qc","category_id":"ckm1fhpzj0004yc977scudire","_id":"ckm1fhpzu000iyc97gdeq3syu"},{"post_id":"ckm1fhpzs000fyc9783uyb66w","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhpzz000oyc970q4lbh3s"},{"post_id":"ckm1fhpzh0003yc97gqbq150z","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq02000tyc977w9u9vvo"},{"post_id":"ckm1fhpzt000hyc97bldc6inl","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq03000wyc97ax0gdjbf"},{"post_id":"ckm1fhpzx000lyc97hq6y0bj7","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq050010yc97efpx3grv"},{"post_id":"ckm1fhpzm0007yc977l5mgsrc","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq060013yc974aq51ikv"},{"post_id":"ckm1fhpzy000nyc970xljemh7","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq070015yc97edh7d6si"},{"post_id":"ckm1fhq00000syc976fpidww1","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq080019yc973dmv193s"},{"post_id":"ckm1fhpzo0009yc9753udhc05","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0a001byc97hvqqdzyc"},{"post_id":"ckm1fhq03000vyc976rlvcz6f","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0c001fyc972wo0ehpq"},{"post_id":"ckm1fhq04000zyc971c1745wn","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0d001iyc97gve21l2e"},{"post_id":"ckm1fhpzp000byc975elc2a8b","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0e001myc979qxhatq0"},{"post_id":"ckm1fhq050012yc97bfg04ddz","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0g001qyc97878i8dye"},{"post_id":"ckm1fhq060014yc97glu50axg","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0h001tyc97bv4r74cs"},{"post_id":"ckm1fhq080018yc97ck6p9dhj","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0i001wyc97b46c17h2"},{"post_id":"ckm1fhq0a001ayc979ahndp4q","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0k001yyc97h2y3gbfa"},{"post_id":"ckm1fhq0b001eyc975ud51z2y","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0l0022yc97bj7w4s1x"},{"post_id":"ckm1fhq0e001lyc97dl1r1hqt","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0m0024yc979jru8ofc"},{"post_id":"ckm1fhq0f001pyc97hilv3vxh","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0n0028yc97dt836a5a"},{"post_id":"ckm1fhq0g001syc970u8seiuy","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0o002ayc97c20c83j0"},{"post_id":"ckm1fhq0c001hyc97g9nf0fqz","category_id":"ckm1fhq0f001nyc97094cel4u","_id":"ckm1fhq0q002eyc976u9a5y4e"},{"post_id":"ckm1fhq0i001vyc9722087wdx","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0r002hyc97f05ph3wi"},{"post_id":"ckm1fhq0j001xyc97d1c6fapv","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0s002lyc97376ragz8"},{"post_id":"ckm1fhq0k0021yc974qw78nex","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0u002pyc9744la6hn8"},{"post_id":"ckm1fhq0l0023yc970re7b3eb","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0v002tyc97ab3hgxxv"},{"post_id":"ckm1fhq0n0027yc97haes0eod","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq0z002xyc97dyzshw67"},{"post_id":"ckm1fhq0o0029yc975bz1fcie","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq100031yc97864xg47h"},{"post_id":"ckm1fhq0p002dyc9749r9fw5y","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq110034yc970ebz1b1j"},{"post_id":"ckm1fhq0t002oyc97hk1de1m7","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq130038yc97aontd8a4"},{"post_id":"ckm1fhq0u002syc97d9n5g4e5","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq14003byc97hco73zfe"},{"post_id":"ckm1fhq0q002gyc9740jz5vst","category_id":"ckm1fhq0t002myc97hxhwbr1s","_id":"ckm1fhq14003dyc977di3bpi2"},{"post_id":"ckm1fhq0v002vyc975dl2g7ud","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq14003gyc9737tddk9l"},{"post_id":"ckm1fhq100030yc97bv00hbit","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq15003iyc97e835brw1"},{"post_id":"ckm1fhq0r002kyc972jnmgvdb","category_id":"ckm1fhq0t002myc97hxhwbr1s","_id":"ckm1fhq15003lyc973e4c30br"},{"post_id":"ckm1fhq110033yc974xbk02cr","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq15003nyc97c2e17hkk"},{"post_id":"ckm1fhq120037yc978hu3bcec","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq16003qyc97bbva5f17"},{"post_id":"ckm1fhq13003ayc972r0dh6vn","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq16003syc973smsf50a"},{"post_id":"ckm1fhq1t0049yc97c1na5i76","category_id":"ckm1fhq1v004byc978uke14fl","_id":"ckm1fhq1z004kyc97395e5vt3"},{"post_id":"ckm1fhq1x004fyc9704a52a6e","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq20004myc977rhy5vrn"},{"post_id":"ckm1fhq1x004hyc97hykh95re","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq22004pyc979bh37v35"},{"post_id":"ckm1fhq20004lyc973n7n4mew","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq24004tyc979r7nhjhq"},{"post_id":"ckm1fhq21004nyc97gin9febt","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq25004vyc9797yz5999"},{"post_id":"ckm1fhq22004ryc97ecpt2u72","category_id":"ckm1fhpzq000cyc974xl33cki","_id":"ckm1fhq25004xyc97513ocb52"}],"PostTag":[{"post_id":"ckm1fhpzd0001yc976z9ae6qc","tag_id":"ckm1fhpzk0005yc970o2e5srb","_id":"ckm1fhpzx000myc97evsqcedn"},{"post_id":"ckm1fhpzd0001yc976z9ae6qc","tag_id":"ckm1fhpzq000dyc97h8gld550","_id":"ckm1fhpzz000pyc97f59t0eip"},{"post_id":"ckm1fhpzh0003yc97gqbq150z","tag_id":"ckm1fhpzv000kyc975mye735b","_id":"ckm1fhq03000uyc970zyp1xxj"},{"post_id":"ckm1fhpzm0007yc977l5mgsrc","tag_id":"ckm1fhpzz000ryc976sn340hc","_id":"ckm1fhq050011yc97efm49wiw"},{"post_id":"ckm1fhpzo0009yc9753udhc05","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq080017yc97c98c3wy4"},{"post_id":"ckm1fhq080018yc97ck6p9dhj","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0b001dyc97f5fe764t"},{"post_id":"ckm1fhpzp000byc975elc2a8b","tag_id":"ckm1fhq070016yc97614517p0","_id":"ckm1fhq0c001gyc97exqa8yh8"},{"post_id":"ckm1fhq0b001eyc975ud51z2y","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0d001kyc97ec5ddg6j"},{"post_id":"ckm1fhpzs000fyc9783uyb66w","tag_id":"ckm1fhq0b001cyc97hcyxaa9q","_id":"ckm1fhq0f001oyc97d1pq2unu"},{"post_id":"ckm1fhpzt000hyc97bldc6inl","tag_id":"ckm1fhq0d001jyc97br1x2n7g","_id":"ckm1fhq0h001uyc970ewsgulc"},{"post_id":"ckm1fhpzx000lyc97hq6y0bj7","tag_id":"ckm1fhq0g001ryc978zhn5m68","_id":"ckm1fhq0k0020yc97bdi9g3jp"},{"post_id":"ckm1fhpzy000nyc970xljemh7","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0m0026yc973k80dols"},{"post_id":"ckm1fhq0n0027yc97haes0eod","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0p002cyc970lvr7wlm"},{"post_id":"ckm1fhq00000syc976fpidww1","tag_id":"ckm1fhq0m0025yc97fzme2wch","_id":"ckm1fhq0q002fyc97bf7d8kw9"},{"post_id":"ckm1fhq0o0029yc975bz1fcie","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0r002jyc975i4k96gk"},{"post_id":"ckm1fhq0p002dyc9749r9fw5y","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0t002nyc97f4haap8t"},{"post_id":"ckm1fhq03000vyc976rlvcz6f","tag_id":"ckm1fhq0m0025yc97fzme2wch","_id":"ckm1fhq0u002ryc974sa3bqs5"},{"post_id":"ckm1fhq04000zyc971c1745wn","tag_id":"ckm1fhq0m0025yc97fzme2wch","_id":"ckm1fhq0v002uyc978e2b258b"},{"post_id":"ckm1fhq0t002oyc97hk1de1m7","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq0z002zyc97dkmqgx49"},{"post_id":"ckm1fhq0u002syc97d9n5g4e5","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq110032yc97dtqkfdr4"},{"post_id":"ckm1fhq050012yc97bfg04ddz","tag_id":"ckm1fhq0u002qyc97a7wp6msu","_id":"ckm1fhq120035yc970dy5ck35"},{"post_id":"ckm1fhq0v002vyc975dl2g7ud","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq130039yc97eq9hhobe"},{"post_id":"ckm1fhq100030yc97bv00hbit","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq14003cyc976ogb0ccz"},{"post_id":"ckm1fhq060014yc97glu50axg","tag_id":"ckm1fhq0z002yyc97h88mcerb","_id":"ckm1fhq14003fyc9747xqfhrx"},{"post_id":"ckm1fhq110033yc974xbk02cr","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq15003hyc9748mh9rlz"},{"post_id":"ckm1fhq120037yc978hu3bcec","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq15003kyc97grqx60hz"},{"post_id":"ckm1fhq13003ayc972r0dh6vn","tag_id":"ckm1fhq04000yyc97gkj4eqhd","_id":"ckm1fhq15003myc97f3mufhbu"},{"post_id":"ckm1fhq0a001ayc979ahndp4q","tag_id":"ckm1fhq120036yc97ce8a5jx5","_id":"ckm1fhq15003pyc972lsf230k"},{"post_id":"ckm1fhq0c001hyc97g9nf0fqz","tag_id":"ckm1fhq14003eyc973zc54ps4","_id":"ckm1fhq16003ryc97bz8ecujw"},{"post_id":"ckm1fhq0e001lyc97dl1r1hqt","tag_id":"ckm1fhq15003jyc97hmakfzq8","_id":"ckm1fhq16003uyc97ckhadu44"},{"post_id":"ckm1fhq0f001pyc97hilv3vxh","tag_id":"ckm1fhq15003jyc97hmakfzq8","_id":"ckm1fhq16003vyc97dnucduxz"},{"post_id":"ckm1fhq0g001syc970u8seiuy","tag_id":"ckm1fhq15003jyc97hmakfzq8","_id":"ckm1fhq17003xyc972nnc75ir"},{"post_id":"ckm1fhq0i001vyc9722087wdx","tag_id":"ckm1fhq15003jyc97hmakfzq8","_id":"ckm1fhq18003zyc977sla14oc"},{"post_id":"ckm1fhq0j001xyc97d1c6fapv","tag_id":"ckm1fhq17003yyc97eqtaa0eg","_id":"ckm1fhq190041yc97gm5b3kuw"},{"post_id":"ckm1fhq0k0021yc974qw78nex","tag_id":"ckm1fhq190040yc97e8vs7s6n","_id":"ckm1fhq1a0043yc975m7bbv7p"},{"post_id":"ckm1fhq0l0023yc970re7b3eb","tag_id":"ckm1fhq190042yc9756wu0egs","_id":"ckm1fhq1a0045yc977oav201w"},{"post_id":"ckm1fhq0q002gyc9740jz5vst","tag_id":"ckm1fhq1a0044yc97exwf3fcp","_id":"ckm1fhq1a0047yc97a0yy5iq3"},{"post_id":"ckm1fhq0r002kyc972jnmgvdb","tag_id":"ckm1fhq1a0044yc97exwf3fcp","_id":"ckm1fhq1a0048yc977owd8c2z"},{"post_id":"ckm1fhq1t0049yc97c1na5i76","tag_id":"ckm1fhq1v004cyc976huxc99c","_id":"ckm1fhq1x004gyc97fn7n0875"},{"post_id":"ckm1fhq1x004fyc9704a52a6e","tag_id":"ckm1fhq1y004iyc974rxpgior","_id":"ckm1fhq22004qyc97f09phun9"},{"post_id":"ckm1fhq1x004hyc97hykh95re","tag_id":"ckm1fhq21004oyc97cyeybmx8","_id":"ckm1fhq25004wyc973p4s7vsu"},{"post_id":"ckm1fhq20004lyc973n7n4mew","tag_id":"ckm1fhq24004uyc973zub0gpu","_id":"ckm1fhq26004zyc972vlf1he0"},{"post_id":"ckm1fhq21004nyc97gin9febt","tag_id":"ckm1fhq21004oyc97cyeybmx8","_id":"ckm1fhq260051yc979rgl4abm"},{"post_id":"ckm1fhq22004ryc97ecpt2u72","tag_id":"ckm1fhq260050yc9780z92mjc","_id":"ckm1fhq260052yc97gdapgyue"}],"Tag":[{"name":"日志分析","_id":"ckm1fhpzk0005yc970o2e5srb"},{"name":"nginx","_id":"ckm1fhpzq000dyc97h8gld550"},{"name":"prometheus snmp 监控","_id":"ckm1fhpzv000kyc975mye735b"},{"name":"linux 监控 metricbeat","_id":"ckm1fhpzz000ryc976sn340hc"},{"name":"linux","_id":"ckm1fhq04000yyc97gkj4eqhd"},{"name":"lucene ELK kibana","_id":"ckm1fhq070016yc97614517p0"},{"name":"nginx pika cache","_id":"ckm1fhq0b001cyc97hcyxaa9q"},{"name":"linux ssh","_id":"ckm1fhq0d001jyc97br1x2n7g"},{"name":"linux ansible 自动化","_id":"ckm1fhq0g001ryc978zhn5m68"},{"name":"linux  ELK","_id":"ckm1fhq0m0025yc97fzme2wch"},{"name":"linux  telegraf infludb granfan","_id":"ckm1fhq0u002qyc97a7wp6msu"},{"name":"linux  git","_id":"ckm1fhq0z002yyc97h88mcerb"},{"name":"linux  convirt","_id":"ckm1fhq120036yc97ce8a5jx5"},{"name":"生活","_id":"ckm1fhq14003eyc973zc54ps4"},{"name":"fastdfs","_id":"ckm1fhq15003jyc97hmakfzq8"},{"name":"mysql","_id":"ckm1fhq17003yyc97eqtaa0eg"},{"name":"CDH","_id":"ckm1fhq190040yc97e8vs7s6n"},{"name":"https","_id":"ckm1fhq190042yc9756wu0egs"},{"name":"linux  docker","_id":"ckm1fhq1a0044yc97exwf3fcp"},{"name":"博客","_id":"ckm1fhq1v004cyc976huxc99c"},{"name":"系统调优","_id":"ckm1fhq1y004iyc974rxpgior"},{"name":"学习方法","_id":"ckm1fhq21004oyc97cyeybmx8"},{"name":"lnmp","_id":"ckm1fhq24004uyc973zub0gpu"},{"name":"运维工具","_id":"ckm1fhq260050yc9780z92mjc"}]}}